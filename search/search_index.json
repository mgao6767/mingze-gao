{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"A Random Walk Away Finance. \u00b6 I\u2019m Mingze Gao , aka Adrian . Finance PhD candidate, research assistant and tutor at the University of Sydney. Research interests: corporate finance, banking, market microcstructure. Authored the Python package frds - financial research data services . Programmed also the Interactive Option Pricing and LeGao - Make LEGO Mosaics . Contact Email: mingze.gao@sydney.edu.au Room 236E, Postgraduate Research Centre The Codrington Building (H69) The University of Sydney NSW 2006 var ctx = document.getElementById('site-stats'); var config = { type: 'line', data: { labels: [], datasets: [{ label: 'Site Visits', data: [], backgroundColor: 'rgba(0, 136, 255, 0.4)', borderColor: 'rgba(0, 136, 255, 0.8)' }, { label: 'Visitors', data: [], }] }, options: { responsive: true, legend: { display: true }, title: { display: true, fontFamily: 'Roboto', text: '30-Day Site Statistics', }, animation: {duration:1500}, scales: { yAxes: [{ ticks: { beginAtZero: true } }] } } }; var myChart = new Chart(ctx, config); (function(w,d,s,g,js,fs){ g=w.gapi||(w.gapi={});g.analytics={q:[],ready:function(f){this.q.push(f);}}; js=d.createElement(s);fs=d.getElementsByTagName(s)[0]; js.src='https://apis.google.com/js/platform.js'; fs.parentNode.insertBefore(js,fs);js.onload=function(){g.load('analytics');}; }(window,document,'script')); gapi.analytics.ready(function () { fetch('https://api.adrian-gao.com/ga/access_token') .then(response => response.json()) .then(tokenInfo => { gapi.analytics.auth.authorize({ 'serverAuth': { 'access_token': tokenInfo.token } }); var report = new gapi.analytics.report.Data({ query: { 'ids': 'ga:169685330', 'start-date': '30daysAgo', 'end-date': 'yesterday', 'metrics': 'ga:sessions,ga:users', 'dimensions': 'ga:date' } }); report.on('success', function (resp) { resp.rows.forEach(element => { var year = element[0].substring(0, 4); var month = element[0].substring(4, 6); var day = element[0].substring(6, 8); var date = new Date(year, month - 1, day) config.data.labels.push(date.toDateString().substring(4, 10)); config.data.datasets[0].data.push( element[1] ); config.data.datasets[1].data.push( element[2] ); }); myChart.destroy(); myChart = new Chart(ctx, config); }); report.execute(); }) });","title":"Home"},{"location":"#a-random-walk-away-finance","text":"I\u2019m Mingze Gao , aka Adrian . Finance PhD candidate, research assistant and tutor at the University of Sydney. Research interests: corporate finance, banking, market microcstructure. Authored the Python package frds - financial research data services . Programmed also the Interactive Option Pricing and LeGao - Make LEGO Mosaics . Contact Email: mingze.gao@sydney.edu.au Room 236E, Postgraduate Research Centre The Codrington Building (H69) The University of Sydney NSW 2006 var ctx = document.getElementById('site-stats'); var config = { type: 'line', data: { labels: [], datasets: [{ label: 'Site Visits', data: [], backgroundColor: 'rgba(0, 136, 255, 0.4)', borderColor: 'rgba(0, 136, 255, 0.8)' }, { label: 'Visitors', data: [], }] }, options: { responsive: true, legend: { display: true }, title: { display: true, fontFamily: 'Roboto', text: '30-Day Site Statistics', }, animation: {duration:1500}, scales: { yAxes: [{ ticks: { beginAtZero: true } }] } } }; var myChart = new Chart(ctx, config); (function(w,d,s,g,js,fs){ g=w.gapi||(w.gapi={});g.analytics={q:[],ready:function(f){this.q.push(f);}}; js=d.createElement(s);fs=d.getElementsByTagName(s)[0]; js.src='https://apis.google.com/js/platform.js'; fs.parentNode.insertBefore(js,fs);js.onload=function(){g.load('analytics');}; }(window,document,'script')); gapi.analytics.ready(function () { fetch('https://api.adrian-gao.com/ga/access_token') .then(response => response.json()) .then(tokenInfo => { gapi.analytics.auth.authorize({ 'serverAuth': { 'access_token': tokenInfo.token } }); var report = new gapi.analytics.report.Data({ query: { 'ids': 'ga:169685330', 'start-date': '30daysAgo', 'end-date': 'yesterday', 'metrics': 'ga:sessions,ga:users', 'dimensions': 'ga:date' } }); report.on('success', function (resp) { resp.rows.forEach(element => { var year = element[0].substring(0, 4); var month = element[0].substring(4, 6); var day = element[0].substring(6, 8); var date = new Date(year, month - 1, day) config.data.labels.push(date.toDateString().substring(4, 10)); config.data.datasets[0].data.push( element[1] ); config.data.datasets[1].data.push( element[2] ); }); myChart.destroy(); myChart = new Chart(ctx, config); }); report.execute(); }) });","title":"A Random Walk Away Finance."},{"location":"cv/","text":"Curriculum Vitae \u00b6 \ud83c\udf93 Education \u00b6 PhD , Finance , University of Sydney (2017 - Present) Supervisors: Dr. Buhui Qiu and Dr. Henry Leung Bachelor of Commerce (Hon) , Finance , Unviersity of Sydney (2016) Thesis: \"Liquidity, Adverse Selection, and Information Asymmetry around Corporate Earnings Announcements\" Supervisor: Dr. Joakim Westerholm Bachelor of Commerce , Econometrics & Finance , Unviersity of Sydney (2013 - 2015) \ud83d\udcc4 Publications \u00b6 Journal Article \u00b6 Gao, M. , Leung, H. and Qiu, B. (2021). Organization Capital and Executive Performance Incentives, Journal of Banking & Finance , 123, 106017. Conference Paper \u00b6 Organization Capital and Executive Performance Incentives , with Henry Leung and Buhui Qiu. The 2020 FMA Annual Meeting (Virtual), October 2020. The 3 rd Global PhD Colloquium, April 2019, Fordham University, New York -- Outstanding PhD Student Paper Award The 32 nd Annual PhD Conference in Economics and Business, Australian National University, October 2019, Canberra, Australia. \ud83c\udfc6 Grants & Awards \u00b6 The Paulette Isabel Jones PhD Completion Scholarship , University of Sydney, 2020. AFA Ph.D. Student Travel Grant Award for the 2020 Annual Meeting in San Diego, California from January 3-5, 2020. Outstanding PhD Student Paper Award at the 3 rd Global PhD Colloquium in Fordharm University, New York, April 2019. The University of Sydney Honours Scholarship , University of Sydney, 2016. \ud83c\udfdb Academic Experience \u00b6 Visiting Scholar , University of Hong Kong, 2019 (cancelled). Member of the Business Financing and Banking Research Group at the University of Sydney. Discussant : The 2020 FMA Annual Meeting (Virtual), October 2020. \ud83d\udc68\ud83c\udffb\u200d\ud83c\udfeb Teaching Experience \u00b6 Time Course Institution Semester 1, 2021 FINC2011 Corporate Finance I FINC6013 International Business Finance University of Sydney Semester 2, 2020 FINC6001 Intermediate Corporate Finance FINC6010 Derivative Securities University of Sydney Semester 1, 2020 FINC2012 Corporate Finance II University of Sydney Semester 2, 2019 FINC2012 Corporate Finance II FINC6010 Derivative Securities University of Sydney Semester 1, 2019 FINC2011 Corporate Finance I FINC2012 Corporate Finance II University of Sydney Semester 2, 2018 FINC2011 Corporate Finance I FINC2012 Corporate Finance II University of Sydney Semester 1, 2018 FINC2012 Corporate Finance II University of Sydney Semester 2, 2017 FINC2012 Corporate Finance II FINC3013 Mergers & Acquisitions University of Sydney Semester 1, 2017 FINC2012 Corporate Finance II FINC3011 International Financial Management University of Sydney Semester 2, 2016 FINC2012 Corporate Finance II University of Sydney \ud83d\udc68\ud83c\udffb\u200d\ud83d\udcbc Professional Experience \u00b6 Quantitative Consultant - Infinitas Asset Management Ltd (2017 - Present) Infinitas Asset Management (ABN 78 129 953 724 / AFSL 326087) is a boutique financial adviser and investment manager with a wide client base, including high and ultra-high net worth individuals, family offices, SMSFs, foundations and not-for-profit groups. Co-Founder, Director - Transcendental Capital Pty Ltd (2018 - Present) Transcendental Capital (ABN 28 624 272 199) is a proprietary investment company established in 2018 by three finance PhD students from the University of Sydney Business School. The company leverages frontier academic insights in trading and investments across different assets and markets to achieve superior long-term risk-adjusted performance.","title":"CV"},{"location":"cv/#curriculum-vitae","text":"","title":"Curriculum Vitae"},{"location":"cv/#education","text":"PhD , Finance , University of Sydney (2017 - Present) Supervisors: Dr. Buhui Qiu and Dr. Henry Leung Bachelor of Commerce (Hon) , Finance , Unviersity of Sydney (2016) Thesis: \"Liquidity, Adverse Selection, and Information Asymmetry around Corporate Earnings Announcements\" Supervisor: Dr. Joakim Westerholm Bachelor of Commerce , Econometrics & Finance , Unviersity of Sydney (2013 - 2015)","title":"\ud83c\udf93 Education"},{"location":"cv/#publications","text":"","title":"\ud83d\udcc4 Publications"},{"location":"cv/#journal-article","text":"Gao, M. , Leung, H. and Qiu, B. (2021). Organization Capital and Executive Performance Incentives, Journal of Banking & Finance , 123, 106017.","title":"Journal Article"},{"location":"cv/#conference-paper","text":"Organization Capital and Executive Performance Incentives , with Henry Leung and Buhui Qiu. The 2020 FMA Annual Meeting (Virtual), October 2020. The 3 rd Global PhD Colloquium, April 2019, Fordham University, New York -- Outstanding PhD Student Paper Award The 32 nd Annual PhD Conference in Economics and Business, Australian National University, October 2019, Canberra, Australia.","title":"Conference Paper"},{"location":"cv/#grants-awards","text":"The Paulette Isabel Jones PhD Completion Scholarship , University of Sydney, 2020. AFA Ph.D. Student Travel Grant Award for the 2020 Annual Meeting in San Diego, California from January 3-5, 2020. Outstanding PhD Student Paper Award at the 3 rd Global PhD Colloquium in Fordharm University, New York, April 2019. The University of Sydney Honours Scholarship , University of Sydney, 2016.","title":"\ud83c\udfc6 Grants &amp; Awards"},{"location":"cv/#academic-experience","text":"Visiting Scholar , University of Hong Kong, 2019 (cancelled). Member of the Business Financing and Banking Research Group at the University of Sydney. Discussant : The 2020 FMA Annual Meeting (Virtual), October 2020.","title":"\ud83c\udfdb Academic Experience"},{"location":"cv/#teaching-experience","text":"Time Course Institution Semester 1, 2021 FINC2011 Corporate Finance I FINC6013 International Business Finance University of Sydney Semester 2, 2020 FINC6001 Intermediate Corporate Finance FINC6010 Derivative Securities University of Sydney Semester 1, 2020 FINC2012 Corporate Finance II University of Sydney Semester 2, 2019 FINC2012 Corporate Finance II FINC6010 Derivative Securities University of Sydney Semester 1, 2019 FINC2011 Corporate Finance I FINC2012 Corporate Finance II University of Sydney Semester 2, 2018 FINC2011 Corporate Finance I FINC2012 Corporate Finance II University of Sydney Semester 1, 2018 FINC2012 Corporate Finance II University of Sydney Semester 2, 2017 FINC2012 Corporate Finance II FINC3013 Mergers & Acquisitions University of Sydney Semester 1, 2017 FINC2012 Corporate Finance II FINC3011 International Financial Management University of Sydney Semester 2, 2016 FINC2012 Corporate Finance II University of Sydney","title":"\ud83d\udc68\ud83c\udffb\u200d\ud83c\udfeb Teaching Experience"},{"location":"cv/#professional-experience","text":"Quantitative Consultant - Infinitas Asset Management Ltd (2017 - Present) Infinitas Asset Management (ABN 78 129 953 724 / AFSL 326087) is a boutique financial adviser and investment manager with a wide client base, including high and ultra-high net worth individuals, family offices, SMSFs, foundations and not-for-profit groups. Co-Founder, Director - Transcendental Capital Pty Ltd (2018 - Present) Transcendental Capital (ABN 28 624 272 199) is a proprietary investment company established in 2018 by three finance PhD students from the University of Sydney Business School. The company leverages frontier academic insights in trading and investments across different assets and markets to achieve superior long-term risk-adjusted performance.","title":"\ud83d\udc68\ud83c\udffb\u200d\ud83d\udcbc Professional Experience"},{"location":"timetable/","text":"Timetable for Teaching and Consultation \u00b6 Below is the schedule of my tutorials, workshops and consultations for the current and past semesters since 2018. 2021 Semester 1 \u00b6 All tutorials are delivered online due to COVID-19. Please check Canvas for the Zoom link for each tutorial. FINC2011 Corporate Finance I \u00b6 Type Time Schedule Tutorial Monday 9am Week 2 to 12 Tutorial Monday 11am Week 2 to 12 Tutorial Monday 5pm Week 2 to 12 Tutorial Monday 6pm Week 2 to 12 FINC6013 International Business Finance \u00b6 Type Time Schedule Tutorial Thursday 9am Week 2 to 12 Tutorial Thursday 10am Week 2 to 12 Tutorial Thursday 1pm Week 2 to 12 Tutorial Thursday 2pm Week 2 to 12 2020 Semester 2 \u00b6 All tutorials are delivered online due to COVID-19. Please check Canvas for the Zoom link for each tutorial. FINC6001 Intermediate Corporate Finance \u00b6 Type Time Schedule Tutorial Wednesday 5pm Week 1 to 12 Tutorial Wednesday 6pm Week 1 to 12 Tutorial Wednesday 7pm Week 1 to 12 Tutorial Thursday 7pm Week 1 to 12 FINC6010 Derivatives Securities \u00b6 Type Time Schedule Tutorial Monday 9am Week 1 to 12 Tutorial Monday 7pm Week 1 to 12 Tutorial Thursday 11am Week 1 to 12 Tutorial Thursday 2pm Week 1 to 12 2020 Semester 1 \u00b6 FINC2012 Corporate Finance II \u00b6 All changed to Zoom online sessions due to COVID-19. Tutorial Wednesday 10:00 Eastern Avenue Seminar Room 312 Week 2 to 13 Tutorial Wednesday 11:00 Institute Tutorial Room 386 Week 2 to 13 Tutorial Wednesday 12:00 Storie Dixson Room N334 Week 2 to 3 Tutorial Wednesday 12:00 Eastern Avenue Seminar Room 121 Week 4 to 13 Tutorial Wednesday 13:00 Storie Dixson Room N333 Week 2 to 13 Tutorial Thursday 13:00 Storie Dixson Room N334 Week 2 to 13 2019 Semester 2 \u00b6 FINC6010 Derivative Securities \u00b6 Workshop Friday 9:00 PNR Lecture Theatre 2 Workshop Friday 10:00 PNR Lecture Theatre 2 FINC2012 Corporate Finance II \u00b6 Tutorial Monday 14:00 ABS Seminar Room 2250 Tutorial Monday 15:00 ABS Seminar Room 2250 Tutorial Wednesday 12:00 ABS Seminar Room 2070 Tutorial Wednesday 13:00 ABS Collaborative Learning Studio 3190 Tutorial Wednesday 14:00 Carslaw Learning Studio 353 2019 Semester 1 \u00b6 FINC2011 Corporate Finance I \u00b6 Tutorial Monday 9:00 Storie Dixson Room N333 Week 2 to 7, 9 to 13 Tutorial Monday 10:00 Storie Dixson Room N333 Week 2 to 7, 9 to 13 Tutorial Monday 11:00 Storie Dixson Room N333 Week 2 to 7, 9 to 13 FINC2012 Corporate Finance II \u00b6 Tutorial Tuesday 13:00 ABS Seminar Room 3280 Week 4 to 7, 9 to 13 Tutorial Tuesday 14:00 ABS Seminar Room 3280 Week 2 to 7, 9 to 13 Tutorial Tuesday 15:00 ABS Seminar Room 3280 Week 3 to 7, 9 to 13 Tutorial Wednesday 13:00 Mackie Seminar Room 107 Week 3 to 7, 9 to 13 Tutorial Wednesday 14:00 Edward Ford Tutorial Room 136 Week 3 to 7, 9 to 13 Tutorial Wednesday 15:00 ABS Case Study Room 1060 Week 4 to 7, 9 to 13 Tutorial Thursday 13:00 Storie Disxon Room N334v Week 2 Tutorial Thursday 14:00 Madsen Tutorial Room 318 Week 2 Tutorial Thursday 15:00 Madsen Tutorial Room 315 Week 2 2018 Semester 2 \u00b6 FINC2011 Corporate Finance I \u00b6 Tutorial Monday 9:00 ABS Seminar Room 3240 Tutorial Monday 10:00 ABS Seminar Room 3240 Tutorial Monday 11:00 ABS Seminar Room 3240 Tutorial Monday 12:00 ABS Seminar Room 3240 Consultation TBA FINC2012 Corporate Finance II \u00b6 Tutorial Tuesday 16:00 Carslaw Tutorial Room 274 Tutorial Tuesday 17:00 Carslaw Tutorial Room 274 Tutorial Wednesday 12:00 Merewether Seminar Room 1 (Rm 154) Tutorial Wednesday 13:00 Merewether Seminar Room 1 (Rm 154) Tutorial Wednesday 14:00 Merewether Seminar Room 1 (Rm 154) Tutorial (new) Wednesday 15:00 Merewether Seminar Room 1 (Rm 154) Tutorial (new) Wednesday 16:00 Merewether Seminar Room 1 (Rm 154) Tutorial (new) Wednesday 17:00 Merewether Seminar Room 3 (Rm 156) Consultation Thursday 11:00-12:00 Economics & Business Building H69 Rm 215 2018 Semester 1 \u00b6 FINC2012 Corporate Finance II \u00b6 Tutorial Monday 10:00 ABS Seminar Room 2010 Tutorial Monday 11:00 ABS Seminar Room 2010 Tutorial Monday 12:00 ABS Seminar Room 2010 Tutorial Tuesday 10:00 ABS Seminar Room 3280 Tutorial Tuesday 11:00 ABS Seminar Room 3280 Tutorial Thursday 14:00 Merewether Seminar Room 398 Consultation Thursday 15:00 Economics & Business Building (H69) Room 215 Happy studying!","title":"Timetable"},{"location":"timetable/#timetable-for-teaching-and-consultation","text":"Below is the schedule of my tutorials, workshops and consultations for the current and past semesters since 2018.","title":"Timetable for Teaching and Consultation"},{"location":"timetable/#2021-semester-1","text":"All tutorials are delivered online due to COVID-19. Please check Canvas for the Zoom link for each tutorial.","title":"2021 Semester 1"},{"location":"timetable/#finc2011-corporate-finance-i","text":"Type Time Schedule Tutorial Monday 9am Week 2 to 12 Tutorial Monday 11am Week 2 to 12 Tutorial Monday 5pm Week 2 to 12 Tutorial Monday 6pm Week 2 to 12","title":"FINC2011 Corporate Finance I"},{"location":"timetable/#finc6013-international-business-finance","text":"Type Time Schedule Tutorial Thursday 9am Week 2 to 12 Tutorial Thursday 10am Week 2 to 12 Tutorial Thursday 1pm Week 2 to 12 Tutorial Thursday 2pm Week 2 to 12","title":"FINC6013 International Business Finance"},{"location":"timetable/#2020-semester-2","text":"All tutorials are delivered online due to COVID-19. Please check Canvas for the Zoom link for each tutorial.","title":"2020 Semester 2"},{"location":"timetable/#finc6001-intermediate-corporate-finance","text":"Type Time Schedule Tutorial Wednesday 5pm Week 1 to 12 Tutorial Wednesday 6pm Week 1 to 12 Tutorial Wednesday 7pm Week 1 to 12 Tutorial Thursday 7pm Week 1 to 12","title":"FINC6001 Intermediate Corporate Finance"},{"location":"timetable/#finc6010-derivatives-securities","text":"Type Time Schedule Tutorial Monday 9am Week 1 to 12 Tutorial Monday 7pm Week 1 to 12 Tutorial Thursday 11am Week 1 to 12 Tutorial Thursday 2pm Week 1 to 12","title":"FINC6010 Derivatives Securities"},{"location":"timetable/#2020-semester-1","text":"","title":"2020 Semester 1"},{"location":"timetable/#finc2012-corporate-finance-ii","text":"All changed to Zoom online sessions due to COVID-19. Tutorial Wednesday 10:00 Eastern Avenue Seminar Room 312 Week 2 to 13 Tutorial Wednesday 11:00 Institute Tutorial Room 386 Week 2 to 13 Tutorial Wednesday 12:00 Storie Dixson Room N334 Week 2 to 3 Tutorial Wednesday 12:00 Eastern Avenue Seminar Room 121 Week 4 to 13 Tutorial Wednesday 13:00 Storie Dixson Room N333 Week 2 to 13 Tutorial Thursday 13:00 Storie Dixson Room N334 Week 2 to 13","title":"FINC2012 Corporate Finance II"},{"location":"timetable/#2019-semester-2","text":"","title":"2019 Semester 2"},{"location":"timetable/#finc6010-derivative-securities","text":"Workshop Friday 9:00 PNR Lecture Theatre 2 Workshop Friday 10:00 PNR Lecture Theatre 2","title":"FINC6010 Derivative Securities"},{"location":"timetable/#finc2012-corporate-finance-ii_1","text":"Tutorial Monday 14:00 ABS Seminar Room 2250 Tutorial Monday 15:00 ABS Seminar Room 2250 Tutorial Wednesday 12:00 ABS Seminar Room 2070 Tutorial Wednesday 13:00 ABS Collaborative Learning Studio 3190 Tutorial Wednesday 14:00 Carslaw Learning Studio 353","title":"FINC2012 Corporate Finance II"},{"location":"timetable/#2019-semester-1","text":"","title":"2019 Semester 1"},{"location":"timetable/#finc2011-corporate-finance-i_1","text":"Tutorial Monday 9:00 Storie Dixson Room N333 Week 2 to 7, 9 to 13 Tutorial Monday 10:00 Storie Dixson Room N333 Week 2 to 7, 9 to 13 Tutorial Monday 11:00 Storie Dixson Room N333 Week 2 to 7, 9 to 13","title":"FINC2011 Corporate Finance I"},{"location":"timetable/#finc2012-corporate-finance-ii_2","text":"Tutorial Tuesday 13:00 ABS Seminar Room 3280 Week 4 to 7, 9 to 13 Tutorial Tuesday 14:00 ABS Seminar Room 3280 Week 2 to 7, 9 to 13 Tutorial Tuesday 15:00 ABS Seminar Room 3280 Week 3 to 7, 9 to 13 Tutorial Wednesday 13:00 Mackie Seminar Room 107 Week 3 to 7, 9 to 13 Tutorial Wednesday 14:00 Edward Ford Tutorial Room 136 Week 3 to 7, 9 to 13 Tutorial Wednesday 15:00 ABS Case Study Room 1060 Week 4 to 7, 9 to 13 Tutorial Thursday 13:00 Storie Disxon Room N334v Week 2 Tutorial Thursday 14:00 Madsen Tutorial Room 318 Week 2 Tutorial Thursday 15:00 Madsen Tutorial Room 315 Week 2","title":"FINC2012 Corporate Finance II"},{"location":"timetable/#2018-semester-2","text":"","title":"2018 Semester 2"},{"location":"timetable/#finc2011-corporate-finance-i_2","text":"Tutorial Monday 9:00 ABS Seminar Room 3240 Tutorial Monday 10:00 ABS Seminar Room 3240 Tutorial Monday 11:00 ABS Seminar Room 3240 Tutorial Monday 12:00 ABS Seminar Room 3240 Consultation TBA","title":"FINC2011 Corporate Finance I"},{"location":"timetable/#finc2012-corporate-finance-ii_3","text":"Tutorial Tuesday 16:00 Carslaw Tutorial Room 274 Tutorial Tuesday 17:00 Carslaw Tutorial Room 274 Tutorial Wednesday 12:00 Merewether Seminar Room 1 (Rm 154) Tutorial Wednesday 13:00 Merewether Seminar Room 1 (Rm 154) Tutorial Wednesday 14:00 Merewether Seminar Room 1 (Rm 154) Tutorial (new) Wednesday 15:00 Merewether Seminar Room 1 (Rm 154) Tutorial (new) Wednesday 16:00 Merewether Seminar Room 1 (Rm 154) Tutorial (new) Wednesday 17:00 Merewether Seminar Room 3 (Rm 156) Consultation Thursday 11:00-12:00 Economics & Business Building H69 Rm 215","title":"FINC2012 Corporate Finance II"},{"location":"timetable/#2018-semester-1","text":"","title":"2018 Semester 1"},{"location":"timetable/#finc2012-corporate-finance-ii_4","text":"Tutorial Monday 10:00 ABS Seminar Room 2010 Tutorial Monday 11:00 ABS Seminar Room 2010 Tutorial Monday 12:00 ABS Seminar Room 2010 Tutorial Tuesday 10:00 ABS Seminar Room 3280 Tutorial Tuesday 11:00 ABS Seminar Room 3280 Tutorial Thursday 14:00 Merewether Seminar Room 398 Consultation Thursday 15:00 Economics & Business Building (H69) Room 215 Happy studying!","title":"FINC2012 Corporate Finance II"},{"location":"curriculum-vitae/","text":"","title":"Index"},{"location":"data/","text":"FRDS - Financial Research Data Services \u00b6 Note The old Research Data Services has been deprecated and will be merged into frds in a future release. frds is a Python framework I authored that aims to provide the simplest way to compute a collection of major academic measures used in the finance literature, one-click with a Graphical User Interface (GUI). It features: consolidation of major data sources such as WRDS, Federal Reserve Board, Refinitiv, Thomson Reuters, Bloomberg and more. one-liner to compute major measures used in literature. Installation & Configuration \u00b6 frds requires Python3.8 or higher. To install using pip : 1 $ pip install frds After installation, a folder frds will be created under your user's home directory, which contains a data folder, a result folder and a default configuration file config.ini : 1 2 3 4 5 6 7 8 [Paths] base_dir: ~/frds data_dir: ${base_dir}/data result_dir: ${base_dir}/result [Login] wrds_username: wrds_password: You need to enter your WRDS username and password under the login section. Usage \u00b6 To start estimating various measures, run frds as a module: 1 $ python -m frds.gui.run Alternatively, run without GUI: 1 $ python -m frds.run The output data will be saved as STATA .dta file in the result folder. Example Output \u00b6 Below is an example output for tangibility , defined as the Property, Plant and Equipment (Net) scaled by Assets (Total), estimated for all firms in the Compustat Fundamental Annual. The result dataset is saved in /result/Tangibility.dta . Supported Measures \u00b6 Measure Description Datasets Used tangibility Property, Plant and Equipment (Net) scaled by Assets (Total) wrds.comp.funda roa Income Before Extraordinary Items scaled by Assets (Total) wrds.comp.funda roe Income Before Extraordinary Items scaled by Common Equity (Total) wrds.comp.funda book leverage (Long-term Debt + Debt in Current Liabilities) / (Long-term Debt + Debt in Current Liabilities + Common Equity) wrds.comp.funda capital expenditure Capital Expenditures scaled by Assets (Total) wrds.comp.funda market to book Market Value of Common Equity to Book Common Equity wrds.comp.funda accounting restatement Number of various accounting restatements during the fiscal year wrds.comp.funda, wrds.audit.auditnonreli","title":"Data"},{"location":"data/#frds-financial-research-data-services","text":"Note The old Research Data Services has been deprecated and will be merged into frds in a future release. frds is a Python framework I authored that aims to provide the simplest way to compute a collection of major academic measures used in the finance literature, one-click with a Graphical User Interface (GUI). It features: consolidation of major data sources such as WRDS, Federal Reserve Board, Refinitiv, Thomson Reuters, Bloomberg and more. one-liner to compute major measures used in literature.","title":"FRDS - Financial Research Data Services"},{"location":"data/#installation-configuration","text":"frds requires Python3.8 or higher. To install using pip : 1 $ pip install frds After installation, a folder frds will be created under your user's home directory, which contains a data folder, a result folder and a default configuration file config.ini : 1 2 3 4 5 6 7 8 [Paths] base_dir: ~/frds data_dir: ${base_dir}/data result_dir: ${base_dir}/result [Login] wrds_username: wrds_password: You need to enter your WRDS username and password under the login section.","title":"Installation &amp; Configuration"},{"location":"data/#usage","text":"To start estimating various measures, run frds as a module: 1 $ python -m frds.gui.run Alternatively, run without GUI: 1 $ python -m frds.run The output data will be saved as STATA .dta file in the result folder.","title":"Usage"},{"location":"data/#example-output","text":"Below is an example output for tangibility , defined as the Property, Plant and Equipment (Net) scaled by Assets (Total), estimated for all firms in the Compustat Fundamental Annual. The result dataset is saved in /result/Tangibility.dta .","title":"Example Output"},{"location":"data/#supported-measures","text":"Measure Description Datasets Used tangibility Property, Plant and Equipment (Net) scaled by Assets (Total) wrds.comp.funda roa Income Before Extraordinary Items scaled by Assets (Total) wrds.comp.funda roe Income Before Extraordinary Items scaled by Common Equity (Total) wrds.comp.funda book leverage (Long-term Debt + Debt in Current Liabilities) / (Long-term Debt + Debt in Current Liabilities + Common Equity) wrds.comp.funda capital expenditure Capital Expenditures scaled by Assets (Total) wrds.comp.funda market to book Market Value of Common Equity to Book Common Equity wrds.comp.funda accounting restatement Number of various accounting restatements during the fiscal year wrds.comp.funda, wrds.audit.auditnonreli","title":"Supported Measures"},{"location":"data/rds/","text":"RDS - deprecated \u00b6 Warning This research data service has been deprecated and will be merged into frds - financial research data services . A database of market microstructure measures. Proof-of-concept joint work with Prof. Joakim Westerholm and Dr. Henry Leung . Our objective is to construct and maintain a database of market micriostructure measures based on high-frequency tick history sourced from Refinitiv Thomson Reuters Tick History . Example Usage \u00b6 I provide an easy-to-use SQL interface for researchers to retrieve the data. Below is an example usage in SAS. Currently, you'll need to be inside the USYD's network to use RDS. You can either use a PC inside the Business School or use VPN. 1 2 3 4 /* Assign lib reference to connect to the server. */ libname rds mysql server= \"asgard.econ.usyd.edu.au\" database=rds user=actualusername password=actualpassword; If you enconter this error: ERROR: The SAS/ACCESS Interface to MYSQL cannot be loaded. The libmysql code appendage could not be loaded. Solution is here http://support.sas.com/kb/19/250.html . Let's now use RDS to get a collection of measures estimated. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 /* Some example usage. */ /* More measures and complete documentaion to come. */ proc sql; /* Retrieve the full table of estimated measures. */ create table measures as select * from rds . measures order by local_date asc, RIC asc; /* Retrieve all Bid-Ask Spread estimates. */ create table baspread as select * from rds . bidaskspread; /* Retrieve all Effective Spread estimates for RIC=AAL.OQ. */ create table espread as select * from rds . effectivespread where RIC= 'AAL.OQ' ; /* Retrieve all Realized Spread estimates from 2019-01-01 to 2019-01-15. */ create table rspread as select * from rds . realizedspread where local_date between \"01Jan2019\" d and \"15Jan2019\" d; /* Retrieve all LinSangerBooth1995 estimates of adverse selection. */ create table lsb1995 as select * from rds . measures where measure= \"LinSangerBooth1995\" ; quit; Let's try plot a timeseries to prove it works. 1 2 3 4 5 6 7 /* Simple timeseries plot */ title \"Timeseries Plot of Realized Spread For USB.N and AIG.N\" ; proc sgplot data=measures; where measure= \"RealizedSpread\" & (RIC= \"USB.N\" | RIC= \"AIG.N\" ); series x =local_date y=estimate /markers group =RIC; refline 0 /axis=y ; run; The output is: Technology Stack \u00b6 I wrote this system in Python and C/C++. A workstation of an 8-core 16-thread CPU, 64GB RAM and m.2. SSDs is used. Behind the scene, the program classifies trade directions using Lee and Ready (1991) algorithm on the fly, and estimates several measures for each security and each day. Results are stored in a MySQL database inside the university network, but may be stored and served at AWS in the future. Development Plan \u00b6 We plan to continue the development of this project and: cover more measures, securities and extend the data period; provide an easy-to-use web interface apart from the SQL interface; provide a REST API for more efficient and professional usage. Disclaimer \u00b6 This project may contain errors. Users are recommended to double check the data quality before usage. We hold no responsibility for any damage and/or loss incurred as a result of using any data provided on this site. We may provide the source code for selected measures and encourage users to check it for correctness and accuracy. If there is any bug and/or error, please contact me at mingze.gao@sydney.edu.au . Contact \u00b6 Mingze Gao: mingze.gao@sydney.edu.au . Henry Leung: henry.leung@sydney.edu.au . Joakim Westerholm: joakim.westerholm@sydney.edu.au .","title":"RDS - deprecated"},{"location":"data/rds/#rds-deprecated","text":"Warning This research data service has been deprecated and will be merged into frds - financial research data services . A database of market microstructure measures. Proof-of-concept joint work with Prof. Joakim Westerholm and Dr. Henry Leung . Our objective is to construct and maintain a database of market micriostructure measures based on high-frequency tick history sourced from Refinitiv Thomson Reuters Tick History .","title":"RDS - deprecated"},{"location":"data/rds/#example-usage","text":"I provide an easy-to-use SQL interface for researchers to retrieve the data. Below is an example usage in SAS. Currently, you'll need to be inside the USYD's network to use RDS. You can either use a PC inside the Business School or use VPN. 1 2 3 4 /* Assign lib reference to connect to the server. */ libname rds mysql server= \"asgard.econ.usyd.edu.au\" database=rds user=actualusername password=actualpassword; If you enconter this error: ERROR: The SAS/ACCESS Interface to MYSQL cannot be loaded. The libmysql code appendage could not be loaded. Solution is here http://support.sas.com/kb/19/250.html . Let's now use RDS to get a collection of measures estimated. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 /* Some example usage. */ /* More measures and complete documentaion to come. */ proc sql; /* Retrieve the full table of estimated measures. */ create table measures as select * from rds . measures order by local_date asc, RIC asc; /* Retrieve all Bid-Ask Spread estimates. */ create table baspread as select * from rds . bidaskspread; /* Retrieve all Effective Spread estimates for RIC=AAL.OQ. */ create table espread as select * from rds . effectivespread where RIC= 'AAL.OQ' ; /* Retrieve all Realized Spread estimates from 2019-01-01 to 2019-01-15. */ create table rspread as select * from rds . realizedspread where local_date between \"01Jan2019\" d and \"15Jan2019\" d; /* Retrieve all LinSangerBooth1995 estimates of adverse selection. */ create table lsb1995 as select * from rds . measures where measure= \"LinSangerBooth1995\" ; quit; Let's try plot a timeseries to prove it works. 1 2 3 4 5 6 7 /* Simple timeseries plot */ title \"Timeseries Plot of Realized Spread For USB.N and AIG.N\" ; proc sgplot data=measures; where measure= \"RealizedSpread\" & (RIC= \"USB.N\" | RIC= \"AIG.N\" ); series x =local_date y=estimate /markers group =RIC; refline 0 /axis=y ; run; The output is:","title":"Example Usage"},{"location":"data/rds/#technology-stack","text":"I wrote this system in Python and C/C++. A workstation of an 8-core 16-thread CPU, 64GB RAM and m.2. SSDs is used. Behind the scene, the program classifies trade directions using Lee and Ready (1991) algorithm on the fly, and estimates several measures for each security and each day. Results are stored in a MySQL database inside the university network, but may be stored and served at AWS in the future.","title":"Technology Stack"},{"location":"data/rds/#development-plan","text":"We plan to continue the development of this project and: cover more measures, securities and extend the data period; provide an easy-to-use web interface apart from the SQL interface; provide a REST API for more efficient and professional usage.","title":"Development Plan"},{"location":"data/rds/#disclaimer","text":"This project may contain errors. Users are recommended to double check the data quality before usage. We hold no responsibility for any damage and/or loss incurred as a result of using any data provided on this site. We may provide the source code for selected measures and encourage users to check it for correctness and accuracy. If there is any bug and/or error, please contact me at mingze.gao@sydney.edu.au .","title":"Disclaimer"},{"location":"data/rds/#contact","text":"Mingze Gao: mingze.gao@sydney.edu.au . Henry Leung: henry.leung@sydney.edu.au . Joakim Westerholm: joakim.westerholm@sydney.edu.au .","title":"Contact"},{"location":"measures/accounting_restatement/","text":"Accounting Restatement \u00b6 Definition \u00b6 Restating previous financial statements is a signal worth attention and investigation. This measure counts the number of restatements in the past fiscal year (configurable to arbitrary number of years) due to various reasons based on the WRDS AuditAnalytics Non-Reliance Restatement dataset. Specifically, the following variables from WRDS.AUDIT.AUDITNONRELI are used: Variable Description company_fkey EDGAR CIK file_date Filing date res_notif_key Restatement notification key res_accounting Restatement due to accounting issues res_adverse Restatement had an adverse impact res_fraud Restatement related to fraud res_cler_err Restatement due to clerical errors res_sec_invest Restatement followed by SEC investigation The dataset is merged with WRDS.COMP.FUNDA on CIK , grouped by gvkey and datadate . Then the frequency of each restatement type is counted.","title":"Accounting Restatement"},{"location":"measures/accounting_restatement/#accounting-restatement","text":"","title":"Accounting Restatement"},{"location":"measures/accounting_restatement/#definition","text":"Restating previous financial statements is a signal worth attention and investigation. This measure counts the number of restatements in the past fiscal year (configurable to arbitrary number of years) due to various reasons based on the WRDS AuditAnalytics Non-Reliance Restatement dataset. Specifically, the following variables from WRDS.AUDIT.AUDITNONRELI are used: Variable Description company_fkey EDGAR CIK file_date Filing date res_notif_key Restatement notification key res_accounting Restatement due to accounting issues res_adverse Restatement had an adverse impact res_fraud Restatement related to fraud res_cler_err Restatement due to clerical errors res_sec_invest Restatement followed by SEC investigation The dataset is merged with WRDS.COMP.FUNDA on CIK , grouped by gvkey and datadate . Then the frequency of each restatement type is counted.","title":"Definition"},{"location":"measures/asset_tangibility/","text":"Asset Tangibility \u00b6 Definition \u00b6 Property, Plant and Equipment (Net) scaled by Assets (Total). \\text{Asset Tangibility}_{i,t}=\\frac{PPENT_{i,t}}{AT_{i,t}} \\text{Asset Tangibility}_{i,t}=\\frac{PPENT_{i,t}}{AT_{i,t}} where PPENT PPENT and AT AT are from Compustat Fundamentals Annual WRDS.COMP.FUNDA .","title":"Asset Tangibility"},{"location":"measures/asset_tangibility/#asset-tangibility","text":"","title":"Asset Tangibility"},{"location":"measures/asset_tangibility/#definition","text":"Property, Plant and Equipment (Net) scaled by Assets (Total). \\text{Asset Tangibility}_{i,t}=\\frac{PPENT_{i,t}}{AT_{i,t}} \\text{Asset Tangibility}_{i,t}=\\frac{PPENT_{i,t}}{AT_{i,t}} where PPENT PPENT and AT AT are from Compustat Fundamentals Annual WRDS.COMP.FUNDA .","title":"Definition"},{"location":"measures/bhc_dividend_to_assets/","text":"BHC Dividend / Assets \u00b6 Definition \u00b6 Cash dividends on common stock BHCK4460 scaled by total assets BHCK2170 . \\text{Dividend/Assets}_{i,t}=\\frac{\\text{BHCK4460}_{i,t}}{\\text{BHCK2170}_{i,t}} \\text{Dividend/Assets}_{i,t}=\\frac{\\text{BHCK4460}_{i,t}}{\\text{BHCK2170}_{i,t}} where BHCK4460 and BHCK2170 are from the Bank Holding Company data by the Federal Reserve Bank of Chicago. 1 Reference \u00b6 Rampini, Viswanathan and Vuillemey (2020 JF) . https://www.chicagofed.org/banking/financial-institution-reports/bhc-data . \u21a9","title":"BHC Dividend/Assets"},{"location":"measures/bhc_dividend_to_assets/#bhc-dividend-assets","text":"","title":"BHC Dividend / Assets"},{"location":"measures/bhc_dividend_to_assets/#definition","text":"Cash dividends on common stock BHCK4460 scaled by total assets BHCK2170 . \\text{Dividend/Assets}_{i,t}=\\frac{\\text{BHCK4460}_{i,t}}{\\text{BHCK2170}_{i,t}} \\text{Dividend/Assets}_{i,t}=\\frac{\\text{BHCK4460}_{i,t}}{\\text{BHCK2170}_{i,t}} where BHCK4460 and BHCK2170 are from the Bank Holding Company data by the Federal Reserve Bank of Chicago. 1","title":"Definition"},{"location":"measures/bhc_dividend_to_assets/#reference","text":"Rampini, Viswanathan and Vuillemey (2020 JF) . https://www.chicagofed.org/banking/financial-institution-reports/bhc-data . \u21a9","title":"Reference"},{"location":"measures/bhc_fx_exposure/","text":"BHC FX Exposure \u00b6 Definition \u00b6 Fee and interest income from loans in foreign offices BHCK4059 scaled by total interest income BHCK4107 . \\text{FX Exposure}_{i,t}=\\frac{\\text{BHCK4059}_{i,t}}{\\text{BHCK4107}_{i,t}} \\text{FX Exposure}_{i,t}=\\frac{\\text{BHCK4059}_{i,t}}{\\text{BHCK4107}_{i,t}} where BHCK4059 and BHCK4107 are from the Bank Holding Company data by the Federal Reserve Bank of Chicago. 1 Reference \u00b6 Rampini, Viswanathan and Vuillemey (2020 JF) . https://www.chicagofed.org/banking/financial-institution-reports/bhc-data . \u21a9","title":"BHC FX Exposure"},{"location":"measures/bhc_fx_exposure/#bhc-fx-exposure","text":"","title":"BHC FX Exposure"},{"location":"measures/bhc_fx_exposure/#definition","text":"Fee and interest income from loans in foreign offices BHCK4059 scaled by total interest income BHCK4107 . \\text{FX Exposure}_{i,t}=\\frac{\\text{BHCK4059}_{i,t}}{\\text{BHCK4107}_{i,t}} \\text{FX Exposure}_{i,t}=\\frac{\\text{BHCK4059}_{i,t}}{\\text{BHCK4107}_{i,t}} where BHCK4059 and BHCK4107 are from the Bank Holding Company data by the Federal Reserve Bank of Chicago. 1","title":"Definition"},{"location":"measures/bhc_fx_exposure/#reference","text":"Rampini, Viswanathan and Vuillemey (2020 JF) . https://www.chicagofed.org/banking/financial-institution-reports/bhc-data . \u21a9","title":"Reference"},{"location":"measures/bhc_gross_fx_hedging/","text":"BHC Gross Foreign Exchange Rate Hedging \u00b6 Definition \u00b6 Total gross notional amount of foreign exchange rate derivatives held for purposes other than trading BHCK8726 over total assets BHCK2170 ; for the period 1995 to 2000, contracts not marked to market BHCK8730 are added. If t \\in [1995, 2000] t \\in [1995, 2000] : \\text{Gross FX Hedging}_{i,t}=\\frac{\\text{BHCK8726}_{i,t}+\\text{BHCK8730}_{i,t}}{\\text{BHCK2170}_{i,t}} \\text{Gross FX Hedging}_{i,t}=\\frac{\\text{BHCK8726}_{i,t}+\\text{BHCK8730}_{i,t}}{\\text{BHCK2170}_{i,t}} Otherwise: \\text{Gross FX Hedging}_{i,t}=\\frac{\\text{BHCK8726}_{i,t}}{\\text{BHCK2170}_{i,t}} \\text{Gross FX Hedging}_{i,t}=\\frac{\\text{BHCK8726}_{i,t}}{\\text{BHCK2170}_{i,t}} where BHCK8726 , BHCK8730 and BHCK4107 are from the Bank Holding Company data by the Federal Reserve Bank of Chicago. 1 Reference \u00b6 Rampini, Viswanathan and Vuillemey (2020 JF) . https://www.chicagofed.org/banking/financial-institution-reports/bhc-data . \u21a9","title":"BHC Gross FX Hedging"},{"location":"measures/bhc_gross_fx_hedging/#bhc-gross-foreign-exchange-rate-hedging","text":"","title":"BHC Gross Foreign Exchange Rate Hedging"},{"location":"measures/bhc_gross_fx_hedging/#definition","text":"Total gross notional amount of foreign exchange rate derivatives held for purposes other than trading BHCK8726 over total assets BHCK2170 ; for the period 1995 to 2000, contracts not marked to market BHCK8730 are added. If t \\in [1995, 2000] t \\in [1995, 2000] : \\text{Gross FX Hedging}_{i,t}=\\frac{\\text{BHCK8726}_{i,t}+\\text{BHCK8730}_{i,t}}{\\text{BHCK2170}_{i,t}} \\text{Gross FX Hedging}_{i,t}=\\frac{\\text{BHCK8726}_{i,t}+\\text{BHCK8730}_{i,t}}{\\text{BHCK2170}_{i,t}} Otherwise: \\text{Gross FX Hedging}_{i,t}=\\frac{\\text{BHCK8726}_{i,t}}{\\text{BHCK2170}_{i,t}} \\text{Gross FX Hedging}_{i,t}=\\frac{\\text{BHCK8726}_{i,t}}{\\text{BHCK2170}_{i,t}} where BHCK8726 , BHCK8730 and BHCK4107 are from the Bank Holding Company data by the Federal Reserve Bank of Chicago. 1","title":"Definition"},{"location":"measures/bhc_gross_fx_hedging/#reference","text":"Rampini, Viswanathan and Vuillemey (2020 JF) . https://www.chicagofed.org/banking/financial-institution-reports/bhc-data . \u21a9","title":"Reference"},{"location":"measures/bhc_gross_ir_hedging/","text":"BHC Gross Interest Rate Hedging \u00b6 Definition \u00b6 Total gross notional amount of interest rate derivatives held for purposes other than trading BHCK8725 over total assets BHCK2170 ; for the period 1995 to 2000, contracts not marked to market BHCK8729 are added. If t \\in [1995, 2000] t \\in [1995, 2000] : \\text{Gross IR Hedging}_{i,t}=\\frac{\\text{BHCK8725}_{i,t}+\\text{BHCK8729}_{i,t}}{\\text{BHCK2170}_{i,t}} \\text{Gross IR Hedging}_{i,t}=\\frac{\\text{BHCK8725}_{i,t}+\\text{BHCK8729}_{i,t}}{\\text{BHCK2170}_{i,t}} Otherwise: \\text{Gross IR Hedging}_{i,t}=\\frac{\\text{BHCK8725}_{i,t}}{\\text{BHCK2170}_{i,t}} \\text{Gross IR Hedging}_{i,t}=\\frac{\\text{BHCK8725}_{i,t}}{\\text{BHCK2170}_{i,t}} where BHCK8725 , BHCK8729 and BHCK4107 are from the Bank Holding Company data by the Federal Reserve Bank of Chicago. 1 Reference \u00b6 Rampini, Viswanathan and Vuillemey (2020 JF) . https://www.chicagofed.org/banking/financial-institution-reports/bhc-data . \u21a9","title":"BHC Gross IR Hedging"},{"location":"measures/bhc_gross_ir_hedging/#bhc-gross-interest-rate-hedging","text":"","title":"BHC Gross Interest Rate Hedging"},{"location":"measures/bhc_gross_ir_hedging/#definition","text":"Total gross notional amount of interest rate derivatives held for purposes other than trading BHCK8725 over total assets BHCK2170 ; for the period 1995 to 2000, contracts not marked to market BHCK8729 are added. If t \\in [1995, 2000] t \\in [1995, 2000] : \\text{Gross IR Hedging}_{i,t}=\\frac{\\text{BHCK8725}_{i,t}+\\text{BHCK8729}_{i,t}}{\\text{BHCK2170}_{i,t}} \\text{Gross IR Hedging}_{i,t}=\\frac{\\text{BHCK8725}_{i,t}+\\text{BHCK8729}_{i,t}}{\\text{BHCK2170}_{i,t}} Otherwise: \\text{Gross IR Hedging}_{i,t}=\\frac{\\text{BHCK8725}_{i,t}}{\\text{BHCK2170}_{i,t}} \\text{Gross IR Hedging}_{i,t}=\\frac{\\text{BHCK8725}_{i,t}}{\\text{BHCK2170}_{i,t}} where BHCK8725 , BHCK8729 and BHCK4107 are from the Bank Holding Company data by the Federal Reserve Bank of Chicago. 1","title":"Definition"},{"location":"measures/bhc_gross_ir_hedging/#reference","text":"Rampini, Viswanathan and Vuillemey (2020 JF) . https://www.chicagofed.org/banking/financial-institution-reports/bhc-data . \u21a9","title":"Reference"},{"location":"measures/bhc_loan_growth/","text":"BHC Loan Growth \u00b6 Definition \u00b6 The natural logarithm of a bank's total loans in the current quarter, divided by its total loans in the previous quarter. 2 Here the total loans are measures by BHCK2122 in FR Y-9C reports. This item represents the proportion of a bank's total loans that do not exclude the allowance for loans and lease losses. \\text{LoanGrowth}_{i,t} = \\ln \\left( \\frac{\\text{BHCK2122}_{i,t}}{\\text{BHCK2122}_{i,t-1}} \\right) \\text{LoanGrowth}_{i,t} = \\ln \\left( \\frac{\\text{BHCK2122}_{i,t}}{\\text{BHCK2122}_{i,t-1}} \\right) where BHCK2122 is from the Bank Holding Company data by the Federal Reserve Bank of Chicago. 1 Warning A caveat is that if \\text{BHCK2122}_{i,t} \\text{BHCK2122}_{i,t} is 0, then this measure would be invalid as \\ln(0) \\ln(0) is undefined. In this case, I replace it with -1 which means the total loans is reduced by 100% to 0. An alternative measure of loan growth, the percentage change in the total loans, is not affected by this issue. \\text{LoanGrowthPct}_{i,t} = \\left( \\frac{\\text{BHCK2122}_{i,t}}{\\text{BHCK2122}_{i,t-1}} -1\\right) \\times 100 \\text{LoanGrowthPct}_{i,t} = \\left( \\frac{\\text{BHCK2122}_{i,t}}{\\text{BHCK2122}_{i,t-1}} -1\\right) \\times 100 Their correlation is over 99%. Equivalent Stata Code \u00b6 1 2 3 4 5 use \"~/frds/result/BankHoldingCompany LoanGrowth.dta\" , clear gen qtr = qofd (RSSD9999) format qtr %tq xtset RSSD9001 qtr, quarterly gen BHCLoanGrowthPct = (BHCK2122 / L . BHCK2122 - 1 ) * 100 Reference \u00b6 https://www.chicagofed.org/banking/financial-institution-reports/bhc-data . \u21a9 This definition is from Zheng (2020 JBF) . \u21a9","title":"BHC Loan Growth"},{"location":"measures/bhc_loan_growth/#bhc-loan-growth","text":"","title":"BHC Loan Growth"},{"location":"measures/bhc_loan_growth/#definition","text":"The natural logarithm of a bank's total loans in the current quarter, divided by its total loans in the previous quarter. 2 Here the total loans are measures by BHCK2122 in FR Y-9C reports. This item represents the proportion of a bank's total loans that do not exclude the allowance for loans and lease losses. \\text{LoanGrowth}_{i,t} = \\ln \\left( \\frac{\\text{BHCK2122}_{i,t}}{\\text{BHCK2122}_{i,t-1}} \\right) \\text{LoanGrowth}_{i,t} = \\ln \\left( \\frac{\\text{BHCK2122}_{i,t}}{\\text{BHCK2122}_{i,t-1}} \\right) where BHCK2122 is from the Bank Holding Company data by the Federal Reserve Bank of Chicago. 1 Warning A caveat is that if \\text{BHCK2122}_{i,t} \\text{BHCK2122}_{i,t} is 0, then this measure would be invalid as \\ln(0) \\ln(0) is undefined. In this case, I replace it with -1 which means the total loans is reduced by 100% to 0. An alternative measure of loan growth, the percentage change in the total loans, is not affected by this issue. \\text{LoanGrowthPct}_{i,t} = \\left( \\frac{\\text{BHCK2122}_{i,t}}{\\text{BHCK2122}_{i,t-1}} -1\\right) \\times 100 \\text{LoanGrowthPct}_{i,t} = \\left( \\frac{\\text{BHCK2122}_{i,t}}{\\text{BHCK2122}_{i,t-1}} -1\\right) \\times 100 Their correlation is over 99%.","title":"Definition"},{"location":"measures/bhc_loan_growth/#equivalent-stata-code","text":"1 2 3 4 5 use \"~/frds/result/BankHoldingCompany LoanGrowth.dta\" , clear gen qtr = qofd (RSSD9999) format qtr %tq xtset RSSD9001 qtr, quarterly gen BHCLoanGrowthPct = (BHCK2122 / L . BHCK2122 - 1 ) * 100","title":"Equivalent Stata Code"},{"location":"measures/bhc_loan_growth/#reference","text":"https://www.chicagofed.org/banking/financial-institution-reports/bhc-data . \u21a9 This definition is from Zheng (2020 JBF) . \u21a9","title":"Reference"},{"location":"measures/bhc_maturity_gap/","text":"BHC Maturity Gap \u00b6 Definition \u00b6 Maturity Gap \u00b6 Earning assets that are repriceable or mature within one year BHCK3197 minus interest-bearing deposits that mature or reprice within one year BHCK3296 minus long-term debt that reprices or matures within one year BHCK3298 + BHCK3409 minus variable rate preferred stock BHCK3408 minus other borrowed money with a maturity of one year or less BHCK2332 minus commercial paper BHCK2309 minus federal funds and repo liabilities BHDMB993 + BHCKB995 , normalized by total assets BHCK2170 , where all variables are from the Bank Holding Company data by the Federal Reserve Bank of Chicago. 1 Narrow Maturity Gap \u00b6 Narrow maturity gap is defined similarly to Maturity Gap, except that it does not subtract interest-bearing deposits that mature or reprice within one year BHCK3296 . Reference \u00b6 Rampini, Viswanathan and Vuillemey (2020 JF) . https://www.chicagofed.org/banking/financial-institution-reports/bhc-data . \u21a9","title":"BHC Maturity Gap"},{"location":"measures/bhc_maturity_gap/#bhc-maturity-gap","text":"","title":"BHC Maturity Gap"},{"location":"measures/bhc_maturity_gap/#definition","text":"","title":"Definition"},{"location":"measures/bhc_maturity_gap/#maturity-gap","text":"Earning assets that are repriceable or mature within one year BHCK3197 minus interest-bearing deposits that mature or reprice within one year BHCK3296 minus long-term debt that reprices or matures within one year BHCK3298 + BHCK3409 minus variable rate preferred stock BHCK3408 minus other borrowed money with a maturity of one year or less BHCK2332 minus commercial paper BHCK2309 minus federal funds and repo liabilities BHDMB993 + BHCKB995 , normalized by total assets BHCK2170 , where all variables are from the Bank Holding Company data by the Federal Reserve Bank of Chicago. 1","title":"Maturity Gap"},{"location":"measures/bhc_maturity_gap/#narrow-maturity-gap","text":"Narrow maturity gap is defined similarly to Maturity Gap, except that it does not subtract interest-bearing deposits that mature or reprice within one year BHCK3296 .","title":"Narrow Maturity Gap"},{"location":"measures/bhc_maturity_gap/#reference","text":"Rampini, Viswanathan and Vuillemey (2020 JF) . https://www.chicagofed.org/banking/financial-institution-reports/bhc-data . \u21a9","title":"Reference"},{"location":"measures/bhc_netincome_to_assets/","text":"BHC Net Income / Assets \u00b6 Definition \u00b6 Net income BHCK4340 scaled by total assets BHCK2170 . \\text{NetIncome/Assets}_{i,t}=\\frac{\\text{BHCK4340}_{i,t}}{\\text{BHCK2170}_{i,t}} \\text{NetIncome/Assets}_{i,t}=\\frac{\\text{BHCK4340}_{i,t}}{\\text{BHCK2170}_{i,t}} where BHCK4340 and BHCK2170 are from the Bank Holding Company data by the Federal Reserve Bank of Chicago. 1 Reference \u00b6 Rampini, Viswanathan and Vuillemey (2020 JF) . https://www.chicagofed.org/banking/financial-institution-reports/bhc-data . \u21a9","title":"BHC NetIncome/Assets"},{"location":"measures/bhc_netincome_to_assets/#bhc-net-income-assets","text":"","title":"BHC Net Income / Assets"},{"location":"measures/bhc_netincome_to_assets/#definition","text":"Net income BHCK4340 scaled by total assets BHCK2170 . \\text{NetIncome/Assets}_{i,t}=\\frac{\\text{BHCK4340}_{i,t}}{\\text{BHCK2170}_{i,t}} \\text{NetIncome/Assets}_{i,t}=\\frac{\\text{BHCK4340}_{i,t}}{\\text{BHCK2170}_{i,t}} where BHCK4340 and BHCK2170 are from the Bank Holding Company data by the Federal Reserve Bank of Chicago. 1","title":"Definition"},{"location":"measures/bhc_netincome_to_assets/#reference","text":"Rampini, Viswanathan and Vuillemey (2020 JF) . https://www.chicagofed.org/banking/financial-institution-reports/bhc-data . \u21a9","title":"Reference"},{"location":"measures/bhc_regcap_to_assets/","text":"BHC Regulatory Capital / Assets \u00b6 Definition \u00b6 Total qualifying capital allowable under the risk-based capital guidelines BHCK3792 normalized by risk-weighted assets BHCKA223 . \\text{RegCap/Assets}_{i,t}=\\frac{\\text{BHCK3792}_{i,t}}{\\text{BHCKA223}_{i,t}} \\text{RegCap/Assets}_{i,t}=\\frac{\\text{BHCK3792}_{i,t}}{\\text{BHCKA223}_{i,t}} where BHCK3792 and BHCKA223 are from the Bank Holding Company data by the Federal Reserve Bank of Chicago. 1 Reference \u00b6 Rampini, Viswanathan and Vuillemey (2020 JF) . https://www.chicagofed.org/banking/financial-institution-reports/bhc-data . \u21a9","title":"BHC RegulatoryCapital/Assets"},{"location":"measures/bhc_regcap_to_assets/#bhc-regulatory-capital-assets","text":"","title":"BHC Regulatory Capital / Assets"},{"location":"measures/bhc_regcap_to_assets/#definition","text":"Total qualifying capital allowable under the risk-based capital guidelines BHCK3792 normalized by risk-weighted assets BHCKA223 . \\text{RegCap/Assets}_{i,t}=\\frac{\\text{BHCK3792}_{i,t}}{\\text{BHCKA223}_{i,t}} \\text{RegCap/Assets}_{i,t}=\\frac{\\text{BHCK3792}_{i,t}}{\\text{BHCKA223}_{i,t}} where BHCK3792 and BHCKA223 are from the Bank Holding Company data by the Federal Reserve Bank of Chicago. 1","title":"Definition"},{"location":"measures/bhc_regcap_to_assets/#reference","text":"Rampini, Viswanathan and Vuillemey (2020 JF) . https://www.chicagofed.org/banking/financial-institution-reports/bhc-data . \u21a9","title":"Reference"},{"location":"measures/bhc_size/","text":"BHC Size \u00b6 Definition \u00b6 Natural logarithm of total assets BHCK2170 . \\text{Size}_{i,t} = \\ln \\left( \\text{BHCK2170}_{i,t} \\right) \\text{Size}_{i,t} = \\ln \\left( \\text{BHCK2170}_{i,t} \\right) where BHCK2170 is from the Bank Holding Company data by the Federal Reserve Bank of Chicago. 1 https://www.chicagofed.org/banking/financial-institution-reports/bhc-data . \u21a9","title":"BHC Size"},{"location":"measures/bhc_size/#bhc-size","text":"","title":"BHC Size"},{"location":"measures/bhc_size/#definition","text":"Natural logarithm of total assets BHCK2170 . \\text{Size}_{i,t} = \\ln \\left( \\text{BHCK2170}_{i,t} \\right) \\text{Size}_{i,t} = \\ln \\left( \\text{BHCK2170}_{i,t} \\right) where BHCK2170 is from the Bank Holding Company data by the Federal Reserve Bank of Chicago. 1 https://www.chicagofed.org/banking/financial-institution-reports/bhc-data . \u21a9","title":"Definition"},{"location":"measures/bhc_tier1cap_to_assets/","text":"BHC Tier1 Capital / Assets \u00b6 Definition \u00b6 Tier 1 capital allowable under the risk-based capital guidelines BHCK8274 normalized by risk-weighted assets BHCKA223 . \\text{Tier1Cap/Assets}_{i,t}=\\frac{\\text{BHCK8274}_{i,t}}{\\text{BHCKA223}_{i,t}} \\text{Tier1Cap/Assets}_{i,t}=\\frac{\\text{BHCK8274}_{i,t}}{\\text{BHCKA223}_{i,t}} where BHCK8274 and BHCKA223 are from the Bank Holding Company data by the Federal Reserve Bank of Chicago. 1 Reference \u00b6 Rampini, Viswanathan and Vuillemey (2020 JF) . https://www.chicagofed.org/banking/financial-institution-reports/bhc-data . \u21a9","title":"BHC Tier1Capital/Assets"},{"location":"measures/bhc_tier1cap_to_assets/#bhc-tier1-capital-assets","text":"","title":"BHC Tier1 Capital / Assets"},{"location":"measures/bhc_tier1cap_to_assets/#definition","text":"Tier 1 capital allowable under the risk-based capital guidelines BHCK8274 normalized by risk-weighted assets BHCKA223 . \\text{Tier1Cap/Assets}_{i,t}=\\frac{\\text{BHCK8274}_{i,t}}{\\text{BHCKA223}_{i,t}} \\text{Tier1Cap/Assets}_{i,t}=\\frac{\\text{BHCK8274}_{i,t}}{\\text{BHCKA223}_{i,t}} where BHCK8274 and BHCKA223 are from the Bank Holding Company data by the Federal Reserve Bank of Chicago. 1","title":"Definition"},{"location":"measures/bhc_tier1cap_to_assets/#reference","text":"Rampini, Viswanathan and Vuillemey (2020 JF) . https://www.chicagofed.org/banking/financial-institution-reports/bhc-data . \u21a9","title":"Reference"},{"location":"measures/board_independence/","text":"Board Independence \u00b6 Definition \u00b6 BoardSize \u00b6 Number of directors, where directors are identified as those whose seniority in the BoardEx na_wrds_org_composition table is either \"Executiver Director\" or \"Supervisory Director\". IndependentMembers \u00b6 Number of independent members on board, identified as those directors whose rolename in BoardEx na_wrds_org_composition table contains \"independent\". BoardIndependence \u00b6 Ratio of independent board members to board size. \\text{BoardIndependence}_{i,t}=\\frac{\\text{IndependentMembers}_{i,t}}{\\text{BoardSize}_{i,t}} \\text{BoardIndependence}_{i,t}=\\frac{\\text{IndependentMembers}_{i,t}}{\\text{BoardSize}_{i,t}}","title":"Board Independence"},{"location":"measures/board_independence/#board-independence","text":"","title":"Board Independence"},{"location":"measures/board_independence/#definition","text":"","title":"Definition"},{"location":"measures/board_independence/#boardsize","text":"Number of directors, where directors are identified as those whose seniority in the BoardEx na_wrds_org_composition table is either \"Executiver Director\" or \"Supervisory Director\".","title":"BoardSize"},{"location":"measures/board_independence/#independentmembers","text":"Number of independent members on board, identified as those directors whose rolename in BoardEx na_wrds_org_composition table contains \"independent\".","title":"IndependentMembers"},{"location":"measures/board_independence/#boardindependence","text":"Ratio of independent board members to board size. \\text{BoardIndependence}_{i,t}=\\frac{\\text{IndependentMembers}_{i,t}}{\\text{BoardSize}_{i,t}} \\text{BoardIndependence}_{i,t}=\\frac{\\text{IndependentMembers}_{i,t}}{\\text{BoardSize}_{i,t}}","title":"BoardIndependence"},{"location":"measures/book_leverage/","text":"Book Leverage \u00b6 Definition \u00b6 The book leverage is defined as the amount of debts scaled by the firm's total debts plus common equity. \\text{Book Leverage}_{i,t} = \\frac{DLTT_{i,t}+DLC_{i,t}}{DLTT_{i,t}+DLC_{i,t}+CEQ_{i,t}} \\text{Book Leverage}_{i,t} = \\frac{DLTT_{i,t}+DLC_{i,t}}{DLTT_{i,t}+DLC_{i,t}+CEQ_{i,t}} where DLTT DLTT is the long-term debt, DLC DLC is the debt in current liabilities, and CEQ CEQ is the common equity, all from Compustat Fundamentals Annual WRDS.COMP.FUNDA . If CEQ CEQ is missing, the book leverage is treated as missing.","title":"Book Leverage"},{"location":"measures/book_leverage/#book-leverage","text":"","title":"Book Leverage"},{"location":"measures/book_leverage/#definition","text":"The book leverage is defined as the amount of debts scaled by the firm's total debts plus common equity. \\text{Book Leverage}_{i,t} = \\frac{DLTT_{i,t}+DLC_{i,t}}{DLTT_{i,t}+DLC_{i,t}+CEQ_{i,t}} \\text{Book Leverage}_{i,t} = \\frac{DLTT_{i,t}+DLC_{i,t}}{DLTT_{i,t}+DLC_{i,t}+CEQ_{i,t}} where DLTT DLTT is the long-term debt, DLC DLC is the debt in current liabilities, and CEQ CEQ is the common equity, all from Compustat Fundamentals Annual WRDS.COMP.FUNDA . If CEQ CEQ is missing, the book leverage is treated as missing.","title":"Definition"},{"location":"measures/capital_expenditure/","text":"Capital Expenditure \u00b6 Definition \u00b6 The capital expenditures scaled by total assets. \\text{Capital Expenditure}_{i,t} = \\frac{CAPX_{i,t}}{AT_{i,t}} \\text{Capital Expenditure}_{i,t} = \\frac{CAPX_{i,t}}{AT_{i,t}} where CAPX CAPX and AT AT are from Compustat Fundamentals Annual WRDS.COMP.FUNDA .","title":"Capital Expenditure"},{"location":"measures/capital_expenditure/#capital-expenditure","text":"","title":"Capital Expenditure"},{"location":"measures/capital_expenditure/#definition","text":"The capital expenditures scaled by total assets. \\text{Capital Expenditure}_{i,t} = \\frac{CAPX_{i,t}}{AT_{i,t}} \\text{Capital Expenditure}_{i,t} = \\frac{CAPX_{i,t}}{AT_{i,t}} where CAPX CAPX and AT AT are from Compustat Fundamentals Annual WRDS.COMP.FUNDA .","title":"Definition"},{"location":"measures/credit_rating/","text":"Credit Rating \u00b6 Definition \u00b6 S&P Credit Ratings retrieved from the WRDS Capital IQ database. Specifically, it merges wrds.ciq.erating and wrds.ciq.gvkey by Company ID and if there are multiple ratings issued in a day for the same entity, the last rating data is used. However, there are a few cases where the same entity receive different ratings the same day, and the reporting time data is insufficient to discern the most recent one. For ease of empirical analysis, the S&P ratings are transformed into conventional numerical scores from 1 to 22, where 1 represents a AAA rating and 22 reflects a D rating. Specifically, the mapping is: \"AAA\": 1, \"AA+\": 2, \"AA\": 3, \"AA-\": 4, \"A+\": 5, \"A\": 6, \"A-\": 7, \"BBB+\": 8, \"BBB\": 9, \"BBB-\": 10, \"BB+\": 11, \"BB\": 12, \"BB-\": 13, \"B+\": 14, \"B\": 15, \"B-\": 16, \"CCC+\": 17, \"CCC\": 18, \"CCC-\": 19, \"CC\": 20, \"C\": 21, \"D\": 22. Equivalent SAS Code \u00b6 1 2 3 4 5 6 7 8 9 10 proc sql; create table credt_rating as select distinct company_id, rdate, rating, rtype, b . gvkey from ciq . wrds_erating as a inner join ciq . wrds_gvkey as b on a . company_id=b . companyid and (a . rdate <= b . enddate or b . enddate=.E) and (a . rdate >= b . startdate or b . startdate=.B) and not missing (b . gvkey) and rtype= \"Local Currency LT\" group by gvkey, rdate having rtime= max( rtime) order by company_id, rdate ; quit;","title":"Credit Rating"},{"location":"measures/credit_rating/#credit-rating","text":"","title":"Credit Rating"},{"location":"measures/credit_rating/#definition","text":"S&P Credit Ratings retrieved from the WRDS Capital IQ database. Specifically, it merges wrds.ciq.erating and wrds.ciq.gvkey by Company ID and if there are multiple ratings issued in a day for the same entity, the last rating data is used. However, there are a few cases where the same entity receive different ratings the same day, and the reporting time data is insufficient to discern the most recent one. For ease of empirical analysis, the S&P ratings are transformed into conventional numerical scores from 1 to 22, where 1 represents a AAA rating and 22 reflects a D rating. Specifically, the mapping is: \"AAA\": 1, \"AA+\": 2, \"AA\": 3, \"AA-\": 4, \"A+\": 5, \"A\": 6, \"A-\": 7, \"BBB+\": 8, \"BBB\": 9, \"BBB-\": 10, \"BB+\": 11, \"BB\": 12, \"BB-\": 13, \"B+\": 14, \"B\": 15, \"B-\": 16, \"CCC+\": 17, \"CCC\": 18, \"CCC-\": 19, \"CC\": 20, \"C\": 21, \"D\": 22.","title":"Definition"},{"location":"measures/credit_rating/#equivalent-sas-code","text":"1 2 3 4 5 6 7 8 9 10 proc sql; create table credt_rating as select distinct company_id, rdate, rating, rtype, b . gvkey from ciq . wrds_erating as a inner join ciq . wrds_gvkey as b on a . company_id=b . companyid and (a . rdate <= b . enddate or b . enddate=.E) and (a . rdate >= b . startdate or b . startdate=.B) and not missing (b . gvkey) and rtype= \"Local Currency LT\" group by gvkey, rdate having rtime= max( rtime) order by company_id, rdate ; quit;","title":"Equivalent SAS Code"},{"location":"measures/executive_ownership/","text":"Executive Ownership \u00b6 Definition \u00b6 Executive ownership measures the proportion of the firm's common equity owned by its executives. ExecSharePct \u00b6 Executive-year level, executive share ownership: \\text{ExecSharePct}_{e,t} = \\frac{SHROWN\\_TOT_{e,t}}{CSHO_{i,t}} \\text{ExecSharePct}_{e,t} = \\frac{SHROWN\\_TOT_{e,t}}{CSHO_{i,t}} where SHROWN\\_TOT SHROWN\\_TOT is the shares owned by the executive (as reported) from Compustat Execucomp Annual Compensation EXECCOMP.ANNCOMP , and CSHO CSHO is the common shares outstanding from Compustat Fundamentals Annual WRDS.COMP.FUNDA . ExecSharePctExclOpt \u00b6 Executive-year level, executive share ownership excluding options: \\text{ExecSharePctExclOpt}_{e,t} = \\frac{SHROWN\\_EXCL\\_OPTS_{e,t}}{CSHO_{i,t}} \\text{ExecSharePctExclOpt}_{e,t} = \\frac{SHROWN\\_EXCL\\_OPTS_{e,t}}{CSHO_{i,t}} where SHROWN\\_EXCL\\_OPTS SHROWN\\_EXCL\\_OPTS is the shares owned by the executive, excluding options, from Compustat Execucomp Annual Compensation EXECCOMP.ANNCOMP , and CSHO CSHO is the common shares outstanding from Compustat Fundamentals Annual WRDS.COMP.FUNDA . ExecOptPct \u00b6 Executive-year level, executive share ownership based on shares acquired on option exercise: \\text{ExecOptPct}_{e,t} = \\frac{OPT\\_EXER\\_NUM_{e,t}}{CSHO_{i,t}} \\text{ExecOptPct}_{e,t} = \\frac{OPT\\_EXER\\_NUM_{e,t}}{CSHO_{i,t}} where OPT\\_EXER\\_NUM OPT\\_EXER\\_NUM is the number of shares acquired on option exercise by the executive from Compustat Execucomp Annual Compensation EXECCOMP.ANNCOMP , and CSHO CSHO is the common shares outstanding from Compustat Fundamentals Annual WRDS.COMP.FUNDA . ExecShareVestPct \u00b6 Executive-year level, executive share ownership based on shared acquired on vesting: \\text{ExecShareVestPct}_{e,t} = \\frac{SHRS\\_VEST\\_NUM_{e,t}}{CSHO_{i,t}} \\text{ExecShareVestPct}_{e,t} = \\frac{SHRS\\_VEST\\_NUM_{e,t}}{CSHO_{i,t}} where SHRS\\_VEST\\_NUM SHRS\\_VEST\\_NUM is the number of shares acquired on vesting by the executive from Compustat Execucomp Annual Compensation EXECCOMP.ANNCOMP , and CSHO CSHO is the common shares outstanding from Compustat Fundamentals Annual WRDS.COMP.FUNDA . ExecIncentivePct \u00b6 Executive-year level, value realized on option exercise and vesting scaled by total compensation: \\text{ExecIncentivePct}_{e,t} = \\frac{OPT\\_EXER\\_VAL_{e,t} + SHRS\\_VEST\\_NUM_{e,t}}{TDC1_{e,t}} \\text{ExecIncentivePct}_{e,t} = \\frac{OPT\\_EXER\\_VAL_{e,t} + SHRS\\_VEST\\_NUM_{e,t}}{TDC1_{e,t}} where OPT\\_EXER\\_VAL OPT\\_EXER\\_VAL is the value realized on vesting and TDC1 TDC1 is the executive's total compensation, both from Compustat Execucomp Annual Compensation EXECCOMP.ANNCOMP .","title":"Executive Ownership"},{"location":"measures/executive_ownership/#executive-ownership","text":"","title":"Executive Ownership"},{"location":"measures/executive_ownership/#definition","text":"Executive ownership measures the proportion of the firm's common equity owned by its executives.","title":"Definition"},{"location":"measures/executive_ownership/#execsharepct","text":"Executive-year level, executive share ownership: \\text{ExecSharePct}_{e,t} = \\frac{SHROWN\\_TOT_{e,t}}{CSHO_{i,t}} \\text{ExecSharePct}_{e,t} = \\frac{SHROWN\\_TOT_{e,t}}{CSHO_{i,t}} where SHROWN\\_TOT SHROWN\\_TOT is the shares owned by the executive (as reported) from Compustat Execucomp Annual Compensation EXECCOMP.ANNCOMP , and CSHO CSHO is the common shares outstanding from Compustat Fundamentals Annual WRDS.COMP.FUNDA .","title":"ExecSharePct"},{"location":"measures/executive_ownership/#execsharepctexclopt","text":"Executive-year level, executive share ownership excluding options: \\text{ExecSharePctExclOpt}_{e,t} = \\frac{SHROWN\\_EXCL\\_OPTS_{e,t}}{CSHO_{i,t}} \\text{ExecSharePctExclOpt}_{e,t} = \\frac{SHROWN\\_EXCL\\_OPTS_{e,t}}{CSHO_{i,t}} where SHROWN\\_EXCL\\_OPTS SHROWN\\_EXCL\\_OPTS is the shares owned by the executive, excluding options, from Compustat Execucomp Annual Compensation EXECCOMP.ANNCOMP , and CSHO CSHO is the common shares outstanding from Compustat Fundamentals Annual WRDS.COMP.FUNDA .","title":"ExecSharePctExclOpt"},{"location":"measures/executive_ownership/#execoptpct","text":"Executive-year level, executive share ownership based on shares acquired on option exercise: \\text{ExecOptPct}_{e,t} = \\frac{OPT\\_EXER\\_NUM_{e,t}}{CSHO_{i,t}} \\text{ExecOptPct}_{e,t} = \\frac{OPT\\_EXER\\_NUM_{e,t}}{CSHO_{i,t}} where OPT\\_EXER\\_NUM OPT\\_EXER\\_NUM is the number of shares acquired on option exercise by the executive from Compustat Execucomp Annual Compensation EXECCOMP.ANNCOMP , and CSHO CSHO is the common shares outstanding from Compustat Fundamentals Annual WRDS.COMP.FUNDA .","title":"ExecOptPct"},{"location":"measures/executive_ownership/#execsharevestpct","text":"Executive-year level, executive share ownership based on shared acquired on vesting: \\text{ExecShareVestPct}_{e,t} = \\frac{SHRS\\_VEST\\_NUM_{e,t}}{CSHO_{i,t}} \\text{ExecShareVestPct}_{e,t} = \\frac{SHRS\\_VEST\\_NUM_{e,t}}{CSHO_{i,t}} where SHRS\\_VEST\\_NUM SHRS\\_VEST\\_NUM is the number of shares acquired on vesting by the executive from Compustat Execucomp Annual Compensation EXECCOMP.ANNCOMP , and CSHO CSHO is the common shares outstanding from Compustat Fundamentals Annual WRDS.COMP.FUNDA .","title":"ExecShareVestPct"},{"location":"measures/executive_ownership/#execincentivepct","text":"Executive-year level, value realized on option exercise and vesting scaled by total compensation: \\text{ExecIncentivePct}_{e,t} = \\frac{OPT\\_EXER\\_VAL_{e,t} + SHRS\\_VEST\\_NUM_{e,t}}{TDC1_{e,t}} \\text{ExecIncentivePct}_{e,t} = \\frac{OPT\\_EXER\\_VAL_{e,t} + SHRS\\_VEST\\_NUM_{e,t}}{TDC1_{e,t}} where OPT\\_EXER\\_VAL OPT\\_EXER\\_VAL is the value realized on vesting and TDC1 TDC1 is the executive's total compensation, both from Compustat Execucomp Annual Compensation EXECCOMP.ANNCOMP .","title":"ExecIncentivePct"},{"location":"measures/firm_size/","text":"Firm Size \u00b6 Definition \u00b6 The natural logarithm of total assets. \\text{Firm Size}_{i,t} = \\ln \\left( AT_{i,t} \\right) \\text{Firm Size}_{i,t} = \\ln \\left( AT_{i,t} \\right) where AT AT is from Compustat Fundamentals Annual WRDS.COMP.FUNDA .","title":"Firm Size"},{"location":"measures/firm_size/#firm-size","text":"","title":"Firm Size"},{"location":"measures/firm_size/#definition","text":"The natural logarithm of total assets. \\text{Firm Size}_{i,t} = \\ln \\left( AT_{i,t} \\right) \\text{Firm Size}_{i,t} = \\ln \\left( AT_{i,t} \\right) where AT AT is from Compustat Fundamentals Annual WRDS.COMP.FUNDA .","title":"Definition"},{"location":"measures/kyleslambda/","text":"Kyle's Lambda \u00b6 A measure of market impact cost from Kyle (1985), which can be interpreted as the cost of demanding a certain amount of liquidity over a given time period. Definition \u00b6 Following Hasbrouck (2009) and Goyenko, Holden, Trzcinka (2009), Kyle's Lambda for a given stock i i and day t t , is calculated as the slope coefficient \\lambda_{i,t} \\lambda_{i,t} in the regression: ret_{i,t,n}= \\delta_{i,t} + \\lambda_{i,t} S_{i,t,n}+\\epsilon_{i,t,n} ret_{i,t,n}= \\delta_{i,t} + \\lambda_{i,t} S_{i,t,n}+\\epsilon_{i,t,n} where for the n n th five-minute period on date t t and stock i i , ret_{i,t,n} ret_{i,t,n} is the stock return and S_{i,t,n} S_{i,t,n} is the sum of the signed square-root dollar volume, that is, S_{i,t,n}=\\sum_k{sign}(dvol_{i,t,n,k}) \\sqrt{dvol_{i,t,n,k}} S_{i,t,n}=\\sum_k{sign}(dvol_{i,t,n,k}) \\sqrt{dvol_{i,t,n,k}} Source Code \u00b6 This example Python code is not optimized for speed and serves only demonstration purpose. It may contain errors. It returns \\lambda \\times 10^6 \\lambda \\times 10^6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 # KylesLambda.py import numpy as np name = 'KylesLambda' description = \"\"\" A measure of market impact cost from Kyle (1985), which can be interpreted as the cost of demanding a certain amount of liquidity over a given time period. Result is Lambda*1E6. \"\"\" vars_needed = [ 'Price' , 'Volume' , 'Direction' ] def estimate ( data ): price = data [ 'Price' ] . to_numpy () volume = data [ 'Volume' ] . to_numpy () direction = data [ 'Direction' ] . to_numpy () sqrt_dollar_volume = np . sqrt ( np . multiply ( price , volume )) signed_sqrt_dollar_volume = np . abs ( np . multiply ( direction , sqrt_dollar_volume )) # Find the total signed sqrt dollar volume and return per 5 min. timestamps = np . array ( data . index , dtype = 'datetime64' ) last_ts , last_price = timestamps [ 0 ], price [ 0 ] bracket_ssdv = 0 bracket = last_ts + np . timedelta64 ( 5 , 'm' ) rets , ssdvs , = [], [] for idx , ts in enumerate ( timestamps ): if ts <= bracket : bracket_ssdv += signed_sqrt_dollar_volume [ idx ] else : ret = np . log ( price [ idx - 1 ] / last_price ) if not np . isnan ( ret ) and not np . isnan ( bracket_ssdv ): rets . append ( ret ) ssdvs . append ( bracket_ssdv ) # Reset bracket bracket = ts + np . timedelta64 ( 5 , 'm' ) last_price = price [ idx ] bracket_ssdv = signed_sqrt_dollar_volume [ idx ] # Perform regression. x = np . vstack ([ np . ones ( len ( ssdvs )), np . array ( ssdvs )]) . T try : coef , _ , _ , _ = np . linalg . lstsq ( x , np . array ( rets ), rcond = None ) except np . linalg . LinAlgError : return None else : return None if np . isnan ( coef [ 1 ]) else coef [ 1 ] * 1E6","title":"Kyle's Lambda"},{"location":"measures/kyleslambda/#kyles-lambda","text":"A measure of market impact cost from Kyle (1985), which can be interpreted as the cost of demanding a certain amount of liquidity over a given time period.","title":"Kyle's Lambda"},{"location":"measures/kyleslambda/#definition","text":"Following Hasbrouck (2009) and Goyenko, Holden, Trzcinka (2009), Kyle's Lambda for a given stock i i and day t t , is calculated as the slope coefficient \\lambda_{i,t} \\lambda_{i,t} in the regression: ret_{i,t,n}= \\delta_{i,t} + \\lambda_{i,t} S_{i,t,n}+\\epsilon_{i,t,n} ret_{i,t,n}= \\delta_{i,t} + \\lambda_{i,t} S_{i,t,n}+\\epsilon_{i,t,n} where for the n n th five-minute period on date t t and stock i i , ret_{i,t,n} ret_{i,t,n} is the stock return and S_{i,t,n} S_{i,t,n} is the sum of the signed square-root dollar volume, that is, S_{i,t,n}=\\sum_k{sign}(dvol_{i,t,n,k}) \\sqrt{dvol_{i,t,n,k}} S_{i,t,n}=\\sum_k{sign}(dvol_{i,t,n,k}) \\sqrt{dvol_{i,t,n,k}}","title":"Definition"},{"location":"measures/kyleslambda/#source-code","text":"This example Python code is not optimized for speed and serves only demonstration purpose. It may contain errors. It returns \\lambda \\times 10^6 \\lambda \\times 10^6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 # KylesLambda.py import numpy as np name = 'KylesLambda' description = \"\"\" A measure of market impact cost from Kyle (1985), which can be interpreted as the cost of demanding a certain amount of liquidity over a given time period. Result is Lambda*1E6. \"\"\" vars_needed = [ 'Price' , 'Volume' , 'Direction' ] def estimate ( data ): price = data [ 'Price' ] . to_numpy () volume = data [ 'Volume' ] . to_numpy () direction = data [ 'Direction' ] . to_numpy () sqrt_dollar_volume = np . sqrt ( np . multiply ( price , volume )) signed_sqrt_dollar_volume = np . abs ( np . multiply ( direction , sqrt_dollar_volume )) # Find the total signed sqrt dollar volume and return per 5 min. timestamps = np . array ( data . index , dtype = 'datetime64' ) last_ts , last_price = timestamps [ 0 ], price [ 0 ] bracket_ssdv = 0 bracket = last_ts + np . timedelta64 ( 5 , 'm' ) rets , ssdvs , = [], [] for idx , ts in enumerate ( timestamps ): if ts <= bracket : bracket_ssdv += signed_sqrt_dollar_volume [ idx ] else : ret = np . log ( price [ idx - 1 ] / last_price ) if not np . isnan ( ret ) and not np . isnan ( bracket_ssdv ): rets . append ( ret ) ssdvs . append ( bracket_ssdv ) # Reset bracket bracket = ts + np . timedelta64 ( 5 , 'm' ) last_price = price [ idx ] bracket_ssdv = signed_sqrt_dollar_volume [ idx ] # Perform regression. x = np . vstack ([ np . ones ( len ( ssdvs )), np . array ( ssdvs )]) . T try : coef , _ , _ , _ = np . linalg . lstsq ( x , np . array ( rets ), rcond = None ) except np . linalg . LinAlgError : return None else : return None if np . isnan ( coef [ 1 ]) else coef [ 1 ] * 1E6","title":"Source Code"},{"location":"measures/lomackinlay1988/","text":"Variance Ratio Test - Lo and MacKinlay (1988) \u00b6 A simple test for the random walk hypothesis of prices and efficient market. Definition \u00b6 Let's assume: a price series \\{p_t\\}=\\{p_0,p_1,p_2,...,p_T\\} \\{p_t\\}=\\{p_0,p_1,p_2,...,p_T\\} and a log return series \\{x_t\\}=\\{x_1, x_2, ..., x_T\\} \\{x_t\\}=\\{x_1, x_2, ..., x_T\\} where x_t=\\ln \\frac{p_t}{p_{t-1}} x_t=\\ln \\frac{p_t}{p_{t-1}} Variance Ratio (VR) \u00b6 The variance ratio of k k -period return is defined as: \\textit{V}(k)=\\frac{\\textit{Var}(x_t+x_{t-1}+...+x_{t-k+1})/k}{\\textit{Var}(x_t)} \\textit{V}(k)=\\frac{\\textit{Var}(x_t+x_{t-1}+...+x_{t-k+1})/k}{\\textit{Var}(x_t)} The estimator of \\textit{V}(k) \\textit{V}(k) proposed in Lo and MacKinlay (1988) is \\textit{VR}(k)=\\frac{\\hat\\sigma^2(k)}{\\hat\\sigma^2(1)} \\textit{VR}(k)=\\frac{\\hat\\sigma^2(k)}{\\hat\\sigma^2(1)} where \\hat\\sigma^2(1) \\hat\\sigma^2(1) is the unbiased estimator of the one-period return variance, using the one-period returns \\{x_t\\} \\{x_t\\} , and is defined as \\hat\\sigma^2(1)=\\frac{1}{T-1} \\sum_{t-1}^T (x_t - \\hat\\mu)^2 \\hat\\sigma^2(1)=\\frac{1}{T-1} \\sum_{t-1}^T (x_t - \\hat\\mu)^2 and \\hat\\sigma^2(k) \\hat\\sigma^2(k) is the estimator of k k -period return variance using k k -period returns. Lo and MacKinlay (1988) defined it, due to limited sample size and the desire to improve the power of the test, as \\hat\\sigma^2(k)=\\frac{1}{m} \\sum_{t-1}^T \\left(\\ln\\frac{P_t}{P_{t-k}} - k\\hat\\mu \\right)^2 \\hat\\sigma^2(k)=\\frac{1}{m} \\sum_{t-1}^T \\left(\\ln\\frac{P_t}{P_{t-k}} - k\\hat\\mu \\right)^2 where m=k(T-k+1)(1-k/T) m=k(T-k+1)(1-k/T) is chosen such that \\hat\\sigma^2(k) \\hat\\sigma^2(k) is an unbiased estimator of the k k -period return variance when \\sigma^2_t \\sigma^2_t is constant over time. Variance Ratio Test Statistics \u00b6 Lo and MacKinlay (1988) proposed that under the null hypothesis of V(k)=1 V(k)=1 , the test statistic is given by Z(k)=\\frac{\\textit{VR}(k)-1}{\\sqrt{\\phi(k)}} Z(k)=\\frac{\\textit{VR}(k)-1}{\\sqrt{\\phi(k)}} which follows the standard normal distribution asymptotically. Homoscedasticity \u00b6 Under the assumption of homoscedasticity, the asymptotic variance \\phi \\phi is given by \\phi(k)=\\frac{2(2k-1)(k-1)}{3kT} \\phi(k)=\\frac{2(2k-1)(k-1)}{3kT} Heteroscedasticity \u00b6 Under the assumption of heteroscedasticity, the asymptotic variance \\phi \\phi is given by \\phi(k)=\\sum_{j=1}^{k-1} \\left[\\frac{2(k-j)}{k} \\right]^2\\delta(j) \\phi(k)=\\sum_{j=1}^{k-1} \\left[\\frac{2(k-j)}{k} \\right]^2\\delta(j) \\delta(j)=\\frac{\\sum_{t=j+1}^T (x_t - \\hat\\mu)^2(x_{t-j} - \\hat\\mu)^2}{\\left[\\sum_{t=1}^T (x_t - \\hat\\mu)^2\\right]^2} \\delta(j)=\\frac{\\sum_{t=j+1}^T (x_t - \\hat\\mu)^2(x_{t-j} - \\hat\\mu)^2}{\\left[\\sum_{t=1}^T (x_t - \\hat\\mu)^2\\right]^2} Erratum Note that there's a missing T T in the numerator of \\delta(j) \\delta(j) above. It is actually missing the 1988 RFS paper and the 1998 JE'mtric paper, but has been corrected in the 1990 RFS Issue 1: https://doi.org/10.1093/rfs/3.1.ii . The corrected version reads: \\delta(j)=\\frac{T\\sum_{t=j+1}^T (x_t - \\hat\\mu)^2(x_{t-j} - \\hat\\mu)^2}{\\left[\\sum_{t=1}^T (x_t - \\hat\\mu)^2\\right]^2} \\delta(j)=\\frac{T\\sum_{t=j+1}^T (x_t - \\hat\\mu)^2(x_{t-j} - \\hat\\mu)^2}{\\left[\\sum_{t=1}^T (x_t - \\hat\\mu)^2\\right]^2} To correct it in the example code below, change the highlighted line 51 to: 1 delta_arr = T * b_arr / np.square(np.sum(sqr_demeaned_x)) I thank Simon Jurkatis for letting me know about the erratum. Source Code \u00b6 This example Python code has been optimized for speed but serves only demonstration purpose. It may contain errors. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 # LoMacKinlay.py import numpy as np from numba import jit name = 'LoMacKinlay1988' description = 'Variance ratio and test statistics as in Lo and MacKinlay (1988)' vars_needed = [ 'Price' ] @jit ( nopython = True , nogil = True , cache = True ) def _estimate ( log_prices , k , const_arr ): # Log returns = [x2, x3, x4, ..., xT], where x(i)=ln[p(i)/p(i-1)] rets = np . diff ( log_prices ) # T is the length of return series T = len ( rets ) # mu is the mean log return mu = np . mean ( rets ) # sqr_demeaned_x is the array of squared demeaned log returns sqr_demeaned_x = np . square ( rets - mu ) # Var(1) # Didn't use np.var(rets, ddof=1) because # sqr_demeaned_x is calculated already and will be used many times. var_1 = np . sum ( sqr_demeaned_x ) / ( T - 1 ) # Var(k) # Variance of log returns where x(i) = ln[p(i)/p(i-k)] # Before np.roll() - array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) # After np.roll(,shift=2) - array([8, 9, 0, 1, 2, 3, 4, 5, 6, 7]) # Discard the first k elements. rets_k = ( log_prices - np . roll ( log_prices , k ))[ k :] m = k * ( T - k + 1 ) * ( 1 - k / T ) var_k = 1 / m * np . sum ( np . square ( rets_k - k * mu )) # Variance Ratio vr = var_k / var_1 # a_arr is an array of { (2*(k-j)/k)^2 } for j=1,2,...,k-1, fixed for a given k: # When k=5, a_arr = array([2.56, 1.44, 0.64, 0.16]). # When k=8, a_arr = array([3.0625, 2.25, 1.5625, 1., 0.5625, 0.25, 0.0625]) # Without JIT it's defined as: # a_arr = np.square(np.arange(k-1, 0, step=-1, dtype=np.int) * 2 / k) # But np.array creation is not allowed in nopython mode. # So const_arr=np.arange(k-1, 0, step=-1, dtype=np.int) is created outside. a_arr = np . square ( const_arr * 2 / k ) # b_arr is part of the delta_arr. b_arr = np . empty ( k - 1 , dtype = np . float64 ) for j in range ( 1 , k ): b_arr [ j - 1 ] = np . sum (( sqr_demeaned_x * np . roll ( sqr_demeaned_x , j ))[ j + 1 :]) delta_arr = b_arr / np . square ( np . sum ( sqr_demeaned_x )) # Both arrarys are of length (k-1) assert len ( delta_arr ) == len ( a_arr ) == k - 1 phi1 = 2 * ( 2 * k - 1 ) * ( k - 1 ) / ( 3 * k * T ) phi2 = np . sum ( a_arr * delta_arr ) # VR test statistics under two assumptions vr_stat_homoscedasticity = ( vr - 1 ) / np . sqrt ( phi1 ) vr_stat_heteroscedasticity = ( vr - 1 ) / np . sqrt ( phi2 ) return vr , vr_stat_homoscedasticity , vr_stat_heteroscedasticity def estimate ( data ): \"A fast estimation of Variance Ratio test statistics as in Lo and MacKinlay (1988)\" # Prices array = [p1, p2, p3, p4, ..., pT] prices = data [ 'Price' ] . to_numpy ( dtype = np . float64 ) result = [] # Estimate many lags. for k in [ 2 , 4 , 6 , 8 , 10 , 15 , 20 , 30 , 40 , 50 , 100 , 200 , 500 , 1000 ]: # Compute a constant array as np.array creation is not allowed in nopython mode. const_arr = np . arange ( k - 1 , 0 , step =- 1 , dtype = np . int ) vr , stat1 , stat2 = _estimate ( np . log ( prices ), k , const_arr ) result . append ({ f 'Variance Ratio (k= { k } )' : vr , f 'Variance Ratio Test Statistic (k= { k } ) Homoscedasticity Assumption' : stat1 , f 'Variance Ratio Test Statistic (k= { k } ) Heteroscedasticity Assumption' : stat2 }) return result As an example, let's create 1 million prices from random walk and estimate the variance ratio and two test statistics at various lags. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 if __name__ == \"__main__\" : import pandas as pd from pprint import pprint np . random . seed ( 1 ) # Generate random steps with mean=0 and standard deviation=1 steps = np . random . normal ( 0 , 1 , size = 1000000 ) # Set first element to 0 so that the first price will be the starting stock price steps [ 0 ] = 0 # Simulate stock prices, P with a large starting price P = 10000 + np . cumsum ( steps ) # Test data = pd . DataFrame ( P , columns = [ 'Price' ]) result = estimate ( data ) pprint ( result ) In just a few seconds, the output is: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 [{ 'Variance Ratio (k=2)' : 1.0003293867428105 , 'Variance Ratio Test Statistic (k=2) Heteroscedasticity Assumption' : 0.3290463403922243 , 'Variance Ratio Test Statistic (k=2) Homoscedasticity Assumption' : 0.32938657811705435 }, { 'Variance Ratio (k=4)' : 1.0007984480057006 , 'Variance Ratio Test Statistic (k=4) Heteroscedasticity Assumption' : 0.4259533413884602 , 'Variance Ratio Test Statistic (k=4) Homoscedasticity Assumption' : 0.4267881978178301 }, { 'Variance Ratio (k=6)' : 0.9999130202975425 , 'Variance Ratio Test Statistic (k=6) Heteroscedasticity Assumption' : - 0.035117568315004344 , 'Variance Ratio Test Statistic (k=6) Homoscedasticity Assumption' : - 0.03518500446785826 }, { 'Variance Ratio (k=8)' : 1.0001094011344318 , 'Variance Ratio Test Statistic (k=8) Heteroscedasticity Assumption' : 0.036922688136577515 , 'Variance Ratio Test Statistic (k=8) Homoscedasticity Assumption' : 0.03698431520269611 }, { 'Variance Ratio (k=10)' : 1.000702410129927 , 'Variance Ratio Test Statistic (k=10) Heteroscedasticity Assumption' : 0.20772743120012313 , 'Variance Ratio Test Statistic (k=10) Homoscedasticity Assumption' : 0.20803582207641647 }, { 'Variance Ratio (k=15)' : 1.0022173139633856 , 'Variance Ratio Test Statistic (k=15) Heteroscedasticity Assumption' : 0.5213067838911684 , 'Variance Ratio Test Statistic (k=15) Homoscedasticity Assumption' : 0.5219816274021579 }, { 'Variance Ratio (k=20)' : 1.0038048661705044 , 'Variance Ratio Test Statistic (k=20) Heteroscedasticity Assumption' : 0.7646395131154204 , 'Variance Ratio Test Statistic (k=20) Homoscedasticity Assumption' : 0.7655801985571125 }, { 'Variance Ratio (k=30)' : 1.0054447472916035 , 'Variance Ratio Test Statistic (k=30) Heteroscedasticity Assumption' : 0.8819250061384853 , 'Variance Ratio Test Statistic (k=30) Homoscedasticity Assumption' : 0.8829960534692654 }, { 'Variance Ratio (k=40)' : 1.0073830253022766 , 'Variance Ratio Test Statistic (k=40) Heteroscedasticity Assumption' : 1.0290213306735625 , 'Variance Ratio Test Statistic (k=40) Homoscedasticity Assumption' : 1.0303005120740392 }, { 'Variance Ratio (k=50)' : 1.0086502431826903 , 'Variance Ratio Test Statistic (k=50) Heteroscedasticity Assumption' : 1.0741837462564026 , 'Variance Ratio Test Statistic (k=50) Homoscedasticity Assumption' : 1.0755809312730416 }, { 'Variance Ratio (k=100)' : 1.0153961901671604 , 'Variance Ratio Test Statistic (k=100) Heteroscedasticity Assumption' : 1.3415119471043384 , 'Variance Ratio Test Statistic (k=100) Homoscedasticity Assumption' : 1.3434284573260773 }, { 'Variance Ratio (k=200)' : 1.0157046541161026 , 'Variance Ratio Test Statistic (k=200) Heteroscedasticity Assumption' : 0.9639233626580027 , 'Variance Ratio Test Statistic (k=200) Homoscedasticity Assumption' : 0.9653299929052963 }, { 'Variance Ratio (k=500)' : 1.0182166207668526 , 'Variance Ratio Test Statistic (k=500) Heteroscedasticity Assumption' : 0.7055681216511915 , 'Variance Ratio Test Statistic (k=500) Homoscedasticity Assumption' : 0.7065863036900429 }, { 'Variance Ratio (k=1000)' : 1.0187822241562863 , 'Variance Ratio Test Statistic (k=1000) Heteroscedasticity Assumption' : 0.5140698821944161 , 'Variance Ratio Test Statistic (k=1000) Homoscedasticity Assumption' : 0.5147582201029065 }] It's easy to see that at all lags tested, we cannot reject the null hypothesis that this price series follows a random walk. For comparison purpose, below is an implementation in pure Python. It is more readable but is significantly slower. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 def estimate_python ( data , k = 5 ): \"A slow pure python implementation\" prices = data [ 'Price' ] . to_numpy ( dtype = np . float64 ) log_prices = np . log ( prices ) rets = np . diff ( log_prices ) T = len ( rets ) mu = np . mean ( rets ) var_1 = np . var ( rets , ddof = 1 , dtype = np . float64 ) rets_k = ( log_prices - np . roll ( log_prices , k ))[ k :] m = k * ( T - k + 1 ) * ( 1 - k / T ) var_k = 1 / m * np . sum ( np . square ( rets_k - k * mu )) # Variance Ratio vr = var_k / var_1 # Phi1 phi1 = 2 * ( 2 * k - 1 ) * ( k - 1 ) / ( 3 * k * T ) # Phi2 def delta ( j ): res = 0 for t in range ( j + 1 , T + 1 ): t -= 1 # array index is t-1 for t-th element res += np . square (( rets [ t ] - mu ) * ( rets [ t - j ] - mu )) return res / (( T - 1 ) * var_1 ) ** 2 phi2 = 0 for j in range ( 1 , k ): phi2 += ( 2 * ( k - j ) / k ) ** 2 * delta ( j ) return vr , ( vr - 1 ) / np . sqrt ( phi1 ), ( vr - 1 ) / np . sqrt ( phi2 )","title":"Lo and MacKinlay (1988)"},{"location":"measures/lomackinlay1988/#variance-ratio-test-lo-and-mackinlay-1988","text":"A simple test for the random walk hypothesis of prices and efficient market.","title":"Variance Ratio Test - Lo and MacKinlay (1988)"},{"location":"measures/lomackinlay1988/#definition","text":"Let's assume: a price series \\{p_t\\}=\\{p_0,p_1,p_2,...,p_T\\} \\{p_t\\}=\\{p_0,p_1,p_2,...,p_T\\} and a log return series \\{x_t\\}=\\{x_1, x_2, ..., x_T\\} \\{x_t\\}=\\{x_1, x_2, ..., x_T\\} where x_t=\\ln \\frac{p_t}{p_{t-1}} x_t=\\ln \\frac{p_t}{p_{t-1}}","title":"Definition"},{"location":"measures/lomackinlay1988/#variance-ratio-vr","text":"The variance ratio of k k -period return is defined as: \\textit{V}(k)=\\frac{\\textit{Var}(x_t+x_{t-1}+...+x_{t-k+1})/k}{\\textit{Var}(x_t)} \\textit{V}(k)=\\frac{\\textit{Var}(x_t+x_{t-1}+...+x_{t-k+1})/k}{\\textit{Var}(x_t)} The estimator of \\textit{V}(k) \\textit{V}(k) proposed in Lo and MacKinlay (1988) is \\textit{VR}(k)=\\frac{\\hat\\sigma^2(k)}{\\hat\\sigma^2(1)} \\textit{VR}(k)=\\frac{\\hat\\sigma^2(k)}{\\hat\\sigma^2(1)} where \\hat\\sigma^2(1) \\hat\\sigma^2(1) is the unbiased estimator of the one-period return variance, using the one-period returns \\{x_t\\} \\{x_t\\} , and is defined as \\hat\\sigma^2(1)=\\frac{1}{T-1} \\sum_{t-1}^T (x_t - \\hat\\mu)^2 \\hat\\sigma^2(1)=\\frac{1}{T-1} \\sum_{t-1}^T (x_t - \\hat\\mu)^2 and \\hat\\sigma^2(k) \\hat\\sigma^2(k) is the estimator of k k -period return variance using k k -period returns. Lo and MacKinlay (1988) defined it, due to limited sample size and the desire to improve the power of the test, as \\hat\\sigma^2(k)=\\frac{1}{m} \\sum_{t-1}^T \\left(\\ln\\frac{P_t}{P_{t-k}} - k\\hat\\mu \\right)^2 \\hat\\sigma^2(k)=\\frac{1}{m} \\sum_{t-1}^T \\left(\\ln\\frac{P_t}{P_{t-k}} - k\\hat\\mu \\right)^2 where m=k(T-k+1)(1-k/T) m=k(T-k+1)(1-k/T) is chosen such that \\hat\\sigma^2(k) \\hat\\sigma^2(k) is an unbiased estimator of the k k -period return variance when \\sigma^2_t \\sigma^2_t is constant over time.","title":"Variance Ratio (VR)"},{"location":"measures/lomackinlay1988/#variance-ratio-test-statistics","text":"Lo and MacKinlay (1988) proposed that under the null hypothesis of V(k)=1 V(k)=1 , the test statistic is given by Z(k)=\\frac{\\textit{VR}(k)-1}{\\sqrt{\\phi(k)}} Z(k)=\\frac{\\textit{VR}(k)-1}{\\sqrt{\\phi(k)}} which follows the standard normal distribution asymptotically.","title":"Variance Ratio Test Statistics"},{"location":"measures/lomackinlay1988/#homoscedasticity","text":"Under the assumption of homoscedasticity, the asymptotic variance \\phi \\phi is given by \\phi(k)=\\frac{2(2k-1)(k-1)}{3kT} \\phi(k)=\\frac{2(2k-1)(k-1)}{3kT}","title":"Homoscedasticity"},{"location":"measures/lomackinlay1988/#heteroscedasticity","text":"Under the assumption of heteroscedasticity, the asymptotic variance \\phi \\phi is given by \\phi(k)=\\sum_{j=1}^{k-1} \\left[\\frac{2(k-j)}{k} \\right]^2\\delta(j) \\phi(k)=\\sum_{j=1}^{k-1} \\left[\\frac{2(k-j)}{k} \\right]^2\\delta(j) \\delta(j)=\\frac{\\sum_{t=j+1}^T (x_t - \\hat\\mu)^2(x_{t-j} - \\hat\\mu)^2}{\\left[\\sum_{t=1}^T (x_t - \\hat\\mu)^2\\right]^2} \\delta(j)=\\frac{\\sum_{t=j+1}^T (x_t - \\hat\\mu)^2(x_{t-j} - \\hat\\mu)^2}{\\left[\\sum_{t=1}^T (x_t - \\hat\\mu)^2\\right]^2} Erratum Note that there's a missing T T in the numerator of \\delta(j) \\delta(j) above. It is actually missing the 1988 RFS paper and the 1998 JE'mtric paper, but has been corrected in the 1990 RFS Issue 1: https://doi.org/10.1093/rfs/3.1.ii . The corrected version reads: \\delta(j)=\\frac{T\\sum_{t=j+1}^T (x_t - \\hat\\mu)^2(x_{t-j} - \\hat\\mu)^2}{\\left[\\sum_{t=1}^T (x_t - \\hat\\mu)^2\\right]^2} \\delta(j)=\\frac{T\\sum_{t=j+1}^T (x_t - \\hat\\mu)^2(x_{t-j} - \\hat\\mu)^2}{\\left[\\sum_{t=1}^T (x_t - \\hat\\mu)^2\\right]^2} To correct it in the example code below, change the highlighted line 51 to: 1 delta_arr = T * b_arr / np.square(np.sum(sqr_demeaned_x)) I thank Simon Jurkatis for letting me know about the erratum.","title":"Heteroscedasticity"},{"location":"measures/lomackinlay1988/#source-code","text":"This example Python code has been optimized for speed but serves only demonstration purpose. It may contain errors. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 # LoMacKinlay.py import numpy as np from numba import jit name = 'LoMacKinlay1988' description = 'Variance ratio and test statistics as in Lo and MacKinlay (1988)' vars_needed = [ 'Price' ] @jit ( nopython = True , nogil = True , cache = True ) def _estimate ( log_prices , k , const_arr ): # Log returns = [x2, x3, x4, ..., xT], where x(i)=ln[p(i)/p(i-1)] rets = np . diff ( log_prices ) # T is the length of return series T = len ( rets ) # mu is the mean log return mu = np . mean ( rets ) # sqr_demeaned_x is the array of squared demeaned log returns sqr_demeaned_x = np . square ( rets - mu ) # Var(1) # Didn't use np.var(rets, ddof=1) because # sqr_demeaned_x is calculated already and will be used many times. var_1 = np . sum ( sqr_demeaned_x ) / ( T - 1 ) # Var(k) # Variance of log returns where x(i) = ln[p(i)/p(i-k)] # Before np.roll() - array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) # After np.roll(,shift=2) - array([8, 9, 0, 1, 2, 3, 4, 5, 6, 7]) # Discard the first k elements. rets_k = ( log_prices - np . roll ( log_prices , k ))[ k :] m = k * ( T - k + 1 ) * ( 1 - k / T ) var_k = 1 / m * np . sum ( np . square ( rets_k - k * mu )) # Variance Ratio vr = var_k / var_1 # a_arr is an array of { (2*(k-j)/k)^2 } for j=1,2,...,k-1, fixed for a given k: # When k=5, a_arr = array([2.56, 1.44, 0.64, 0.16]). # When k=8, a_arr = array([3.0625, 2.25, 1.5625, 1., 0.5625, 0.25, 0.0625]) # Without JIT it's defined as: # a_arr = np.square(np.arange(k-1, 0, step=-1, dtype=np.int) * 2 / k) # But np.array creation is not allowed in nopython mode. # So const_arr=np.arange(k-1, 0, step=-1, dtype=np.int) is created outside. a_arr = np . square ( const_arr * 2 / k ) # b_arr is part of the delta_arr. b_arr = np . empty ( k - 1 , dtype = np . float64 ) for j in range ( 1 , k ): b_arr [ j - 1 ] = np . sum (( sqr_demeaned_x * np . roll ( sqr_demeaned_x , j ))[ j + 1 :]) delta_arr = b_arr / np . square ( np . sum ( sqr_demeaned_x )) # Both arrarys are of length (k-1) assert len ( delta_arr ) == len ( a_arr ) == k - 1 phi1 = 2 * ( 2 * k - 1 ) * ( k - 1 ) / ( 3 * k * T ) phi2 = np . sum ( a_arr * delta_arr ) # VR test statistics under two assumptions vr_stat_homoscedasticity = ( vr - 1 ) / np . sqrt ( phi1 ) vr_stat_heteroscedasticity = ( vr - 1 ) / np . sqrt ( phi2 ) return vr , vr_stat_homoscedasticity , vr_stat_heteroscedasticity def estimate ( data ): \"A fast estimation of Variance Ratio test statistics as in Lo and MacKinlay (1988)\" # Prices array = [p1, p2, p3, p4, ..., pT] prices = data [ 'Price' ] . to_numpy ( dtype = np . float64 ) result = [] # Estimate many lags. for k in [ 2 , 4 , 6 , 8 , 10 , 15 , 20 , 30 , 40 , 50 , 100 , 200 , 500 , 1000 ]: # Compute a constant array as np.array creation is not allowed in nopython mode. const_arr = np . arange ( k - 1 , 0 , step =- 1 , dtype = np . int ) vr , stat1 , stat2 = _estimate ( np . log ( prices ), k , const_arr ) result . append ({ f 'Variance Ratio (k= { k } )' : vr , f 'Variance Ratio Test Statistic (k= { k } ) Homoscedasticity Assumption' : stat1 , f 'Variance Ratio Test Statistic (k= { k } ) Heteroscedasticity Assumption' : stat2 }) return result As an example, let's create 1 million prices from random walk and estimate the variance ratio and two test statistics at various lags. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 if __name__ == \"__main__\" : import pandas as pd from pprint import pprint np . random . seed ( 1 ) # Generate random steps with mean=0 and standard deviation=1 steps = np . random . normal ( 0 , 1 , size = 1000000 ) # Set first element to 0 so that the first price will be the starting stock price steps [ 0 ] = 0 # Simulate stock prices, P with a large starting price P = 10000 + np . cumsum ( steps ) # Test data = pd . DataFrame ( P , columns = [ 'Price' ]) result = estimate ( data ) pprint ( result ) In just a few seconds, the output is: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 [{ 'Variance Ratio (k=2)' : 1.0003293867428105 , 'Variance Ratio Test Statistic (k=2) Heteroscedasticity Assumption' : 0.3290463403922243 , 'Variance Ratio Test Statistic (k=2) Homoscedasticity Assumption' : 0.32938657811705435 }, { 'Variance Ratio (k=4)' : 1.0007984480057006 , 'Variance Ratio Test Statistic (k=4) Heteroscedasticity Assumption' : 0.4259533413884602 , 'Variance Ratio Test Statistic (k=4) Homoscedasticity Assumption' : 0.4267881978178301 }, { 'Variance Ratio (k=6)' : 0.9999130202975425 , 'Variance Ratio Test Statistic (k=6) Heteroscedasticity Assumption' : - 0.035117568315004344 , 'Variance Ratio Test Statistic (k=6) Homoscedasticity Assumption' : - 0.03518500446785826 }, { 'Variance Ratio (k=8)' : 1.0001094011344318 , 'Variance Ratio Test Statistic (k=8) Heteroscedasticity Assumption' : 0.036922688136577515 , 'Variance Ratio Test Statistic (k=8) Homoscedasticity Assumption' : 0.03698431520269611 }, { 'Variance Ratio (k=10)' : 1.000702410129927 , 'Variance Ratio Test Statistic (k=10) Heteroscedasticity Assumption' : 0.20772743120012313 , 'Variance Ratio Test Statistic (k=10) Homoscedasticity Assumption' : 0.20803582207641647 }, { 'Variance Ratio (k=15)' : 1.0022173139633856 , 'Variance Ratio Test Statistic (k=15) Heteroscedasticity Assumption' : 0.5213067838911684 , 'Variance Ratio Test Statistic (k=15) Homoscedasticity Assumption' : 0.5219816274021579 }, { 'Variance Ratio (k=20)' : 1.0038048661705044 , 'Variance Ratio Test Statistic (k=20) Heteroscedasticity Assumption' : 0.7646395131154204 , 'Variance Ratio Test Statistic (k=20) Homoscedasticity Assumption' : 0.7655801985571125 }, { 'Variance Ratio (k=30)' : 1.0054447472916035 , 'Variance Ratio Test Statistic (k=30) Heteroscedasticity Assumption' : 0.8819250061384853 , 'Variance Ratio Test Statistic (k=30) Homoscedasticity Assumption' : 0.8829960534692654 }, { 'Variance Ratio (k=40)' : 1.0073830253022766 , 'Variance Ratio Test Statistic (k=40) Heteroscedasticity Assumption' : 1.0290213306735625 , 'Variance Ratio Test Statistic (k=40) Homoscedasticity Assumption' : 1.0303005120740392 }, { 'Variance Ratio (k=50)' : 1.0086502431826903 , 'Variance Ratio Test Statistic (k=50) Heteroscedasticity Assumption' : 1.0741837462564026 , 'Variance Ratio Test Statistic (k=50) Homoscedasticity Assumption' : 1.0755809312730416 }, { 'Variance Ratio (k=100)' : 1.0153961901671604 , 'Variance Ratio Test Statistic (k=100) Heteroscedasticity Assumption' : 1.3415119471043384 , 'Variance Ratio Test Statistic (k=100) Homoscedasticity Assumption' : 1.3434284573260773 }, { 'Variance Ratio (k=200)' : 1.0157046541161026 , 'Variance Ratio Test Statistic (k=200) Heteroscedasticity Assumption' : 0.9639233626580027 , 'Variance Ratio Test Statistic (k=200) Homoscedasticity Assumption' : 0.9653299929052963 }, { 'Variance Ratio (k=500)' : 1.0182166207668526 , 'Variance Ratio Test Statistic (k=500) Heteroscedasticity Assumption' : 0.7055681216511915 , 'Variance Ratio Test Statistic (k=500) Homoscedasticity Assumption' : 0.7065863036900429 }, { 'Variance Ratio (k=1000)' : 1.0187822241562863 , 'Variance Ratio Test Statistic (k=1000) Heteroscedasticity Assumption' : 0.5140698821944161 , 'Variance Ratio Test Statistic (k=1000) Homoscedasticity Assumption' : 0.5147582201029065 }] It's easy to see that at all lags tested, we cannot reject the null hypothesis that this price series follows a random walk. For comparison purpose, below is an implementation in pure Python. It is more readable but is significantly slower. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 def estimate_python ( data , k = 5 ): \"A slow pure python implementation\" prices = data [ 'Price' ] . to_numpy ( dtype = np . float64 ) log_prices = np . log ( prices ) rets = np . diff ( log_prices ) T = len ( rets ) mu = np . mean ( rets ) var_1 = np . var ( rets , ddof = 1 , dtype = np . float64 ) rets_k = ( log_prices - np . roll ( log_prices , k ))[ k :] m = k * ( T - k + 1 ) * ( 1 - k / T ) var_k = 1 / m * np . sum ( np . square ( rets_k - k * mu )) # Variance Ratio vr = var_k / var_1 # Phi1 phi1 = 2 * ( 2 * k - 1 ) * ( k - 1 ) / ( 3 * k * T ) # Phi2 def delta ( j ): res = 0 for t in range ( j + 1 , T + 1 ): t -= 1 # array index is t-1 for t-th element res += np . square (( rets [ t ] - mu ) * ( rets [ t - j ] - mu )) return res / (( T - 1 ) * var_1 ) ** 2 phi2 = 0 for j in range ( 1 , k ): phi2 += ( 2 * ( k - j ) / k ) ** 2 * delta ( j ) return vr , ( vr - 1 ) / np . sqrt ( phi1 ), ( vr - 1 ) / np . sqrt ( phi2 )","title":"Source Code"},{"location":"measures/market_to_book/","text":"Market to Book Ratio \u00b6 Definition \u00b6 Market value of common equity scaled by the book value common equity. MTB_{i,t} = \\frac{PRCC\\_F_{i,t}\\times CSHO_{i,t}}{CEQ_{i,t}} MTB_{i,t} = \\frac{PRCC\\_F_{i,t}\\times CSHO_{i,t}}{CEQ_{i,t}} where PRCC\\_F PRCC\\_F is the share price at fiscal year end, CSHO CSHO is the common shares outstanding, and CEQ CEQ is common equity, all from Compustat Fundamentals Annual WRDS.COMP.FUNDA .","title":"Market to Book"},{"location":"measures/market_to_book/#market-to-book-ratio","text":"","title":"Market to Book Ratio"},{"location":"measures/market_to_book/#definition","text":"Market value of common equity scaled by the book value common equity. MTB_{i,t} = \\frac{PRCC\\_F_{i,t}\\times CSHO_{i,t}}{CEQ_{i,t}} MTB_{i,t} = \\frac{PRCC\\_F_{i,t}\\times CSHO_{i,t}}{CEQ_{i,t}} where PRCC\\_F PRCC\\_F is the share price at fiscal year end, CSHO CSHO is the common shares outstanding, and CEQ CEQ is common equity, all from Compustat Fundamentals Annual WRDS.COMP.FUNDA .","title":"Definition"},{"location":"measures/measures/","text":"Measures \u00b6 My (growing) collection of various measures' definitions. Please see frds.io for how to compute all these measures in one click. Firm Characteristics \u00b6 Accounting Restatements Number of various accounting restatements during the past ( n ) fiscal year. Source: wrds.comp.funda , wrds.audit.auditnonreli . Asset Tangibility Property, Plant and Equipment (Net) scaled by total assets. Source: wrds.comp.funda . Board Independence Board size and independence measured as the ratio of independent board members to board size. Source: wrds.funda , wrds.boardex.na_wrds_company_profile , wrds.boardex.na_wrds_org_composition . Book Leverage Amount of debts scaled by the firm's total debts plus common equity. Source: wrds.comp.funda . Capital Expenditure Capital expenditures scaled by total assets. Source: wrds.comp.funda . Credit Rating S&P credit rating. Source: wrds.ciq.erating , wrds.ciq.gvkey . Executive Ownership Various measures of executive stock ownership. Source: wrds.comp.funda , wrds.execcomp.anncomp . Firm Size Natural logarithm of total assets. Source: wrds.comp.funda . Market-to-Book Ratio Market value of common equity to book value of common equity. Source: wrds.comp.funda . ROA Income before extraordinary items scaled by total assets. Source: wrds.comp.funda . ROE Income before extraordinary items scaled by common equity. Source: wrds.comp.funda . Stock Delisting Stocks delisted due to financial troubles or as a result of being merged. Source: wrds.crsp.dse . Tobin's Q Tobin's Q Source: wrds.comp.funda . Reference: Gompers, Ishii and Metrick (2003 QJE) , and Kaplan and Zingales (1997 QJE) . Bank Holding Company (BHC) Characteristics \u00b6 BHC Size Natural logarithm of total assets. Source: frb_chicago.bhc.bhcf . BHC Loan Growth Natural logarithm of total loans in the current quarter divided by the total loans in the previous quarter. Source: frb_chicago.bhc.bhcf . Referece: Zheng (2020 JBF) . BHC FX Exposure Fee and interest income from loans in foreign offices (BHCK4059) scaled by total interest income (BHCK4107). Source: frb_chicago.bhc.bhcf . Reference: Rampini, Viswanathan and Vuillemey (2020 JF) . BHC NetIncome/Assets Net income (BHCK4340) / total assets (BHCK2170). Source: frb_chicago.bhc.bhcf . Reference: Rampini, Viswanathan and Vuillemey (2020 JF) . BHC Dividend/Assets Cash dividends on common stock (BHCK4460) / total assets (BHCK2170). Source: frb_chicago.bhc.bhcf . Reference: Rampini, Viswanathan and Vuillemey (2020 JF) . BHC RegulatoryCapital/Assets Total qualifying capital allowable under the risk-based capital guidelines (BHCK3792) normalized by risk-weighted assets (BHCKA223). Source: frb_chicago.bhc.bhcf . Reference: Rampini, Viswanathan and Vuillemey (2020 JF) . BHC Tier1Capital/Assets Tier 1 capital allowable under the risk-based capital guidelines (BHCK8274) normalized by risk-weighted assets (BHCKA223). Source: frb_chicago.bhc.bhcf . Reference: Rampini, Viswanathan and Vuillemey (2020 JF) . BHC Gross IR Hedging Total gross notional amount of interest rate derivatives held for purposes other than trading (BHCK8725) over total assets (BHCK2170); for the period 1995 to 2000, contracts not marked to market (BHCK8729) are added. Source: frb_chicago.bhc.bhcf . Reference: Rampini, Viswanathan and Vuillemey (2020 JF) . BHC Gross FX Hedging Total gross notional amount of foreign exchange rate derivatives held for purposes other than trading (BHCK8726) over total assets (BHCK2170); for the period 1995 to 2000, contracts not marked to market (BHCK8730) are added. Source: frb_chicago.bhc.bhcf . Reference: Rampini, Viswanathan and Vuillemey (2020 JF) . BHC Maturity Gap & Narrow Maturity Gap Maturity gap is defined as the earning assets that are repriceable or mature within one year (BHCK3197) minus interest-bearing deposits that mature or reprice within one year (BHCK3296) minus long-term debt that reprices or matures within one year (BHCK3298 + BHCK3409) minus variable rate preferred stock (BHCK3408) minus other borrowed money with a maturity of one year or less (BHCK2332) minus commercial paper (BHCK2309) minus federal funds and repo liabilities (BHDMB993 + BHCKB995), normalized by total assets. Narrow maturity gap does not subtract interest-bearing deposits that mature or reprice within one year (BHCK3296). Source: frb_chicago.bhc.bhcf . Reference: Rampini, Viswanathan and Vuillemey (2020 JF) .","title":"Overview"},{"location":"measures/measures/#measures","text":"My (growing) collection of various measures' definitions. Please see frds.io for how to compute all these measures in one click.","title":"Measures"},{"location":"measures/measures/#firm-characteristics","text":"Accounting Restatements Number of various accounting restatements during the past ( n ) fiscal year. Source: wrds.comp.funda , wrds.audit.auditnonreli . Asset Tangibility Property, Plant and Equipment (Net) scaled by total assets. Source: wrds.comp.funda . Board Independence Board size and independence measured as the ratio of independent board members to board size. Source: wrds.funda , wrds.boardex.na_wrds_company_profile , wrds.boardex.na_wrds_org_composition . Book Leverage Amount of debts scaled by the firm's total debts plus common equity. Source: wrds.comp.funda . Capital Expenditure Capital expenditures scaled by total assets. Source: wrds.comp.funda . Credit Rating S&P credit rating. Source: wrds.ciq.erating , wrds.ciq.gvkey . Executive Ownership Various measures of executive stock ownership. Source: wrds.comp.funda , wrds.execcomp.anncomp . Firm Size Natural logarithm of total assets. Source: wrds.comp.funda . Market-to-Book Ratio Market value of common equity to book value of common equity. Source: wrds.comp.funda . ROA Income before extraordinary items scaled by total assets. Source: wrds.comp.funda . ROE Income before extraordinary items scaled by common equity. Source: wrds.comp.funda . Stock Delisting Stocks delisted due to financial troubles or as a result of being merged. Source: wrds.crsp.dse . Tobin's Q Tobin's Q Source: wrds.comp.funda . Reference: Gompers, Ishii and Metrick (2003 QJE) , and Kaplan and Zingales (1997 QJE) .","title":"Firm Characteristics"},{"location":"measures/measures/#bank-holding-company-bhc-characteristics","text":"BHC Size Natural logarithm of total assets. Source: frb_chicago.bhc.bhcf . BHC Loan Growth Natural logarithm of total loans in the current quarter divided by the total loans in the previous quarter. Source: frb_chicago.bhc.bhcf . Referece: Zheng (2020 JBF) . BHC FX Exposure Fee and interest income from loans in foreign offices (BHCK4059) scaled by total interest income (BHCK4107). Source: frb_chicago.bhc.bhcf . Reference: Rampini, Viswanathan and Vuillemey (2020 JF) . BHC NetIncome/Assets Net income (BHCK4340) / total assets (BHCK2170). Source: frb_chicago.bhc.bhcf . Reference: Rampini, Viswanathan and Vuillemey (2020 JF) . BHC Dividend/Assets Cash dividends on common stock (BHCK4460) / total assets (BHCK2170). Source: frb_chicago.bhc.bhcf . Reference: Rampini, Viswanathan and Vuillemey (2020 JF) . BHC RegulatoryCapital/Assets Total qualifying capital allowable under the risk-based capital guidelines (BHCK3792) normalized by risk-weighted assets (BHCKA223). Source: frb_chicago.bhc.bhcf . Reference: Rampini, Viswanathan and Vuillemey (2020 JF) . BHC Tier1Capital/Assets Tier 1 capital allowable under the risk-based capital guidelines (BHCK8274) normalized by risk-weighted assets (BHCKA223). Source: frb_chicago.bhc.bhcf . Reference: Rampini, Viswanathan and Vuillemey (2020 JF) . BHC Gross IR Hedging Total gross notional amount of interest rate derivatives held for purposes other than trading (BHCK8725) over total assets (BHCK2170); for the period 1995 to 2000, contracts not marked to market (BHCK8729) are added. Source: frb_chicago.bhc.bhcf . Reference: Rampini, Viswanathan and Vuillemey (2020 JF) . BHC Gross FX Hedging Total gross notional amount of foreign exchange rate derivatives held for purposes other than trading (BHCK8726) over total assets (BHCK2170); for the period 1995 to 2000, contracts not marked to market (BHCK8730) are added. Source: frb_chicago.bhc.bhcf . Reference: Rampini, Viswanathan and Vuillemey (2020 JF) . BHC Maturity Gap & Narrow Maturity Gap Maturity gap is defined as the earning assets that are repriceable or mature within one year (BHCK3197) minus interest-bearing deposits that mature or reprice within one year (BHCK3296) minus long-term debt that reprices or matures within one year (BHCK3298 + BHCK3409) minus variable rate preferred stock (BHCK3408) minus other borrowed money with a maturity of one year or less (BHCK2332) minus commercial paper (BHCK2309) minus federal funds and repo liabilities (BHDMB993 + BHCKB995), normalized by total assets. Narrow maturity gap does not subtract interest-bearing deposits that mature or reprice within one year (BHCK3296). Source: frb_chicago.bhc.bhcf . Reference: Rampini, Viswanathan and Vuillemey (2020 JF) .","title":"Bank Holding Company (BHC) Characteristics"},{"location":"measures/roa/","text":"ROA \u00b6 Definition \u00b6 Income Before Extraordinary Items scaled by Assets (Total). ROA_{i,t} = \\frac{IB_{i,t}}{AT_{i,t}} ROA_{i,t} = \\frac{IB_{i,t}}{AT_{i,t}} where IB IB and AT AT are from Compustat Fundamentals Annual WRDS.COMP.FUNDA .","title":"ROA"},{"location":"measures/roa/#roa","text":"","title":"ROA"},{"location":"measures/roa/#definition","text":"Income Before Extraordinary Items scaled by Assets (Total). ROA_{i,t} = \\frac{IB_{i,t}}{AT_{i,t}} ROA_{i,t} = \\frac{IB_{i,t}}{AT_{i,t}} where IB IB and AT AT are from Compustat Fundamentals Annual WRDS.COMP.FUNDA .","title":"Definition"},{"location":"measures/roe/","text":"ROE \u00b6 Definition \u00b6 Income Before Extraordinary Items scaled by Common Equity (Total). ROE_{i,t} = \\frac{IB_{i,t}}{CEQ_{i,t}} ROE_{i,t} = \\frac{IB_{i,t}}{CEQ_{i,t}} where IB IB and CEQ CEQ are from Compustat Fundamentals Annual WRDS.COMP.FUNDA .","title":"ROE"},{"location":"measures/roe/#roe","text":"","title":"ROE"},{"location":"measures/roe/#definition","text":"Income Before Extraordinary Items scaled by Common Equity (Total). ROE_{i,t} = \\frac{IB_{i,t}}{CEQ_{i,t}} ROE_{i,t} = \\frac{IB_{i,t}}{CEQ_{i,t}} where IB IB and CEQ CEQ are from Compustat Fundamentals Annual WRDS.COMP.FUNDA .","title":"Definition"},{"location":"measures/stock_delisting/","text":"Stock Delisting \u00b6 Definition \u00b6 This dataset contains the stocks delisted either due to financial troubles (delisting code dlstcd = 500-599) or as a result of being merged (delisting code = 200-299).","title":"Stock Delisting"},{"location":"measures/stock_delisting/#stock-delisting","text":"","title":"Stock Delisting"},{"location":"measures/stock_delisting/#definition","text":"This dataset contains the stocks delisted either due to financial troubles (delisting code dlstcd = 500-599) or as a result of being merged (delisting code = 200-299).","title":"Definition"},{"location":"measures/tobin_q/","text":"Tobin's Q \u00b6 Definition \u00b6 Tobin's Q is defined as the ratio between the market value of the firm over the replacement cost of its assets. \\text{TobinQ} = \\frac{\\text{Marekt value of the firm}}{\\text{Replacement cost of assets}} \\text{TobinQ} = \\frac{\\text{Marekt value of the firm}}{\\text{Replacement cost of assets}} There're a number of ways to estimate Toin's Q empirically. Gompers, Ishii and Metrick (2003 QJE) , following Kaplan and Zingales (1997 QJE) , define Tobin's Q as: The market value of assets divided by the book value of assets (Compustat item 6), where the market value of assets is computed as book value of assets plus the market value of common stock less the sum of the book value of common stock (Compustat item 60) and balance sheet deferred taxes (Compustat item 74). All book values for fiscal year t (from Compustat) are combined with the market value of common equity at the calendar end of year t. 1 which gives: \\text{TobinQ}_{i,t} = \\frac{\\text{Total Assets}_{i,t} + \\text{Market Equity}_{i,t} - \\text{Book Equity}_{i,t}}{\\text{Total Assets}_{i,t}} \\text{TobinQ}_{i,t} = \\frac{\\text{Total Assets}_{i,t} + \\text{Market Equity}_{i,t} - \\text{Book Equity}_{i,t}}{\\text{Total Assets}_{i,t}} where: \\text{Total Assets} \\text{Total Assets} is the book value total assets as reported \\text{Market Equity}=PRCC\\_C \\times CSHO \\text{Market Equity}=PRCC\\_C \\times CSHO \\text{Book Equity}=SEQ+TXDB+ITCB-PREF \\text{Book Equity}=SEQ+TXDB+ITCB-PREF and PREF=\\text{coalesce}(PSTKRV,PSTKL,PSTK) PREF=\\text{coalesce}(PSTKRV,PSTKL,PSTK) Variables \u00b6 Variable Description PRCC_C Stock price at the calendar year end for a fair cross sectional comparison CSHO Common shares outstanding SEQ Shareholder equity TXDB Deferred taxes ITCB Investment Tax Credit PREF Preferred Stock PSTKRV Preferred stock - redemption value PSTKL Preferred stock - liquidating value PSTK Preferred stock - carrying value See Appendix 2 of Gompers, Ishii and Metrick (2003 QJE) . \u21a9","title":"Tobin's Q"},{"location":"measures/tobin_q/#tobins-q","text":"","title":"Tobin's Q"},{"location":"measures/tobin_q/#definition","text":"Tobin's Q is defined as the ratio between the market value of the firm over the replacement cost of its assets. \\text{TobinQ} = \\frac{\\text{Marekt value of the firm}}{\\text{Replacement cost of assets}} \\text{TobinQ} = \\frac{\\text{Marekt value of the firm}}{\\text{Replacement cost of assets}} There're a number of ways to estimate Toin's Q empirically. Gompers, Ishii and Metrick (2003 QJE) , following Kaplan and Zingales (1997 QJE) , define Tobin's Q as: The market value of assets divided by the book value of assets (Compustat item 6), where the market value of assets is computed as book value of assets plus the market value of common stock less the sum of the book value of common stock (Compustat item 60) and balance sheet deferred taxes (Compustat item 74). All book values for fiscal year t (from Compustat) are combined with the market value of common equity at the calendar end of year t. 1 which gives: \\text{TobinQ}_{i,t} = \\frac{\\text{Total Assets}_{i,t} + \\text{Market Equity}_{i,t} - \\text{Book Equity}_{i,t}}{\\text{Total Assets}_{i,t}} \\text{TobinQ}_{i,t} = \\frac{\\text{Total Assets}_{i,t} + \\text{Market Equity}_{i,t} - \\text{Book Equity}_{i,t}}{\\text{Total Assets}_{i,t}} where: \\text{Total Assets} \\text{Total Assets} is the book value total assets as reported \\text{Market Equity}=PRCC\\_C \\times CSHO \\text{Market Equity}=PRCC\\_C \\times CSHO \\text{Book Equity}=SEQ+TXDB+ITCB-PREF \\text{Book Equity}=SEQ+TXDB+ITCB-PREF and PREF=\\text{coalesce}(PSTKRV,PSTKL,PSTK) PREF=\\text{coalesce}(PSTKRV,PSTKL,PSTK)","title":"Definition"},{"location":"measures/tobin_q/#variables","text":"Variable Description PRCC_C Stock price at the calendar year end for a fair cross sectional comparison CSHO Common shares outstanding SEQ Shareholder equity TXDB Deferred taxes ITCB Investment Tax Credit PREF Preferred Stock PSTKRV Preferred stock - redemption value PSTKL Preferred stock - liquidating value PSTK Preferred stock - carrying value See Appendix 2 of Gompers, Ishii and Metrick (2003 QJE) . \u21a9","title":"Variables"},{"location":"posts/100-bitcoins-forgone-for-science/","text":"100 Bitcoins Forgone for Science \u00b6 This post is just another piece of my serious nonsense. All of a sudden, I wanted to know how many Bitcoins I could have mined since 2012? This is because I\u2019ve known Bitcoin since its existence in 2009, but have never really put any effort in mining. Instead, I was fascinated by the idea of using distributed (volunteer) computing to solve scientific problems. For example, BOINC and related projects like World Community Grid are using the computing power donated from around the world to find effective treatments for cancer and HIV/AIDS, low-cost water filtration systems and new materials for capturing solar energy efficiently, etc. I was one of the many volunteers for a long time, even before the genesis block of Bitcoin. An interesting question is, what if I didn\u2019t donate my computers to volunteer computing, but used them in Bitcoin instead? How many Bitcoins I could have mined? To solve this question, I started from looking at my contribution history of the World Community Grid (it\u2019s awesome that the full history is available). According to WCG\u2019s website , 7 WCG Point are equal to 1 BOINC credit, which represents 1/100 day of CPU time on a reference computer that does 1,000 MFLOPS based on the Whetstone benchmark . However, the defnition of BOINC credit has been changed to 1/200 day of CPU time since 2010, though on WCG\u2019s website it still says the total WCG Points divided by 700 gives the number of GigaFLOPs. I\u2019m going to stick to the WCG\u2019s website for now. Suppose I\u2019ve got one WCG Point today, then it means my computer has spent 1/700 day of CPU time, i.e. 123 seconds, at a computing rate of 1 GigaFLOP/second. So, if I can convert GigaFLOPs to Bitcoin hashrate, the problem will be quite easy. However, FLOPs cannot be converted to hashrate in a simple manner as Bitcoin hashes are about integer math, totally different from floating point operations. I\u2019m just going to use a very rough estimate that 1 hash results 12.7k FLOPs (source: BitcoinTalk thread , CoinDesk ), so that 1 WCG Point implies mining at a speed of 78.7kH/s for 123 seconds. -- a very rough estimate Then, if I received 1k Points a day, it might be safe to say I\u2019ve been mining for about 123k seconds at a speed of 78.7kH/s, which translates to an average daily hashrate of 112kH/s or 0.112MH/s. I did some math and found that it seems in June 2012 my hashrate was as high as 0.006% of the whole network, though one year later it\u2019s effectively 0%. lol. Next step will be calculating how many Bitcoins I could have mined based on the hashrate history. Taking into account the average block time and the controlled supply of Bitcoin (table below), I plot the daily average number of blocks and Bitcoins generated in this period. Date reached Block Reward Era BTC/block End BTC % of Limit 2009-01-03 0 1 50.00 12.500% 2010-04-22 52500 1 50.00 25.000% 2011-01-28 105000 1 50.00 37.500% 2011-12-14 157500 1 50.00 50.000% 2012-11-28 210000 2 25.00 56.250% 2013-10-09 262500 2 25.00 62.500% 2014-08-11 315000 2 25.00 68.750% 2015-07-29 367500 2 25.00 75.000% 2016-07-09 420000 3 12.50 78.125% 2017-06-23 472500 3 12.50 81.250% 2018-05-29 525000 3 12.50 84.375% Based my average hashrate and the historical network hashrate, the plot below shows how many Bitcoins I could have mined if I didn\u2019t denote my computers\u2019 computing power to the World Community Grid but to Bitcoin mining \u2013 14.8 Bitcoins ! Okay, problem solved. If I\u2019ve really mined these 14.8 Bitcoins, then I\u2019ll probably have a shot at becoming a millionaire, if again I could hold them and time the market perfectly. At Bitcoin\u2019s highest historical price in Australian dollar, 14.8 Bitcoins are roughly 380,505 dollars . Even if I follow the redefined BOINC credit, I still could have mined half of the 14.8 Bitcoins and potentially pocketed 190k dollars. I\u2019ve also participated in more than just World Community Grid, including some famous ones like SETI@Home and Einstein@Home . Below are two certificates of contributed computing power. So together I\u2019ve put in about 2.28 quintillion , or 2.28E18, FLOPs into these two projects. The funny thing is that I\u2019ve put in only 348 PetaFLOPs into World Community Grid during this entire period, or 0.348 quintillion FLOPs in total. Hence, if my donation of computing power to SETI@Home and Einstein@Home happened at similar time as to WCG, then potentially I could have mined at least 6 times more Bitcoins. Well, I couldn\u2019t imagine what my life would be if I\u2019ve mined 100 Bitcoins , which might be $2.5 million .","title":"100 Bitcoins forgone for science"},{"location":"posts/100-bitcoins-forgone-for-science/#100-bitcoins-forgone-for-science","text":"This post is just another piece of my serious nonsense. All of a sudden, I wanted to know how many Bitcoins I could have mined since 2012? This is because I\u2019ve known Bitcoin since its existence in 2009, but have never really put any effort in mining. Instead, I was fascinated by the idea of using distributed (volunteer) computing to solve scientific problems. For example, BOINC and related projects like World Community Grid are using the computing power donated from around the world to find effective treatments for cancer and HIV/AIDS, low-cost water filtration systems and new materials for capturing solar energy efficiently, etc. I was one of the many volunteers for a long time, even before the genesis block of Bitcoin. An interesting question is, what if I didn\u2019t donate my computers to volunteer computing, but used them in Bitcoin instead? How many Bitcoins I could have mined? To solve this question, I started from looking at my contribution history of the World Community Grid (it\u2019s awesome that the full history is available). According to WCG\u2019s website , 7 WCG Point are equal to 1 BOINC credit, which represents 1/100 day of CPU time on a reference computer that does 1,000 MFLOPS based on the Whetstone benchmark . However, the defnition of BOINC credit has been changed to 1/200 day of CPU time since 2010, though on WCG\u2019s website it still says the total WCG Points divided by 700 gives the number of GigaFLOPs. I\u2019m going to stick to the WCG\u2019s website for now. Suppose I\u2019ve got one WCG Point today, then it means my computer has spent 1/700 day of CPU time, i.e. 123 seconds, at a computing rate of 1 GigaFLOP/second. So, if I can convert GigaFLOPs to Bitcoin hashrate, the problem will be quite easy. However, FLOPs cannot be converted to hashrate in a simple manner as Bitcoin hashes are about integer math, totally different from floating point operations. I\u2019m just going to use a very rough estimate that 1 hash results 12.7k FLOPs (source: BitcoinTalk thread , CoinDesk ), so that 1 WCG Point implies mining at a speed of 78.7kH/s for 123 seconds. -- a very rough estimate Then, if I received 1k Points a day, it might be safe to say I\u2019ve been mining for about 123k seconds at a speed of 78.7kH/s, which translates to an average daily hashrate of 112kH/s or 0.112MH/s. I did some math and found that it seems in June 2012 my hashrate was as high as 0.006% of the whole network, though one year later it\u2019s effectively 0%. lol. Next step will be calculating how many Bitcoins I could have mined based on the hashrate history. Taking into account the average block time and the controlled supply of Bitcoin (table below), I plot the daily average number of blocks and Bitcoins generated in this period. Date reached Block Reward Era BTC/block End BTC % of Limit 2009-01-03 0 1 50.00 12.500% 2010-04-22 52500 1 50.00 25.000% 2011-01-28 105000 1 50.00 37.500% 2011-12-14 157500 1 50.00 50.000% 2012-11-28 210000 2 25.00 56.250% 2013-10-09 262500 2 25.00 62.500% 2014-08-11 315000 2 25.00 68.750% 2015-07-29 367500 2 25.00 75.000% 2016-07-09 420000 3 12.50 78.125% 2017-06-23 472500 3 12.50 81.250% 2018-05-29 525000 3 12.50 84.375% Based my average hashrate and the historical network hashrate, the plot below shows how many Bitcoins I could have mined if I didn\u2019t denote my computers\u2019 computing power to the World Community Grid but to Bitcoin mining \u2013 14.8 Bitcoins ! Okay, problem solved. If I\u2019ve really mined these 14.8 Bitcoins, then I\u2019ll probably have a shot at becoming a millionaire, if again I could hold them and time the market perfectly. At Bitcoin\u2019s highest historical price in Australian dollar, 14.8 Bitcoins are roughly 380,505 dollars . Even if I follow the redefined BOINC credit, I still could have mined half of the 14.8 Bitcoins and potentially pocketed 190k dollars. I\u2019ve also participated in more than just World Community Grid, including some famous ones like SETI@Home and Einstein@Home . Below are two certificates of contributed computing power. So together I\u2019ve put in about 2.28 quintillion , or 2.28E18, FLOPs into these two projects. The funny thing is that I\u2019ve put in only 348 PetaFLOPs into World Community Grid during this entire period, or 0.348 quintillion FLOPs in total. Hence, if my donation of computing power to SETI@Home and Einstein@Home happened at similar time as to WCG, then potentially I could have mined at least 6 times more Bitcoins. Well, I couldn\u2019t imagine what my life would be if I\u2019ve mined 100 Bitcoins , which might be $2.5 million .","title":"100 Bitcoins Forgone for Science"},{"location":"posts/accumulator-option-pricing/","text":"An accumulator is a financial derivative that is sometimes known as \" I kill you later \". This post attempts to explain how it is structured and price it via Monte Carlo simulations in Python. 1. Overview of Accumulator \u00b6 Like all derivatives, there are two parties invovled in an accumulator, the buyer and the seller, both agree on a strike price that is usually at a discount to the prevailing market price of the underlying security at the time of contract origination. The buyer has the obligation to buy certain amount of the underlying security at the predetermined strike price. The seller has the obligation to sell the specified amount of the underlying security at the strike price to the buyer. The accumulator is settled periodically throughout its term. At each settlement: If the market price of the underlying security is above the predetermined knock-out price , the contract is terminated. If the market price of the underlying security is between the knock-out price and the strike price, the buyer \"accumulates\" the underlying security at the strike price. If the market price of the underlying security is below the strike price, the buyer is obligated to buy the underlying security at the strike price at 2 (or more) times of the predetermined amount. 2. An Example 6-month Accumulator \u00b6 Let's make up an example so as to illustrate how it works. 2.1. Month 0 \u00b6 Suppose that I bought an accumulator from Sherry the seller today, where the underlying security is Transcendental Capital 's stock (TSC, hypothetical ticker), currently trading at $100. The strike price is $90 and the knock-out price is $105. The amount of stocks that I can buy is 1,000 in each settlement. The accumulator lasts for 6 months and settles monthly. 2.2. Month 1 \u00b6 At the end of month 1, the market price of TSC is $102, which is between the strike price ($90) and the knock-out price ($105). I can buy 1,000 shares from Sherry at the strike price of $90 each and make a profit of (\\$102-\\$90)\\times1000=\\$12,000 (\\$102-\\$90)\\times1000=\\$12,000 . 2.3. Month 2 \u00b6 At the end of month 2, the market price of TSC is $95, which is between the strike price ($90) and the knock-out price ($105). I can buy 1,000 shares from Sherry at the strike price of $90 each and make a profit of (\\$95-\\$90)\\times1000=\\$5,000 (\\$95-\\$90)\\times1000=\\$5,000 . 2.4. Month 3 \u00b6 At the end of month 3, the market price of TSC is $85, which is below the strike price ($90). I have to buy 2,000 shares from Sherry at the strike price of $90, making a loss of (\\$90-\\$85)\\times2000=\\$10,000 (\\$90-\\$85)\\times2000=\\$10,000 . 2.5. Month 4 \u00b6 At the end of month 4, the market price of TSC is $88, which is below the strike price ($90). I have to buy 2,000 shares from Sherry at the strike price of $90, making a loss of (\\$90-\\$88)\\times2000=\\$4,000 (\\$90-\\$88)\\times2000=\\$4,000 . 2.6. Month 5 \u00b6 At the end of month 5, the market price of TSC is $106, which is above the knock-out price, so the contract is terminated immediately. I cannot make any profit from Sherry any longer. 3. Some Observations \u00b6 In the example above: I've accumulated in total of 6,000 shares of TSC at a cost of $90 per share. This implies that an accumulator is like a forward contract and helps the buyer lock in the cost of acquiring the underlying security (why it's also known as share forward accumulator). As long as the share price is between the strike price and knock-out price, the buyer can accumulate shares at a discount. The 6-month accumulator terminates in 5 months because of the knock out and so the seller's loss is limited. When the share price is below the strike price, the buyer accumulates more shares but at a loss. All these taken together, we can find that the buyer has: 1. a limited upside potential because the potential gain is capped by the knock-out price and zero when knocked out, and 2. a disproportional (limited) downside in that any loss is amplified by the doubled amount of shares he or she has to purchase from the seller when share price is below the strike. But this is not the full story. Another hidden feature is that while the accumulator is terminated when the share price is above the knock-out price, the contract does not terminate when the buyer is at a loss untill it matures. So, even though the maximum losses of both the buyer and the seller are fixed, but they differ significantly and disproportionately. If so, why would anyone become interested in buying the contract? Potentially it's because the strike is set to be lower at market price, therefore at the beginning the buyers always feel like they are taking advantages. They may also think that once the price increases to above the knock-out level, which might be set to slightly higher than market price, the contract is terminated so they are free of any loss. However, the buyers often underestimate the probability of a price decline and how big the impact it will have on accumulator buyers. The \" I kill you later \" earns its name for a reason. 4. Some Math ... \u00b6 Let's make some notations. Strike price is K K Share price at time t t is S_t S_t Knock-out price is K^+ K^+ The amount of shares to buy is: A A when K<S_t<K^+ K<S_t<K^+ , and cA cA when S_t>K^+ S_t>K^+ , where c>1 c>1 There are N N settlements So at each settlement, the payoff matrix conditional on the contract not terminated in the previous settlement is: Share Price Buyer's Payoff Seller's Payoff S_t>K^+ S_t>K^+ 0 0 K\\le S_t\\le K^+ K\\le S_t\\le K^+ A(S_t-K)\\ge0 A(S_t-K)\\ge0 -A(S_t-K)\\le0 -A(S_t-K)\\le0 S_t<K S_t<K c A(S_t-K)<0 c A(S_t-K)<0 -cA(S_t-K)>0 -cA(S_t-K)>0 However, deriving a closed-end analytical solution is not easy since there are many settlements in the contract and the total payoff is path-dependent (the knock out). There is a conference paper in 2009 discussing the issue and the PDF version is available here . 5. ... A Simulation Approach \u00b6 I am to going to use Monte Carlo simulations to find out the distribution of buyer's payoff. 5.1. Assumptions \u00b6 For simplicity, I'm going to make the following assumptions: the share price when the contract is signed S_t=\\$100 S_t=\\$100 . the strike price and the knock-out price are symmetric around $100. the strike price K=100-k K=100-k the knock-out price K^+=100+k K^+=100+k the contract lasts for a year with 12 settlements and each month end. the amount of shares to buy in each settlement: A=1,000 A=1,000 if the share price at settlement is between the strike price and the knock-out price. A=2,000 A=2,000 if the share prices settlement is below the strike price. the monthly stock returns follow a normal distribution with mean zero and a standard deviation of \\sigma \\sigma . Then, there are only two variables: k k and \\sigma \\sigma that I will need to vary! 5.2. Core Code \u00b6 The simulation code I write below leverages Numba to speed up the calculation. For 1 million simulations per pair of (k, \\sigma) (k, \\sigma) , it takes about 2 seconds on my laptop with JIT and almost 1 minute without it. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 import random import numpy as np from collections import OrderedDict from numba import jitclass , int32 , float32 @jitclass ( OrderedDict ({ 'times' : int32 , 'strike_price' : float32 , 'knock_out_price' : float32 , 'volatility' : float32 })) class FastSimulation : def __init__ ( self , times , strike_price , knock_out_price , volatility ): self . times = times self . strike_price = strike_price self . knock_out_price = knock_out_price self . volatility = volatility def run ( self ): np . random . seed ( 1 ) buyer_payoffs = [] for i in range ( self . times ): # generate 12 monthly returns from a normal distribution # written this way as size parameter is not supported by numba returns = [ np . random . normal ( loc = 0 , scale = self . volatility ) / 100 + 1 for _ in range ( 12 )] # convert returns to a price array prices = np . asarray ( returns ) . cumprod () * 100 payoff = 0 for price in prices : # the accumulator is terminated immediately if price > self . knock_out_price : break payoff += self . buyer_payoff ( price ) buyer_payoffs . append ( payoff ) return buyer_payoffs def buyer_payoff ( self , share_price ): \"Buyer payoff conditional on the accumulator not terminated\" if share_price > self . knock_out_price : return 0 payoff = 1000 * ( share_price - self . strike_price ) if self . strike_price <= share_price <= self . knock_out_price : return payoff else : return payoff * 2 5.3. Results \u00b6 Numbers are boring. So here I put two plots showing the distribution of the buyer's payoffs. 5.3.1. k=5 k=5 and v\\in [1..5] v\\in [1..5] \u00b6 5.3.2. k=10 k=10 and v\\in [1..5] v\\in [1..5] \u00b6 6. Discussion \u00b6 Apparently, the accumulator is a very interesting and sometimes evil derivative. From the plots above we can notice several things: When volatility is low, an accumulator gives the buyer an opportunity to accumulate shares at a discount and therefore positive payoffs. When volatility is high, the buyer's payoff distribution becomes increasingly negatively skewed. The maximum potential payoff is capped and decreasing in volatility but VaR is increasing in the volatility. ...... Hence, as a buyer of an accumulator, you win small with low volatility but lose big and huge with high volatility. I don't think any rational investor would like to take the long position. However, we do find exceptions, like CITIC Limited lost HK$15 billion in accumulators back in 2008.","title":"Accumulator option pricing"},{"location":"posts/accumulator-option-pricing/#1-overview-of-accumulator","text":"Like all derivatives, there are two parties invovled in an accumulator, the buyer and the seller, both agree on a strike price that is usually at a discount to the prevailing market price of the underlying security at the time of contract origination. The buyer has the obligation to buy certain amount of the underlying security at the predetermined strike price. The seller has the obligation to sell the specified amount of the underlying security at the strike price to the buyer. The accumulator is settled periodically throughout its term. At each settlement: If the market price of the underlying security is above the predetermined knock-out price , the contract is terminated. If the market price of the underlying security is between the knock-out price and the strike price, the buyer \"accumulates\" the underlying security at the strike price. If the market price of the underlying security is below the strike price, the buyer is obligated to buy the underlying security at the strike price at 2 (or more) times of the predetermined amount.","title":"1. Overview of Accumulator"},{"location":"posts/accumulator-option-pricing/#2-an-example-6-month-accumulator","text":"Let's make up an example so as to illustrate how it works.","title":"2. An Example 6-month Accumulator"},{"location":"posts/accumulator-option-pricing/#21-month-0","text":"Suppose that I bought an accumulator from Sherry the seller today, where the underlying security is Transcendental Capital 's stock (TSC, hypothetical ticker), currently trading at $100. The strike price is $90 and the knock-out price is $105. The amount of stocks that I can buy is 1,000 in each settlement. The accumulator lasts for 6 months and settles monthly.","title":"2.1. Month 0"},{"location":"posts/accumulator-option-pricing/#22-month-1","text":"At the end of month 1, the market price of TSC is $102, which is between the strike price ($90) and the knock-out price ($105). I can buy 1,000 shares from Sherry at the strike price of $90 each and make a profit of (\\$102-\\$90)\\times1000=\\$12,000 (\\$102-\\$90)\\times1000=\\$12,000 .","title":"2.2. Month 1"},{"location":"posts/accumulator-option-pricing/#23-month-2","text":"At the end of month 2, the market price of TSC is $95, which is between the strike price ($90) and the knock-out price ($105). I can buy 1,000 shares from Sherry at the strike price of $90 each and make a profit of (\\$95-\\$90)\\times1000=\\$5,000 (\\$95-\\$90)\\times1000=\\$5,000 .","title":"2.3. Month 2"},{"location":"posts/accumulator-option-pricing/#24-month-3","text":"At the end of month 3, the market price of TSC is $85, which is below the strike price ($90). I have to buy 2,000 shares from Sherry at the strike price of $90, making a loss of (\\$90-\\$85)\\times2000=\\$10,000 (\\$90-\\$85)\\times2000=\\$10,000 .","title":"2.4. Month 3"},{"location":"posts/accumulator-option-pricing/#25-month-4","text":"At the end of month 4, the market price of TSC is $88, which is below the strike price ($90). I have to buy 2,000 shares from Sherry at the strike price of $90, making a loss of (\\$90-\\$88)\\times2000=\\$4,000 (\\$90-\\$88)\\times2000=\\$4,000 .","title":"2.5. Month 4"},{"location":"posts/accumulator-option-pricing/#26-month-5","text":"At the end of month 5, the market price of TSC is $106, which is above the knock-out price, so the contract is terminated immediately. I cannot make any profit from Sherry any longer.","title":"2.6. Month 5"},{"location":"posts/accumulator-option-pricing/#3-some-observations","text":"In the example above: I've accumulated in total of 6,000 shares of TSC at a cost of $90 per share. This implies that an accumulator is like a forward contract and helps the buyer lock in the cost of acquiring the underlying security (why it's also known as share forward accumulator). As long as the share price is between the strike price and knock-out price, the buyer can accumulate shares at a discount. The 6-month accumulator terminates in 5 months because of the knock out and so the seller's loss is limited. When the share price is below the strike price, the buyer accumulates more shares but at a loss. All these taken together, we can find that the buyer has: 1. a limited upside potential because the potential gain is capped by the knock-out price and zero when knocked out, and 2. a disproportional (limited) downside in that any loss is amplified by the doubled amount of shares he or she has to purchase from the seller when share price is below the strike. But this is not the full story. Another hidden feature is that while the accumulator is terminated when the share price is above the knock-out price, the contract does not terminate when the buyer is at a loss untill it matures. So, even though the maximum losses of both the buyer and the seller are fixed, but they differ significantly and disproportionately. If so, why would anyone become interested in buying the contract? Potentially it's because the strike is set to be lower at market price, therefore at the beginning the buyers always feel like they are taking advantages. They may also think that once the price increases to above the knock-out level, which might be set to slightly higher than market price, the contract is terminated so they are free of any loss. However, the buyers often underestimate the probability of a price decline and how big the impact it will have on accumulator buyers. The \" I kill you later \" earns its name for a reason.","title":"3. Some Observations"},{"location":"posts/accumulator-option-pricing/#4-some-math","text":"Let's make some notations. Strike price is K K Share price at time t t is S_t S_t Knock-out price is K^+ K^+ The amount of shares to buy is: A A when K<S_t<K^+ K<S_t<K^+ , and cA cA when S_t>K^+ S_t>K^+ , where c>1 c>1 There are N N settlements So at each settlement, the payoff matrix conditional on the contract not terminated in the previous settlement is: Share Price Buyer's Payoff Seller's Payoff S_t>K^+ S_t>K^+ 0 0 K\\le S_t\\le K^+ K\\le S_t\\le K^+ A(S_t-K)\\ge0 A(S_t-K)\\ge0 -A(S_t-K)\\le0 -A(S_t-K)\\le0 S_t<K S_t<K c A(S_t-K)<0 c A(S_t-K)<0 -cA(S_t-K)>0 -cA(S_t-K)>0 However, deriving a closed-end analytical solution is not easy since there are many settlements in the contract and the total payoff is path-dependent (the knock out). There is a conference paper in 2009 discussing the issue and the PDF version is available here .","title":"4. Some Math ..."},{"location":"posts/accumulator-option-pricing/#5-a-simulation-approach","text":"I am to going to use Monte Carlo simulations to find out the distribution of buyer's payoff.","title":"5. ... A Simulation Approach"},{"location":"posts/accumulator-option-pricing/#51-assumptions","text":"For simplicity, I'm going to make the following assumptions: the share price when the contract is signed S_t=\\$100 S_t=\\$100 . the strike price and the knock-out price are symmetric around $100. the strike price K=100-k K=100-k the knock-out price K^+=100+k K^+=100+k the contract lasts for a year with 12 settlements and each month end. the amount of shares to buy in each settlement: A=1,000 A=1,000 if the share price at settlement is between the strike price and the knock-out price. A=2,000 A=2,000 if the share prices settlement is below the strike price. the monthly stock returns follow a normal distribution with mean zero and a standard deviation of \\sigma \\sigma . Then, there are only two variables: k k and \\sigma \\sigma that I will need to vary!","title":"5.1. Assumptions"},{"location":"posts/accumulator-option-pricing/#52-core-code","text":"The simulation code I write below leverages Numba to speed up the calculation. For 1 million simulations per pair of (k, \\sigma) (k, \\sigma) , it takes about 2 seconds on my laptop with JIT and almost 1 minute without it. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 import random import numpy as np from collections import OrderedDict from numba import jitclass , int32 , float32 @jitclass ( OrderedDict ({ 'times' : int32 , 'strike_price' : float32 , 'knock_out_price' : float32 , 'volatility' : float32 })) class FastSimulation : def __init__ ( self , times , strike_price , knock_out_price , volatility ): self . times = times self . strike_price = strike_price self . knock_out_price = knock_out_price self . volatility = volatility def run ( self ): np . random . seed ( 1 ) buyer_payoffs = [] for i in range ( self . times ): # generate 12 monthly returns from a normal distribution # written this way as size parameter is not supported by numba returns = [ np . random . normal ( loc = 0 , scale = self . volatility ) / 100 + 1 for _ in range ( 12 )] # convert returns to a price array prices = np . asarray ( returns ) . cumprod () * 100 payoff = 0 for price in prices : # the accumulator is terminated immediately if price > self . knock_out_price : break payoff += self . buyer_payoff ( price ) buyer_payoffs . append ( payoff ) return buyer_payoffs def buyer_payoff ( self , share_price ): \"Buyer payoff conditional on the accumulator not terminated\" if share_price > self . knock_out_price : return 0 payoff = 1000 * ( share_price - self . strike_price ) if self . strike_price <= share_price <= self . knock_out_price : return payoff else : return payoff * 2","title":"5.2. Core Code"},{"location":"posts/accumulator-option-pricing/#53-results","text":"Numbers are boring. So here I put two plots showing the distribution of the buyer's payoffs.","title":"5.3. Results"},{"location":"posts/accumulator-option-pricing/#531-k5k5-and-vin-15vin-15","text":"","title":"5.3.1. k=5k=5 and v\\in [1..5]v\\in [1..5]"},{"location":"posts/accumulator-option-pricing/#532-k10k10-and-vin-15vin-15","text":"","title":"5.3.2. k=10k=10 and v\\in [1..5]v\\in [1..5]"},{"location":"posts/accumulator-option-pricing/#6-discussion","text":"Apparently, the accumulator is a very interesting and sometimes evil derivative. From the plots above we can notice several things: When volatility is low, an accumulator gives the buyer an opportunity to accumulate shares at a discount and therefore positive payoffs. When volatility is high, the buyer's payoff distribution becomes increasingly negatively skewed. The maximum potential payoff is capped and decreasing in volatility but VaR is increasing in the volatility. ...... Hence, as a buyer of an accumulator, you win small with low volatility but lose big and huge with high volatility. I don't think any rational investor would like to take the long position. However, we do find exceptions, like CITIC Limited lost HK$15 billion in accumulators back in 2008.","title":"6. Discussion"},{"location":"posts/beta-unlevered-and-levered/","text":"Beta - Unlevered and Levered \u00b6 Beta is a measure of market risk. Unlevered Firm u \u00b6 If a firm has no debt, it's all equity-financed and thus its equity's beta \\beta_{E} \\beta_{E} equals its asset's beta \\beta_{A} \\beta_{A} . This beta is also the unlevered beta , \\beta_{\\text{unlevered}} \\beta_{\\text{unlevered}} , since it's unaffected by leverage. The unlevered beta measures the market risk exposure of the firm's shareholders. Let's call this firm u u , Hence, we have: \\begin{equation} \\beta_{\\text{unlevered}}=\\beta_E^u=\\beta_A^u \\end{equation} \\begin{equation} \\beta_{\\text{unlevered}}=\\beta_E^u=\\beta_A^u \\end{equation} This equality says that in an unlevered firm, the unlevered beta equals its equity beta and its asset beta. Levered Firm l \u00b6 If the same firm is partly financed by debt, let's call it firm l l . The asset of the levered firm l l is financed by both equity and debt, and hence the asset's market risk is from both equity and debt. The asset's beta is a weighted average of its equity beta and debt beta. \\begin{equation} \\beta_A^l = \\frac{E}{E+D(1-t)} \\beta_E^l + \\frac{D(1-t)}{E+D(1-t)} \\beta_D^l \\end{equation} \\begin{equation} \\beta_A^l = \\frac{E}{E+D(1-t)} \\beta_E^l + \\frac{D(1-t)}{E+D(1-t)} \\beta_D^l \\end{equation} \\beta_A^l \\beta_A^l measures the change in the return on a portfolio of all firm l l 's securities (debt and equity) for each additional one percent change in the market return. This part is not very hard to understand. The beta of a portfolio is the weighted average beta of its constituents. If you believe that debt beta is zero since the value of debt may not be affected by the equity market, then \\beta_D^l=0 \\beta_D^l=0 and the equation (2) can be simplified to: \\begin{align} \\beta_A^l &= \\frac{E}{E+D(1-t)} \\beta_E^l \\newline &= \\frac{1}{1+\\frac{D}{E}(1-t)} \\beta_E^l \\end{align} \\begin{align} \\beta_A^l &= \\frac{E}{E+D(1-t)} \\beta_E^l \\newline &= \\frac{1}{1+\\frac{D}{E}(1-t)} \\beta_E^l \\end{align} However, this firm's shareholders are now more exposed to the market risk than before, because leverage increases the variation in the payoff to shareholders. This means the equity's beta of this levered firm is higher than the equity's beta of the unlevered firm, i.e. \\beta_E^l>\\beta_E^u \\beta_E^l>\\beta_E^u . Note that, the levered beta \\beta_{\\text{levered}} \\beta_{\\text{levered}} that we talk about refers to \\beta_E^l \\beta_E^l , which is the equity beta of the levered firm l l . Unlevered vs Levered \u00b6 On the other hand, firm u u and firm l l differ only in capital structure whilst both have the same asset. Let's say we have a portfolio of firm u u 's asset and the other portfolio of firm l l 's asset, then these two portfolios should have the same expected return and market risk exposure. 2 This means the two portfolios have the same beta, implying: \\begin{equation}\\beta_A^u = \\beta_A^l \\end{equation} \\begin{equation}\\beta_A^u = \\beta_A^l \\end{equation} If we substitue in the definition of unlevered and levered beta (equation (1) and (4)): \\begin{equation} \\beta_{\\text{unlevered}} = \\frac{1}{1+\\frac{D}{E}(1-t)} \\beta_{\\text{levered}} \\end{equation} \\begin{equation} \\beta_{\\text{unlevered}} = \\frac{1}{1+\\frac{D}{E}(1-t)} \\beta_{\\text{levered}} \\end{equation} or \\begin{equation} \\beta_{\\text{levered}} = \\left( 1+\\frac{D}{E}(1-t) \\right) \\beta_{\\text{unlevered}} \\end{equation} \\begin{equation} \\beta_{\\text{levered}} = \\left( 1+\\frac{D}{E}(1-t) \\right) \\beta_{\\text{unlevered}} \\end{equation} This is the formula that we use to lever and unlever beta. 1 Further Clarification \u00b6 The equity beta of a firm with debts is levered . To remove the impact of leverage on shareholders' market risk exposure, we need to unlever this beta in order to get the unlevered beta . This unlevered beta is also called the asset beta . Note that the asset beta is a syncronym for unlevered beta . It is not, however, the asset's beta \\beta_A^l \\beta_A^l when the firm is leveraged as in equation (2) to (4). This convention is confusing indeed, so throughout this post, I'm using asset's beta to refer to the beta of a portfolio of all securities (debt and equity) of the levered firm. Notations \u00b6 \\beta_E^u \\beta_E^u : the equity's beta of the unlevered firm \\beta_A^u \\beta_A^u : the asset's beta of the unlevered firm \\beta_E^l \\beta_E^l : the equity's beta of the levered firm \\beta_D^l \\beta_D^l : the debt's beta of the levered firm \\beta_A^l \\beta_A^l : the asset's beta of the levered firm D D : the size of the firm's debt E E : the size of the firm's equity t t : the tax rate \\beta_{\\text{unleverd}} \\beta_{\\text{unleverd}} : unlevered beta , the equity (asset) beta of the unlevered version of the firm \\beta_{\\text{leverd}} \\beta_{\\text{leverd}} : levered beta , the equity beta of the levered version of the firm This eq.(7) is also named Hamada Equation , where we assumed a zero debt beta. It draws on the Modigliani-Miller theorem on capital structure, and appeared in Prof. Robert Hamada's paper \"The Effect of the Firm's Capital Structure on the Systematic Risk of Common Stocks\" in the Journal of Finance in 1972. \u21a9 Modigliani-Miller theorem states that the capital structure should not affect a firm's value. \u21a9","title":"Beta, unlevered and levered"},{"location":"posts/beta-unlevered-and-levered/#beta-unlevered-and-levered","text":"Beta is a measure of market risk.","title":"Beta - Unlevered and Levered"},{"location":"posts/beta-unlevered-and-levered/#unlevered-firm-u","text":"If a firm has no debt, it's all equity-financed and thus its equity's beta \\beta_{E} \\beta_{E} equals its asset's beta \\beta_{A} \\beta_{A} . This beta is also the unlevered beta , \\beta_{\\text{unlevered}} \\beta_{\\text{unlevered}} , since it's unaffected by leverage. The unlevered beta measures the market risk exposure of the firm's shareholders. Let's call this firm u u , Hence, we have: \\begin{equation} \\beta_{\\text{unlevered}}=\\beta_E^u=\\beta_A^u \\end{equation} \\begin{equation} \\beta_{\\text{unlevered}}=\\beta_E^u=\\beta_A^u \\end{equation} This equality says that in an unlevered firm, the unlevered beta equals its equity beta and its asset beta.","title":"Unlevered Firm u"},{"location":"posts/beta-unlevered-and-levered/#levered-firm-l","text":"If the same firm is partly financed by debt, let's call it firm l l . The asset of the levered firm l l is financed by both equity and debt, and hence the asset's market risk is from both equity and debt. The asset's beta is a weighted average of its equity beta and debt beta. \\begin{equation} \\beta_A^l = \\frac{E}{E+D(1-t)} \\beta_E^l + \\frac{D(1-t)}{E+D(1-t)} \\beta_D^l \\end{equation} \\begin{equation} \\beta_A^l = \\frac{E}{E+D(1-t)} \\beta_E^l + \\frac{D(1-t)}{E+D(1-t)} \\beta_D^l \\end{equation} \\beta_A^l \\beta_A^l measures the change in the return on a portfolio of all firm l l 's securities (debt and equity) for each additional one percent change in the market return. This part is not very hard to understand. The beta of a portfolio is the weighted average beta of its constituents. If you believe that debt beta is zero since the value of debt may not be affected by the equity market, then \\beta_D^l=0 \\beta_D^l=0 and the equation (2) can be simplified to: \\begin{align} \\beta_A^l &= \\frac{E}{E+D(1-t)} \\beta_E^l \\newline &= \\frac{1}{1+\\frac{D}{E}(1-t)} \\beta_E^l \\end{align} \\begin{align} \\beta_A^l &= \\frac{E}{E+D(1-t)} \\beta_E^l \\newline &= \\frac{1}{1+\\frac{D}{E}(1-t)} \\beta_E^l \\end{align} However, this firm's shareholders are now more exposed to the market risk than before, because leverage increases the variation in the payoff to shareholders. This means the equity's beta of this levered firm is higher than the equity's beta of the unlevered firm, i.e. \\beta_E^l>\\beta_E^u \\beta_E^l>\\beta_E^u . Note that, the levered beta \\beta_{\\text{levered}} \\beta_{\\text{levered}} that we talk about refers to \\beta_E^l \\beta_E^l , which is the equity beta of the levered firm l l .","title":"Levered Firm l"},{"location":"posts/beta-unlevered-and-levered/#unlevered-vs-levered","text":"On the other hand, firm u u and firm l l differ only in capital structure whilst both have the same asset. Let's say we have a portfolio of firm u u 's asset and the other portfolio of firm l l 's asset, then these two portfolios should have the same expected return and market risk exposure. 2 This means the two portfolios have the same beta, implying: \\begin{equation}\\beta_A^u = \\beta_A^l \\end{equation} \\begin{equation}\\beta_A^u = \\beta_A^l \\end{equation} If we substitue in the definition of unlevered and levered beta (equation (1) and (4)): \\begin{equation} \\beta_{\\text{unlevered}} = \\frac{1}{1+\\frac{D}{E}(1-t)} \\beta_{\\text{levered}} \\end{equation} \\begin{equation} \\beta_{\\text{unlevered}} = \\frac{1}{1+\\frac{D}{E}(1-t)} \\beta_{\\text{levered}} \\end{equation} or \\begin{equation} \\beta_{\\text{levered}} = \\left( 1+\\frac{D}{E}(1-t) \\right) \\beta_{\\text{unlevered}} \\end{equation} \\begin{equation} \\beta_{\\text{levered}} = \\left( 1+\\frac{D}{E}(1-t) \\right) \\beta_{\\text{unlevered}} \\end{equation} This is the formula that we use to lever and unlever beta. 1","title":"Unlevered vs Levered"},{"location":"posts/beta-unlevered-and-levered/#further-clarification","text":"The equity beta of a firm with debts is levered . To remove the impact of leverage on shareholders' market risk exposure, we need to unlever this beta in order to get the unlevered beta . This unlevered beta is also called the asset beta . Note that the asset beta is a syncronym for unlevered beta . It is not, however, the asset's beta \\beta_A^l \\beta_A^l when the firm is leveraged as in equation (2) to (4). This convention is confusing indeed, so throughout this post, I'm using asset's beta to refer to the beta of a portfolio of all securities (debt and equity) of the levered firm.","title":"Further Clarification"},{"location":"posts/beta-unlevered-and-levered/#notations","text":"\\beta_E^u \\beta_E^u : the equity's beta of the unlevered firm \\beta_A^u \\beta_A^u : the asset's beta of the unlevered firm \\beta_E^l \\beta_E^l : the equity's beta of the levered firm \\beta_D^l \\beta_D^l : the debt's beta of the levered firm \\beta_A^l \\beta_A^l : the asset's beta of the levered firm D D : the size of the firm's debt E E : the size of the firm's equity t t : the tax rate \\beta_{\\text{unleverd}} \\beta_{\\text{unleverd}} : unlevered beta , the equity (asset) beta of the unlevered version of the firm \\beta_{\\text{leverd}} \\beta_{\\text{leverd}} : levered beta , the equity beta of the levered version of the firm This eq.(7) is also named Hamada Equation , where we assumed a zero debt beta. It draws on the Modigliani-Miller theorem on capital structure, and appeared in Prof. Robert Hamada's paper \"The Effect of the Firm's Capital Structure on the Systematic Risk of Common Stocks\" in the Journal of Finance in 1972. \u21a9 Modigliani-Miller theorem states that the capital structure should not affect a firm's value. \u21a9","title":"Notations"},{"location":"posts/bitcoin-address-generator-in-obfuscated-python/","text":"Bitcoin Address Generator in Obfuscated Python \u00b6 Never underestimate what programmers can do. The code below shows a fully-functioning Bitcoin address generator in obfuscated Python (2.5-2.7), which I saw in an interesting article posted in 2013. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 _ = r \"\"\"A(W/2,*M(3*G *G*V(2*J%P),G,J,G)+((M((J-T )*V((G-S)%P),S,T,G)if(S@(G,J))if( W%2@(S,T)))if(W@(S,T);H=2**256;import&h ashlib&as&h,os,re,bi nascii&as&k;J$:int( k.b2a_hex(W),16);C$:C (W/ 58)+[W%58]if(W@ [];X=h.new(\"rip em d160\");Y$:h.sha25 6(W).digest();I$ d=32:I(W/256,d-1)+ chr(W%256)if(d>0@\"\"; U$:J(k.a2b_base 64(W));f=J(os.urando m(64)) %(H-U(\"AUVRIxl Qt1/EQC2hcy/JvsA=\"))+ 1;M$Q,R,G :((W*W-Q-G)%P, (W*(G+2*Q-W*W)-R)%P) ;P=H-2** 32-977;V$Q=P,L= 1,O=0:V(Q%W,W,O-Q/W* L,L)if(W@O%P;S, T=A(f,U(\"eb5mfvncu6 xVoGKVzocLBwKb/Nst zijZWfKBWxb4F5g=\"), U(\"SDra dyajxGVdpPv8DhEI qP0XtEimhVQZnEfQj/ sQ1Lg=\"), 0,0);F$:\"1\"+F(W [1:])if(W[:1 ]==\"\\0\"@\"\" .join(map(B,C( J(W))));K$: F(W +Y(Y(W))[:4]); X.update(Y(\"\\4\"+ I(S)+I(T)));B$ :re.sub(\"[0OIl _]| [^\\\\w]\",\"\",\"\".jo in(map(chr,ra nge (123))))[W];print\"Addre ss:\",K(\"\\0\"+X.dig est())+\"\\nPrivkey:\",K( \"\\x80\"+I(f))\"\"\" ; exec ( reduce ( lambda W , X : W . replace ( * X ), zip ( \" \\n &$@\" ,[ \"\" , \"\" , \" \" , \"=lambda W,\" , \")else \" ]) , \"A$G,J,S,T:\" + _ )) I\u2019ve tested it on Python 2.7 on Ubuntu. Working like a charm. Warning Don't use this address! The private key is not private!","title":"Bitcoin address generator in obfuscated Python"},{"location":"posts/bitcoin-address-generator-in-obfuscated-python/#bitcoin-address-generator-in-obfuscated-python","text":"Never underestimate what programmers can do. The code below shows a fully-functioning Bitcoin address generator in obfuscated Python (2.5-2.7), which I saw in an interesting article posted in 2013. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 _ = r \"\"\"A(W/2,*M(3*G *G*V(2*J%P),G,J,G)+((M((J-T )*V((G-S)%P),S,T,G)if(S@(G,J))if( W%2@(S,T)))if(W@(S,T);H=2**256;import&h ashlib&as&h,os,re,bi nascii&as&k;J$:int( k.b2a_hex(W),16);C$:C (W/ 58)+[W%58]if(W@ [];X=h.new(\"rip em d160\");Y$:h.sha25 6(W).digest();I$ d=32:I(W/256,d-1)+ chr(W%256)if(d>0@\"\"; U$:J(k.a2b_base 64(W));f=J(os.urando m(64)) %(H-U(\"AUVRIxl Qt1/EQC2hcy/JvsA=\"))+ 1;M$Q,R,G :((W*W-Q-G)%P, (W*(G+2*Q-W*W)-R)%P) ;P=H-2** 32-977;V$Q=P,L= 1,O=0:V(Q%W,W,O-Q/W* L,L)if(W@O%P;S, T=A(f,U(\"eb5mfvncu6 xVoGKVzocLBwKb/Nst zijZWfKBWxb4F5g=\"), U(\"SDra dyajxGVdpPv8DhEI qP0XtEimhVQZnEfQj/ sQ1Lg=\"), 0,0);F$:\"1\"+F(W [1:])if(W[:1 ]==\"\\0\"@\"\" .join(map(B,C( J(W))));K$: F(W +Y(Y(W))[:4]); X.update(Y(\"\\4\"+ I(S)+I(T)));B$ :re.sub(\"[0OIl _]| [^\\\\w]\",\"\",\"\".jo in(map(chr,ra nge (123))))[W];print\"Addre ss:\",K(\"\\0\"+X.dig est())+\"\\nPrivkey:\",K( \"\\x80\"+I(f))\"\"\" ; exec ( reduce ( lambda W , X : W . replace ( * X ), zip ( \" \\n &$@\" ,[ \"\" , \"\" , \" \" , \"=lambda W,\" , \")else \" ]) , \"A$G,J,S,T:\" + _ )) I\u2019ve tested it on Python 2.7 on Ubuntu. Working like a charm. Warning Don't use this address! The private key is not private!","title":"Bitcoin Address Generator in Obfuscated Python"},{"location":"posts/bloomberg-bquant/","text":"Bloomberg BQuant (BQNT) \u00b6 Bloomberg is developing a new function in the Terminal, called BQuant, BQNT , under the Bloomberg Anywhere license. I happen to be able to test it thanks to a fund manager and find it could be a future way of using Bloomberg Terminal. Background \u00b6 Bloomberg recently made JupyterLab available inside the Terminal and invited partners to test it out. This function is named BQuant , or BQNT<GO> , which is still under heavy development, but the idea is just great. Jupyter notebooks inside Bloomberg Terminal! Just before this news, I was helping a fund manager in writing some alert programs that do some analysis on equity market and then send email notifications, which didn\u2019t go well because first it is very easy to breach the data limit using Bloomberg API (blpapi) and second I wasn\u2019t very comfortable about the presentation of analysis results. I was using poor HTML code in emails and didn\u2019t find a convenient way to insert plots and figures. Besides, I was also writing some back testing code to evaluate potential trading strategies. But still there\u2019s a concern as I won\u2019t be working there full time and they probably won\u2019t have a permanent programmer, so if they want to alter parameters a little bit it\u2019ll be a problem. But things happen, with BQNT or more specifically the Jupyter notebook, I can make an interactive UI-based application without worrying about the data limit issue, as they also provide a new data retrieval interface, BQL , Bloomberg Query Language . In the past, pulling data through blpapi is basically retrieving data from the Terminal. But BQL, something like SQL, is to submit the query request to Bloomberg\u2019s server and get the data directly from server, which also enables basic calculations so as to further reduce the size of data being pulled out. Then, BQNT comes with pre-installed bqplot and some wrappers of libraries like ipwidgets, which makes visualization much easier and interactive. As BQNT is a customized JupyterLab, output cells can be maximized and code hided. The result is just like a single-page application. The tearsheet above shows some basic features of BQNT, and of course there are more. There\u2019s a gallery in the Terminal with several demos showing what BQNT can make, including portfolio performance report, security filtering, trading strategy back test, etc., quite inspiring. With a quick play, I was able to write a multi-security back test of William %R based strategy with trailing stop. All input parameters can be varied using sliders, dropdowns, calendars and etc. There is also an autocomplete security selection widget to assist you in defining the universe. Plots and tables can be aligned nicely using HBox and VBox\u2026 So, I\u2019m impressed, really. I can foresee that in the future, users of Bloomberg Terminal can have BQNT powered applications tailored to their needs. For example, I want to know the stock volatility and price plot together with some commodity futures orderbook info. BQNT may give you the app. But of course, I\u2019ve only a rough guess and there could be many possibles and impossibles ahead of BQNT. I\u2019m a big fan, though. My Work \u00b6 BQL for Data Retrieval \u00b6 We know there\u2019s a blpapi available already. Using this API one can pull data from a Terminal to Excel, Python, etc. But there is a limit on the frequency or total queries allowed in a certain period, which however isn\u2019t clear. As Bloomberg doesn\u2019t allow local storage of its data, if we need to retrieve a sizeable data too many times, there will be an issue. The good thing about BQNT is that it comes with a new query system \u2013 so called BQL. It allows simple calculations done on the server side so as to reduce the size of data transferred. And, people in Bloomberg said, by using BQL we are not very likely to face any data limit issue again. I haven\u2019t done much stress tests so I can\u2019t tell whether there is still a limit or not. Some Quick Examples \u00b6 Get all component stocks of an index: 1 2 3 import bql bq = bql . Service () securities = bq . univ . members ( 'AS31 Index' ) Get OHLC data of all component stocks: 4 5 6 7 from bql.util import get_time_series start_date = '2017-01-01' end_date = '2018-01-01' data = get_time_series ( securities , [ 'PX_LAST' , 'PX_OPEN' , 'PX_HIGH' , 'PX_LOW' ], start_date , end_date ) If I want to know the industry sector of these stock, all I need is: 8 9 req = bql . Request ( securities , bq . data . industry_sector ()) data_industry = bql . combined_df ( bq . execute ( req )) The returned data is a pandas.DataFrame , which is just awesome! Customised JupyterLab \u00b6 Jupyter Notebook has always been a favourite environment in data science. No need to say much. A JupyterLab inside Bloomberg Terminal together with BQL, basically the core idea of BQNT, is no doubt fantastic. For quants who need to do a lot of testings on trading ideas, filtering of securities, etc., this integrated environment is absolutely a good place to sort everything out. Moreover, files in BQNT are synced under a BBA license, you can easily pick up your work from any Terminal. In our meeting today, the size of this free cloud storage is said to be about 250MB but may be upgraded. For fund managers or traders who want only a ready-to-use application, they can have some programmers to make one for them. The BQNT team kindly demonstrated a beta feature, where a \u2018 consumer view \u2019 can be shared to others, which hides all Jupyter Notebook related parts and is really the final output alone \u2014 just like the Calculator on Windows. The %R Backtesting App \u00b6 This App I wrote replicates BT<GO> in its back testing outputs, but comes with more flexibility such as trailing stop loss, which isn\u2019t available in BT<GO>. It serves as a demo of BQNT powered application, validating current beta. The objectives of the app are: to perform %R strategy on a single security as well as on all components of an index; to provide both quantitative and qualitative back testing results; be friendly to any user with zero programming knowledge. Main UI \u00b6 The main UI provides a short description of the trading strategy under back test, followed by a control panel where we can specify benchmark, underlying, time range, % parameters as well as trailing stop loss percentage. I also put a progress bar and status bar below for more immediate feedback. Outputs \u00b6 If the underlying selected is a single security, e.g. CBA AU Equity, the simple back test output is something like below. An InteractiveLinePlot linked with a subplot to show equity evolution in selection; a LinePlot for the price series of the security with markers for enters and exits; and a LinePlot for the %R indicator. If the underlying selected is an index, e.g. AS31 Index, the back test is performed on each individual component of the index and results are presented below. A KDEPlot shows the distribution of total return, max return and min return, followed by a ToggleButtons to show All, Positive only and Negative only. Equity Return by industry sector and the benchmark return are sorted and plotted below. Then there is the detailed DataGrid for all calculated metrics of all securities and of each industry sectors, just like the output in BT<GO>. Results can be exported to a spreadsheet which will be conveniently stored in the BQNT platform, or the \u2018cloud\u2019 of size 250MB in total. A qualitative summary of this particular back test is provided in the end. This App is by no means a finished work. I basically tried to mix in as many different things as possible. The end product should be one such that provides a condensed and conclusive opinion after each run, considering that its users may be those fund managers who do not want to get their hands dirty. Other Thoughts \u00b6 In my chat with Bloomberg BQNT team, I visioned BQNT powered apps may be the future way of using Bloomberg. For one, with more internal integration worked out, like the current one with PORT<GO>, surely users can use these UI-based apps to get jobs done. The good thing is that it can put everything you need together in one place, and only those you need. Once consumer view is rolled out, this will be more evident. They also are developing a scheduling module which will run Notebooks automatically, although at an additional cost. Another thing I suggested is a marketplace for those BQNT powered apps. Say, I\u2019ve developed a market analysis application on BQNT, maybe I can put it for sale on the marketplace so someone else won\u2019t need to reinvent the wheel. It can also foster a community around BQNT, if any. The only downside is that BQNT is accessible only under BBA licence, which isn\u2019t cheap. Individual programmers / quants may not be able to afford it, and those in big institutions may not have the time and right to build and sell apps on it. This kinda sucks. I can see the huge potential of BQNT, which if operates well can be the new way of using Bloomberg Terminal \u2014 the learning curve of Terminal is really too steep for many current and potential users, and they don\u2019t get very much out of it. But, if there are many ready-to-use UI-based applications for their customised needs, things definitely will be better. Unfortunately, BQNT is not open-source, and the access to it is very limited (BBA licence), I don\u2019t believe there will be an active community and hence a marketplace of a variety of apps.","title":"Bloomberg BQuant (BQNT)"},{"location":"posts/bloomberg-bquant/#bloomberg-bquant-bqnt","text":"Bloomberg is developing a new function in the Terminal, called BQuant, BQNT , under the Bloomberg Anywhere license. I happen to be able to test it thanks to a fund manager and find it could be a future way of using Bloomberg Terminal.","title":"Bloomberg BQuant (BQNT)"},{"location":"posts/bloomberg-bquant/#background","text":"Bloomberg recently made JupyterLab available inside the Terminal and invited partners to test it out. This function is named BQuant , or BQNT<GO> , which is still under heavy development, but the idea is just great. Jupyter notebooks inside Bloomberg Terminal! Just before this news, I was helping a fund manager in writing some alert programs that do some analysis on equity market and then send email notifications, which didn\u2019t go well because first it is very easy to breach the data limit using Bloomberg API (blpapi) and second I wasn\u2019t very comfortable about the presentation of analysis results. I was using poor HTML code in emails and didn\u2019t find a convenient way to insert plots and figures. Besides, I was also writing some back testing code to evaluate potential trading strategies. But still there\u2019s a concern as I won\u2019t be working there full time and they probably won\u2019t have a permanent programmer, so if they want to alter parameters a little bit it\u2019ll be a problem. But things happen, with BQNT or more specifically the Jupyter notebook, I can make an interactive UI-based application without worrying about the data limit issue, as they also provide a new data retrieval interface, BQL , Bloomberg Query Language . In the past, pulling data through blpapi is basically retrieving data from the Terminal. But BQL, something like SQL, is to submit the query request to Bloomberg\u2019s server and get the data directly from server, which also enables basic calculations so as to further reduce the size of data being pulled out. Then, BQNT comes with pre-installed bqplot and some wrappers of libraries like ipwidgets, which makes visualization much easier and interactive. As BQNT is a customized JupyterLab, output cells can be maximized and code hided. The result is just like a single-page application. The tearsheet above shows some basic features of BQNT, and of course there are more. There\u2019s a gallery in the Terminal with several demos showing what BQNT can make, including portfolio performance report, security filtering, trading strategy back test, etc., quite inspiring. With a quick play, I was able to write a multi-security back test of William %R based strategy with trailing stop. All input parameters can be varied using sliders, dropdowns, calendars and etc. There is also an autocomplete security selection widget to assist you in defining the universe. Plots and tables can be aligned nicely using HBox and VBox\u2026 So, I\u2019m impressed, really. I can foresee that in the future, users of Bloomberg Terminal can have BQNT powered applications tailored to their needs. For example, I want to know the stock volatility and price plot together with some commodity futures orderbook info. BQNT may give you the app. But of course, I\u2019ve only a rough guess and there could be many possibles and impossibles ahead of BQNT. I\u2019m a big fan, though.","title":"Background"},{"location":"posts/bloomberg-bquant/#my-work","text":"","title":"My Work"},{"location":"posts/bloomberg-bquant/#bql-for-data-retrieval","text":"We know there\u2019s a blpapi available already. Using this API one can pull data from a Terminal to Excel, Python, etc. But there is a limit on the frequency or total queries allowed in a certain period, which however isn\u2019t clear. As Bloomberg doesn\u2019t allow local storage of its data, if we need to retrieve a sizeable data too many times, there will be an issue. The good thing about BQNT is that it comes with a new query system \u2013 so called BQL. It allows simple calculations done on the server side so as to reduce the size of data transferred. And, people in Bloomberg said, by using BQL we are not very likely to face any data limit issue again. I haven\u2019t done much stress tests so I can\u2019t tell whether there is still a limit or not.","title":"BQL for Data Retrieval"},{"location":"posts/bloomberg-bquant/#some-quick-examples","text":"Get all component stocks of an index: 1 2 3 import bql bq = bql . Service () securities = bq . univ . members ( 'AS31 Index' ) Get OHLC data of all component stocks: 4 5 6 7 from bql.util import get_time_series start_date = '2017-01-01' end_date = '2018-01-01' data = get_time_series ( securities , [ 'PX_LAST' , 'PX_OPEN' , 'PX_HIGH' , 'PX_LOW' ], start_date , end_date ) If I want to know the industry sector of these stock, all I need is: 8 9 req = bql . Request ( securities , bq . data . industry_sector ()) data_industry = bql . combined_df ( bq . execute ( req )) The returned data is a pandas.DataFrame , which is just awesome!","title":"Some Quick Examples"},{"location":"posts/bloomberg-bquant/#customised-jupyterlab","text":"Jupyter Notebook has always been a favourite environment in data science. No need to say much. A JupyterLab inside Bloomberg Terminal together with BQL, basically the core idea of BQNT, is no doubt fantastic. For quants who need to do a lot of testings on trading ideas, filtering of securities, etc., this integrated environment is absolutely a good place to sort everything out. Moreover, files in BQNT are synced under a BBA license, you can easily pick up your work from any Terminal. In our meeting today, the size of this free cloud storage is said to be about 250MB but may be upgraded. For fund managers or traders who want only a ready-to-use application, they can have some programmers to make one for them. The BQNT team kindly demonstrated a beta feature, where a \u2018 consumer view \u2019 can be shared to others, which hides all Jupyter Notebook related parts and is really the final output alone \u2014 just like the Calculator on Windows.","title":"Customised JupyterLab"},{"location":"posts/bloomberg-bquant/#the-r-backtesting-app","text":"This App I wrote replicates BT<GO> in its back testing outputs, but comes with more flexibility such as trailing stop loss, which isn\u2019t available in BT<GO>. It serves as a demo of BQNT powered application, validating current beta. The objectives of the app are: to perform %R strategy on a single security as well as on all components of an index; to provide both quantitative and qualitative back testing results; be friendly to any user with zero programming knowledge.","title":"The %R Backtesting App"},{"location":"posts/bloomberg-bquant/#main-ui","text":"The main UI provides a short description of the trading strategy under back test, followed by a control panel where we can specify benchmark, underlying, time range, % parameters as well as trailing stop loss percentage. I also put a progress bar and status bar below for more immediate feedback.","title":"Main UI"},{"location":"posts/bloomberg-bquant/#outputs","text":"If the underlying selected is a single security, e.g. CBA AU Equity, the simple back test output is something like below. An InteractiveLinePlot linked with a subplot to show equity evolution in selection; a LinePlot for the price series of the security with markers for enters and exits; and a LinePlot for the %R indicator. If the underlying selected is an index, e.g. AS31 Index, the back test is performed on each individual component of the index and results are presented below. A KDEPlot shows the distribution of total return, max return and min return, followed by a ToggleButtons to show All, Positive only and Negative only. Equity Return by industry sector and the benchmark return are sorted and plotted below. Then there is the detailed DataGrid for all calculated metrics of all securities and of each industry sectors, just like the output in BT<GO>. Results can be exported to a spreadsheet which will be conveniently stored in the BQNT platform, or the \u2018cloud\u2019 of size 250MB in total. A qualitative summary of this particular back test is provided in the end. This App is by no means a finished work. I basically tried to mix in as many different things as possible. The end product should be one such that provides a condensed and conclusive opinion after each run, considering that its users may be those fund managers who do not want to get their hands dirty.","title":"Outputs"},{"location":"posts/bloomberg-bquant/#other-thoughts","text":"In my chat with Bloomberg BQNT team, I visioned BQNT powered apps may be the future way of using Bloomberg. For one, with more internal integration worked out, like the current one with PORT<GO>, surely users can use these UI-based apps to get jobs done. The good thing is that it can put everything you need together in one place, and only those you need. Once consumer view is rolled out, this will be more evident. They also are developing a scheduling module which will run Notebooks automatically, although at an additional cost. Another thing I suggested is a marketplace for those BQNT powered apps. Say, I\u2019ve developed a market analysis application on BQNT, maybe I can put it for sale on the marketplace so someone else won\u2019t need to reinvent the wheel. It can also foster a community around BQNT, if any. The only downside is that BQNT is accessible only under BBA licence, which isn\u2019t cheap. Individual programmers / quants may not be able to afford it, and those in big institutions may not have the time and right to build and sell apps on it. This kinda sucks. I can see the huge potential of BQNT, which if operates well can be the new way of using Bloomberg Terminal \u2014 the learning curve of Terminal is really too steep for many current and potential users, and they don\u2019t get very much out of it. But, if there are many ready-to-use UI-based applications for their customised needs, things definitely will be better. Unfortunately, BQNT is not open-source, and the access to it is very limited (BBA licence), I don\u2019t believe there will be an active community and hence a marketplace of a variety of apps.","title":"Other Thoughts"},{"location":"posts/call-option-value-from-two-approaches/","text":"Call Option Value from Two Approaches \u00b6 Suppose today the stock price is S S and in one year time, the stock price could be either S_1 S_1 or S_2 S_2 . You hold an European call option on this stock with an exercise price of X=S X=S , where S_1<X<S_2 S_1<X<S_2 for simplicity. So you'll exercise the call when the stock price turns out to be S_2 S_2 and leave it unexercised if S_1 S_1 . 1. Replicating Portfolio Approach \u00b6 Case 1 Case 2 Stock Price S_1 S_1 S_2 S_2 Option: 1 Call of cost c c Exercise? No Yes Payoff (to replicate) 0 S_2-X S_2-X Stock: \\delta \\delta shares of cost \\delta S \\delta S Payoff \\delta S_1 \\delta S_1 \\delta S_2 \\delta S_2 Borrowing PV(K) Repay K K So we have: \\begin{equation} \\delta S_1-K=0 \\end{equation} \\begin{equation} \\delta S_1-K=0 \\end{equation} \\begin{equation} \\delta S_2 -K = S_2-X \\end{equation} \\begin{equation} \\delta S_2 -K = S_2-X \\end{equation} Therefore, the call option value is given by the difference between the cost of \\delta \\delta units of shares and the amount of borrowing: \\begin{align} c_{REP} &= \\delta S - PV(K) \\newline &= \\delta S - Ke^{-r_f} \\newline &= \\delta S - \\delta S_1e^{-r_f} \\end{align} \\begin{align} c_{REP} &= \\delta S - PV(K) \\newline &= \\delta S - Ke^{-r_f} \\newline &= \\delta S - \\delta S_1e^{-r_f} \\end{align} When \\delta \\delta is defined as \\frac{(S_2-X)-0}{S_2-S_1} \\frac{(S_2-X)-0}{S_2-S_1} as in the textbook (at introductory level), \\begin{equation} c_{REP}= \\frac{S_2-X}{S_2-S_1}(S - S_1e^{-r_f}) \\end{equation} \\begin{equation} c_{REP}= \\frac{S_2-X}{S_2-S_1}(S - S_1e^{-r_f}) \\end{equation} 2. Risk Neutral Approach \u00b6 Without too much trouble, we can derive the call value using risk neutral approach as \\begin{align} c_{RN} &= \\frac{p(S_2-X)+(1-p)\\times0}{e^{r_f}}\\newline &= \\frac{p(S_2-X)+0}{e^{r_f}}\\newline &= p(S_2-X) e^{-r_f} \\end{align} \\begin{align} c_{RN} &= \\frac{p(S_2-X)+(1-p)\\times0}{e^{r_f}}\\newline &= \\frac{p(S_2-X)+0}{e^{r_f}}\\newline &= p(S_2-X) e^{-r_f} \\end{align} We know that \\begin{equation} p\\times \\frac{S_2}{S} + (1-p)\\frac{S_1}{S} = e^{r_f} \\end{equation} \\begin{equation} p\\times \\frac{S_2}{S} + (1-p)\\frac{S_1}{S} = e^{r_f} \\end{equation} so \\begin{align} p &= \\frac{e^{r_f}-\\frac{S_1}{S}}{\\frac{S_2}{S}-\\frac{S_1}{S}}\\newline &=\\frac{Se^{r_f}-S_1}{S_2-S_1} \\end{align} \\begin{align} p &= \\frac{e^{r_f}-\\frac{S_1}{S}}{\\frac{S_2}{S}-\\frac{S_1}{S}}\\newline &=\\frac{Se^{r_f}-S_1}{S_2-S_1} \\end{align} Therefore, \\begin{align} c_{RN} &= p(S_2-X) e^{r_f}\\newline &=\\frac{Se^{r_f}-S_1}{S_2-S_1}(S_2-X) e^{-r_f}\\newline &=\\frac{S-S_1e^{-r_f}}{S_2-S_1}(S_2-X) \\end{align} \\begin{align} c_{RN} &= p(S_2-X) e^{r_f}\\newline &=\\frac{Se^{r_f}-S_1}{S_2-S_1}(S_2-X) e^{-r_f}\\newline &=\\frac{S-S_1e^{-r_f}}{S_2-S_1}(S_2-X) \\end{align} Identical Result from the Two Methods \u00b6 It's easy to find that c_{RN} = c_{REP} c_{RN} = c_{REP} Hence, the call option value from replicating portfolio is the same as from risk neutral approach.","title":"Call option value from two approaches"},{"location":"posts/call-option-value-from-two-approaches/#call-option-value-from-two-approaches","text":"Suppose today the stock price is S S and in one year time, the stock price could be either S_1 S_1 or S_2 S_2 . You hold an European call option on this stock with an exercise price of X=S X=S , where S_1<X<S_2 S_1<X<S_2 for simplicity. So you'll exercise the call when the stock price turns out to be S_2 S_2 and leave it unexercised if S_1 S_1 .","title":"Call Option Value from Two Approaches"},{"location":"posts/call-option-value-from-two-approaches/#1-replicating-portfolio-approach","text":"Case 1 Case 2 Stock Price S_1 S_1 S_2 S_2 Option: 1 Call of cost c c Exercise? No Yes Payoff (to replicate) 0 S_2-X S_2-X Stock: \\delta \\delta shares of cost \\delta S \\delta S Payoff \\delta S_1 \\delta S_1 \\delta S_2 \\delta S_2 Borrowing PV(K) Repay K K So we have: \\begin{equation} \\delta S_1-K=0 \\end{equation} \\begin{equation} \\delta S_1-K=0 \\end{equation} \\begin{equation} \\delta S_2 -K = S_2-X \\end{equation} \\begin{equation} \\delta S_2 -K = S_2-X \\end{equation} Therefore, the call option value is given by the difference between the cost of \\delta \\delta units of shares and the amount of borrowing: \\begin{align} c_{REP} &= \\delta S - PV(K) \\newline &= \\delta S - Ke^{-r_f} \\newline &= \\delta S - \\delta S_1e^{-r_f} \\end{align} \\begin{align} c_{REP} &= \\delta S - PV(K) \\newline &= \\delta S - Ke^{-r_f} \\newline &= \\delta S - \\delta S_1e^{-r_f} \\end{align} When \\delta \\delta is defined as \\frac{(S_2-X)-0}{S_2-S_1} \\frac{(S_2-X)-0}{S_2-S_1} as in the textbook (at introductory level), \\begin{equation} c_{REP}= \\frac{S_2-X}{S_2-S_1}(S - S_1e^{-r_f}) \\end{equation} \\begin{equation} c_{REP}= \\frac{S_2-X}{S_2-S_1}(S - S_1e^{-r_f}) \\end{equation}","title":"1. Replicating Portfolio Approach"},{"location":"posts/call-option-value-from-two-approaches/#2-risk-neutral-approach","text":"Without too much trouble, we can derive the call value using risk neutral approach as \\begin{align} c_{RN} &= \\frac{p(S_2-X)+(1-p)\\times0}{e^{r_f}}\\newline &= \\frac{p(S_2-X)+0}{e^{r_f}}\\newline &= p(S_2-X) e^{-r_f} \\end{align} \\begin{align} c_{RN} &= \\frac{p(S_2-X)+(1-p)\\times0}{e^{r_f}}\\newline &= \\frac{p(S_2-X)+0}{e^{r_f}}\\newline &= p(S_2-X) e^{-r_f} \\end{align} We know that \\begin{equation} p\\times \\frac{S_2}{S} + (1-p)\\frac{S_1}{S} = e^{r_f} \\end{equation} \\begin{equation} p\\times \\frac{S_2}{S} + (1-p)\\frac{S_1}{S} = e^{r_f} \\end{equation} so \\begin{align} p &= \\frac{e^{r_f}-\\frac{S_1}{S}}{\\frac{S_2}{S}-\\frac{S_1}{S}}\\newline &=\\frac{Se^{r_f}-S_1}{S_2-S_1} \\end{align} \\begin{align} p &= \\frac{e^{r_f}-\\frac{S_1}{S}}{\\frac{S_2}{S}-\\frac{S_1}{S}}\\newline &=\\frac{Se^{r_f}-S_1}{S_2-S_1} \\end{align} Therefore, \\begin{align} c_{RN} &= p(S_2-X) e^{r_f}\\newline &=\\frac{Se^{r_f}-S_1}{S_2-S_1}(S_2-X) e^{-r_f}\\newline &=\\frac{S-S_1e^{-r_f}}{S_2-S_1}(S_2-X) \\end{align} \\begin{align} c_{RN} &= p(S_2-X) e^{r_f}\\newline &=\\frac{Se^{r_f}-S_1}{S_2-S_1}(S_2-X) e^{-r_f}\\newline &=\\frac{S-S_1e^{-r_f}}{S_2-S_1}(S_2-X) \\end{align}","title":"2. Risk Neutral Approach"},{"location":"posts/call-option-value-from-two-approaches/#identical-result-from-the-two-methods","text":"It's easy to find that c_{RN} = c_{REP} c_{RN} = c_{REP} Hence, the call option value from replicating portfolio is the same as from risk neutral approach.","title":"Identical Result from the Two Methods"},{"location":"posts/compute-jackknife-coefficient-estimates-in-sas/","text":"Compute Jackknife Coefficient Estimates in SAS \u00b6 In certain scenarios, we want to estimate a model's parameters on the sample for each observation with itself excluded. This can be achieved by estimating the model repeatedly on the leave-one-out samples but is very inefficient. If we estimate the model on the full sample, however, the coefficient estimates will certainly be biased. Thankfully, we have the Jackknife method to correct for the bias, which produces the Jackknifed coefficient estimates for each observation. Variable Definition \u00b6 Let's start with some variable definitions to help with the explanation. Variable Definition b(i) b(i) the parameter estimates after deleting the i i th observation s^2(i) s^2(i) the variance estimate after deleting the i i th observation X(i) X(i) the X X matrix without the i i th observation \\hat{y}(i) \\hat{y}(i) the i i th value predicted without using the i i th observation r_i = y_i - \\hat{y}_i r_i = y_i - \\hat{y}_i the i i th residual h_i = x_i(X'X)^{-1}x_i' h_i = x_i(X'X)^{-1}x_i' the i i th diagonal of the projection matrix for the predictor space, also called the hat matrix RStudent =\\frac{r_i}{s(i) \\sqrt{1-h_i}} RStudent =\\frac{r_i}{s(i) \\sqrt{1-h_i}} studentized residual (X'X)_{jj} (X'X)_{jj} the (j,j) (j,j) th element of (X'X)^{-1} (X'X)^{-1} DFBeta_j = \\frac{b_{j} - b_{(i)j}}{s(i)\\sqrt{(X'X)_{jj}}} DFBeta_j = \\frac{b_{j} - b_{(i)j}}{s(i)\\sqrt{(X'X)_{jj}}} the scaled measures of the change in the j j th parameter estimate calculated by deleting the i i th observation Objective \u00b6 Compute the coefficient estiamtes with the i i th observation excluded from the sample, i.e. b(i) b(i) , or the Jackknifed coefficient estimate. Formula \u00b6 From the table above, we can get that the j j th Jackknifed coefficient estimate b_{(i)j} b_{(i)j} without using the i i th observation is: b_{(i)j} = b_j - DFBeta_j \\times s(i) \\sqrt{(X'X)_{jj}} b_{(i)j} = b_j - DFBeta_j \\times s(i) \\sqrt{(X'X)_{jj}} Hence, b_{(i)j} = b_j - DFBeta_j \\times \\frac{r_i}{RStudent\\times \\sqrt{1-h_i}} \\sqrt{(X'X)_{jj}} b_{(i)j} = b_j - DFBeta_j \\times \\frac{r_i}{RStudent\\times \\sqrt{1-h_i}} \\sqrt{(X'X)_{jj}} The good thing is that PROC REG produces the coefficient estimate b_j b_j for j=1,2,...K j=1,2,...K , where K K is the number of coefficients, and the INFLUENCE and I options produce the remaining statistics just enough to compute b(i) b(i) : Variable Option in PROC REG or MODEL statement Name in the output dataset b_j b_j Outest= option in PROC REG <jthVariable> r_i r_i OutputStatistics= from INFLUENCE option in MODEL statement Residual RStudent RStudent OutputStatistics= from INFLUENCE option in MODEL statement RStudent h_i h_i OutputStatistics= from INFLUENCE option in MODEL statement HatDiagnol DFBeta_j DFBeta_j OutputStatistics= from INFLUENCE option in MODEL statement DFB_<jthVariable> (X'X)_{jj} (X'X)_{jj} InvXPX= from I option in MODEL statement <jthVariable> Example \u00b6 Discretionary accruals \u00b6 Suppose we want to calculate the firm-level discretionary accruals for each year using the Jones (1991) model and Kothari et al (2005) model. For a firm i i , we need to first estimate the model for the industry-year excluding firm i i , then use the coefficient estimates to generate predicted accruals for firm i i . The firm's discretionary accruals is the actual accruals minus the predicted accruals. Below is an example PROC REG that produces three datasets named work.params , work.outstats and work.xpxinv , which contain sufficient statistics to compute the Jackknifed estimates and thus the predicted accruals. 1 2 3 4 5 6 7 8 9 10 11 12 13 ods listing close ; proc reg data=work . funda edf outest=work . params; /* industry-year regression */ by fyear sic2; /* id is necessary for later matching Jackknifed coefficients to firm-year */ id key ; /* Jones Model */ Jones: model tac = inv_at_l drev ppe / noint influence i; /* Kothari Model with ROA */ Kothari: model tac = inv_at_l drevadj ppe roa / noint influence i; ods output OutputStatistics=work . outstats InvXPX=work . xpxinv ; run; ods listing; Full SAS program for estimating 5 different measures of discretionary accruals: SAS code for computing discretionary accruals 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 /* Use Jackknife method to compute discretionary accruals */ /* see https://mingze-gao.com/posts/compute-jackknife-coefficient-estimates-in-sas/ */ /* UseHribarCollinsTotalAccruals: - true: use Hribar-Collins Cashflow Total Accruals - false: use normal method */ %let UseHribarCollinsTotalAccruals = false; /* Include %array and %do_over */ filename do_over url \"https://mingze-gao.com/utils/do_over.sas\" ; filename array url \"https://mingze-gao.com/utils/array.sas\" ; %include do_over array ; /* Winsorize macro */ filename winsor url \"https://mingze-gao.com/utils/winsor.sas\" ; %include winsor; /* Earnings management models Author: Mingze (Adrian) Gao, Feb 2019 Modified based on the work by Joost Impink, March 2016 Models estimated (Note that the intercept a0 is removed in the modified code below): - Jones model, tac = a0 + a1 1/TAt-1 + a2chSales + a3PPE + a4ROA + error. - variable names DA_Jones - Modified Jones model, as Jones model, but using chSales - chREC to compute fitted values. - variable names DA_mJones - Kothari 2005, controlling for ROA, tac = a0 + a1 1/TAt-1 + a2(chSales - chREC) + a3PPE + a4ROA + error. - variable names DA_Kothari - Kothari 2005, performance matched, Jones model, difference in discretionary accruals between firm and closest firm in terms of (contemporaneous) roa - variable names DA_pmKothari_Jones - Kothari 2005, performance matched, modified Jones model, difference in discretionary accruals between firm and closest firm in terms of (contemporaneous) roa - variable names DA_pmKothari_mJones tac: Total accruals, computed as net profit after tax before extraordinary items less cash flows from operations 1/TAt-1: Inverse of beginning of year total assets chSales: Change in net sales revenue chREC: Change in net receivables PPE: Gross property, plant, and equipment ROA: Return on assets. Variables used Compustat Funda AT: Total assets IB: Income Before Extraordinary Items IBC: Income Before Extraordinary Items (Cash Flow) (used if IB is missing) OANCF: Operating Activities - Net Cash Flow PPEGT: Property, Plant and Equipment - Total (Gross) RECT: Receivables - Total SALE: Sales INVT: Inventories - Total LCO: Current Liabilities Other Total DP: Depreciation and Amortization ACO: Current Assets Other Total AP: Accounts Payable - Trade */ /* Get Funda variables */ %let fundaVars = at ib ibc oancf ppegt rect sale xidoc lco dp aco invt ap ; data work . a_funda( keep = key gvkey fyear datadate sich &fundaVars ); set comp . funda; if 1980 <= fyear <= 2018 ; /* Generic filter */ if indfmt= 'INDL' and datafmt= 'STD' and popsrc= 'D' and consol= 'C' ; /* Firm-year identifier */ key = gvkey || fyear; /* Keep if sale > 0, at > 0 */ if sale > 0 and at > 0 ; /* Use Income Before Extraordinary Items (Cash Flow) if ib is missing */ if ib =. then ib=ibc ; run; /* Lagged values for: at sale rect invt aco ap lco */ %let lagVars = at sale rect invt aco ap lco; /* Self join to get lagged values at_l, sale_l, rect_l */ proc sql; create table work . b_funda as select a.*, %do_over (values= &lagVars , between=comma, phrase=b.? as ?_l) from work . a_funda a, work . a_funda b where a . gvkey = b . gvkey and a . fyear -1 = b . fyear ; quit; /* Construct additional variables */ data work . b_funda(compress=yes); set work . b_funda; /* 2-digit SIC */ sic2 = int( sich/ 100 ); /* variables */ if \" &UseHribarCollinsTotalAccruals. \" eq \"false\" then tac = ((rect-rect_l)+(invt-invt_l)+(aco-aco_l)-(ap-ap_l)-(lco-lco_l)-dp)/at_l; /* Accruals ratio */ else tac = (ibc - oancf + xidoc)/at_l; /* Hribar Collins total cash flow accruals */ inv_at_l = 1 / at_l; drev = (sale - sale_l) / at_l; drevadj = (sale - sale_l)/at_l - (rect - rect_l)/at_l; ppe = ppegt / at_l; roa = ib / at_l; /* these variables may not be missing (cmiss counts missing variables)*/ *if cmiss (of tac inv_at_l drevadj ppe roa) eq 0; run; /* Optional winsorization before industry-year regression */ %let winsVars = tac inv_at_l drev drevadj ppe roa ; %winsor (dsetin=work . b_funda, dsetout=work . b_funda_wins, byvar=fyear, vars= &winsVars , type=winsor, pctl= 1 99 ); /* Regression by industry-year edf(error degrees of freedom) + #params will equal the number of obs (no need for proc univariate to count) */ proc sort data=work . b_funda_wins; by fyear sic2 ; run; /* regressors */ %array (vars, values=inv_at_l drev ppe drevadj roa); ods listing close ; proc reg data=work . b_funda_wins edf outest=work . c_parms; by fyear sic2; id key ; /* Jones Model */ Jones: model tac = inv_at_l drev ppe / noint influence i; /* Kothari with ROA in model */ Kothari: model tac = inv_at_l drevadj ppe roa / noint influence i; ods output OutputStatistics=work . outstats InvXPX=work . xpxinv ; run; ods listing; /* Compute discretionary accrual measures */ proc sql; /* Compute firm-year Jackknifed coefficient estimates */ create table work . xpxinv2 as /* Extract the diagnol elements of the symmetric inv(X'X) for each firm-year */ select fyear, sic2, model, %do_over (vars, phrase= sum( case when variable= \"?\" then xpxinv else . end ) as ?, between=comma) from ( select fyear, sic2, model, variable, case %do_over (vars, phrase=when variable= \"?\" then ?) else . end as xpxinv from work . xpxinv where variable ~= 'tac' ) group by fyear, sic2, model order by fyear, sic2, model; /* The difference between original coefficient estimates and the Jackknifed estimates */ create table work . bias as select a . fyear, a . sic2, a . model, a . key , %do_over (vars, phrase=a . DFB_?*(a . Residual/(a . RStudent* sqrt( 1 -a . HatDiagonal)))* sqrt( b.?) as bias_?, between=comma) from work . outstats as a left join work . xpxinv2 as b on a . fyear=b . fyear and a . sic2=b . sic2 and a . model=b . model order by a . fyear, a . sic2, a . model, a . key ; /* Compute Jackknifed coefficient estimates by subtracting the bias from the original estimates */ create table work . Jackknifed_params as select a . fyear, a . sic2, a . model, a . key , %do_over (vars, phrase=b.? - a . bias_? as ?, between=comma), b . _EDF_ from work . bias as a left join work . c_parms as b on a . fyear=b . fyear and a . sic2=b . sic2 and a . model=b . _MODEL_ order by a . fyear, a . sic2, a . model, a . key ; /* Compute discretionary accruals */ create table work . tmp as select distinct a . fyear, a . sic2, a . gvkey, a . key , /* Jones model at a minimum 8 obs (5 degrees of freedom + 3 params) */ sum( case when b . model eq 'Jones' and b . _EDF_ ge 5 then a . tac - ( %do_over (values=inv_at_l drev ppe, between= %str (+), phrase=a.? * b.?)) else . end ) as DA_Jones, /* Modified Jones model: drev is used in first model, but drevadj is used to compute fitted value */ sum( case when b . model eq 'Jones' and b . _EDF_ ge 5 then a . tac - (a . drevadj * b . drev + %do_over (values=inv_at_l ppe, between= %str (+), phrase=a.? * b.?)) else . end ) as DA_mJones, /* Kothari model (with ROA in regression) at a minimum 8 obs (4 degrees of freedom + 4 params) */ sum( case when b . model eq 'Kothari' and b . _EDF_ ge 4 then a . tac - ( %do_over (values=inv_at_l drevadj ppe roa, between= %str (+), phrase=a.? * b.?)) else . end ) as DA_Kothari from work . b_funda_wins as a left join work . Jackknifed_params as b on a . key =b . key group by a . key order by a . gvkey, a . fyear; /* Kothari performance matching: get DA_Jones (DA_mJones) accruals for the matched firm closest in ROA */ create table work . da_roa as select a.*, b . roa from work . tmp as a left join work . b_funda_wins as b on a . key =b . key ; create table work . da_all as select a.*, /* gvkey of matched firm */ b . gvkey as gvkey_m, /* difference in ROA */ abs( a . roa - b . roa) as Difference, /* difference in DA_Jones */ a . DA_Jones - b . DA_Jones as DA_pmKothari_Jones, a . DA_mJones - b . DA_mJones as DA_pmKothari_mJones from work . da_roa as a left join work . da_roa as b on a . fyear = b . fyear and a . sic2 = b . sic2 /* same 2-digit SIC industry-year */ and a . key ne b . key /* not the same firm */ group by a . gvkey, a . fyear having Difference = min( Difference) /* keep best match for size difference */ order by gvkey, fyear ; quit; /* drop possible multiple matches (with the same difference) in previous step */ proc sort data=work . da_all nodupkey; by key ; run; %let DAVars = DA_Jones DA_mJones DA_Kothari DA_pmKothari_Jones DA_pmKothari_mJones; /* Winsorize discretionary accrual variables (Optional) */ %winsor (dsetin=work . da_all, dsetout=work . accruals_HribarCollins_ &UseHribarCollinsTotalAccruals. , byvar=fyear, vars= &DAVars , type=winsor, pctl= 1 99 ); /* Means, medians for key variables */ proc means data=work . accruals_HribarCollins_ &UseHribarCollinsTotalAccruals. n mean min median max; var &DAVars ; run;","title":"Compute jackknife coefficient estimates in SAS"},{"location":"posts/compute-jackknife-coefficient-estimates-in-sas/#compute-jackknife-coefficient-estimates-in-sas","text":"In certain scenarios, we want to estimate a model's parameters on the sample for each observation with itself excluded. This can be achieved by estimating the model repeatedly on the leave-one-out samples but is very inefficient. If we estimate the model on the full sample, however, the coefficient estimates will certainly be biased. Thankfully, we have the Jackknife method to correct for the bias, which produces the Jackknifed coefficient estimates for each observation.","title":"Compute Jackknife Coefficient Estimates in SAS"},{"location":"posts/compute-jackknife-coefficient-estimates-in-sas/#variable-definition","text":"Let's start with some variable definitions to help with the explanation. Variable Definition b(i) b(i) the parameter estimates after deleting the i i th observation s^2(i) s^2(i) the variance estimate after deleting the i i th observation X(i) X(i) the X X matrix without the i i th observation \\hat{y}(i) \\hat{y}(i) the i i th value predicted without using the i i th observation r_i = y_i - \\hat{y}_i r_i = y_i - \\hat{y}_i the i i th residual h_i = x_i(X'X)^{-1}x_i' h_i = x_i(X'X)^{-1}x_i' the i i th diagonal of the projection matrix for the predictor space, also called the hat matrix RStudent =\\frac{r_i}{s(i) \\sqrt{1-h_i}} RStudent =\\frac{r_i}{s(i) \\sqrt{1-h_i}} studentized residual (X'X)_{jj} (X'X)_{jj} the (j,j) (j,j) th element of (X'X)^{-1} (X'X)^{-1} DFBeta_j = \\frac{b_{j} - b_{(i)j}}{s(i)\\sqrt{(X'X)_{jj}}} DFBeta_j = \\frac{b_{j} - b_{(i)j}}{s(i)\\sqrt{(X'X)_{jj}}} the scaled measures of the change in the j j th parameter estimate calculated by deleting the i i th observation","title":"Variable Definition"},{"location":"posts/compute-jackknife-coefficient-estimates-in-sas/#objective","text":"Compute the coefficient estiamtes with the i i th observation excluded from the sample, i.e. b(i) b(i) , or the Jackknifed coefficient estimate.","title":"Objective"},{"location":"posts/compute-jackknife-coefficient-estimates-in-sas/#formula","text":"From the table above, we can get that the j j th Jackknifed coefficient estimate b_{(i)j} b_{(i)j} without using the i i th observation is: b_{(i)j} = b_j - DFBeta_j \\times s(i) \\sqrt{(X'X)_{jj}} b_{(i)j} = b_j - DFBeta_j \\times s(i) \\sqrt{(X'X)_{jj}} Hence, b_{(i)j} = b_j - DFBeta_j \\times \\frac{r_i}{RStudent\\times \\sqrt{1-h_i}} \\sqrt{(X'X)_{jj}} b_{(i)j} = b_j - DFBeta_j \\times \\frac{r_i}{RStudent\\times \\sqrt{1-h_i}} \\sqrt{(X'X)_{jj}} The good thing is that PROC REG produces the coefficient estimate b_j b_j for j=1,2,...K j=1,2,...K , where K K is the number of coefficients, and the INFLUENCE and I options produce the remaining statistics just enough to compute b(i) b(i) : Variable Option in PROC REG or MODEL statement Name in the output dataset b_j b_j Outest= option in PROC REG <jthVariable> r_i r_i OutputStatistics= from INFLUENCE option in MODEL statement Residual RStudent RStudent OutputStatistics= from INFLUENCE option in MODEL statement RStudent h_i h_i OutputStatistics= from INFLUENCE option in MODEL statement HatDiagnol DFBeta_j DFBeta_j OutputStatistics= from INFLUENCE option in MODEL statement DFB_<jthVariable> (X'X)_{jj} (X'X)_{jj} InvXPX= from I option in MODEL statement <jthVariable>","title":"Formula"},{"location":"posts/compute-jackknife-coefficient-estimates-in-sas/#example","text":"","title":"Example"},{"location":"posts/compute-jackknife-coefficient-estimates-in-sas/#discretionary-accruals","text":"Suppose we want to calculate the firm-level discretionary accruals for each year using the Jones (1991) model and Kothari et al (2005) model. For a firm i i , we need to first estimate the model for the industry-year excluding firm i i , then use the coefficient estimates to generate predicted accruals for firm i i . The firm's discretionary accruals is the actual accruals minus the predicted accruals. Below is an example PROC REG that produces three datasets named work.params , work.outstats and work.xpxinv , which contain sufficient statistics to compute the Jackknifed estimates and thus the predicted accruals. 1 2 3 4 5 6 7 8 9 10 11 12 13 ods listing close ; proc reg data=work . funda edf outest=work . params; /* industry-year regression */ by fyear sic2; /* id is necessary for later matching Jackknifed coefficients to firm-year */ id key ; /* Jones Model */ Jones: model tac = inv_at_l drev ppe / noint influence i; /* Kothari Model with ROA */ Kothari: model tac = inv_at_l drevadj ppe roa / noint influence i; ods output OutputStatistics=work . outstats InvXPX=work . xpxinv ; run; ods listing; Full SAS program for estimating 5 different measures of discretionary accruals: SAS code for computing discretionary accruals 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 /* Use Jackknife method to compute discretionary accruals */ /* see https://mingze-gao.com/posts/compute-jackknife-coefficient-estimates-in-sas/ */ /* UseHribarCollinsTotalAccruals: - true: use Hribar-Collins Cashflow Total Accruals - false: use normal method */ %let UseHribarCollinsTotalAccruals = false; /* Include %array and %do_over */ filename do_over url \"https://mingze-gao.com/utils/do_over.sas\" ; filename array url \"https://mingze-gao.com/utils/array.sas\" ; %include do_over array ; /* Winsorize macro */ filename winsor url \"https://mingze-gao.com/utils/winsor.sas\" ; %include winsor; /* Earnings management models Author: Mingze (Adrian) Gao, Feb 2019 Modified based on the work by Joost Impink, March 2016 Models estimated (Note that the intercept a0 is removed in the modified code below): - Jones model, tac = a0 + a1 1/TAt-1 + a2chSales + a3PPE + a4ROA + error. - variable names DA_Jones - Modified Jones model, as Jones model, but using chSales - chREC to compute fitted values. - variable names DA_mJones - Kothari 2005, controlling for ROA, tac = a0 + a1 1/TAt-1 + a2(chSales - chREC) + a3PPE + a4ROA + error. - variable names DA_Kothari - Kothari 2005, performance matched, Jones model, difference in discretionary accruals between firm and closest firm in terms of (contemporaneous) roa - variable names DA_pmKothari_Jones - Kothari 2005, performance matched, modified Jones model, difference in discretionary accruals between firm and closest firm in terms of (contemporaneous) roa - variable names DA_pmKothari_mJones tac: Total accruals, computed as net profit after tax before extraordinary items less cash flows from operations 1/TAt-1: Inverse of beginning of year total assets chSales: Change in net sales revenue chREC: Change in net receivables PPE: Gross property, plant, and equipment ROA: Return on assets. Variables used Compustat Funda AT: Total assets IB: Income Before Extraordinary Items IBC: Income Before Extraordinary Items (Cash Flow) (used if IB is missing) OANCF: Operating Activities - Net Cash Flow PPEGT: Property, Plant and Equipment - Total (Gross) RECT: Receivables - Total SALE: Sales INVT: Inventories - Total LCO: Current Liabilities Other Total DP: Depreciation and Amortization ACO: Current Assets Other Total AP: Accounts Payable - Trade */ /* Get Funda variables */ %let fundaVars = at ib ibc oancf ppegt rect sale xidoc lco dp aco invt ap ; data work . a_funda( keep = key gvkey fyear datadate sich &fundaVars ); set comp . funda; if 1980 <= fyear <= 2018 ; /* Generic filter */ if indfmt= 'INDL' and datafmt= 'STD' and popsrc= 'D' and consol= 'C' ; /* Firm-year identifier */ key = gvkey || fyear; /* Keep if sale > 0, at > 0 */ if sale > 0 and at > 0 ; /* Use Income Before Extraordinary Items (Cash Flow) if ib is missing */ if ib =. then ib=ibc ; run; /* Lagged values for: at sale rect invt aco ap lco */ %let lagVars = at sale rect invt aco ap lco; /* Self join to get lagged values at_l, sale_l, rect_l */ proc sql; create table work . b_funda as select a.*, %do_over (values= &lagVars , between=comma, phrase=b.? as ?_l) from work . a_funda a, work . a_funda b where a . gvkey = b . gvkey and a . fyear -1 = b . fyear ; quit; /* Construct additional variables */ data work . b_funda(compress=yes); set work . b_funda; /* 2-digit SIC */ sic2 = int( sich/ 100 ); /* variables */ if \" &UseHribarCollinsTotalAccruals. \" eq \"false\" then tac = ((rect-rect_l)+(invt-invt_l)+(aco-aco_l)-(ap-ap_l)-(lco-lco_l)-dp)/at_l; /* Accruals ratio */ else tac = (ibc - oancf + xidoc)/at_l; /* Hribar Collins total cash flow accruals */ inv_at_l = 1 / at_l; drev = (sale - sale_l) / at_l; drevadj = (sale - sale_l)/at_l - (rect - rect_l)/at_l; ppe = ppegt / at_l; roa = ib / at_l; /* these variables may not be missing (cmiss counts missing variables)*/ *if cmiss (of tac inv_at_l drevadj ppe roa) eq 0; run; /* Optional winsorization before industry-year regression */ %let winsVars = tac inv_at_l drev drevadj ppe roa ; %winsor (dsetin=work . b_funda, dsetout=work . b_funda_wins, byvar=fyear, vars= &winsVars , type=winsor, pctl= 1 99 ); /* Regression by industry-year edf(error degrees of freedom) + #params will equal the number of obs (no need for proc univariate to count) */ proc sort data=work . b_funda_wins; by fyear sic2 ; run; /* regressors */ %array (vars, values=inv_at_l drev ppe drevadj roa); ods listing close ; proc reg data=work . b_funda_wins edf outest=work . c_parms; by fyear sic2; id key ; /* Jones Model */ Jones: model tac = inv_at_l drev ppe / noint influence i; /* Kothari with ROA in model */ Kothari: model tac = inv_at_l drevadj ppe roa / noint influence i; ods output OutputStatistics=work . outstats InvXPX=work . xpxinv ; run; ods listing; /* Compute discretionary accrual measures */ proc sql; /* Compute firm-year Jackknifed coefficient estimates */ create table work . xpxinv2 as /* Extract the diagnol elements of the symmetric inv(X'X) for each firm-year */ select fyear, sic2, model, %do_over (vars, phrase= sum( case when variable= \"?\" then xpxinv else . end ) as ?, between=comma) from ( select fyear, sic2, model, variable, case %do_over (vars, phrase=when variable= \"?\" then ?) else . end as xpxinv from work . xpxinv where variable ~= 'tac' ) group by fyear, sic2, model order by fyear, sic2, model; /* The difference between original coefficient estimates and the Jackknifed estimates */ create table work . bias as select a . fyear, a . sic2, a . model, a . key , %do_over (vars, phrase=a . DFB_?*(a . Residual/(a . RStudent* sqrt( 1 -a . HatDiagonal)))* sqrt( b.?) as bias_?, between=comma) from work . outstats as a left join work . xpxinv2 as b on a . fyear=b . fyear and a . sic2=b . sic2 and a . model=b . model order by a . fyear, a . sic2, a . model, a . key ; /* Compute Jackknifed coefficient estimates by subtracting the bias from the original estimates */ create table work . Jackknifed_params as select a . fyear, a . sic2, a . model, a . key , %do_over (vars, phrase=b.? - a . bias_? as ?, between=comma), b . _EDF_ from work . bias as a left join work . c_parms as b on a . fyear=b . fyear and a . sic2=b . sic2 and a . model=b . _MODEL_ order by a . fyear, a . sic2, a . model, a . key ; /* Compute discretionary accruals */ create table work . tmp as select distinct a . fyear, a . sic2, a . gvkey, a . key , /* Jones model at a minimum 8 obs (5 degrees of freedom + 3 params) */ sum( case when b . model eq 'Jones' and b . _EDF_ ge 5 then a . tac - ( %do_over (values=inv_at_l drev ppe, between= %str (+), phrase=a.? * b.?)) else . end ) as DA_Jones, /* Modified Jones model: drev is used in first model, but drevadj is used to compute fitted value */ sum( case when b . model eq 'Jones' and b . _EDF_ ge 5 then a . tac - (a . drevadj * b . drev + %do_over (values=inv_at_l ppe, between= %str (+), phrase=a.? * b.?)) else . end ) as DA_mJones, /* Kothari model (with ROA in regression) at a minimum 8 obs (4 degrees of freedom + 4 params) */ sum( case when b . model eq 'Kothari' and b . _EDF_ ge 4 then a . tac - ( %do_over (values=inv_at_l drevadj ppe roa, between= %str (+), phrase=a.? * b.?)) else . end ) as DA_Kothari from work . b_funda_wins as a left join work . Jackknifed_params as b on a . key =b . key group by a . key order by a . gvkey, a . fyear; /* Kothari performance matching: get DA_Jones (DA_mJones) accruals for the matched firm closest in ROA */ create table work . da_roa as select a.*, b . roa from work . tmp as a left join work . b_funda_wins as b on a . key =b . key ; create table work . da_all as select a.*, /* gvkey of matched firm */ b . gvkey as gvkey_m, /* difference in ROA */ abs( a . roa - b . roa) as Difference, /* difference in DA_Jones */ a . DA_Jones - b . DA_Jones as DA_pmKothari_Jones, a . DA_mJones - b . DA_mJones as DA_pmKothari_mJones from work . da_roa as a left join work . da_roa as b on a . fyear = b . fyear and a . sic2 = b . sic2 /* same 2-digit SIC industry-year */ and a . key ne b . key /* not the same firm */ group by a . gvkey, a . fyear having Difference = min( Difference) /* keep best match for size difference */ order by gvkey, fyear ; quit; /* drop possible multiple matches (with the same difference) in previous step */ proc sort data=work . da_all nodupkey; by key ; run; %let DAVars = DA_Jones DA_mJones DA_Kothari DA_pmKothari_Jones DA_pmKothari_mJones; /* Winsorize discretionary accrual variables (Optional) */ %winsor (dsetin=work . da_all, dsetout=work . accruals_HribarCollins_ &UseHribarCollinsTotalAccruals. , byvar=fyear, vars= &DAVars , type=winsor, pctl= 1 99 ); /* Means, medians for key variables */ proc means data=work . accruals_HribarCollins_ &UseHribarCollinsTotalAccruals. n mean min median max; var &DAVars ; run;","title":"Discretionary accruals"},{"location":"posts/compute-weekly-return-from-daily-crsp-data/","text":"Compute Weekly Return from Daily CRSP Data \u00b6 Computing the weekly returns from the CRSP daily stock data is a common task but may be tricky sometimes. Let's discuss a few different ways to get it done incorrectly and correctly. TL;DR Take me to the final solution! Surely -> The solution INCORRECT ways \u00b6 Let me start with a few incorrect ways, which may seem perfectly okay at first glance. This part is important because it shows you how a small mistake can lead to hard-to-discover bugs. Weekly index return from daily data \u00b6 Date as the Friday of the week Using intnx() , we can derive the Friday of the week given a date, as shown below. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 proc sql; /* Compute weekly marekt return from daily data */ create table mktret_weekly as select distinct date, year( date) as Year, week(date) as Week, case when weekday( date)= 6 then date else intnx( \"week.6\" ,date, 1 ) end as FridayOfWeek format =date9., ( exp(sum(log( 1 +sprtrn)))- 1 )* 100 as mktret label = \"Weekly SP500 Index Return (%)\" from crsp . dsi where year( date) between &startyear. and &endyear. group by year( date), week(date) order by date ; quit; Note that intnx(\"weekday.6\", date, 0) will give the last Friday, which is not what we want. We want the next Friday of the week for a given date, so we use intnx(\"weekday.6\", date, 1) . The case...when... statement ensures that if the given date is already a Friday, we don't go for the next one. Below is a sample output of the mktret_weekly table generated. Example output of mktret_weekly Obs Date Year Week FridayOfWeek mktret 1 19860102 1986 0 03JAN1986 -0.1893222 2 19860103 1986 0 03JAN1986 -0.1893222 3 19860106 1986 1 10JAN1986 -2.333080418 4 19860107 1986 1 10JAN1986 -2.333080418 5 19860108 1986 1 10JAN1986 -2.333080418 6 19860109 1986 1 10JAN1986 -2.333080418 7 19860110 1986 1 10JAN1986 -2.333080418 8 19860113 1986 2 17JAN1986 1.1992620931 9 19860114 1986 2 17JAN1986 1.1992620931 We can verify that the FridayOfWeek indeed gives the Friday of the week. Therefore, the final weekly dataset using Friday as the date identifier just need to keep FridayOfWeek and mktret . 1 2 3 4 5 6 7 8 9 10 11 12 13 proc sql; /* Compute weekly marekt return from daily data */ create table mktret_weekly as select distinct case when weekday( date)= 6 then date else intnx( \"week.6\" ,date, 1 ) end as date format =date9. label = \"Friday of the Week\" , ( exp(sum(log( 1 +sprtrn)))- 1 )* 100 as mktret label = \"Weekly SP500 Index Return (%)\" from crsp . dsi where year( date) between &startyear. and &endyear. group by year( date), week(date) order by date ; quit; Example output of mktret_weekly Obs date mktret 1 03JAN1986 -0.1893222 2 10JAN1986 -2.333080418 3 17JAN1986 1.1992620931 4 24JAN1986 -0.959555101 5 31JAN1986 2.5916781551 6 07FEB1986 1.3126828796 Date as the last trading day of the week 1 2 3 4 5 6 7 8 9 10 11 12 13 %let startyear= 1986 ; %let endyear= 2019 ; proc sql; /* Compute weekly marekt return from daily data */ create table mktret_weekly as select distinct date, ( exp(sum(log( 1 +sprtrn)))- 1 )* 100 as mktret label = \"Weekly SP500 Index Return (%)\" from crsp . dsi where year( date) between &startyear. and &endyear. group by year( date), week(date) having date= max( date) order by date ; quit; Note here that it's tempting to use having weekday(date)=6 to make sure the dates are all Friday. However, if Friday in a week is not the last trading day, then the weekly return will be missing. This is why here I use date=max(date) to ensure non-missing weekly returns. The date is the last trading day in any given week, consistent with the CRSP's daily stock file. The caveat here is that since the dates are the weekly last trading days, when merged with other weekly datasets, you should be very careful about whether the other dataset is using Friday or the last trading day per week as its date variable. Weekly stock return from daily data \u00b6 Following the same logic, we can calculate the weekly stock returns from daily CRSP data, where dates are aligned to the Friday of the week. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 proc sql; /* Stocks (ordinary shares only) in the financial sector */ create table stocks as select distinct permno from crsp . stocknames where shrcd in ( 10 , 11 ) and floor( siccd/ 100 ) between 60 and 67 ; create table stockrets_weekly as select distinct permno, case when weekday( date)= 6 then date else intnx( \"week.6\" ,date, 1 ) end as date format =date9. label = \"Friday of the Week\" , ( exp(sum(log( 1 +ret)))- 1 )* 100 as ret label = \"Weekly Return (%)\" from crsp . dsf where year( date) between &startyear. and &endyear. and permno in ( select * from stocks) and prc> 0 and not missing (ret) group by year( date), week(date), permno order by permno, date ; quit; What's wrong? \u00b6 The code above seems okay. We know that CRSP daily stock file contains many observations where the daily trading volume is 0, in which case the price is recorded as the negative bid-ask midpoint. Therefore, we restrict to only those with positive stock prices. So what's the problem? The problem is that a week can span two calendar years. For example, check out the last week of 2019: Mon Tue Wed Thu Fri Sat Sun 30 31 1 2 3 4 5 Dec30 and Dec31 belong to week 53 of 2019, while the code above will use these two days' returns to compute the weekly return and align the date to Jan03 of 2020. Jan01 to Jan03 belong to week 0 of 2020, so the code above will use these three days' returns to compute the weekly return and align the date to Jan03 of 2020. Now we have a mistake. A single week is broken into two because of the use of week() function in SAS. Another consequence is that when there're many years of data, there will be a lot of duplicates. CORRECT ways \u00b6 Now let's explore two ways that avoid this mistake. Although both generate the same result (there can be a few differences, see the caveat), the second one is much faster. 1. Start with a list of dates (slow version) \u00b6 Now we can write some correct code to compute the weekly returns. We'll generate a series of Fridays first, then we merge based on the past 5 calendar days. This will ensure all trading days with non-missing data will be included in the weekly return calculation, and correct the mistake mentioned above. 1 2 3 4 5 6 7 8 9 10 11 12 %let start_date = 01Jan1986; %let end_date = 31Dec2019; /* Generate a series of Fridays */ data fridays; date= \" &start_date \" d; do while (date<= \" &end_date \" d); if weekday( date)= 6 then output ; date= intnx( 'day' , date, 1 , 's' ); end ; format date date9. ; run; Weekly index return from daily data (as at Friday) 13 14 15 16 17 18 19 20 21 22 23 proc sql; /* Compute weekly index return from daily data */ create table mktret_weekly as select distinct a . date, ( exp(sum(log( 1 +sprtrn)))- 1 )* 100 as mktret label = \"Weekly SP500 Index Return (%)\" from fridays as a left join crsp . dsi as dsi on dsi . date between intnx( 'day' , a . date, - 4 ) and a . date group by a . date order by a . date ; quit; Weekly stock return from daily data (as at Friday) Note that this version is inefficient and takes a long time to run. 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 proc sql; /* Stocks (ordinary shares) in the financial sector (2-digit SIC=60-67) */ create table stocks as select distinct permno from crsp . stocknames where shrcd in ( 10 , 11 ) and floor( siccd/ 100 ) between 60 and 67 ; /* Compute weekly stock return from daily data */ create table stockrets_weekly as select distinct a . date, dsf . permno, dsf . hsiccd, ( exp(sum(log( 1 +ret)))- 1 )* 100 as ret label = \"Weekly Return (%)\" from fridays as a left join crsp . dsf as dsf on dsf . date between intnx( 'day' , a . date, - 4 ) and a . date and dsf . permno in ( select * from stocks) and dsf . prc> 0 and not missing (dsf . ret) group by dsf . permno, a . date order by dsf . permno, a . date ; quit; 2. Group using aligned dates (fast version with caveat) \u00b6 This version uses a similar logic from the previous incorrect one , but it groups based on the aligned dates instead of year(date) and week(date) . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 proc sql; /* Compute weekly stock return from daily data */ create table stockrets_weekly2 as select distinct permno, hsiccd, case when weekday( date)= 6 then date else intnx( \"week.6\" ,date, 1 ) end as date format =date9. label = \"Friday of the Week\" , ( exp(sum(log( 1 +ret)))- 1 )* 100 as ret label = \"Weekly Return (%)\" from crsp . dsf ( keep =permno date ret prc shrout hsiccd) where date between \"01Jan1986\" d and \"31Dec2019\" d and permno in ( select * from stocks) and prc> 0 and not missing (ret) group by permno, calculated date order by permno, date ; quit; Caveat If the beginning and ending dates, \"01Jan1986\"d and \"31Dec2019\"d in the example, are not Fridays, then the first and last weekly returns for all stocks will be incorrect, because they are not using all the daily data in those weeks. To fix this minor issue, simply extand the beginning and ending dates beyond your sample period by a few weeks.","title":"Compute weekly return from daily CRSP data"},{"location":"posts/compute-weekly-return-from-daily-crsp-data/#compute-weekly-return-from-daily-crsp-data","text":"Computing the weekly returns from the CRSP daily stock data is a common task but may be tricky sometimes. Let's discuss a few different ways to get it done incorrectly and correctly. TL;DR Take me to the final solution! Surely -> The solution","title":"Compute Weekly Return from Daily CRSP Data"},{"location":"posts/compute-weekly-return-from-daily-crsp-data/#incorrect-ways","text":"Let me start with a few incorrect ways, which may seem perfectly okay at first glance. This part is important because it shows you how a small mistake can lead to hard-to-discover bugs.","title":"INCORRECT ways"},{"location":"posts/compute-weekly-return-from-daily-crsp-data/#weekly-index-return-from-daily-data","text":"Date as the Friday of the week Using intnx() , we can derive the Friday of the week given a date, as shown below. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 proc sql; /* Compute weekly marekt return from daily data */ create table mktret_weekly as select distinct date, year( date) as Year, week(date) as Week, case when weekday( date)= 6 then date else intnx( \"week.6\" ,date, 1 ) end as FridayOfWeek format =date9., ( exp(sum(log( 1 +sprtrn)))- 1 )* 100 as mktret label = \"Weekly SP500 Index Return (%)\" from crsp . dsi where year( date) between &startyear. and &endyear. group by year( date), week(date) order by date ; quit; Note that intnx(\"weekday.6\", date, 0) will give the last Friday, which is not what we want. We want the next Friday of the week for a given date, so we use intnx(\"weekday.6\", date, 1) . The case...when... statement ensures that if the given date is already a Friday, we don't go for the next one. Below is a sample output of the mktret_weekly table generated. Example output of mktret_weekly Obs Date Year Week FridayOfWeek mktret 1 19860102 1986 0 03JAN1986 -0.1893222 2 19860103 1986 0 03JAN1986 -0.1893222 3 19860106 1986 1 10JAN1986 -2.333080418 4 19860107 1986 1 10JAN1986 -2.333080418 5 19860108 1986 1 10JAN1986 -2.333080418 6 19860109 1986 1 10JAN1986 -2.333080418 7 19860110 1986 1 10JAN1986 -2.333080418 8 19860113 1986 2 17JAN1986 1.1992620931 9 19860114 1986 2 17JAN1986 1.1992620931 We can verify that the FridayOfWeek indeed gives the Friday of the week. Therefore, the final weekly dataset using Friday as the date identifier just need to keep FridayOfWeek and mktret . 1 2 3 4 5 6 7 8 9 10 11 12 13 proc sql; /* Compute weekly marekt return from daily data */ create table mktret_weekly as select distinct case when weekday( date)= 6 then date else intnx( \"week.6\" ,date, 1 ) end as date format =date9. label = \"Friday of the Week\" , ( exp(sum(log( 1 +sprtrn)))- 1 )* 100 as mktret label = \"Weekly SP500 Index Return (%)\" from crsp . dsi where year( date) between &startyear. and &endyear. group by year( date), week(date) order by date ; quit; Example output of mktret_weekly Obs date mktret 1 03JAN1986 -0.1893222 2 10JAN1986 -2.333080418 3 17JAN1986 1.1992620931 4 24JAN1986 -0.959555101 5 31JAN1986 2.5916781551 6 07FEB1986 1.3126828796 Date as the last trading day of the week 1 2 3 4 5 6 7 8 9 10 11 12 13 %let startyear= 1986 ; %let endyear= 2019 ; proc sql; /* Compute weekly marekt return from daily data */ create table mktret_weekly as select distinct date, ( exp(sum(log( 1 +sprtrn)))- 1 )* 100 as mktret label = \"Weekly SP500 Index Return (%)\" from crsp . dsi where year( date) between &startyear. and &endyear. group by year( date), week(date) having date= max( date) order by date ; quit; Note here that it's tempting to use having weekday(date)=6 to make sure the dates are all Friday. However, if Friday in a week is not the last trading day, then the weekly return will be missing. This is why here I use date=max(date) to ensure non-missing weekly returns. The date is the last trading day in any given week, consistent with the CRSP's daily stock file. The caveat here is that since the dates are the weekly last trading days, when merged with other weekly datasets, you should be very careful about whether the other dataset is using Friday or the last trading day per week as its date variable.","title":"Weekly index return from daily data"},{"location":"posts/compute-weekly-return-from-daily-crsp-data/#weekly-stock-return-from-daily-data","text":"Following the same logic, we can calculate the weekly stock returns from daily CRSP data, where dates are aligned to the Friday of the week. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 proc sql; /* Stocks (ordinary shares only) in the financial sector */ create table stocks as select distinct permno from crsp . stocknames where shrcd in ( 10 , 11 ) and floor( siccd/ 100 ) between 60 and 67 ; create table stockrets_weekly as select distinct permno, case when weekday( date)= 6 then date else intnx( \"week.6\" ,date, 1 ) end as date format =date9. label = \"Friday of the Week\" , ( exp(sum(log( 1 +ret)))- 1 )* 100 as ret label = \"Weekly Return (%)\" from crsp . dsf where year( date) between &startyear. and &endyear. and permno in ( select * from stocks) and prc> 0 and not missing (ret) group by year( date), week(date), permno order by permno, date ; quit;","title":"Weekly stock return from daily data"},{"location":"posts/compute-weekly-return-from-daily-crsp-data/#whats-wrong","text":"The code above seems okay. We know that CRSP daily stock file contains many observations where the daily trading volume is 0, in which case the price is recorded as the negative bid-ask midpoint. Therefore, we restrict to only those with positive stock prices. So what's the problem? The problem is that a week can span two calendar years. For example, check out the last week of 2019: Mon Tue Wed Thu Fri Sat Sun 30 31 1 2 3 4 5 Dec30 and Dec31 belong to week 53 of 2019, while the code above will use these two days' returns to compute the weekly return and align the date to Jan03 of 2020. Jan01 to Jan03 belong to week 0 of 2020, so the code above will use these three days' returns to compute the weekly return and align the date to Jan03 of 2020. Now we have a mistake. A single week is broken into two because of the use of week() function in SAS. Another consequence is that when there're many years of data, there will be a lot of duplicates.","title":"What's wrong?"},{"location":"posts/compute-weekly-return-from-daily-crsp-data/#correct-ways","text":"Now let's explore two ways that avoid this mistake. Although both generate the same result (there can be a few differences, see the caveat), the second one is much faster.","title":"CORRECT ways"},{"location":"posts/compute-weekly-return-from-daily-crsp-data/#1-start-with-a-list-of-dates-slow-version","text":"Now we can write some correct code to compute the weekly returns. We'll generate a series of Fridays first, then we merge based on the past 5 calendar days. This will ensure all trading days with non-missing data will be included in the weekly return calculation, and correct the mistake mentioned above. 1 2 3 4 5 6 7 8 9 10 11 12 %let start_date = 01Jan1986; %let end_date = 31Dec2019; /* Generate a series of Fridays */ data fridays; date= \" &start_date \" d; do while (date<= \" &end_date \" d); if weekday( date)= 6 then output ; date= intnx( 'day' , date, 1 , 's' ); end ; format date date9. ; run; Weekly index return from daily data (as at Friday) 13 14 15 16 17 18 19 20 21 22 23 proc sql; /* Compute weekly index return from daily data */ create table mktret_weekly as select distinct a . date, ( exp(sum(log( 1 +sprtrn)))- 1 )* 100 as mktret label = \"Weekly SP500 Index Return (%)\" from fridays as a left join crsp . dsi as dsi on dsi . date between intnx( 'day' , a . date, - 4 ) and a . date group by a . date order by a . date ; quit; Weekly stock return from daily data (as at Friday) Note that this version is inefficient and takes a long time to run. 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 proc sql; /* Stocks (ordinary shares) in the financial sector (2-digit SIC=60-67) */ create table stocks as select distinct permno from crsp . stocknames where shrcd in ( 10 , 11 ) and floor( siccd/ 100 ) between 60 and 67 ; /* Compute weekly stock return from daily data */ create table stockrets_weekly as select distinct a . date, dsf . permno, dsf . hsiccd, ( exp(sum(log( 1 +ret)))- 1 )* 100 as ret label = \"Weekly Return (%)\" from fridays as a left join crsp . dsf as dsf on dsf . date between intnx( 'day' , a . date, - 4 ) and a . date and dsf . permno in ( select * from stocks) and dsf . prc> 0 and not missing (dsf . ret) group by dsf . permno, a . date order by dsf . permno, a . date ; quit;","title":"1. Start with a list of dates (slow version)"},{"location":"posts/compute-weekly-return-from-daily-crsp-data/#2-group-using-aligned-dates-fast-version-with-caveat","text":"This version uses a similar logic from the previous incorrect one , but it groups based on the aligned dates instead of year(date) and week(date) . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 proc sql; /* Compute weekly stock return from daily data */ create table stockrets_weekly2 as select distinct permno, hsiccd, case when weekday( date)= 6 then date else intnx( \"week.6\" ,date, 1 ) end as date format =date9. label = \"Friday of the Week\" , ( exp(sum(log( 1 +ret)))- 1 )* 100 as ret label = \"Weekly Return (%)\" from crsp . dsf ( keep =permno date ret prc shrout hsiccd) where date between \"01Jan1986\" d and \"31Dec2019\" d and permno in ( select * from stocks) and prc> 0 and not missing (ret) group by permno, calculated date order by permno, date ; quit; Caveat If the beginning and ending dates, \"01Jan1986\"d and \"31Dec2019\"d in the example, are not Fridays, then the first and last weekly returns for all stocks will be incorrect, because they are not using all the daily data in those weeks. To fix this minor issue, simply extand the beginning and ending dates beyond your sample period by a few weeks.","title":"2. Group using aligned dates (fast version with caveat)"},{"location":"posts/computing-jackknifed-coefficient-estimates-in-sas/","text":"","title":"Index"},{"location":"posts/convert-between-numeric-and-character-variables/","text":"Convert Between Numeric and Character Variable \u00b6 Converting between numeric and character variables is one of the most frequently encountered issues when processing datasets. This article explains how to do this conversion correctly and efficiently. Numeric to Character \u00b6 Assume there's an imported dataset named filings , where cik is stored as a numeric variable as shown below: cik file_type date 1000229 8-K 2011-09-30 100591 8-K 2006-05-11 100826 8-K 2009-06-30 93542 8-K 2007-01-25 Because cik is of different digits, to convert the numeric cik into a character variable, the natural procedure is to pad it with leading zeros. For example, cik (Central Index Key) itself is a 10-digit number used by SEC. In SAS, convert numeric variable to string with leading zeros (assuming 10-digit fixed length) is done via PUT() function: 1 2 3 data filings( drop =cik); set filings; cik_char = put (cik, z10.) ; run; Tip PUT() function also works in PROC SQL . The generated cik_char variable is of format and informat $10. , and the dataset becomes: cik_char file_type date 0001000229 8-K 2011-09-30 0000100591 8-K 2006-05-11 0000100826 8-K 2009-06-30 0000093542 8-K 2007-01-25 In STATA, convert numeric variable to string with leading zeros (assuming 6-digit fixed length) can be achieved via the string() function. 1 gen char_var = string (num_var, \"%06.0f\" ) Character to Numeric \u00b6 In SAS, converting a character variable to a numeric one uses the INPUT() function: 1 var_numeric = input (var_char, best12.); In STATA, this conversion be can be done via either real() function or destring command. 1 gen num_var = real (char_var); The real() function works on a single variable. destring command can convert all character variables into numeric in one go. 1 destring , repalce Warning If a character variable has non-numeric characters in it, then it will not be converted. In such a case, you may choose to use the encode command, although it in fact is generating categories. A more detailed explanation with examples is available at stats.idre.ucla.edu","title":"Convert between numeric and character variables"},{"location":"posts/convert-between-numeric-and-character-variables/#convert-between-numeric-and-character-variable","text":"Converting between numeric and character variables is one of the most frequently encountered issues when processing datasets. This article explains how to do this conversion correctly and efficiently.","title":"Convert Between Numeric and Character Variable"},{"location":"posts/convert-between-numeric-and-character-variables/#numeric-to-character","text":"Assume there's an imported dataset named filings , where cik is stored as a numeric variable as shown below: cik file_type date 1000229 8-K 2011-09-30 100591 8-K 2006-05-11 100826 8-K 2009-06-30 93542 8-K 2007-01-25 Because cik is of different digits, to convert the numeric cik into a character variable, the natural procedure is to pad it with leading zeros. For example, cik (Central Index Key) itself is a 10-digit number used by SEC. In SAS, convert numeric variable to string with leading zeros (assuming 10-digit fixed length) is done via PUT() function: 1 2 3 data filings( drop =cik); set filings; cik_char = put (cik, z10.) ; run; Tip PUT() function also works in PROC SQL . The generated cik_char variable is of format and informat $10. , and the dataset becomes: cik_char file_type date 0001000229 8-K 2011-09-30 0000100591 8-K 2006-05-11 0000100826 8-K 2009-06-30 0000093542 8-K 2007-01-25 In STATA, convert numeric variable to string with leading zeros (assuming 6-digit fixed length) can be achieved via the string() function. 1 gen char_var = string (num_var, \"%06.0f\" )","title":"Numeric to Character"},{"location":"posts/convert-between-numeric-and-character-variables/#character-to-numeric","text":"In SAS, converting a character variable to a numeric one uses the INPUT() function: 1 var_numeric = input (var_char, best12.); In STATA, this conversion be can be done via either real() function or destring command. 1 gen num_var = real (char_var); The real() function works on a single variable. destring command can convert all character variables into numeric in one go. 1 destring , repalce Warning If a character variable has non-numeric characters in it, then it will not be converted. In such a case, you may choose to use the encode command, although it in fact is generating categories. A more detailed explanation with examples is available at stats.idre.ucla.edu","title":"Character to Numeric"},{"location":"posts/decomposing-hhi-index/","text":"Decomposing Herfindahl\u2013Hirschman (HHI) Index \u00b6 Herfindahl\u2013Hirschman (HHI) Index is a well-known market concentration measure determined by two factors: the size distribution (variance) of firms, and the number of firms. Intuitively, having a hundred similar-sized gas stations in town means a far less concentrated environment than just one or two available, and when the number of firms is constant, their size distribution or variance determines the magnitude of market concentration. Since these two properties jointly determine the HHI measure of concentration, naturally we want a decomposition of HHI that can reflects these two dimensions respectively. This is particularly useful when two distinct markets have the same level of HHI measure, but the concentration may result from different sources. Note that here these two markets do not necessarily have to be industry A vesus industry B, but can be the same industry niche in two geographical areas, for example. Thus, we can think of HHI as the sum of the actual marekt state's deviation from 1) all firms having the same size, and the deviation from 2) a fully competitive environment with infinite number of firms in the market. Some simple math can solve our problem. Some math \u00b6 Let's say in a market ther are n n firms sized x_1, x_2, ... x_n x_1, x_2, ... x_n , thus we can describe the market using a \\mathbb R_+^n \\mathbb R_+^n vector: \\mathbf{x}=(x_1, x_2, ... x_n) \\mathbf{x}=(x_1, x_2, ... x_n) In the first scenario where all firms' sizes are equal, we can describe it with: \\mathbf{\\bar{x}}=(\\bar{x}, \\bar{x}, ... \\bar{x}) \\mathbf{\\bar{x}}=(\\bar{x}, \\bar{x}, ... \\bar{x}) where \\bar{x}=\\frac{1}{n} \\sum_{i=1}^{n}x_i \\bar{x}=\\frac{1}{n} \\sum_{i=1}^{n}x_i is the average firm size. The Euclidean distance between the point \\mathbf{x} \\mathbf{x} and \\mathbf{\\bar{x}} \\mathbf{\\bar{x}} , denoted as d(\\mathbf{x}, \\mathbf{\\bar{x}}) d(\\mathbf{x}, \\mathbf{\\bar{x}}) , is thus d(\\mathbf{x}, \\mathbf{\\bar{x}})=\\sqrt{ \\sum_{i=1}^{n} x_{i}^2 - n \\bar{x}^2 } d(\\mathbf{x}, \\mathbf{\\bar{x}})=\\sqrt{ \\sum_{i=1}^{n} x_{i}^2 - n \\bar{x}^2 } For the ease of discussion, let's consider the other spectrum of the second scenario where there's only one firm in the market instead of infinite firms, assuming its size is the sum of all firms in the first scenario (i.e. its size is n\\bar{x} n\\bar{x} ), we know that this market is the most concentrated state, \\mathbf{x^*} \\mathbf{x^*} . In other words, its distance to the market state in scenario one is the largest. \\max_{x} d(\\mathbf{x}, \\mathbf{\\bar{x}})=d(\\mathbf{x^*}, \\mathbf{\\bar{x}}) = ... = \\sqrt{ (n-1)n \\bar{x}^2 } \\max_{x} d(\\mathbf{x}, \\mathbf{\\bar{x}})=d(\\mathbf{x^*}, \\mathbf{\\bar{x}}) = ... = \\sqrt{ (n-1)n \\bar{x}^2 } Hence, the distance of any market state \\mathbf{x} \\mathbf{x} to the first scenario, the equidistribution point \\mathbf{\\bar{x}} \\mathbf{\\bar{x}} , should lie between 0 0 to d(\\mathbf{x^*}, \\mathbf{\\bar{x}}) d(\\mathbf{x^*}, \\mathbf{\\bar{x}}) . Thus we can derive a relative index of concentration (when n>1 n>1 ) as \\tau \\tau : \\tau=\\frac{ d(\\mathbf{x}, \\mathbf{\\bar{x}}) }{ d(\\mathbf{x^*}, \\mathbf{\\bar{x}}) } \\in [0, 1] \\tau=\\frac{ d(\\mathbf{x}, \\mathbf{\\bar{x}}) }{ d(\\mathbf{x^*}, \\mathbf{\\bar{x}}) } \\in [0, 1] Now, given the definition of Herfindahl-Hirschman Index H H that H=\\sum_{i=1}^{n} (\\frac{x_i}{n\\bar{x}})^2 H=\\sum_{i=1}^{n} (\\frac{x_i}{n\\bar{x}})^2 we can get: \\tau=\\sqrt{\\frac{n}{n-1}(H-\\frac{1}{n})} = \\sqrt{\\frac{nH-1}{n-1}} \\tau=\\sqrt{\\frac{n}{n-1}(H-\\frac{1}{n})} = \\sqrt{\\frac{nH-1}{n-1}} Here comes the important implications. Recall that \\tau \\tau represents the ratio of the distance between a market state and the equidistribution point to the maximum possible distance given a total market size of n\\bar{x} n\\bar{x} . When we observe a market state \\mathbf{x}=(x_1, x_2, ... x_n) \\mathbf{x}=(x_1, x_2, ... x_n) at a given time, the total market size is fixed and thus \\tau \\tau is only varying with the distance between the observed actual market state and the equidistribution state where all firms have the same size. This implies that \\tau \\tau could be a measure of the first determinant of market concentration, i.e. the size distribution (variance) of firms. Further, \\tau \\tau represents a sequence of functions whose limit is \\sqrt{H} \\sqrt{H} as n \\to +\\infty n \\to +\\infty , when the market is in a fully competitive environment. Thus, given a H' H' from the knowledge of n' n' and \\mathbf{x'} \\mathbf{x'} , we know there is one and only one matching \\tau' \\tau' and its limit of \\sqrt{H'} \\sqrt{H'} in the fully competitive environment. The graph below shows that H H can therefore be decomposed into two components, that is H = E_i + E_n H = E_i + E_n where E_i = \\tau^2 E_i = \\tau^2 , and E_n = H-\\tau^2 E_n = H-\\tau^2 . We mentioned before that \\tau \\tau can be measure of the market concentration resulted from the size distribution (variance) of firms, such that E_i=\\tau^2 E_i=\\tau^2 can be an even better one since it's smaller than H H , which enables us to measure the concentration contributed from the number of firms, measured by E_n E_n . This decomposition is appealing also in that E_n E_n , from the graph above, effectively is the horizontal difference between the two curves, i.e. the 'distance' between the actual market state and the fully competitive market with infinite number of firms (scenario two). Thus, it's safe to say this decomposition produces two components explaining the observed market concentration, 1) E_i E_i , the inequality of firm sizes effect, and 2) E_n E_n , the number of firms effect. Another finding from the graph is that with higher market concentration measured by H H , the relative importance of the two components is changing. When H H is small, most of the concentration is resulted from E_n E_n as highlighted below, which means the number of firms has a greater impact on market concentration. When H H is larger, on the other hand, E_i E_i contributes more to H H , which means the firm size inequality plays a bigger role in market concentration. A potential implication for regulators who are concerned about market concentration, I think, is to 1) focus more on reducing the entry barrier if the current concentration level is moderate, and to 2) focus more on antitrust if the concentration level is already high. Another implication for researchers is that even though H \\in [\\frac{1}{n}, 1] H \\in [\\frac{1}{n}, 1] is affected by the number of firms in a market, we should not attempt to use the \\text{normalized HHI}=\\frac{H-1/n}{1-1/n} \\in [0,1] \\text{normalized HHI}=\\frac{H-1/n}{1-1/n} \\in [0,1] . The reason is now very simple and clear -- the normalized HHI is nothing but E_i=\\tau^2 E_i=\\tau^2 , which reflects only the market concentration due to the inequality of firm sizes. When we compare across markets or the same market over time, apparently a market with 1,000 firms has a different competitive landscape than a market with only 2 firms. Acknowledgement \u00b6 This post is largely a replicate of the paper \"A Decomposition of the Herfindahl Index of Concentration\" by Giacomo de Gioia in 2017.","title":"Decomposing Herfindahl\u2013Hirschman (HHI) Index"},{"location":"posts/decomposing-hhi-index/#decomposing-herfindahlhirschman-hhi-index","text":"Herfindahl\u2013Hirschman (HHI) Index is a well-known market concentration measure determined by two factors: the size distribution (variance) of firms, and the number of firms. Intuitively, having a hundred similar-sized gas stations in town means a far less concentrated environment than just one or two available, and when the number of firms is constant, their size distribution or variance determines the magnitude of market concentration. Since these two properties jointly determine the HHI measure of concentration, naturally we want a decomposition of HHI that can reflects these two dimensions respectively. This is particularly useful when two distinct markets have the same level of HHI measure, but the concentration may result from different sources. Note that here these two markets do not necessarily have to be industry A vesus industry B, but can be the same industry niche in two geographical areas, for example. Thus, we can think of HHI as the sum of the actual marekt state's deviation from 1) all firms having the same size, and the deviation from 2) a fully competitive environment with infinite number of firms in the market. Some simple math can solve our problem.","title":"Decomposing Herfindahl\u2013Hirschman (HHI) Index"},{"location":"posts/decomposing-hhi-index/#some-math","text":"Let's say in a market ther are n n firms sized x_1, x_2, ... x_n x_1, x_2, ... x_n , thus we can describe the market using a \\mathbb R_+^n \\mathbb R_+^n vector: \\mathbf{x}=(x_1, x_2, ... x_n) \\mathbf{x}=(x_1, x_2, ... x_n) In the first scenario where all firms' sizes are equal, we can describe it with: \\mathbf{\\bar{x}}=(\\bar{x}, \\bar{x}, ... \\bar{x}) \\mathbf{\\bar{x}}=(\\bar{x}, \\bar{x}, ... \\bar{x}) where \\bar{x}=\\frac{1}{n} \\sum_{i=1}^{n}x_i \\bar{x}=\\frac{1}{n} \\sum_{i=1}^{n}x_i is the average firm size. The Euclidean distance between the point \\mathbf{x} \\mathbf{x} and \\mathbf{\\bar{x}} \\mathbf{\\bar{x}} , denoted as d(\\mathbf{x}, \\mathbf{\\bar{x}}) d(\\mathbf{x}, \\mathbf{\\bar{x}}) , is thus d(\\mathbf{x}, \\mathbf{\\bar{x}})=\\sqrt{ \\sum_{i=1}^{n} x_{i}^2 - n \\bar{x}^2 } d(\\mathbf{x}, \\mathbf{\\bar{x}})=\\sqrt{ \\sum_{i=1}^{n} x_{i}^2 - n \\bar{x}^2 } For the ease of discussion, let's consider the other spectrum of the second scenario where there's only one firm in the market instead of infinite firms, assuming its size is the sum of all firms in the first scenario (i.e. its size is n\\bar{x} n\\bar{x} ), we know that this market is the most concentrated state, \\mathbf{x^*} \\mathbf{x^*} . In other words, its distance to the market state in scenario one is the largest. \\max_{x} d(\\mathbf{x}, \\mathbf{\\bar{x}})=d(\\mathbf{x^*}, \\mathbf{\\bar{x}}) = ... = \\sqrt{ (n-1)n \\bar{x}^2 } \\max_{x} d(\\mathbf{x}, \\mathbf{\\bar{x}})=d(\\mathbf{x^*}, \\mathbf{\\bar{x}}) = ... = \\sqrt{ (n-1)n \\bar{x}^2 } Hence, the distance of any market state \\mathbf{x} \\mathbf{x} to the first scenario, the equidistribution point \\mathbf{\\bar{x}} \\mathbf{\\bar{x}} , should lie between 0 0 to d(\\mathbf{x^*}, \\mathbf{\\bar{x}}) d(\\mathbf{x^*}, \\mathbf{\\bar{x}}) . Thus we can derive a relative index of concentration (when n>1 n>1 ) as \\tau \\tau : \\tau=\\frac{ d(\\mathbf{x}, \\mathbf{\\bar{x}}) }{ d(\\mathbf{x^*}, \\mathbf{\\bar{x}}) } \\in [0, 1] \\tau=\\frac{ d(\\mathbf{x}, \\mathbf{\\bar{x}}) }{ d(\\mathbf{x^*}, \\mathbf{\\bar{x}}) } \\in [0, 1] Now, given the definition of Herfindahl-Hirschman Index H H that H=\\sum_{i=1}^{n} (\\frac{x_i}{n\\bar{x}})^2 H=\\sum_{i=1}^{n} (\\frac{x_i}{n\\bar{x}})^2 we can get: \\tau=\\sqrt{\\frac{n}{n-1}(H-\\frac{1}{n})} = \\sqrt{\\frac{nH-1}{n-1}} \\tau=\\sqrt{\\frac{n}{n-1}(H-\\frac{1}{n})} = \\sqrt{\\frac{nH-1}{n-1}} Here comes the important implications. Recall that \\tau \\tau represents the ratio of the distance between a market state and the equidistribution point to the maximum possible distance given a total market size of n\\bar{x} n\\bar{x} . When we observe a market state \\mathbf{x}=(x_1, x_2, ... x_n) \\mathbf{x}=(x_1, x_2, ... x_n) at a given time, the total market size is fixed and thus \\tau \\tau is only varying with the distance between the observed actual market state and the equidistribution state where all firms have the same size. This implies that \\tau \\tau could be a measure of the first determinant of market concentration, i.e. the size distribution (variance) of firms. Further, \\tau \\tau represents a sequence of functions whose limit is \\sqrt{H} \\sqrt{H} as n \\to +\\infty n \\to +\\infty , when the market is in a fully competitive environment. Thus, given a H' H' from the knowledge of n' n' and \\mathbf{x'} \\mathbf{x'} , we know there is one and only one matching \\tau' \\tau' and its limit of \\sqrt{H'} \\sqrt{H'} in the fully competitive environment. The graph below shows that H H can therefore be decomposed into two components, that is H = E_i + E_n H = E_i + E_n where E_i = \\tau^2 E_i = \\tau^2 , and E_n = H-\\tau^2 E_n = H-\\tau^2 . We mentioned before that \\tau \\tau can be measure of the market concentration resulted from the size distribution (variance) of firms, such that E_i=\\tau^2 E_i=\\tau^2 can be an even better one since it's smaller than H H , which enables us to measure the concentration contributed from the number of firms, measured by E_n E_n . This decomposition is appealing also in that E_n E_n , from the graph above, effectively is the horizontal difference between the two curves, i.e. the 'distance' between the actual market state and the fully competitive market with infinite number of firms (scenario two). Thus, it's safe to say this decomposition produces two components explaining the observed market concentration, 1) E_i E_i , the inequality of firm sizes effect, and 2) E_n E_n , the number of firms effect. Another finding from the graph is that with higher market concentration measured by H H , the relative importance of the two components is changing. When H H is small, most of the concentration is resulted from E_n E_n as highlighted below, which means the number of firms has a greater impact on market concentration. When H H is larger, on the other hand, E_i E_i contributes more to H H , which means the firm size inequality plays a bigger role in market concentration. A potential implication for regulators who are concerned about market concentration, I think, is to 1) focus more on reducing the entry barrier if the current concentration level is moderate, and to 2) focus more on antitrust if the concentration level is already high. Another implication for researchers is that even though H \\in [\\frac{1}{n}, 1] H \\in [\\frac{1}{n}, 1] is affected by the number of firms in a market, we should not attempt to use the \\text{normalized HHI}=\\frac{H-1/n}{1-1/n} \\in [0,1] \\text{normalized HHI}=\\frac{H-1/n}{1-1/n} \\in [0,1] . The reason is now very simple and clear -- the normalized HHI is nothing but E_i=\\tau^2 E_i=\\tau^2 , which reflects only the market concentration due to the inequality of firm sizes. When we compare across markets or the same market over time, apparently a market with 1,000 firms has a different competitive landscape than a market with only 2 firms.","title":"Some math"},{"location":"posts/decomposing-hhi-index/#acknowledgement","text":"This post is largely a replicate of the paper \"A Decomposition of the Herfindahl Index of Concentration\" by Giacomo de Gioia in 2017.","title":"Acknowledgement"},{"location":"posts/docker-nginx-letsencrypt/","text":"Setup Docker/Ngnix and Let's Encrypt on Ubuntu \u00b6 This is a note for setting up a Docker, Nginx and Let's Encrypt environment on Ubuntu 20.04 LTS. Create a Ubuntu 20.04 LTS instance \u00b6 Install Docker using the convenience script \u00b6 1 2 $ curl -fsSL https://get.docker.com -o get-docker.sh $ sudo sh get-docker.sh Manage Docker as a non-root user \u00b6 If you don't want to preface the docker command with sudo , create a Unix group called docker and add users to it. When the Docker daemon starts, it creates a Unix socket accessible by members of the docker group. To create the docker group and add your user: Create the docker group. 1 $ sudo groupadd docker Add your user to the docker group. 1 $ sudo usermod -aG docker $USER Log out and log back in so that your group membership is re-evaluated. On Linux, you can also run the following command to activate the changes to groups: 1 $ newgrp docker Configure Docker to start on boot \u00b6 1 $ sudo systemctl enable docker To disable this behavior, use disable instead. 1 $ sudo systemctl disable docker Install Docker Compose \u00b6 On Linux, you can download the Docker Compose binary from the Compose repository release page on GitHub . Follow the instructions from the link, which involve running the curl command in your terminal to download the binaries. These step-by-step instructions are also included below. Run this command to download the current stable release of Docker Compose: 1 $ sudo curl -L \"https://github.com/docker/compose/releases/download/1.25.5/docker-compose- $( uname -s ) - $( uname -m ) \" -o /usr/local/bin/docker-compose Note To install a different version of Compose, substitute 1.25.5 with the version of Compose you want to use. Apply executable permissions to the binary: 1 $ sudo chmod +x /usr/local/bin/docker-compose Note If the command docker-compose fails after installation, check your path. You can also create a symbolic link to /usr/bin or any other directory in your path. For example: 1 $ sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose Set up Nginx-Proxy \u00b6 Create a unique network for nginx-proxy and other Docker containers to communicate through. 1 $ docker network create nginx-proxy Create a directory nginx-proxy for the compose file. 1 $ mkdir nginx-proxy && cd nginx-proxy In the nginx-proxy directory, create a new file named docker-compose.yml and paste in the following text: example docker-compose.yml for nginx-proxy 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 version : '3' services : nginx : image : nginx restart : always container_name : nginx-proxy ports : - \"80:80\" - \"443:443\" volumes : - conf:/etc/nginx/conf.d - vhost:/etc/nginx/vhost.d - html:/usr/share/nginx/html - certs:/etc/nginx/certs labels : - \"com.github.jrcs.letsencrypt_nginx_proxy_companion.nginx_proxy=true\" dockergen : image : jwilder/docker-gen restart : always container_name : nginx-proxy-gen depends_on : - nginx command : -notify-sighup nginx-proxy -watch -wait 5s:30s /etc/docker-gen/templates/nginx.tmpl /etc/nginx/conf.d/default.conf volumes : - conf:/etc/nginx/conf.d - vhost:/etc/nginx/vhost.d - html:/usr/share/nginx/html - certs:/etc/nginx/certs - /var/run/docker.sock:/tmp/docker.sock:ro - ./nginx.tmpl:/etc/docker-gen/templates/nginx.tmpl:ro letsencrypt : image : jrcs/letsencrypt-nginx-proxy-companion restart : always container_name : nginx-proxy-le depends_on : - nginx - dockergen environment : NGINX_PROXY_CONTAINER : nginx-proxy NGINX_DOCKER_GEN_CONTAINER : nginx-proxy-gen volumes : - conf:/etc/nginx/conf.d - vhost:/etc/nginx/vhost.d - html:/usr/share/nginx/html - certs:/etc/nginx/certs - /var/run/docker.sock:/var/run/docker.sock:ro volumes : conf : vhost : html : certs : networks : default : external : name : nginx-proxy Inside of the nginx-proxy directory, use the following curl command to copy the developer\u2019s sample nginx.tmpl file to your VPS. 1 $ curl https://raw.githubusercontent.com/jwilder/nginx-proxy/master/nginx.tmpl > nginx.tmpl Increase upload file size To increase the maximum upload size, for example, add client_max_body_size 100M; to the server{} section in the nginx.tmpl template file. For WordPress, Running nginx-proxy . 1 $ docker-compose up -d Add a WordPress container \u00b6 Create a directory for the docker-compose.yml with: example docker-compose.yml for WordPress container 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 version : \"3\" services : db_node_domain : image : mysql:5.7 volumes : - db_data:/var/lib/mysql restart : always environment : MYSQL_ROOT_PASSWORD : somewordpress MYSQL_DATABASE : wordpress MYSQL_USER : wordpress MYSQL_PASSWORD : wordpress container_name : wp_test_db wordpress : depends_on : - db_node_domain image : wordpress:latest expose : - 80 restart : always environment : VIRTUAL_HOST : blog.example.com LETSENCRYPT_HOST : blog.example.com LETSENCRYPT_EMAIL : foo@example.com WORDPRESS_DB_HOST : db_node_domain:3306 WORDPRESS_DB_USER : wordpress WORDPRESS_DB_PASSWORD : wordpress container_name : wp_test volumes : db_data : networks : default : external : name : nginx-proxy To create a second WordPress container, add MYSQL_TCP_PORT environment variable and set it to a different port. Increase maximum WordPress upload file size \u00b6 Enter the bash of the WordPress container. 1 $ docker exec -t wordpress_container_name bash Move inside your /var/www/html directory (already there if you\u2019re using the standard Docker Compose image). Run the following command to insert the values. 1 $ sed -i '/^# END WordPress.*/i php_value upload_max_filesize 256M\\nphp_value post_max_size 256M' .htaccess Note To restore the values, run $ sed -i \"11,12d\" .htaccess","title":"Setup Docker/Ngnix and Let's Encrypt on Ubuntu"},{"location":"posts/docker-nginx-letsencrypt/#setup-dockerngnix-and-lets-encrypt-on-ubuntu","text":"This is a note for setting up a Docker, Nginx and Let's Encrypt environment on Ubuntu 20.04 LTS.","title":"Setup Docker/Ngnix and Let's Encrypt on Ubuntu"},{"location":"posts/docker-nginx-letsencrypt/#create-a-ubuntu-2004-lts-instance","text":"","title":"Create a Ubuntu 20.04 LTS instance"},{"location":"posts/docker-nginx-letsencrypt/#install-docker-using-the-convenience-script","text":"1 2 $ curl -fsSL https://get.docker.com -o get-docker.sh $ sudo sh get-docker.sh","title":"Install Docker using the convenience script"},{"location":"posts/docker-nginx-letsencrypt/#manage-docker-as-a-non-root-user","text":"If you don't want to preface the docker command with sudo , create a Unix group called docker and add users to it. When the Docker daemon starts, it creates a Unix socket accessible by members of the docker group. To create the docker group and add your user: Create the docker group. 1 $ sudo groupadd docker Add your user to the docker group. 1 $ sudo usermod -aG docker $USER Log out and log back in so that your group membership is re-evaluated. On Linux, you can also run the following command to activate the changes to groups: 1 $ newgrp docker","title":"Manage Docker as a non-root user"},{"location":"posts/docker-nginx-letsencrypt/#configure-docker-to-start-on-boot","text":"1 $ sudo systemctl enable docker To disable this behavior, use disable instead. 1 $ sudo systemctl disable docker","title":"Configure Docker to start on boot"},{"location":"posts/docker-nginx-letsencrypt/#install-docker-compose","text":"On Linux, you can download the Docker Compose binary from the Compose repository release page on GitHub . Follow the instructions from the link, which involve running the curl command in your terminal to download the binaries. These step-by-step instructions are also included below. Run this command to download the current stable release of Docker Compose: 1 $ sudo curl -L \"https://github.com/docker/compose/releases/download/1.25.5/docker-compose- $( uname -s ) - $( uname -m ) \" -o /usr/local/bin/docker-compose Note To install a different version of Compose, substitute 1.25.5 with the version of Compose you want to use. Apply executable permissions to the binary: 1 $ sudo chmod +x /usr/local/bin/docker-compose Note If the command docker-compose fails after installation, check your path. You can also create a symbolic link to /usr/bin or any other directory in your path. For example: 1 $ sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose","title":"Install Docker Compose"},{"location":"posts/docker-nginx-letsencrypt/#set-up-nginx-proxy","text":"Create a unique network for nginx-proxy and other Docker containers to communicate through. 1 $ docker network create nginx-proxy Create a directory nginx-proxy for the compose file. 1 $ mkdir nginx-proxy && cd nginx-proxy In the nginx-proxy directory, create a new file named docker-compose.yml and paste in the following text: example docker-compose.yml for nginx-proxy 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 version : '3' services : nginx : image : nginx restart : always container_name : nginx-proxy ports : - \"80:80\" - \"443:443\" volumes : - conf:/etc/nginx/conf.d - vhost:/etc/nginx/vhost.d - html:/usr/share/nginx/html - certs:/etc/nginx/certs labels : - \"com.github.jrcs.letsencrypt_nginx_proxy_companion.nginx_proxy=true\" dockergen : image : jwilder/docker-gen restart : always container_name : nginx-proxy-gen depends_on : - nginx command : -notify-sighup nginx-proxy -watch -wait 5s:30s /etc/docker-gen/templates/nginx.tmpl /etc/nginx/conf.d/default.conf volumes : - conf:/etc/nginx/conf.d - vhost:/etc/nginx/vhost.d - html:/usr/share/nginx/html - certs:/etc/nginx/certs - /var/run/docker.sock:/tmp/docker.sock:ro - ./nginx.tmpl:/etc/docker-gen/templates/nginx.tmpl:ro letsencrypt : image : jrcs/letsencrypt-nginx-proxy-companion restart : always container_name : nginx-proxy-le depends_on : - nginx - dockergen environment : NGINX_PROXY_CONTAINER : nginx-proxy NGINX_DOCKER_GEN_CONTAINER : nginx-proxy-gen volumes : - conf:/etc/nginx/conf.d - vhost:/etc/nginx/vhost.d - html:/usr/share/nginx/html - certs:/etc/nginx/certs - /var/run/docker.sock:/var/run/docker.sock:ro volumes : conf : vhost : html : certs : networks : default : external : name : nginx-proxy Inside of the nginx-proxy directory, use the following curl command to copy the developer\u2019s sample nginx.tmpl file to your VPS. 1 $ curl https://raw.githubusercontent.com/jwilder/nginx-proxy/master/nginx.tmpl > nginx.tmpl Increase upload file size To increase the maximum upload size, for example, add client_max_body_size 100M; to the server{} section in the nginx.tmpl template file. For WordPress, Running nginx-proxy . 1 $ docker-compose up -d","title":"Set up Nginx-Proxy"},{"location":"posts/docker-nginx-letsencrypt/#add-a-wordpress-container","text":"Create a directory for the docker-compose.yml with: example docker-compose.yml for WordPress container 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 version : \"3\" services : db_node_domain : image : mysql:5.7 volumes : - db_data:/var/lib/mysql restart : always environment : MYSQL_ROOT_PASSWORD : somewordpress MYSQL_DATABASE : wordpress MYSQL_USER : wordpress MYSQL_PASSWORD : wordpress container_name : wp_test_db wordpress : depends_on : - db_node_domain image : wordpress:latest expose : - 80 restart : always environment : VIRTUAL_HOST : blog.example.com LETSENCRYPT_HOST : blog.example.com LETSENCRYPT_EMAIL : foo@example.com WORDPRESS_DB_HOST : db_node_domain:3306 WORDPRESS_DB_USER : wordpress WORDPRESS_DB_PASSWORD : wordpress container_name : wp_test volumes : db_data : networks : default : external : name : nginx-proxy To create a second WordPress container, add MYSQL_TCP_PORT environment variable and set it to a different port.","title":"Add a WordPress container"},{"location":"posts/docker-nginx-letsencrypt/#increase-maximum-wordpress-upload-file-size","text":"Enter the bash of the WordPress container. 1 $ docker exec -t wordpress_container_name bash Move inside your /var/www/html directory (already there if you\u2019re using the standard Docker Compose image). Run the following command to insert the values. 1 $ sed -i '/^# END WordPress.*/i php_value upload_max_filesize 256M\\nphp_value post_max_size 256M' .htaccess Note To restore the values, run $ sed -i \"11,12d\" .htaccess","title":"Increase maximum WordPress upload file size"},{"location":"posts/encode-password-for-sas-remote-submission/","text":"Encode Password for SAS Remote Submission \u00b6 The Wharton Research Data Services (WRDS) allows one to submit and execute SAS programs to the cloud. WRDS has an instruction on accessing WRDS data from SAS on our own PCs . Generally, you should use: 1 2 3 4 5 6 7 8 9 10 %let wrds=wrds-cloud . wharton . upenn . edu 4016 ; options comamid=TCP remote=WRDS; signon username=_prompt_; rsubmit; /* Code for remote execution goes here. */ endrsubmit; signoff; However, if you want to save the effort of entering username and password every time, you'll need to encode your password . Concluding the two articles, basically you just need to follow the steps below. Simple Steps \u00b6 First, open your SAS program locally on your PC, run the following command and replace 1234567890 with your WRDS password: 1 proc pwencode in = \"1234567890\" ; run; The output {SAS002}23AA9C2811439227077603C8365060A44800CA1F is the encoded password (which is 1234567890 in this example). Do NOT share your SAS program with encoded password! Encoded password functions the same as your plain-text password. You should never make public your password in any way. Next, put the following statements at the beginning of your SAS program and replace my_username with your WRDS username: 1 2 3 %let wrds=wrds-cloud . wharton . upenn . edu 4016 ; options comamid=TCP remote=WRDS; signon username=my_username password= \"{SAS002}23AA9C2811439227077603C8365060A44800CA1F\" ; After these statements, you'll be able to submit your SAS program remotely to and execute on the WRDS server by enclosing your statements with rsubmit and endrsubmit . An example would be: 1 2 3 rsubmit ; proc download data=comp . funda out =funda ; run; endrsubmit; As you can guess, this statement actually downloads the whole Compustat Fundamentals Annual to the local work directory, with the downloaded dataset also named funda . Lastly, after everything, you should run signoff to close the connection with WRDS. Full code is as below. 1 2 3 4 5 6 7 8 %let wrds=wrds-cloud . wharton . upenn . edu 4016 ; options comamid=TCP remote=WRDS; signon username=my_username password= \"{SAS002}23AA9C2811439227077603C8365060A44800CA1F\" ; rsubmit ; proc download data=comp . funda out =funda ; run; endrsubmit; signoff; Replace my_username and the encoded password with your actual WRDS username and encoded password, paste it in the SAS program editor and press F3 . You'll be downloading comp.funda in a few seconds! Video Instruction \u00b6 I made a short video introduction as well, available on my YouTube channel.","title":"Encode password for SAS remote submission"},{"location":"posts/encode-password-for-sas-remote-submission/#encode-password-for-sas-remote-submission","text":"The Wharton Research Data Services (WRDS) allows one to submit and execute SAS programs to the cloud. WRDS has an instruction on accessing WRDS data from SAS on our own PCs . Generally, you should use: 1 2 3 4 5 6 7 8 9 10 %let wrds=wrds-cloud . wharton . upenn . edu 4016 ; options comamid=TCP remote=WRDS; signon username=_prompt_; rsubmit; /* Code for remote execution goes here. */ endrsubmit; signoff; However, if you want to save the effort of entering username and password every time, you'll need to encode your password . Concluding the two articles, basically you just need to follow the steps below.","title":"Encode Password for SAS Remote Submission"},{"location":"posts/encode-password-for-sas-remote-submission/#simple-steps","text":"First, open your SAS program locally on your PC, run the following command and replace 1234567890 with your WRDS password: 1 proc pwencode in = \"1234567890\" ; run; The output {SAS002}23AA9C2811439227077603C8365060A44800CA1F is the encoded password (which is 1234567890 in this example). Do NOT share your SAS program with encoded password! Encoded password functions the same as your plain-text password. You should never make public your password in any way. Next, put the following statements at the beginning of your SAS program and replace my_username with your WRDS username: 1 2 3 %let wrds=wrds-cloud . wharton . upenn . edu 4016 ; options comamid=TCP remote=WRDS; signon username=my_username password= \"{SAS002}23AA9C2811439227077603C8365060A44800CA1F\" ; After these statements, you'll be able to submit your SAS program remotely to and execute on the WRDS server by enclosing your statements with rsubmit and endrsubmit . An example would be: 1 2 3 rsubmit ; proc download data=comp . funda out =funda ; run; endrsubmit; As you can guess, this statement actually downloads the whole Compustat Fundamentals Annual to the local work directory, with the downloaded dataset also named funda . Lastly, after everything, you should run signoff to close the connection with WRDS. Full code is as below. 1 2 3 4 5 6 7 8 %let wrds=wrds-cloud . wharton . upenn . edu 4016 ; options comamid=TCP remote=WRDS; signon username=my_username password= \"{SAS002}23AA9C2811439227077603C8365060A44800CA1F\" ; rsubmit ; proc download data=comp . funda out =funda ; run; endrsubmit; signoff; Replace my_username and the encoded password with your actual WRDS username and encoded password, paste it in the SAS program editor and press F3 . You'll be downloading comp.funda in a few seconds!","title":"Simple Steps"},{"location":"posts/encode-password-for-sas-remote-submission/#video-instruction","text":"I made a short video introduction as well, available on my YouTube channel.","title":"Video Instruction"},{"location":"posts/firm-historical-headquarter-state-from-10k/","text":"Firm Historical Headquarter State from SEC 10K/Q Filings \u00b6 Why the need to use SEC filings? \u00b6 In the Compustat database, a firm's headquarter state (and other identification) is in fact the current record stored in comp.company . This means once a firm relocates (or updates its incorporate state, address, etc.), all historical observations will be updated and not recording historical state information anymore. To resolve this issue, an effective way is to use the firm's historical SEC filings. You can follow my previous post Textual Analysis on SEC filings to extract the header information, which includes a wide range of meta data. Alternatively, the University of Notre Dame's Software Repository for Accounting and Finance provides an augmented 10-X header dataset . Do I have to use SEC filings? \u00b6 I'll skip the parsing procedure for now. The most important point is that using the historical SEC filings, you can ensure that you truly are using the historical headquarter state in your empirical estimation. Based on the augmented 10-X header dataset , I find that around 2-3% of Compustat firms changed their headquarter state (as indicated by their business address) each year. Year Firms Changed State Total Firms % Firms Changed State 1995 22 4205 0.52 1996 69 7939 0.87 1997 199 8101 2.46 1998 206 8126 2.54 1999 202 8199 2.46 2000 202 8252 2.45 2001 204 7802 2.61 2002 167 7421 2.25 2003 214 6930 3.09 2004 175 6742 2.6 2005 154 6478 2.38 2006 156 6267 2.49 2007 144 6091 2.36 2008 125 5797 2.16 2009 127 5523 2.3 2010 128 5479 2.34 2011 152 5445 2.79 2012 160 5494 2.91 2013 171 5491 3.11 2014 195 5455 3.57 2015 147 5322 2.76 2016 117 5092 2.3 2017 129 4914 2.63 2018 107 4847 2.21 Moreover, 2,947 out of the 17,221 firms, or about 17% firms changed their headquarter state in the merged sample. This is by no means a small number that can be ignored. So, whenever possible, you should try to use the historical information from past SEC filings' metadata. How to get the actual historical firm HQ state using SEC filings? \u00b6 1969 - 2003 \u00b6 I start with the firm historical HQ state provided by Bai, Fairhurst and Serfling (2020 RFS) . This dataset contains the historical HQ locations from 1969 to 2003, which is based on the SEC filings post 1994 and hand-collected by the authors from the Moody\u2019s Manuals (later Mergent Manuals) and Dun & Bradstreet\u2019s Million Dollar Directory (later bought by Mergent). 1 1994 - 2018 \u00b6 To extend the dataset, I download the augmented 10-X header dataset and use the following Python script to extract the business address (state) filed. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import pandas as pd filepath = \"~/Downloads/LM_EDGAR_10X_Header_1994_2018.csv\" if __name__ == \"__main__\" : df = pd . read_csv ( filepath , usecols = [ \"cik\" , \"file_date\" , \"ba_state\" ], dtype = { \"cik\" : str }, parse_dates = [ \"file_date\" ], ) # Some `ba_stata` codes are lowercase df [ \"ba_state\" ] = df [ \"ba_state\" ] . str . upper () # Some `ba_state` codes are not valid US states df = df [ df [ \"ba_state\" ] . str . isalpha () & ~ pd . isnull ( df [ \"ba_state\" ])] df . drop_duplicates () . to_stata ( \"~/Downloads/historical_state_1994_2018.dta\" , write_index = False , convert_dates = { \"file_date\" : \"td\" }, ) The result is a historical_state.dta Stata file like this: 1969 - 2018 merged \u00b6 Finally, to merge the two datasets together, I imported them into WRDS Cloud and run the following SAS script: Pre-2003, use Bai, Fairhurst and Serfling (2020 RFS) . Post-2003, use the business address as in the header of 10K/Q filings, and the Compustat records if the business address is missing and invalid from parsing the headers. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 libname hs \"~/historical_state\" ; /* Historical HQ state (1994 to 2018) from augmented 10-X header dataset */ proc import datafile= \"~/historical_state/historical_state_1994_2018.dta\" out =historical_state_1994_2018 dbms=stata replace ; /* Historical HQ state (1969 to 2003) from Bai, Fairhurst and Serfling (2020 RFS) */ proc import datafile= \"~/historical_state/hist_headquarters_Bai_et_al.dta\" out =hist_headquarters_Bai_et_al dbms=stata replace ; /* Build the post-1994 dataset using SEC filings */ proc sql; create table funda as select gvkey, cik, datadate, fyear from comp . funda where indfmt= 'INDL' and datafmt= 'STD' and popsrc= 'D' and consol= 'C' and year( datadate) between 1994 and 2018 /* \"For firms that change fiscal year within a calendar year, we take the last reported date when extracting financial data. This leaves us with one set of observations for each firm (gvkey) in each year.\" -- Pelueger, Siriwardane and Sunderam (2020 QJE) */ group by gvkey, fyear having datadate= max( datadate); create table firm_historical_state as select a.*, b . ba_state as state_sec label = \"State from SEC filings\" from funda as a left join historical_state as b on a . cik=b . cik and year( a . datadate)= year( b . file_date) and b . file_date<=a . datadate group by a . gvkey, a . datadate /* use the SEC filing closet to and before the Compustat datadate */ having b . file_date= max( b . file_date); create table historical_state_1994_2018 as select a.*, b . state as state_comp label = \"State from Compustat\" from firm_historical_state as a left join comp . company as b on a . gvkey=b . gvkey order by a . gvkey, a . datadate ; quit; /* Sanity check: no duplicated gvkey-fyear */ proc sort data=historical_state_1994_2018 nodupkey; by gvkey datadate ; run; proc sql; create table hist_headquarters_Bai_et_al as select put (gvkeyn, z6.) as gvkey, fyear, state from hist_headquarters_Bai_et_al ; quit; /* Stack together the two datasets */ data states; set hist_headquarters_Bai_et_al historical_state_1994_2018( where =(fyear> 2003 ) keep =gvkey fyear state:) ; run; proc sql; create table hs . corrected_hist_state_1969_2018 as select *, coalesce(state, state_sec, state_comp) as corrected_state from states where not missing (calculated corrected_state) order by gvkey, fyear ; quit; /* Sanity check: no duplicated gvkey-fyear */ proc sort data=hs . corrected_hist_state_1969_2018 nodupkey; by gvkey fyear ; run; Data available for download \u00b6 You can download the data I compiled here: corrected_hist_state_1969_2018.dta.zip (1MB). The authors note that \"for our final sample of 115,432 firm-year observations, we find that over the 1969 to 2003 period, 9,847 (87.50%) never relocate, 1,211 (10.76%) relocate once, 178 (1.58%) relocate twice, and 18 (0.16%) relocate three times.\" \u21a9","title":"Firm Historical Headquarter State from SEC 10K/Q Filings"},{"location":"posts/firm-historical-headquarter-state-from-10k/#firm-historical-headquarter-state-from-sec-10kq-filings","text":"","title":"Firm Historical Headquarter State from SEC 10K/Q Filings"},{"location":"posts/firm-historical-headquarter-state-from-10k/#why-the-need-to-use-sec-filings","text":"In the Compustat database, a firm's headquarter state (and other identification) is in fact the current record stored in comp.company . This means once a firm relocates (or updates its incorporate state, address, etc.), all historical observations will be updated and not recording historical state information anymore. To resolve this issue, an effective way is to use the firm's historical SEC filings. You can follow my previous post Textual Analysis on SEC filings to extract the header information, which includes a wide range of meta data. Alternatively, the University of Notre Dame's Software Repository for Accounting and Finance provides an augmented 10-X header dataset .","title":"Why the need to use SEC filings?"},{"location":"posts/firm-historical-headquarter-state-from-10k/#do-i-have-to-use-sec-filings","text":"I'll skip the parsing procedure for now. The most important point is that using the historical SEC filings, you can ensure that you truly are using the historical headquarter state in your empirical estimation. Based on the augmented 10-X header dataset , I find that around 2-3% of Compustat firms changed their headquarter state (as indicated by their business address) each year. Year Firms Changed State Total Firms % Firms Changed State 1995 22 4205 0.52 1996 69 7939 0.87 1997 199 8101 2.46 1998 206 8126 2.54 1999 202 8199 2.46 2000 202 8252 2.45 2001 204 7802 2.61 2002 167 7421 2.25 2003 214 6930 3.09 2004 175 6742 2.6 2005 154 6478 2.38 2006 156 6267 2.49 2007 144 6091 2.36 2008 125 5797 2.16 2009 127 5523 2.3 2010 128 5479 2.34 2011 152 5445 2.79 2012 160 5494 2.91 2013 171 5491 3.11 2014 195 5455 3.57 2015 147 5322 2.76 2016 117 5092 2.3 2017 129 4914 2.63 2018 107 4847 2.21 Moreover, 2,947 out of the 17,221 firms, or about 17% firms changed their headquarter state in the merged sample. This is by no means a small number that can be ignored. So, whenever possible, you should try to use the historical information from past SEC filings' metadata.","title":"Do I have to use SEC filings?"},{"location":"posts/firm-historical-headquarter-state-from-10k/#how-to-get-the-actual-historical-firm-hq-state-using-sec-filings","text":"","title":"How to get the actual historical firm HQ state using SEC filings?"},{"location":"posts/firm-historical-headquarter-state-from-10k/#1969-2003","text":"I start with the firm historical HQ state provided by Bai, Fairhurst and Serfling (2020 RFS) . This dataset contains the historical HQ locations from 1969 to 2003, which is based on the SEC filings post 1994 and hand-collected by the authors from the Moody\u2019s Manuals (later Mergent Manuals) and Dun & Bradstreet\u2019s Million Dollar Directory (later bought by Mergent). 1","title":"1969 - 2003"},{"location":"posts/firm-historical-headquarter-state-from-10k/#1994-2018","text":"To extend the dataset, I download the augmented 10-X header dataset and use the following Python script to extract the business address (state) filed. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import pandas as pd filepath = \"~/Downloads/LM_EDGAR_10X_Header_1994_2018.csv\" if __name__ == \"__main__\" : df = pd . read_csv ( filepath , usecols = [ \"cik\" , \"file_date\" , \"ba_state\" ], dtype = { \"cik\" : str }, parse_dates = [ \"file_date\" ], ) # Some `ba_stata` codes are lowercase df [ \"ba_state\" ] = df [ \"ba_state\" ] . str . upper () # Some `ba_state` codes are not valid US states df = df [ df [ \"ba_state\" ] . str . isalpha () & ~ pd . isnull ( df [ \"ba_state\" ])] df . drop_duplicates () . to_stata ( \"~/Downloads/historical_state_1994_2018.dta\" , write_index = False , convert_dates = { \"file_date\" : \"td\" }, ) The result is a historical_state.dta Stata file like this:","title":"1994 - 2018"},{"location":"posts/firm-historical-headquarter-state-from-10k/#1969-2018-merged","text":"Finally, to merge the two datasets together, I imported them into WRDS Cloud and run the following SAS script: Pre-2003, use Bai, Fairhurst and Serfling (2020 RFS) . Post-2003, use the business address as in the header of 10K/Q filings, and the Compustat records if the business address is missing and invalid from parsing the headers. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 libname hs \"~/historical_state\" ; /* Historical HQ state (1994 to 2018) from augmented 10-X header dataset */ proc import datafile= \"~/historical_state/historical_state_1994_2018.dta\" out =historical_state_1994_2018 dbms=stata replace ; /* Historical HQ state (1969 to 2003) from Bai, Fairhurst and Serfling (2020 RFS) */ proc import datafile= \"~/historical_state/hist_headquarters_Bai_et_al.dta\" out =hist_headquarters_Bai_et_al dbms=stata replace ; /* Build the post-1994 dataset using SEC filings */ proc sql; create table funda as select gvkey, cik, datadate, fyear from comp . funda where indfmt= 'INDL' and datafmt= 'STD' and popsrc= 'D' and consol= 'C' and year( datadate) between 1994 and 2018 /* \"For firms that change fiscal year within a calendar year, we take the last reported date when extracting financial data. This leaves us with one set of observations for each firm (gvkey) in each year.\" -- Pelueger, Siriwardane and Sunderam (2020 QJE) */ group by gvkey, fyear having datadate= max( datadate); create table firm_historical_state as select a.*, b . ba_state as state_sec label = \"State from SEC filings\" from funda as a left join historical_state as b on a . cik=b . cik and year( a . datadate)= year( b . file_date) and b . file_date<=a . datadate group by a . gvkey, a . datadate /* use the SEC filing closet to and before the Compustat datadate */ having b . file_date= max( b . file_date); create table historical_state_1994_2018 as select a.*, b . state as state_comp label = \"State from Compustat\" from firm_historical_state as a left join comp . company as b on a . gvkey=b . gvkey order by a . gvkey, a . datadate ; quit; /* Sanity check: no duplicated gvkey-fyear */ proc sort data=historical_state_1994_2018 nodupkey; by gvkey datadate ; run; proc sql; create table hist_headquarters_Bai_et_al as select put (gvkeyn, z6.) as gvkey, fyear, state from hist_headquarters_Bai_et_al ; quit; /* Stack together the two datasets */ data states; set hist_headquarters_Bai_et_al historical_state_1994_2018( where =(fyear> 2003 ) keep =gvkey fyear state:) ; run; proc sql; create table hs . corrected_hist_state_1969_2018 as select *, coalesce(state, state_sec, state_comp) as corrected_state from states where not missing (calculated corrected_state) order by gvkey, fyear ; quit; /* Sanity check: no duplicated gvkey-fyear */ proc sort data=hs . corrected_hist_state_1969_2018 nodupkey; by gvkey fyear ; run;","title":"1969 - 2018 merged"},{"location":"posts/firm-historical-headquarter-state-from-10k/#data-available-for-download","text":"You can download the data I compiled here: corrected_hist_state_1969_2018.dta.zip (1MB). The authors note that \"for our final sample of 115,432 firm-year observations, we find that over the 1969 to 2003 period, 9,847 (87.50%) never relocate, 1,211 (10.76%) relocate once, 178 (1.58%) relocate twice, and 18 (0.16%) relocate three times.\" \u21a9","title":"Data available for download"},{"location":"posts/generate-fama-french-industry-classification-from-sic/","text":"Generate Fama-French Industry Classification From SIC \u00b6 This STATA program creates the Fama-French industry classification from SIC code. Basic usage \u00b6 1 ffind sic, generate (\u201cFF48\u201d) type ( 48 ) where sic is SIC code, FF48 is the generated industry variable name, and we are using 48-industry classification. Alternatively, one can choose 5, 10, 12, 17, 30, 38 or 49 industries. Full Stata code \u00b6 ffind.ado 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 /**************************************** * ffind.ado * Creates variable containing Fama-French * industry classification. * * Author: Judson Caskey, UCLA * December 9, 2007 * * Revised by Malcolm Wardlaw, Uiversity of Texas at Dallas (November 1, 2011) ****************************************/ capture program drop ffind program define ffind version 9.2 syntax varlist (min= 1 max= 1 numeric) [if] [in], Generate(string) Type(numlist max= 1 min= 1 ) tempvar ftyp tokenize \" `type' \" local `ftyp' = `1' * Check if generate is valid variable name capture confirm new variable `generate' if _rc != 0 { di as error \"Variable `generate' is invalid\" exit 111 } * Check type if ~ inlist ( ``ftyp'' , 5 , 10 , 12 , 17 , 30 , 38 , 48 , 49 ) { di as error \"Type must be 5, 10, 12, 17, 30, 38, 48 or 49\" exit 111 } * Set industries tempvar ffind tokenize \" `varlist' \" local `ffind' \" `1' \" qui gen `generate' =. label variable `generate' \"Fama-French industry code ( ``ftyp'' industries)\" capture label drop `generate' if ``ftyp'' == 5 { label define `generate' 1 \"Consumer Durables, NonDurables, Wholesale, Retail, and Some Services (Laundries, Repair Shops)\" 2 \"Manufacturing, Energy, and Utilities\" 3 \"Business Equipment, Telephone and Television Transmission\" 4 \"Healthcare, Medical Equipment, and Drugs\" 5 \"Other -- Mines, Constr, BldMt, Trans, Hotels, Bus Serv, Entertainment, Finance\" label values `generate' `generate' qui replace `generate' = 1 if inrange ( ``ffind'' , 100 , 999 ) | inrange ( ``ffind'' , 2000 , 2399 ) | inrange ( ``ffind'' , 2700 , 2749 ) | inrange ( ``ffind'' , 2770 , 2799 ) | inrange ( ``ffind'' , 3100 , 3199 ) | inrange ( ``ffind'' , 3940 , 3989 ) | inrange ( ``ffind'' , 2500 , 2519 ) | inrange ( ``ffind'' , 2590 , 2599 ) | inrange ( ``ffind'' , 3630 , 3659 ) | inrange ( ``ffind'' , 3710 , 3711 ) | inrange ( ``ffind'' , 3714 , 3714 ) | inrange ( ``ffind'' , 3716 , 3716 ) | inrange ( ``ffind'' , 3750 , 3751 ) | inrange ( ``ffind'' , 3792 , 3792 ) | inrange ( ``ffind'' , 3900 , 3939 ) | inrange ( ``ffind'' , 3990 , 3999 ) | inrange ( ``ffind'' , 5000 , 5999 ) | inrange ( ``ffind'' , 7200 , 7299 ) | inrange ( ``ffind'' , 7600 , 7699 ) qui replace `generate' = 2 if inrange ( ``ffind'' , 2520 , 2589 ) | inrange ( ``ffind'' , 2600 , 2699 ) | inrange ( ``ffind'' , 2750 , 2769 ) | inrange ( ``ffind'' , 2800 , 2829 ) | inrange ( ``ffind'' , 2840 , 2899 ) | inrange ( ``ffind'' , 3000 , 3099 ) | inrange ( ``ffind'' , 3200 , 3569 ) | inrange ( ``ffind'' , 3580 , 3629 ) | inrange ( ``ffind'' , 3700 , 3709 ) | inrange ( ``ffind'' , 3712 , 3713 ) | inrange ( ``ffind'' , 3715 , 3715 ) | inrange ( ``ffind'' , 3717 , 3749 ) | inrange ( ``ffind'' , 3752 , 3791 ) | inrange ( ``ffind'' , 3793 , 3799 ) | inrange ( ``ffind'' , 3830 , 3839 ) | inrange ( ``ffind'' , 3860 , 3899 ) | inrange ( ``ffind'' , 1200 , 1399 ) | inrange ( ``ffind'' , 2900 , 2999 ) | inrange ( ``ffind'' , 4900 , 4949 ) qui replace `generate' = 3 if inrange ( ``ffind'' , 3570 , 3579 ) | inrange ( ``ffind'' , 3622 , 3622 ) | inrange ( ``ffind'' , 3660 , 3692 ) | inrange ( ``ffind'' , 3694 , 3699 ) | inrange ( ``ffind'' , 3810 , 3839 ) | inrange ( ``ffind'' , 7370 , 7372 ) | inrange ( ``ffind'' , 7373 , 7373 ) | inrange ( ``ffind'' , 7374 , 7374 ) | inrange ( ``ffind'' , 7375 , 7375 ) | inrange ( ``ffind'' , 7376 , 7376 ) | inrange ( ``ffind'' , 7377 , 7377 ) | inrange ( ``ffind'' , 7378 , 7378 ) | inrange ( ``ffind'' , 7379 , 7379 ) | inrange ( ``ffind'' , 7391 , 7391 ) | inrange ( ``ffind'' , 8730 , 8734 ) | inrange ( ``ffind'' , 4800 , 4899 ) qui replace `generate' = 4 if inrange ( ``ffind'' , 2830 , 2839 ) | inrange ( ``ffind'' , 3693 , 3693 ) | inrange ( ``ffind'' , 3840 , 3859 ) | inrange ( ``ffind'' , 8000 , 8099 ) qui replace `generate' = 5 if missing ( `generate' ) & ~ missing ( ``ffind'' ) } else if ``ftyp'' == 10 { label define `generate' 1 \"Consumer NonDurables -- Food, Tobacco, Textiles, Apparel, Leather, Toys\" 2 \"Consumer Durables -- Cars, TV's, Furniture, Household Appliances\" 3 \"Manufacturing -- Machinery, Trucks, Planes, Chemicals, Off Furn, Paper, Com Printing\" 4 \"Oil, Gas, and Coal Extraction and Products\" 5 \"Business Equipment -- Computers, Software, and Electronic Equipment\" 6 \"Telephone and Television Transmission\" 7 \"Wholesale, Retail, and Some Services (Laundries, Repair Shops)\" 8 \"Healthcare, Medical Equipment, and Drugs\" 9 \"Utilities\" 10 \"Other -- Mines, Constr, BldMt, Trans, Hotels, Bus Serv, Entertainment, Finance\" label values `generate' `generate' qui replace `generate' = 1 if inrange ( ``ffind'' , 100 , 999 ) | inrange ( ``ffind'' , 2000 , 2399 ) | inrange ( ``ffind'' , 2700 , 2749 ) | inrange ( ``ffind'' , 2770 , 2799 ) | inrange ( ``ffind'' , 3100 , 3199 ) | inrange ( ``ffind'' , 3940 , 3989 ) qui replace `generate' = 2 if inrange ( ``ffind'' , 2500 , 2519 ) | inrange ( ``ffind'' , 2590 , 2599 ) | inrange ( ``ffind'' , 3630 , 3659 ) | inrange ( ``ffind'' , 3710 , 3711 ) | inrange ( ``ffind'' , 3714 , 3714 ) | inrange ( ``ffind'' , 3716 , 3716 ) | inrange ( ``ffind'' , 3750 , 3751 ) | inrange ( ``ffind'' , 3792 , 3792 ) | inrange ( ``ffind'' , 3900 , 3939 ) | inrange ( ``ffind'' , 3990 , 3999 ) qui replace `generate' = 3 if inrange ( ``ffind'' , 2520 , 2589 ) | inrange ( ``ffind'' , 2600 , 2699 ) | inrange ( ``ffind'' , 2750 , 2769 ) | inrange ( ``ffind'' , 2800 , 2829 ) | inrange ( ``ffind'' , 2840 , 2899 ) | inrange ( ``ffind'' , 3000 , 3099 ) | inrange ( ``ffind'' , 3200 , 3569 ) | inrange ( ``ffind'' , 3580 , 3629 ) | inrange ( ``ffind'' , 3700 , 3709 ) | inrange ( ``ffind'' , 3712 , 3713 ) | inrange ( ``ffind'' , 3715 , 3715 ) | inrange ( ``ffind'' , 3717 , 3749 ) | inrange ( ``ffind'' , 3752 , 3791 ) | inrange ( ``ffind'' , 3793 , 3799 ) | inrange ( ``ffind'' , 3830 , 3839 ) | inrange ( ``ffind'' , 3860 , 3899 ) qui replace `generate' = 4 if inrange ( ``ffind'' , 1200 , 1399 ) | inrange ( ``ffind'' , 2900 , 2999 ) qui replace `generate' = 5 if inrange ( ``ffind'' , 3570 , 3579 ) | inrange ( ``ffind'' , 3622 , 3622 ) | inrange ( ``ffind'' , 3660 , 3692 ) | inrange ( ``ffind'' , 3694 , 3699 ) | inrange ( ``ffind'' , 3810 , 3839 ) | inrange ( ``ffind'' , 7370 , 7372 ) | inrange ( ``ffind'' , 7373 , 7373 ) | inrange ( ``ffind'' , 7374 , 7374 ) | inrange ( ``ffind'' , 7375 , 7375 ) | inrange ( ``ffind'' , 7376 , 7376 ) | inrange ( ``ffind'' , 7377 , 7377 ) | inrange ( ``ffind'' , 7378 , 7378 ) | inrange ( ``ffind'' , 7379 , 7379 ) | inrange ( ``ffind'' , 7391 , 7391 ) | inrange ( ``ffind'' , 8730 , 8734 ) qui replace `generate' = 6 if inrange ( ``ffind'' , 4800 , 4899 ) qui replace `generate' = 7 if inrange ( ``ffind'' , 5000 , 5999 ) | inrange ( ``ffind'' , 7200 , 7299 ) | inrange ( ``ffind'' , 7600 , 7699 ) qui replace `generate' = 8 if inrange ( ``ffind'' , 2830 , 2839 ) | inrange ( ``ffind'' , 3693 , 3693 ) | inrange ( ``ffind'' , 3840 , 3859 ) | inrange ( ``ffind'' , 8000 , 8099 ) qui replace `generate' = 9 if inrange ( ``ffind'' , 4900 , 4949 ) qui replace `generate' = 10 if missing ( `generate' ) & ~ missing ( ``ffind'' ) } else if ``ftyp'' == 12 { label define `generate' 1 \"Consumer NonDurables -- Food, Tobacco, Textiles, Apparel, Leather, Toys\" 2 \"Consumer Durables -- Cars, TV's, Furniture, Household Appliances\" 3 \"Manufacturing -- Machinery, Trucks, Planes, Off Furn, Paper, Com Printing\" 4 \"Oil, Gas, and Coal Extraction and Products\" 5 \"Chemicals and Allied Products\" 6 \"Business Equipment -- Computers, Software, and Electronic Equipment\" 7 \"Telephone and Television Transmission\" 8 \"Utilities\" 9 \"Wholesale, Retail, and Some Services (Laundries, Repair Shops)\" 10 \"Healthcare, Medical Equipment, and Drugs\" 11 \"Finance\" 12 \"Other -- Mines, Constr, BldMt, Trans, Hotels, Bus Serv, Entertainment\" label values `generate' `generate' qui replace `generate' = 1 if inrange ( ``ffind'' , 100 , 999 ) | inrange ( ``ffind'' , 2000 , 2399 ) | inrange ( ``ffind'' , 2700 , 2749 ) | inrange ( ``ffind'' , 2770 , 2799 ) | inrange ( ``ffind'' , 3100 , 3199 ) | inrange ( ``ffind'' , 3940 , 3989 ) qui replace `generate' = 2 if inrange ( ``ffind'' , 2500 , 2519 ) | inrange ( ``ffind'' , 2590 , 2599 ) | inrange ( ``ffind'' , 3630 , 3659 ) | inrange ( ``ffind'' , 3710 , 3711 ) | inrange ( ``ffind'' , 3714 , 3714 ) | inrange ( ``ffind'' , 3716 , 3716 ) | inrange ( ``ffind'' , 3750 , 3751 ) | inrange ( ``ffind'' , 3792 , 3792 ) | inrange ( ``ffind'' , 3900 , 3939 ) | inrange ( ``ffind'' , 3990 , 3999 ) qui replace `generate' = 3 if inrange ( ``ffind'' , 2520 , 2589 ) | inrange ( ``ffind'' , 2600 , 2699 ) | inrange ( ``ffind'' , 2750 , 2769 ) | inrange ( ``ffind'' , 3000 , 3099 ) | inrange ( ``ffind'' , 3200 , 3569 ) | inrange ( ``ffind'' , 3580 , 3629 ) | inrange ( ``ffind'' , 3700 , 3709 ) | inrange ( ``ffind'' , 3712 , 3713 ) | inrange ( ``ffind'' , 3715 , 3715 ) | inrange ( ``ffind'' , 3717 , 3749 ) | inrange ( ``ffind'' , 3752 , 3791 ) | inrange ( ``ffind'' , 3793 , 3799 ) | inrange ( ``ffind'' , 3830 , 3839 ) | inrange ( ``ffind'' , 3860 , 3899 ) qui replace `generate' = 4 if inrange ( ``ffind'' , 1200 , 1399 ) | inrange ( ``ffind'' , 2900 , 2999 ) qui replace `generate' = 5 if inrange ( ``ffind'' , 2800 , 2829 ) | inrange ( ``ffind'' , 2840 , 2899 ) qui replace `generate' = 6 if inrange ( ``ffind'' , 3570 , 3579 ) | inrange ( ``ffind'' , 3660 , 3692 ) | inrange ( ``ffind'' , 3694 , 3699 ) | inrange ( ``ffind'' , 3810 , 3829 ) | inrange ( ``ffind'' , 7370 , 7379 ) qui replace `generate' = 7 if inrange ( ``ffind'' , 4800 , 4899 ) qui replace `generate' = 8 if inrange ( ``ffind'' , 4900 , 4949 ) qui replace `generate' = 9 if inrange ( ``ffind'' , 5000 , 5999 ) | inrange ( ``ffind'' , 7200 , 7299 ) | inrange ( ``ffind'' , 7600 , 7699 ) qui replace `generate' = 10 if inrange ( ``ffind'' , 2830 , 2839 ) | inrange ( ``ffind'' , 3693 , 3693 ) | inrange ( ``ffind'' , 3840 , 3859 ) | inrange ( ``ffind'' , 8000 , 8099 ) qui replace `generate' = 11 if inrange ( ``ffind'' , 6000 , 6999 ) qui replace `generate' = 12 if missing ( `generate' ) & ~ missing ( ``ffind'' ) } else if ``ftyp'' == 17 { label define `generate' 1 \"Food\" 2 \"Mining and Minerals\" 3 \"Oil and Petroleum Products\" 4 \"Textiles, Apparel & Footware\" 5 \"Consumer Durables\" 6 \"Chemicals\" 7 \"Drugs, Soap, Prfums, Tobacco\" 8 \"Construction and Construction Materials\" 9 \"Steel Works Etc\" 10 \"Fabricated Products\" 11 \"Machinery and Business Equipment\" 12 \"Automobiles\" 13 \"Transportation\" 14 \"Utilities\" 15 \"Retail Stores\" 16 \"Banks, Insurance Companies, and Other Financials\" 17 \"Other\" label values `generate' `generate' qui replace `generate' = 1 if inrange ( ``ffind'' , 100 , 199 ) | inrange ( ``ffind'' , 200 , 299 ) | inrange ( ``ffind'' , 700 , 799 ) | inrange ( ``ffind'' , 900 , 999 ) | inrange ( ``ffind'' , 2000 , 2009 ) | inrange ( ``ffind'' , 2010 , 2019 ) | inrange ( ``ffind'' , 2020 , 2029 ) | inrange ( ``ffind'' , 2030 , 2039 ) | inrange ( ``ffind'' , 2040 , 2046 ) | inrange ( ``ffind'' , 2047 , 2047 ) | inrange ( ``ffind'' , 2048 , 2048 ) | inrange ( ``ffind'' , 2050 , 2059 ) | inrange ( ``ffind'' , 2060 , 2063 ) | inrange ( ``ffind'' , 2064 , 2068 ) | inrange ( ``ffind'' , 2070 , 2079 ) | inrange ( ``ffind'' , 2080 , 2080 ) | inrange ( ``ffind'' , 2082 , 2082 ) | inrange ( ``ffind'' , 2083 , 2083 ) | inrange ( ``ffind'' , 2084 , 2084 ) | inrange ( ``ffind'' , 2085 , 2085 ) | inrange ( ``ffind'' , 2086 , 2086 ) | inrange ( ``ffind'' , 2087 , 2087 ) | inrange ( ``ffind'' , 2090 , 2092 ) | inrange ( ``ffind'' , 2095 , 2095 ) | inrange ( ``ffind'' , 2096 , 2096 ) | inrange ( ``ffind'' , 2097 , 2097 ) | inrange ( ``ffind'' , 2098 , 2099 ) | inrange ( ``ffind'' , 5140 , 5149 ) | inrange ( ``ffind'' , 5150 , 5159 ) | inrange ( ``ffind'' , 5180 , 5182 ) | inrange ( ``ffind'' , 5191 , 5191 ) qui replace `generate' = 2 if inrange ( ``ffind'' , 1000 , 1009 ) | inrange ( ``ffind'' , 1010 , 1019 ) | inrange ( ``ffind'' , 1020 , 1029 ) | inrange ( ``ffind'' , 1030 , 1039 ) | inrange ( ``ffind'' , 1040 , 1049 ) | inrange ( ``ffind'' , 1060 , 1069 ) | inrange ( ``ffind'' , 1080 , 1089 ) | inrange ( ``ffind'' , 1090 , 1099 ) | inrange ( ``ffind'' , 1200 , 1299 ) | inrange ( ``ffind'' , 1400 , 1499 ) | inrange ( ``ffind'' , 5050 , 5052 ) qui replace `generate' = 3 if inrange ( ``ffind'' , 1300 , 1300 ) | inrange ( ``ffind'' , 1310 , 1319 ) | inrange ( ``ffind'' , 1320 , 1329 ) | inrange ( ``ffind'' , 1380 , 1380 ) | inrange ( ``ffind'' , 1381 , 1381 ) | inrange ( ``ffind'' , 1382 , 1382 ) | inrange ( ``ffind'' , 1389 , 1389 ) | inrange ( ``ffind'' , 2900 , 2912 ) | inrange ( ``ffind'' , 5170 , 5172 ) qui replace `generate' = 4 if inrange ( ``ffind'' , 2200 , 2269 ) | inrange ( ``ffind'' , 2270 , 2279 ) | inrange ( ``ffind'' , 2280 , 2284 ) | inrange ( ``ffind'' , 2290 , 2295 ) | inrange ( ``ffind'' , 2296 , 2296 ) | inrange ( ``ffind'' , 2297 , 2297 ) | inrange ( ``ffind'' , 2298 , 2298 ) | inrange ( ``ffind'' , 2299 , 2299 ) | inrange ( ``ffind'' , 2300 , 2390 ) | inrange ( ``ffind'' , 2391 , 2392 ) | inrange ( ``ffind'' , 2393 , 2395 ) | inrange ( ``ffind'' , 2396 , 2396 ) | inrange ( ``ffind'' , 2397 , 2399 ) | inrange ( ``ffind'' , 3020 , 3021 ) | inrange ( ``ffind'' , 3100 , 3111 ) | inrange ( ``ffind'' , 3130 , 3131 ) | inrange ( ``ffind'' , 3140 , 3149 ) | inrange ( ``ffind'' , 3150 , 3151 ) | inrange ( ``ffind'' , 3963 , 3965 ) | inrange ( ``ffind'' , 5130 , 5139 ) qui replace `generate' = 5 if inrange ( ``ffind'' , 2510 , 2519 ) | inrange ( ``ffind'' , 2590 , 2599 ) | inrange ( ``ffind'' , 3060 , 3069 ) | inrange ( ``ffind'' , 3070 , 3079 ) | inrange ( ``ffind'' , 3080 , 3089 ) | inrange ( ``ffind'' , 3090 , 3099 ) | inrange ( ``ffind'' , 3630 , 3639 ) | inrange ( ``ffind'' , 3650 , 3651 ) | inrange ( ``ffind'' , 3652 , 3652 ) | inrange ( ``ffind'' , 3860 , 3861 ) | inrange ( ``ffind'' , 3870 , 3873 ) | inrange ( ``ffind'' , 3910 , 3911 ) | inrange ( ``ffind'' , 3914 , 3914 ) | inrange ( ``ffind'' , 3915 , 3915 ) | inrange ( ``ffind'' , 3930 , 3931 ) | inrange ( ``ffind'' , 3940 , 3949 ) | inrange ( ``ffind'' , 3960 , 3962 ) | inrange ( ``ffind'' , 5020 , 5023 ) | inrange ( ``ffind'' , 5064 , 5064 ) | inrange ( ``ffind'' , 5094 , 5094 ) | inrange ( ``ffind'' , 5099 , 5099 ) qui replace `generate' = 6 if inrange ( ``ffind'' , 2800 , 2809 ) | inrange ( ``ffind'' , 2810 , 2819 ) | inrange ( ``ffind'' , 2820 , 2829 ) | inrange ( ``ffind'' , 2860 , 2869 ) | inrange ( ``ffind'' , 2870 , 2879 ) | inrange ( ``ffind'' , 2890 , 2899 ) | inrange ( ``ffind'' , 5160 , 5169 ) qui replace `generate' = 7 if inrange ( ``ffind'' , 2100 , 2199 ) | inrange ( ``ffind'' , 2830 , 2830 ) | inrange ( ``ffind'' , 2831 , 2831 ) | inrange ( ``ffind'' , 2833 , 2833 ) | inrange ( ``ffind'' , 2834 , 2834 ) | inrange ( ``ffind'' , 2840 , 2843 ) | inrange ( ``ffind'' , 2844 , 2844 ) | inrange ( ``ffind'' , 5120 , 5122 ) | inrange ( ``ffind'' , 5194 , 5194 ) qui replace `generate' = 8 if inrange ( ``ffind'' , 800 , 899 ) | inrange ( ``ffind'' , 1500 , 1511 ) | inrange ( ``ffind'' , 1520 , 1529 ) | inrange ( ``ffind'' , 1530 , 1539 ) | inrange ( ``ffind'' , 1540 , 1549 ) | inrange ( ``ffind'' , 1600 , 1699 ) | inrange ( ``ffind'' , 1700 , 1799 ) | inrange ( ``ffind'' , 2400 , 2439 ) | inrange ( ``ffind'' , 2440 , 2449 ) | inrange ( ``ffind'' , 2450 , 2459 ) | inrange ( ``ffind'' , 2490 , 2499 ) | inrange ( ``ffind'' , 2850 , 2859 ) | inrange ( ``ffind'' , 2950 , 2952 ) | inrange ( ``ffind'' , 3200 , 3200 ) | inrange ( ``ffind'' , 3210 , 3211 ) | inrange ( ``ffind'' , 3240 , 3241 ) | inrange ( ``ffind'' , 3250 , 3259 ) | inrange ( ``ffind'' , 3261 , 3261 ) | inrange ( ``ffind'' , 3264 , 3264 ) | inrange ( ``ffind'' , 3270 , 3275 ) | inrange ( ``ffind'' , 3280 , 3281 ) | inrange ( ``ffind'' , 3290 , 3293 ) | inrange ( ``ffind'' , 3420 , 3429 ) | inrange ( ``ffind'' , 3430 , 3433 ) | inrange ( ``ffind'' , 3440 , 3441 ) | inrange ( ``ffind'' , 3442 , 3442 ) | inrange ( ``ffind'' , 3446 , 3446 ) | inrange ( ``ffind'' , 3448 , 3448 ) | inrange ( ``ffind'' , 3449 , 3449 ) | inrange ( ``ffind'' , 3450 , 3451 ) | inrange ( ``ffind'' , 3452 , 3452 ) | inrange ( ``ffind'' , 5030 , 5039 ) | inrange ( ``ffind'' , 5070 , 5078 ) | inrange ( ``ffind'' , 5198 , 5198 ) | inrange ( ``ffind'' , 5210 , 5211 ) | inrange ( ``ffind'' , 5230 , 5231 ) | inrange ( ``ffind'' , 5250 , 5251 ) qui replace `generate' = 9 if inrange ( ``ffind'' , 3300 , 3300 ) | inrange ( ``ffind'' , 3310 , 3317 ) | inrange ( ``ffind'' , 3320 , 3325 ) | inrange ( ``ffind'' , 3330 , 3339 ) | inrange ( ``ffind'' , 3340 , 3341 ) | inrange ( ``ffind'' , 3350 , 3357 ) | inrange ( ``ffind'' , 3360 , 3369 ) | inrange ( ``ffind'' , 3390 , 3399 ) qui replace `generate' = 10 if inrange ( ``ffind'' , 3410 , 3412 ) | inrange ( ``ffind'' , 3443 , 3443 ) | inrange ( ``ffind'' , 3444 , 3444 ) | inrange ( ``ffind'' , 3460 , 3469 ) | inrange ( ``ffind'' , 3470 , 3479 ) | inrange ( ``ffind'' , 3480 , 3489 ) | inrange ( ``ffind'' , 3490 , 3499 ) qui replace `generate' = 11 if inrange ( ``ffind'' , 3510 , 3519 ) | inrange ( ``ffind'' , 3520 , 3529 ) | inrange ( ``ffind'' , 3530 , 3530 ) | inrange ( ``ffind'' , 3531 , 3531 ) | inrange ( ``ffind'' , 3532 , 3532 ) | inrange ( ``ffind'' , 3533 , 3533 ) | inrange ( ``ffind'' , 3534 , 3534 ) | inrange ( ``ffind'' , 3535 , 3535 ) | inrange ( ``ffind'' , 3536 , 3536 ) | inrange ( ``ffind'' , 3540 , 3549 ) | inrange ( ``ffind'' , 3550 , 3559 ) | inrange ( ``ffind'' , 3560 , 3569 ) | inrange ( ``ffind'' , 3570 , 3579 ) | inrange ( ``ffind'' , 3580 , 3580 ) | inrange ( ``ffind'' , 3581 , 3581 ) | inrange ( ``ffind'' , 3582 , 3582 ) | inrange ( ``ffind'' , 3585 , 3585 ) | inrange ( ``ffind'' , 3586 , 3586 ) | inrange ( ``ffind'' , 3589 , 3589 ) | inrange ( ``ffind'' , 3590 , 3599 ) | inrange ( ``ffind'' , 3600 , 3600 ) | inrange ( ``ffind'' , 3610 , 3613 ) | inrange ( ``ffind'' , 3620 , 3621 ) | inrange ( ``ffind'' , 3622 , 3622 ) | inrange ( ``ffind'' , 3623 , 3629 ) | inrange ( ``ffind'' , 3670 , 3679 ) | inrange ( ``ffind'' , 3680 , 3680 ) | inrange ( ``ffind'' , 3681 , 3681 ) | inrange ( ``ffind'' , 3682 , 3682 ) | inrange ( ``ffind'' , 3683 , 3683 ) | inrange ( ``ffind'' , 3684 , 3684 ) | inrange ( ``ffind'' , 3685 , 3685 ) | inrange ( ``ffind'' , 3686 , 3686 ) | inrange ( ``ffind'' , 3687 , 3687 ) | inrange ( ``ffind'' , 3688 , 3688 ) | inrange ( ``ffind'' , 3689 , 3689 ) | inrange ( ``ffind'' , 3690 , 3690 ) | inrange ( ``ffind'' , 3691 , 3692 ) | inrange ( ``ffind'' , 3693 , 3693 ) | inrange ( ``ffind'' , 3694 , 3694 ) | inrange ( ``ffind'' , 3695 , 3695 ) | inrange ( ``ffind'' , 3699 , 3699 ) | inrange ( ``ffind'' , 3810 , 3810 ) | inrange ( ``ffind'' , 3811 , 3811 ) | inrange ( ``ffind'' , 3812 , 3812 ) | inrange ( ``ffind'' , 3820 , 3820 ) | inrange ( ``ffind'' , 3821 , 3821 ) | inrange ( ``ffind'' , 3822 , 3822 ) | inrange ( ``ffind'' , 3823 , 3823 ) | inrange ( ``ffind'' , 3824 , 3824 ) | inrange ( ``ffind'' , 3825 , 3825 ) | inrange ( ``ffind'' , 3826 , 3826 ) | inrange ( ``ffind'' , 3827 , 3827 ) | inrange ( ``ffind'' , 3829 , 3829 ) | inrange ( ``ffind'' , 3830 , 3839 ) | inrange ( ``ffind'' , 3950 , 3955 ) | inrange ( ``ffind'' , 5060 , 5060 ) | inrange ( ``ffind'' , 5063 , 5063 ) | inrange ( ``ffind'' , 5065 , 5065 ) | inrange ( ``ffind'' , 5080 , 5080 ) | inrange ( ``ffind'' , 5081 , 5081 ) qui replace `generate' = 12 if inrange ( ``ffind'' , 3710 , 3710 ) | inrange ( ``ffind'' , 3711 , 3711 ) | inrange ( ``ffind'' , 3714 , 3714 ) | inrange ( ``ffind'' , 3716 , 3716 ) | inrange ( ``ffind'' , 3750 , 3751 ) | inrange ( ``ffind'' , 3792 , 3792 ) | inrange ( ``ffind'' , 5010 , 5015 ) | inrange ( ``ffind'' , 5510 , 5521 ) | inrange ( ``ffind'' , 5530 , 5531 ) | inrange ( ``ffind'' , 5560 , 5561 ) | inrange ( ``ffind'' , 5570 , 5571 ) | inrange ( ``ffind'' , 5590 , 5599 ) qui replace `generate' = 13 if inrange ( ``ffind'' , 3713 , 3713 ) | inrange ( ``ffind'' , 3715 , 3715 ) | inrange ( ``ffind'' , 3720 , 3720 ) | inrange ( ``ffind'' , 3721 , 3721 ) | inrange ( ``ffind'' , 3724 , 3724 ) | inrange ( ``ffind'' , 3725 , 3725 ) | inrange ( ``ffind'' , 3728 , 3728 ) | inrange ( ``ffind'' , 3730 , 3731 ) | inrange ( ``ffind'' , 3732 , 3732 ) | inrange ( ``ffind'' , 3740 , 3743 ) | inrange ( ``ffind'' , 3760 , 3769 ) | inrange ( ``ffind'' , 3790 , 3790 ) | inrange ( ``ffind'' , 3795 , 3795 ) | inrange ( ``ffind'' , 3799 , 3799 ) | inrange ( ``ffind'' , 4000 , 4013 ) | inrange ( ``ffind'' , 4100 , 4100 ) | inrange ( ``ffind'' , 4110 , 4119 ) | inrange ( ``ffind'' , 4120 , 4121 ) | inrange ( ``ffind'' , 4130 , 4131 ) | inrange ( ``ffind'' , 4140 , 4142 ) | inrange ( ``ffind'' , 4150 , 4151 ) | inrange ( ``ffind'' , 4170 , 4173 ) | inrange ( ``ffind'' , 4190 , 4199 ) | inrange ( ``ffind'' , 4200 , 4200 ) | inrange ( ``ffind'' , 4210 , 4219 ) | inrange ( ``ffind'' , 4220 , 4229 ) | inrange ( ``ffind'' , 4230 , 4231 ) | inrange ( ``ffind'' , 4400 , 4499 ) | inrange ( ``ffind'' , 4500 , 4599 ) | inrange ( ``ffind'' , 4600 , 4699 ) | inrange ( ``ffind'' , 4700 , 4700 ) | inrange ( ``ffind'' , 4710 , 4712 ) | inrange ( ``ffind'' , 4720 , 4729 ) | inrange ( ``ffind'' , 4730 , 4739 ) | inrange ( ``ffind'' , 4740 , 4742 ) | inrange ( ``ffind'' , 4780 , 4780 ) | inrange ( ``ffind'' , 4783 , 4783 ) | inrange ( ``ffind'' , 4785 , 4785 ) | inrange ( ``ffind'' , 4789 , 4789 ) qui replace `generate' = 14 if inrange ( ``ffind'' , 4900 , 4900 ) | inrange ( ``ffind'' , 4910 , 4911 ) | inrange ( ``ffind'' , 4920 , 4922 ) | inrange ( ``ffind'' , 4923 , 4923 ) | inrange ( ``ffind'' , 4924 , 4925 ) | inrange ( ``ffind'' , 4930 , 4931 ) | inrange ( ``ffind'' , 4932 , 4932 ) | inrange ( ``ffind'' , 4939 , 4939 ) | inrange ( ``ffind'' , 4940 , 4942 ) qui replace `generate' = 15 if inrange ( ``ffind'' , 5260 , 5261 ) | inrange ( ``ffind'' , 5270 , 5271 ) | inrange ( ``ffind'' , 5300 , 5300 ) | inrange ( ``ffind'' , 5310 , 5311 ) | inrange ( ``ffind'' , 5320 , 5320 ) | inrange ( ``ffind'' , 5330 , 5331 ) | inrange ( ``ffind'' , 5334 , 5334 ) | inrange ( ``ffind'' , 5390 , 5399 ) | inrange ( ``ffind'' , 5400 , 5400 ) | inrange ( ``ffind'' , 5410 , 5411 ) | inrange ( ``ffind'' , 5412 , 5412 ) | inrange ( ``ffind'' , 5420 , 5421 ) | inrange ( ``ffind'' , 5430 , 5431 ) | inrange ( ``ffind'' , 5440 , 5441 ) | inrange ( ``ffind'' , 5450 , 5451 ) | inrange ( ``ffind'' , 5460 , 5461 ) | inrange ( ``ffind'' , 5490 , 5499 ) | inrange ( ``ffind'' , 5540 , 5541 ) | inrange ( ``ffind'' , 5550 , 5551 ) | inrange ( ``ffind'' , 5600 , 5699 ) | inrange ( ``ffind'' , 5700 , 5700 ) | inrange ( ``ffind'' , 5710 , 5719 ) | inrange ( ``ffind'' , 5720 , 5722 ) | inrange ( ``ffind'' , 5730 , 5733 ) | inrange ( ``ffind'' , 5734 , 5734 ) | inrange ( ``ffind'' , 5735 , 5735 ) | inrange ( ``ffind'' , 5736 , 5736 ) | inrange ( ``ffind'' , 5750 , 5750 ) | inrange ( ``ffind'' , 5800 , 5813 ) | inrange ( ``ffind'' , 5890 , 5890 ) | inrange ( ``ffind'' , 5900 , 5900 ) | inrange ( ``ffind'' , 5910 , 5912 ) | inrange ( ``ffind'' , 5920 , 5921 ) | inrange ( ``ffind'' , 5930 , 5932 ) | inrange ( ``ffind'' , 5940 , 5940 ) | inrange ( ``ffind'' , 5941 , 5941 ) | inrange ( ``ffind'' , 5942 , 5942 ) | inrange ( ``ffind'' , 5943 , 5943 ) | inrange ( ``ffind'' , 5944 , 5944 ) | inrange ( ``ffind'' , 5945 , 5945 ) | inrange ( ``ffind'' , 5946 , 5946 ) | inrange ( ``ffind'' , 5947 , 5947 ) | inrange ( ``ffind'' , 5948 , 5948 ) | inrange ( ``ffind'' , 5949 , 5949 ) | inrange ( ``ffind'' , 5960 , 5963 ) | inrange ( ``ffind'' , 5980 , 5989 ) | inrange ( ``ffind'' , 5990 , 5990 ) | inrange ( ``ffind'' , 5992 , 5992 ) | inrange ( ``ffind'' , 5993 , 5993 ) | inrange ( ``ffind'' , 5994 , 5994 ) | inrange ( ``ffind'' , 5995 , 5995 ) | inrange ( ``ffind'' , 5999 , 5999 ) qui replace `generate' = 16 if inrange ( ``ffind'' , 6010 , 6019 ) | inrange ( ``ffind'' , 6020 , 6020 ) | inrange ( ``ffind'' , 6021 , 6021 ) | inrange ( ``ffind'' , 6022 , 6022 ) | inrange ( ``ffind'' , 6023 , 6023 ) | inrange ( ``ffind'' , 6025 , 6025 ) | inrange ( ``ffind'' , 6026 , 6026 ) | inrange ( ``ffind'' , 6028 , 6029 ) | inrange ( ``ffind'' , 6030 , 6036 ) | inrange ( ``ffind'' , 6040 , 6049 ) | inrange ( ``ffind'' , 6050 , 6059 ) | inrange ( ``ffind'' , 6060 , 6062 ) | inrange ( ``ffind'' , 6080 , 6082 ) | inrange ( ``ffind'' , 6090 , 6099 ) | inrange ( ``ffind'' , 6100 , 6100 ) | inrange ( ``ffind'' , 6110 , 6111 ) | inrange ( ``ffind'' , 6112 , 6112 ) | inrange ( ``ffind'' , 6120 , 6129 ) | inrange ( ``ffind'' , 6140 , 6149 ) | inrange ( ``ffind'' , 6150 , 6159 ) | inrange ( ``ffind'' , 6160 , 6163 ) | inrange ( ``ffind'' , 6172 , 6172 ) | inrange ( ``ffind'' , 6199 , 6199 ) | inrange ( ``ffind'' , 6200 , 6299 ) | inrange ( ``ffind'' , 6300 , 6300 ) | inrange ( ``ffind'' , 6310 , 6312 ) | inrange ( ``ffind'' , 6320 , 6324 ) | inrange ( ``ffind'' , 6330 , 6331 ) | inrange ( ``ffind'' , 6350 , 6351 ) | inrange ( ``ffind'' , 6360 , 6361 ) | inrange ( ``ffind'' , 6370 , 6371 ) | inrange ( ``ffind'' , 6390 , 6399 ) | inrange ( ``ffind'' , 6400 , 6411 ) | inrange ( ``ffind'' , 6500 , 6500 ) | inrange ( ``ffind'' , 6510 , 6510 ) | inrange ( ``ffind'' , 6512 , 6512 ) | inrange ( ``ffind'' , 6513 , 6513 ) | inrange ( ``ffind'' , 6514 , 6514 ) | inrange ( ``ffind'' , 6515 , 6515 ) | inrange ( ``ffind'' , 6517 , 6519 ) | inrange ( ``ffind'' , 6530 , 6531 ) | inrange ( ``ffind'' , 6532 , 6532 ) | inrange ( ``ffind'' , 6540 , 6541 ) | inrange ( ``ffind'' , 6550 , 6553 ) | inrange ( ``ffind'' , 6611 , 6611 ) | inrange ( ``ffind'' , 6700 , 6700 ) | inrange ( ``ffind'' , 6710 , 6719 ) | inrange ( ``ffind'' , 6720 , 6722 ) | inrange ( ``ffind'' , 6723 , 6723 ) | inrange ( ``ffind'' , 6724 , 6724 ) | inrange ( ``ffind'' , 6725 , 6725 ) | inrange ( ``ffind'' , 6726 , 6726 ) | inrange ( ``ffind'' , 6730 , 6733 ) | inrange ( ``ffind'' , 6790 , 6790 ) | inrange ( ``ffind'' , 6792 , 6792 ) | inrange ( ``ffind'' , 6794 , 6794 ) | inrange ( ``ffind'' , 6795 , 6795 ) | inrange ( ``ffind'' , 6798 , 6798 ) | inrange ( ``ffind'' , 6799 , 6799 ) qui replace `generate' = 17 if missing ( `generate' ) & ~ missing ( ``ffind'' ) } else if ``ftyp'' == 30 { label define `generate' 1 \"Food Products\" 2 \"Beer & Liquor\" 3 \"Tobacco Products\" 4 \"Recreation\" 5 \"Printing and Publishing\" 6 \"Consumer Goods\" 7 \"Apparel\" 8 \"Healthcare, Medical Equipment, Pharmaceutical Products\" 9 \"Chemicals\" 10 \"Textiles\" 11 \"Construction and Construction Materials\" 12 \"Steel Works Etc\" 13 \"Fabricated Products and Machinery\" 14 \"Electrical Equipment\" 15 \"Automobiles and Trucks\" 16 \"Aircraft, ships, and railroad equipment\" 17 \"Precious Metals, Non-Metallic, and Industrial Metal Mining\" 18 \"Coal\" 19 \"Petroleum and Natural Gas\" 20 \"Utilities\" 21 \"Communication\" 22 \"Personal and Business Services\" 23 \"Business Equipment\" 24 \"Business Supplies and Shipping Containers\" 25 \"Transportation\" 26 \"Wholesale\" 27 \"Retail\" 28 \"Restaraunts, Hotels, Motels\" 29 \"Banking, Insurance, Real Estate, Trading\" 30 \"Everything Else\" label values `generate' `generate' qui replace `generate' = 1 if inrange ( ``ffind'' , 100 , 199 ) | inrange ( ``ffind'' , 200 , 299 ) | inrange ( ``ffind'' , 700 , 799 ) | inrange ( ``ffind'' , 910 , 919 ) | inrange ( ``ffind'' , 2000 , 2009 ) | inrange ( ``ffind'' , 2010 , 2019 ) | inrange ( ``ffind'' , 2020 , 2029 ) | inrange ( ``ffind'' , 2030 , 2039 ) | inrange ( ``ffind'' , 2040 , 2046 ) | inrange ( ``ffind'' , 2048 , 2048 ) | inrange ( ``ffind'' , 2050 , 2059 ) | inrange ( ``ffind'' , 2060 , 2063 ) | inrange ( ``ffind'' , 2064 , 2068 ) | inrange ( ``ffind'' , 2070 , 2079 ) | inrange ( ``ffind'' , 2086 , 2086 ) | inrange ( ``ffind'' , 2087 , 2087 ) | inrange ( ``ffind'' , 2090 , 2092 ) | inrange ( ``ffind'' , 2095 , 2095 ) | inrange ( ``ffind'' , 2096 , 2096 ) | inrange ( ``ffind'' , 2097 , 2097 ) | inrange ( ``ffind'' , 2098 , 2099 ) qui replace `generate' = 2 if inrange ( ``ffind'' , 2080 , 2080 ) | inrange ( ``ffind'' , 2082 , 2082 ) | inrange ( ``ffind'' , 2083 , 2083 ) | inrange ( ``ffind'' , 2084 , 2084 ) | inrange ( ``ffind'' , 2085 , 2085 ) qui replace `generate' = 3 if inrange ( ``ffind'' , 2100 , 2199 ) qui replace `generate' = 4 if inrange ( ``ffind'' , 920 , 999 ) | inrange ( ``ffind'' , 3650 , 3651 ) | inrange ( ``ffind'' , 3652 , 3652 ) | inrange ( ``ffind'' , 3732 , 3732 ) | inrange ( ``ffind'' , 3930 , 3931 ) | inrange ( ``ffind'' , 3940 , 3949 ) | inrange ( ``ffind'' , 7800 , 7829 ) | inrange ( ``ffind'' , 7830 , 7833 ) | inrange ( ``ffind'' , 7840 , 7841 ) | inrange ( ``ffind'' , 7900 , 7900 ) | inrange ( ``ffind'' , 7910 , 7911 ) | inrange ( ``ffind'' , 7920 , 7929 ) | inrange ( ``ffind'' , 7930 , 7933 ) | inrange ( ``ffind'' , 7940 , 7949 ) | inrange ( ``ffind'' , 7980 , 7980 ) | inrange ( ``ffind'' , 7990 , 7999 ) qui replace `generate' = 5 if inrange ( ``ffind'' , 2700 , 2709 ) | inrange ( ``ffind'' , 2710 , 2719 ) | inrange ( ``ffind'' , 2720 , 2729 ) | inrange ( ``ffind'' , 2730 , 2739 ) | inrange ( ``ffind'' , 2740 , 2749 ) | inrange ( ``ffind'' , 2750 , 2759 ) | inrange ( ``ffind'' , 2770 , 2771 ) | inrange ( ``ffind'' , 2780 , 2789 ) | inrange ( ``ffind'' , 2790 , 2799 ) | inrange ( ``ffind'' , 3993 , 3993 ) qui replace `generate' = 6 if inrange ( ``ffind'' , 2047 , 2047 ) | inrange ( ``ffind'' , 2391 , 2392 ) | inrange ( ``ffind'' , 2510 , 2519 ) | inrange ( ``ffind'' , 2590 , 2599 ) | inrange ( ``ffind'' , 2840 , 2843 ) | inrange ( ``ffind'' , 2844 , 2844 ) | inrange ( ``ffind'' , 3160 , 3161 ) | inrange ( ``ffind'' , 3170 , 3171 ) | inrange ( ``ffind'' , 3172 , 3172 ) | inrange ( ``ffind'' , 3190 , 3199 ) | inrange ( ``ffind'' , 3229 , 3229 ) | inrange ( ``ffind'' , 3260 , 3260 ) | inrange ( ``ffind'' , 3262 , 3263 ) | inrange ( ``ffind'' , 3269 , 3269 ) | inrange ( ``ffind'' , 3230 , 3231 ) | inrange ( ``ffind'' , 3630 , 3639 ) | inrange ( ``ffind'' , 3750 , 3751 ) | inrange ( ``ffind'' , 3800 , 3800 ) | inrange ( ``ffind'' , 3860 , 3861 ) | inrange ( ``ffind'' , 3870 , 3873 ) | inrange ( ``ffind'' , 3910 , 3911 ) | inrange ( ``ffind'' , 3914 , 3914 ) | inrange ( ``ffind'' , 3915 , 3915 ) | inrange ( ``ffind'' , 3960 , 3962 ) | inrange ( ``ffind'' , 3991 , 3991 ) | inrange ( ``ffind'' , 3995 , 3995 ) qui replace `generate' = 7 if inrange ( ``ffind'' , 2300 , 2390 ) | inrange ( ``ffind'' , 3020 , 3021 ) | inrange ( ``ffind'' , 3100 , 3111 ) | inrange ( ``ffind'' , 3130 , 3131 ) | inrange ( ``ffind'' , 3140 , 3149 ) | inrange ( ``ffind'' , 3150 , 3151 ) | inrange ( ``ffind'' , 3963 , 3965 ) qui replace `generate' = 8 if inrange ( ``ffind'' , 2830 , 2830 ) | inrange ( ``ffind'' , 2831 , 2831 ) | inrange ( ``ffind'' , 2833 , 2833 ) | inrange ( ``ffind'' , 2834 , 2834 ) | inrange ( ``ffind'' , 2835 , 2835 ) | inrange ( ``ffind'' , 2836 , 2836 ) | inrange ( ``ffind'' , 3693 , 3693 ) | inrange ( ``ffind'' , 3840 , 3849 ) | inrange ( ``ffind'' , 3850 , 3851 ) | inrange ( ``ffind'' , 8000 , 8099 ) qui replace `generate' = 9 if inrange ( ``ffind'' , 2800 , 2809 ) | inrange ( ``ffind'' , 2810 , 2819 ) | inrange ( ``ffind'' , 2820 , 2829 ) | inrange ( ``ffind'' , 2850 , 2859 ) | inrange ( ``ffind'' , 2860 , 2869 ) | inrange ( ``ffind'' , 2870 , 2879 ) | inrange ( ``ffind'' , 2890 , 2899 ) qui replace `generate' = 10 if inrange ( ``ffind'' , 2200 , 2269 ) | inrange ( ``ffind'' , 2270 , 2279 ) | inrange ( ``ffind'' , 2280 , 2284 ) | inrange ( ``ffind'' , 2290 , 2295 ) | inrange ( ``ffind'' , 2297 , 2297 ) | inrange ( ``ffind'' , 2298 , 2298 ) | inrange ( ``ffind'' , 2299 , 2299 ) | inrange ( ``ffind'' , 2393 , 2395 ) | inrange ( ``ffind'' , 2397 , 2399 ) qui replace `generate' = 11 if inrange ( ``ffind'' , 800 , 899 ) | inrange ( ``ffind'' , 1500 , 1511 ) | inrange ( ``ffind'' , 1520 , 1529 ) | inrange ( ``ffind'' , 1530 , 1539 ) | inrange ( ``ffind'' , 1540 , 1549 ) | inrange ( ``ffind'' , 1600 , 1699 ) | inrange ( ``ffind'' , 1700 , 1799 ) | inrange ( ``ffind'' , 2400 , 2439 ) | inrange ( ``ffind'' , 2450 , 2459 ) | inrange ( ``ffind'' , 2490 , 2499 ) | inrange ( ``ffind'' , 2660 , 2661 ) | inrange ( ``ffind'' , 2950 , 2952 ) | inrange ( ``ffind'' , 3200 , 3200 ) | inrange ( ``ffind'' , 3210 , 3211 ) | inrange ( ``ffind'' , 3240 , 3241 ) | inrange ( ``ffind'' , 3250 , 3259 ) | inrange ( ``ffind'' , 3261 , 3261 ) | inrange ( ``ffind'' , 3264 , 3264 ) | inrange ( ``ffind'' , 3270 , 3275 ) | inrange ( ``ffind'' , 3280 , 3281 ) | inrange ( ``ffind'' , 3290 , 3293 ) | inrange ( ``ffind'' , 3295 , 3299 ) | inrange ( ``ffind'' , 3420 , 3429 ) | inrange ( ``ffind'' , 3430 , 3433 ) | inrange ( ``ffind'' , 3440 , 3441 ) | inrange ( ``ffind'' , 3442 , 3442 ) | inrange ( ``ffind'' , 3446 , 3446 ) | inrange ( ``ffind'' , 3448 , 3448 ) | inrange ( ``ffind'' , 3449 , 3449 ) | inrange ( ``ffind'' , 3450 , 3451 ) | inrange ( ``ffind'' , 3452 , 3452 ) | inrange ( ``ffind'' , 3490 , 3499 ) | inrange ( ``ffind'' , 3996 , 3996 ) qui replace `generate' = 12 if inrange ( ``ffind'' , 3300 , 3300 ) | inrange ( ``ffind'' , 3310 , 3317 ) | inrange ( ``ffind'' , 3320 , 3325 ) | inrange ( ``ffind'' , 3330 , 3339 ) | inrange ( ``ffind'' , 3340 , 3341 ) | inrange ( ``ffind'' , 3350 , 3357 ) | inrange ( ``ffind'' , 3360 , 3369 ) | inrange ( ``ffind'' , 3370 , 3379 ) | inrange ( ``ffind'' , 3390 , 3399 ) qui replace `generate' = 13 if inrange ( ``ffind'' , 3400 , 3400 ) | inrange ( ``ffind'' , 3443 , 3443 ) | inrange ( ``ffind'' , 3444 , 3444 ) | inrange ( ``ffind'' , 3460 , 3469 ) | inrange ( ``ffind'' , 3470 , 3479 ) | inrange ( ``ffind'' , 3510 , 3519 ) | inrange ( ``ffind'' , 3520 , 3529 ) | inrange ( ``ffind'' , 3530 , 3530 ) | inrange ( ``ffind'' , 3531 , 3531 ) | inrange ( ``ffind'' , 3532 , 3532 ) | inrange ( ``ffind'' , 3533 , 3533 ) | inrange ( ``ffind'' , 3534 , 3534 ) | inrange ( ``ffind'' , 3535 , 3535 ) | inrange ( ``ffind'' , 3536 , 3536 ) | inrange ( ``ffind'' , 3538 , 3538 ) | inrange ( ``ffind'' , 3540 , 3549 ) | inrange ( ``ffind'' , 3550 , 3559 ) | inrange ( ``ffind'' , 3560 , 3569 ) | inrange ( ``ffind'' , 3580 , 3580 ) | inrange ( ``ffind'' , 3581 , 3581 ) | inrange ( ``ffind'' , 3582 , 3582 ) | inrange ( ``ffind'' , 3585 , 3585 ) | inrange ( ``ffind'' , 3586 , 3586 ) | inrange ( ``ffind'' , 3589 , 3589 ) | inrange ( ``ffind'' , 3590 , 3599 ) qui replace `generate' = 14 if inrange ( ``ffind'' , 3600 , 3600 ) | inrange ( ``ffind'' , 3610 , 3613 ) | inrange ( ``ffind'' , 3620 , 3621 ) | inrange ( ``ffind'' , 3623 , 3629 ) | inrange ( ``ffind'' , 3640 , 3644 ) | inrange ( ``ffind'' , 3645 , 3645 ) | inrange ( ``ffind'' , 3646 , 3646 ) | inrange ( ``ffind'' , 3648 , 3649 ) | inrange ( ``ffind'' , 3660 , 3660 ) | inrange ( ``ffind'' , 3690 , 3690 ) | inrange ( ``ffind'' , 3691 , 3692 ) | inrange ( ``ffind'' , 3699 , 3699 ) qui replace `generate' = 15 if inrange ( ``ffind'' , 2296 , 2296 ) | inrange ( ``ffind'' , 2396 , 2396 ) | inrange ( ``ffind'' , 3010 , 3011 ) | inrange ( ``ffind'' , 3537 , 3537 ) | inrange ( ``ffind'' , 3647 , 3647 ) | inrange ( ``ffind'' , 3694 , 3694 ) | inrange ( ``ffind'' , 3700 , 3700 ) | inrange ( ``ffind'' , 3710 , 3710 ) | inrange ( ``ffind'' , 3711 , 3711 ) | inrange ( ``ffind'' , 3713 , 3713 ) | inrange ( ``ffind'' , 3714 , 3714 ) | inrange ( ``ffind'' , 3715 , 3715 ) | inrange ( ``ffind'' , 3716 , 3716 ) | inrange ( ``ffind'' , 3792 , 3792 ) | inrange ( ``ffind'' , 3790 , 3791 ) | inrange ( ``ffind'' , 3799 , 3799 ) qui replace `generate' = 16 if inrange ( ``ffind'' , 3720 , 3720 ) | inrange ( ``ffind'' , 3721 , 3721 ) | inrange ( ``ffind'' , 3723 , 3724 ) | inrange ( ``ffind'' , 3725 , 3725 ) | inrange ( ``ffind'' , 3728 , 3729 ) | inrange ( ``ffind'' , 3730 , 3731 ) | inrange ( ``ffind'' , 3740 , 3743 ) qui replace `generate' = 17 if inrange ( ``ffind'' , 1000 , 1009 ) | inrange ( ``ffind'' , 1010 , 1019 ) | inrange ( ``ffind'' , 1020 , 1029 ) | inrange ( ``ffind'' , 1030 , 1039 ) | inrange ( ``ffind'' , 1040 , 1049 ) | inrange ( ``ffind'' , 1050 , 1059 ) | inrange ( ``ffind'' , 1060 , 1069 ) | inrange ( ``ffind'' , 1070 , 1079 ) | inrange ( ``ffind'' , 1080 , 1089 ) | inrange ( ``ffind'' , 1090 , 1099 ) | inrange ( ``ffind'' , 1100 , 1119 ) | inrange ( ``ffind'' , 1400 , 1499 ) qui replace `generate' = 18 if inrange ( ``ffind'' , 1200 , 1299 ) qui replace `generate' = 19 if inrange ( ``ffind'' , 1300 , 1300 ) | inrange ( ``ffind'' , 1310 , 1319 ) | inrange ( ``ffind'' , 1320 , 1329 ) | inrange ( ``ffind'' , 1330 , 1339 ) | inrange ( ``ffind'' , 1370 , 1379 ) | inrange ( ``ffind'' , 1380 , 1380 ) | inrange ( ``ffind'' , 1381 , 1381 ) | inrange ( ``ffind'' , 1382 , 1382 ) | inrange ( ``ffind'' , 1389 , 1389 ) | inrange ( ``ffind'' , 2900 , 2912 ) | inrange ( ``ffind'' , 2990 , 2999 ) qui replace `generate' = 20 if inrange ( ``ffind'' , 4900 , 4900 ) | inrange ( ``ffind'' , 4910 , 4911 ) | inrange ( ``ffind'' , 4920 , 4922 ) | inrange ( ``ffind'' , 4923 , 4923 ) | inrange ( ``ffind'' , 4924 , 4925 ) | inrange ( ``ffind'' , 4930 , 4931 ) | inrange ( ``ffind'' , 4932 , 4932 ) | inrange ( ``ffind'' , 4939 , 4939 ) | inrange ( ``ffind'' , 4940 , 4942 ) qui replace `generate' = 21 if inrange ( ``ffind'' , 4800 , 4800 ) | inrange ( ``ffind'' , 4810 , 4813 ) | inrange ( ``ffind'' , 4820 , 4822 ) | inrange ( ``ffind'' , 4830 , 4839 ) | inrange ( ``ffind'' , 4840 , 4841 ) | inrange ( ``ffind'' , 4880 , 4889 ) | inrange ( ``ffind'' , 4890 , 4890 ) | inrange ( ``ffind'' , 4891 , 4891 ) | inrange ( ``ffind'' , 4892 , 4892 ) | inrange ( ``ffind'' , 4899 , 4899 ) qui replace `generate' = 22 if inrange ( ``ffind'' , 7020 , 7021 ) | inrange ( ``ffind'' , 7030 , 7033 ) | inrange ( ``ffind'' , 7200 , 7200 ) | inrange ( ``ffind'' , 7210 , 7212 ) | inrange ( ``ffind'' , 7214 , 7214 ) | inrange ( ``ffind'' , 7215 , 7216 ) | inrange ( ``ffind'' , 7217 , 7217 ) | inrange ( ``ffind'' , 7218 , 7218 ) | inrange ( ``ffind'' , 7219 , 7219 ) | inrange ( ``ffind'' , 7220 , 7221 ) | inrange ( ``ffind'' , 7230 , 7231 ) | inrange ( ``ffind'' , 7240 , 7241 ) | inrange ( ``ffind'' , 7250 , 7251 ) | inrange ( ``ffind'' , 7260 , 7269 ) | inrange ( ``ffind'' , 7270 , 7290 ) | inrange ( ``ffind'' , 7291 , 7291 ) | inrange ( ``ffind'' , 7292 , 7299 ) | inrange ( ``ffind'' , 7300 , 7300 ) | inrange ( ``ffind'' , 7310 , 7319 ) | inrange ( ``ffind'' , 7320 , 7329 ) | inrange ( ``ffind'' , 7330 , 7339 ) | inrange ( ``ffind'' , 7340 , 7342 ) | inrange ( ``ffind'' , 7349 , 7349 ) | inrange ( ``ffind'' , 7350 , 7351 ) | inrange ( ``ffind'' , 7352 , 7352 ) | inrange ( ``ffind'' , 7353 , 7353 ) | inrange ( ``ffind'' , 7359 , 7359 ) | inrange ( ``ffind'' , 7360 , 7369 ) | inrange ( ``ffind'' , 7370 , 7372 ) | inrange ( ``ffind'' , 7374 , 7374 ) | inrange ( ``ffind'' , 7375 , 7375 ) | inrange ( ``ffind'' , 7376 , 7376 ) | inrange ( ``ffind'' , 7377 , 7377 ) | inrange ( ``ffind'' , 7378 , 7378 ) | inrange ( ``ffind'' , 7379 , 7379 ) | inrange ( ``ffind'' , 7380 , 7380 ) | inrange ( ``ffind'' , 7381 , 7382 ) | inrange ( ``ffind'' , 7383 , 7383 ) | inrange ( ``ffind'' , 7384 , 7384 ) | inrange ( ``ffind'' , 7385 , 7385 ) | inrange ( ``ffind'' , 7389 , 7390 ) | inrange ( ``ffind'' , 7391 , 7391 ) | inrange ( ``ffind'' , 7392 , 7392 ) | inrange ( ``ffind'' , 7393 , 7393 ) | inrange ( ``ffind'' , 7394 , 7394 ) | inrange ( ``ffind'' , 7395 , 7395 ) | inrange ( ``ffind'' , 7396 , 7396 ) | inrange ( ``ffind'' , 7397 , 7397 ) | inrange ( ``ffind'' , 7399 , 7399 ) | inrange ( ``ffind'' , 7500 , 7500 ) | inrange ( ``ffind'' , 7510 , 7519 ) | inrange ( ``ffind'' , 7520 , 7529 ) | inrange ( ``ffind'' , 7530 , 7539 ) | inrange ( ``ffind'' , 7540 , 7549 ) | inrange ( ``ffind'' , 7600 , 7600 ) | inrange ( ``ffind'' , 7620 , 7620 ) | inrange ( ``ffind'' , 7622 , 7622 ) | inrange ( ``ffind'' , 7623 , 7623 ) | inrange ( ``ffind'' , 7629 , 7629 ) | inrange ( ``ffind'' , 7630 , 7631 ) | inrange ( ``ffind'' , 7640 , 7641 ) | inrange ( ``ffind'' , 7690 , 7699 ) | inrange ( ``ffind'' , 8100 , 8199 ) | inrange ( ``ffind'' , 8200 , 8299 ) | inrange ( ``ffind'' , 8300 , 8399 ) | inrange ( ``ffind'' , 8400 , 8499 ) | inrange ( ``ffind'' , 8600 , 8699 ) | inrange ( ``ffind'' , 8700 , 8700 ) | inrange ( ``ffind'' , 8710 , 8713 ) | inrange ( ``ffind'' , 8720 , 8721 ) | inrange ( ``ffind'' , 8730 , 8734 ) | inrange ( ``ffind'' , 8740 , 8748 ) | inrange ( ``ffind'' , 8800 , 8899 ) | inrange ( ``ffind'' , 8900 , 8910 ) | inrange ( ``ffind'' , 8911 , 8911 ) | inrange ( ``ffind'' , 8920 , 8999 ) qui replace `generate' = 23 if inrange ( ``ffind'' , 3570 , 3579 ) | inrange ( ``ffind'' , 3622 , 3622 ) | inrange ( ``ffind'' , 3661 , 3661 ) | inrange ( ``ffind'' , 3662 , 3662 ) | inrange ( ``ffind'' , 3663 , 3663 ) | inrange ( ``ffind'' , 3664 , 3664 ) | inrange ( ``ffind'' , 3665 , 3665 ) | inrange ( ``ffind'' , 3666 , 3666 ) | inrange ( ``ffind'' , 3669 , 3669 ) | inrange ( ``ffind'' , 3670 , 3679 ) | inrange ( ``ffind'' , 3680 , 3680 ) | inrange ( ``ffind'' , 3681 , 3681 ) | inrange ( ``ffind'' , 3682 , 3682 ) | inrange ( ``ffind'' , 3683 , 3683 ) | inrange ( ``ffind'' , 3684 , 3684 ) | inrange ( ``ffind'' , 3685 , 3685 ) | inrange ( ``ffind'' , 3686 , 3686 ) | inrange ( ``ffind'' , 3687 , 3687 ) | inrange ( ``ffind'' , 3688 , 3688 ) | inrange ( ``ffind'' , 3689 , 3689 ) | inrange ( ``ffind'' , 3695 , 3695 ) | inrange ( ``ffind'' , 3810 , 3810 ) | inrange ( ``ffind'' , 3811 , 3811 ) | inrange ( ``ffind'' , 3812 , 3812 ) | inrange ( ``ffind'' , 3820 , 3820 ) | inrange ( ``ffind'' , 3821 , 3821 ) | inrange ( ``ffind'' , 3822 , 3822 ) | inrange ( ``ffind'' , 3823 , 3823 ) | inrange ( ``ffind'' , 3824 , 3824 ) | inrange ( ``ffind'' , 3825 , 3825 ) | inrange ( ``ffind'' , 3826 , 3826 ) | inrange ( ``ffind'' , 3827 , 3827 ) | inrange ( ``ffind'' , 3829 , 3829 ) | inrange ( ``ffind'' , 3830 , 3839 ) | inrange ( ``ffind'' , 7373 , 7373 ) qui replace `generate' = 24 if inrange ( ``ffind'' , 2440 , 2449 ) | inrange ( ``ffind'' , 2520 , 2549 ) | inrange ( ``ffind'' , 2600 , 2639 ) | inrange ( ``ffind'' , 2640 , 2659 ) | inrange ( ``ffind'' , 2670 , 2699 ) | inrange ( ``ffind'' , 2760 , 2761 ) | inrange ( ``ffind'' , 3220 , 3221 ) | inrange ( ``ffind'' , 3410 , 3412 ) | inrange ( ``ffind'' , 3950 , 3955 ) qui replace `generate' = 25 if inrange ( ``ffind'' , 4000 , 4013 ) | inrange ( ``ffind'' , 4040 , 4049 ) | inrange ( ``ffind'' , 4100 , 4100 ) | inrange ( ``ffind'' , 4110 , 4119 ) | inrange ( ``ffind'' , 4120 , 4121 ) | inrange ( ``ffind'' , 4130 , 4131 ) | inrange ( ``ffind'' , 4140 , 4142 ) | inrange ( ``ffind'' , 4150 , 4151 ) | inrange ( ``ffind'' , 4170 , 4173 ) | inrange ( ``ffind'' , 4190 , 4199 ) | inrange ( ``ffind'' , 4200 , 4200 ) | inrange ( ``ffind'' , 4210 , 4219 ) | inrange ( ``ffind'' , 4220 , 4229 ) | inrange ( ``ffind'' , 4230 , 4231 ) | inrange ( ``ffind'' , 4240 , 4249 ) | inrange ( ``ffind'' , 4400 , 4499 ) | inrange ( ``ffind'' , 4500 , 4599 ) | inrange ( ``ffind'' , 4600 , 4699 ) | inrange ( ``ffind'' , 4700 , 4700 ) | inrange ( ``ffind'' , 4710 , 4712 ) | inrange ( ``ffind'' , 4720 , 4729 ) | inrange ( ``ffind'' , 4730 , 4739 ) | inrange ( ``ffind'' , 4740 , 4749 ) | inrange ( ``ffind'' , 4780 , 4780 ) | inrange ( ``ffind'' , 4782 , 4782 ) | inrange ( ``ffind'' , 4783 , 4783 ) | inrange ( ``ffind'' , 4784 , 4784 ) | inrange ( ``ffind'' , 4785 , 4785 ) | inrange ( ``ffind'' , 4789 , 4789 ) qui replace `generate' = 26 if inrange ( ``ffind'' , 5000 , 5000 ) | inrange ( ``ffind'' , 5010 , 5015 ) | inrange ( ``ffind'' , 5020 , 5023 ) | inrange ( ``ffind'' , 5030 , 5039 ) | inrange ( ``ffind'' , 5040 , 5042 ) | inrange ( ``ffind'' , 5043 , 5043 ) | inrange ( ``ffind'' , 5044 , 5044 ) | inrange ( ``ffind'' , 5045 , 5045 ) | inrange ( ``ffind'' , 5046 , 5046 ) | inrange ( ``ffind'' , 5047 , 5047 ) | inrange ( ``ffind'' , 5048 , 5048 ) | inrange ( ``ffind'' , 5049 , 5049 ) | inrange ( ``ffind'' , 5050 , 5059 ) | inrange ( ``ffind'' , 5060 , 5060 ) | inrange ( ``ffind'' , 5063 , 5063 ) | inrange ( ``ffind'' , 5064 , 5064 ) | inrange ( ``ffind'' , 5065 , 5065 ) | inrange ( ``ffind'' , 5070 , 5078 ) | inrange ( ``ffind'' , 5080 , 5080 ) | inrange ( ``ffind'' , 5081 , 5081 ) | inrange ( ``ffind'' , 5082 , 5082 ) | inrange ( ``ffind'' , 5083 , 5083 ) | inrange ( ``ffind'' , 5084 , 5084 ) | inrange ( ``ffind'' , 5085 , 5085 ) | inrange ( ``ffind'' , 5086 , 5087 ) | inrange ( ``ffind'' , 5088 , 5088 ) | inrange ( ``ffind'' , 5090 , 5090 ) | inrange ( ``ffind'' , 5091 , 5092 ) | inrange ( ``ffind'' , 5093 , 5093 ) | inrange ( ``ffind'' , 5094 , 5094 ) | inrange ( ``ffind'' , 5099 , 5099 ) | inrange ( ``ffind'' , 5100 , 5100 ) | inrange ( ``ffind'' , 5110 , 5113 ) | inrange ( ``ffind'' , 5120 , 5122 ) | inrange ( ``ffind'' , 5130 , 5139 ) | inrange ( ``ffind'' , 5140 , 5149 ) | inrange ( ``ffind'' , 5150 , 5159 ) | inrange ( ``ffind'' , 5160 , 5169 ) | inrange ( ``ffind'' , 5170 , 5172 ) | inrange ( ``ffind'' , 5180 , 5182 ) | inrange ( ``ffind'' , 5190 , 5199 ) qui replace `generate' = 27 if inrange ( ``ffind'' , 5200 , 5200 ) | inrange ( ``ffind'' , 5210 , 5219 ) | inrange ( ``ffind'' , 5220 , 5229 ) | inrange ( ``ffind'' , 5230 , 5231 ) | inrange ( ``ffind'' , 5250 , 5251 ) | inrange ( ``ffind'' , 5260 , 5261 ) | inrange ( ``ffind'' , 5270 , 5271 ) | inrange ( ``ffind'' , 5300 , 5300 ) | inrange ( ``ffind'' , 5310 , 5311 ) | inrange ( ``ffind'' , 5320 , 5320 ) | inrange ( ``ffind'' , 5330 , 5331 ) | inrange ( ``ffind'' , 5334 , 5334 ) | inrange ( ``ffind'' , 5340 , 5349 ) | inrange ( ``ffind'' , 5390 , 5399 ) | inrange ( ``ffind'' , 5400 , 5400 ) | inrange ( ``ffind'' , 5410 , 5411 ) | inrange ( ``ffind'' , 5412 , 5412 ) | inrange ( ``ffind'' , 5420 , 5429 ) | inrange ( ``ffind'' , 5430 , 5439 ) | inrange ( ``ffind'' , 5440 , 5449 ) | inrange ( ``ffind'' , 5450 , 5459 ) | inrange ( ``ffind'' , 5460 , 5469 ) | inrange ( ``ffind'' , 5490 , 5499 ) | inrange ( ``ffind'' , 5500 , 5500 ) | inrange ( ``ffind'' , 5510 , 5529 ) | inrange ( ``ffind'' , 5530 , 5539 ) | inrange ( ``ffind'' , 5540 , 5549 ) | inrange ( ``ffind'' , 5550 , 5559 ) | inrange ( ``ffind'' , 5560 , 5569 ) | inrange ( ``ffind'' , 5570 , 5579 ) | inrange ( ``ffind'' , 5590 , 5599 ) | inrange ( ``ffind'' , 5600 , 5699 ) | inrange ( ``ffind'' , 5700 , 5700 ) | inrange ( ``ffind'' , 5710 , 5719 ) | inrange ( ``ffind'' , 5720 , 5722 ) | inrange ( ``ffind'' , 5730 , 5733 ) | inrange ( ``ffind'' , 5734 , 5734 ) | inrange ( ``ffind'' , 5735 , 5735 ) | inrange ( ``ffind'' , 5736 , 5736 ) | inrange ( ``ffind'' , 5750 , 5799 ) | inrange ( ``ffind'' , 5900 , 5900 ) | inrange ( ``ffind'' , 5910 , 5912 ) | inrange ( ``ffind'' , 5920 , 5929 ) | inrange ( ``ffind'' , 5930 , 5932 ) | inrange ( ``ffind'' , 5940 , 5940 ) | inrange ( ``ffind'' , 5941 , 5941 ) | inrange ( ``ffind'' , 5942 , 5942 ) | inrange ( ``ffind'' , 5943 , 5943 ) | inrange ( ``ffind'' , 5944 , 5944 ) | inrange ( ``ffind'' , 5945 , 5945 ) | inrange ( ``ffind'' , 5946 , 5946 ) | inrange ( ``ffind'' , 5947 , 5947 ) | inrange ( ``ffind'' , 5948 , 5948 ) | inrange ( ``ffind'' , 5949 , 5949 ) | inrange ( ``ffind'' , 5950 , 5959 ) | inrange ( ``ffind'' , 5960 , 5969 ) | inrange ( ``ffind'' , 5970 , 5979 ) | inrange ( ``ffind'' , 5980 , 5989 ) | inrange ( ``ffind'' , 5990 , 5990 ) | inrange ( ``ffind'' , 5992 , 5992 ) | inrange ( ``ffind'' , 5993 , 5993 ) | inrange ( ``ffind'' , 5994 , 5994 ) | inrange ( ``ffind'' , 5995 , 5995 ) | inrange ( ``ffind'' , 5999 , 5999 ) qui replace `generate' = 28 if inrange ( ``ffind'' , 5800 , 5819 ) | inrange ( ``ffind'' , 5820 , 5829 ) | inrange ( ``ffind'' , 5890 , 5899 ) | inrange ( ``ffind'' , 7000 , 7000 ) | inrange ( ``ffind'' , 7010 , 7019 ) | inrange ( ``ffind'' , 7040 , 7049 ) | inrange ( ``ffind'' , 7213 , 7213 ) qui replace `generate' = 29 if inrange ( ``ffind'' , 6000 , 6000 ) | inrange ( ``ffind'' , 6010 , 6019 ) | inrange ( ``ffind'' , 6020 , 6020 ) | inrange ( ``ffind'' , 6021 , 6021 ) | inrange ( ``ffind'' , 6022 , 6022 ) | inrange ( ``ffind'' , 6023 , 6024 ) | inrange ( ``ffind'' , 6025 , 6025 ) | inrange ( ``ffind'' , 6026 , 6026 ) | inrange ( ``ffind'' , 6027 , 6027 ) | inrange ( ``ffind'' , 6028 , 6029 ) | inrange ( ``ffind'' , 6030 , 6036 ) | inrange ( ``ffind'' , 6040 , 6059 ) | inrange ( ``ffind'' , 6060 , 6062 ) | inrange ( ``ffind'' , 6080 , 6082 ) | inrange ( ``ffind'' , 6090 , 6099 ) | inrange ( ``ffind'' , 6100 , 6100 ) | inrange ( ``ffind'' , 6110 , 6111 ) | inrange ( ``ffind'' , 6112 , 6113 ) | inrange ( ``ffind'' , 6120 , 6129 ) | inrange ( ``ffind'' , 6130 , 6139 ) | inrange ( ``ffind'' , 6140 , 6149 ) | inrange ( ``ffind'' , 6150 , 6159 ) | inrange ( ``ffind'' , 6160 , 6169 ) | inrange ( ``ffind'' , 6170 , 6179 ) | inrange ( ``ffind'' , 6190 , 6199 ) | inrange ( ``ffind'' , 6200 , 6299 ) | inrange ( ``ffind'' , 6300 , 6300 ) | inrange ( ``ffind'' , 6310 , 6319 ) | inrange ( ``ffind'' , 6320 , 6329 ) | inrange ( ``ffind'' , 6330 , 6331 ) | inrange ( ``ffind'' , 6350 , 6351 ) | inrange ( ``ffind'' , 6360 , 6361 ) | inrange ( ``ffind'' , 6370 , 6379 ) | inrange ( ``ffind'' , 6390 , 6399 ) | inrange ( ``ffind'' , 6400 , 6411 ) | inrange ( ``ffind'' , 6500 , 6500 ) | inrange ( ``ffind'' , 6510 , 6510 ) | inrange ( ``ffind'' , 6512 , 6512 ) | inrange ( ``ffind'' , 6513 , 6513 ) | inrange ( ``ffind'' , 6514 , 6514 ) | inrange ( ``ffind'' , 6515 , 6515 ) | inrange ( ``ffind'' , 6517 , 6519 ) | inrange ( ``ffind'' , 6520 , 6529 ) | inrange ( ``ffind'' , 6530 , 6531 ) | inrange ( ``ffind'' , 6532 , 6532 ) | inrange ( ``ffind'' , 6540 , 6541 ) | inrange ( ``ffind'' , 6550 , 6553 ) | inrange ( ``ffind'' , 6590 , 6599 ) | inrange ( ``ffind'' , 6610 , 6611 ) | inrange ( ``ffind'' , 6700 , 6700 ) | inrange ( ``ffind'' , 6710 , 6719 ) | inrange ( ``ffind'' , 6720 , 6722 ) | inrange ( ``ffind'' , 6723 , 6723 ) | inrange ( ``ffind'' , 6724 , 6724 ) | inrange ( ``ffind'' , 6725 , 6725 ) | inrange ( ``ffind'' , 6726 , 6726 ) | inrange ( ``ffind'' , 6730 , 6733 ) | inrange ( ``ffind'' , 6740 , 6779 ) | inrange ( ``ffind'' , 6790 , 6791 ) | inrange ( ``ffind'' , 6792 , 6792 ) | inrange ( ``ffind'' , 6793 , 6793 ) | inrange ( ``ffind'' , 6794 , 6794 ) | inrange ( ``ffind'' , 6795 , 6795 ) | inrange ( ``ffind'' , 6798 , 6798 ) | inrange ( ``ffind'' , 6799 , 6799 ) qui replace `generate' = 30 if missing ( `generate' ) & ~ missing ( ``ffind'' ) } else if ``ftyp'' == 38 { label define `generate' 1 \"Agriculture, forestry, and fishing\" 2 \"Mining\" 3 \"Oil and Gas Extraction\" 4 \"Nonmetalic Minerals Except Fuels\" 5 \"Construction\" 6 \"Food and Kindred Products\" 7 \"Tobacco Products\" 8 \"Textile Mill Products\" 9 \"Apparel and other Textile Products\" 10 \"Lumber and Wood Products\" 11 \"Furniture and Fixtures\" 12 \"Paper and Allied Products\" 13 \"Printing and Publishing\" 14 \"Chemicals and Allied Products\" 15 \"Petroleum and Coal Products\" 16 \"Rubber and Miscellaneous Plastics Products\" 17 \"Leather and Leather Products\" 18 \"Stone, Clay and Glass Products\" 19 \"Primary Metal Industries\" 20 \"Fabricated Metal Products\" 21 \"Machinery, Except Electrical\" 22 \"Electrical and Electronic Equipment\" 23 \"Transportation Equipment\" 24 \"Instruments and Related Products\" 25 \"Miscellaneous Manufacturing Industries\" 26 \"Transportation\" 27 \"Telephone and Telegraph Communication\" 28 \"Radio and Television Broadcasting\" 29 \"Electric, Gas, and Water Supply\" 30 \"Sanitary Services\" 31 \"Steam Supply\" 32 \"Irrigation Systems\" 33 \"Wholesale\" 34 \"Retail Stores\" 35 \"Finance, Insurance, and Real Estate\" 36 \"Services\" 37 \"Public Administration\" 38 \"Almost Nothing\" label values `generate' `generate' qui replace `generate' = 1 if inrange ( ``ffind'' , 100 , 999 ) qui replace `generate' = 2 if inrange ( ``ffind'' , 1000 , 1299 ) qui replace `generate' = 3 if inrange ( ``ffind'' , 1300 , 1399 ) qui replace `generate' = 4 if inrange ( ``ffind'' , 1400 , 1499 ) qui replace `generate' = 5 if inrange ( ``ffind'' , 1500 , 1799 ) qui replace `generate' = 6 if inrange ( ``ffind'' , 2000 , 2099 ) qui replace `generate' = 7 if inrange ( ``ffind'' , 2100 , 2199 ) qui replace `generate' = 8 if inrange ( ``ffind'' , 2200 , 2299 ) qui replace `generate' = 9 if inrange ( ``ffind'' , 2300 , 2399 ) qui replace `generate' = 10 if inrange ( ``ffind'' , 2400 , 2499 ) qui replace `generate' = 11 if inrange ( ``ffind'' , 2500 , 2599 ) qui replace `generate' = 12 if inrange ( ``ffind'' , 2600 , 2661 ) qui replace `generate' = 13 if inrange ( ``ffind'' , 2700 , 2799 ) qui replace `generate' = 14 if inrange ( ``ffind'' , 2800 , 2899 ) qui replace `generate' = 15 if inrange ( ``ffind'' , 2900 , 2999 ) qui replace `generate' = 16 if inrange ( ``ffind'' , 3000 , 3099 ) qui replace `generate' = 17 if inrange ( ``ffind'' , 3100 , 3199 ) qui replace `generate' = 18 if inrange ( ``ffind'' , 3200 , 3299 ) qui replace `generate' = 19 if inrange ( ``ffind'' , 3300 , 3399 ) qui replace `generate' = 20 if inrange ( ``ffind'' , 3400 , 3499 ) qui replace `generate' = 21 if inrange ( ``ffind'' , 3500 , 3599 ) qui replace `generate' = 22 if inrange ( ``ffind'' , 3600 , 3699 ) qui replace `generate' = 23 if inrange ( ``ffind'' , 3700 , 3799 ) qui replace `generate' = 24 if inrange ( ``ffind'' , 3800 , 3879 ) qui replace `generate' = 25 if inrange ( ``ffind'' , 3900 , 3999 ) qui replace `generate' = 26 if inrange ( ``ffind'' , 4000 , 4799 ) qui replace `generate' = 27 if inrange ( ``ffind'' , 4800 , 4829 ) qui replace `generate' = 28 if inrange ( ``ffind'' , 4830 , 4899 ) qui replace `generate' = 29 if inrange ( ``ffind'' , 4900 , 4949 ) qui replace `generate' = 30 if inrange ( ``ffind'' , 4950 , 4959 ) qui replace `generate' = 31 if inrange ( ``ffind'' , 4960 , 4969 ) qui replace `generate' = 32 if inrange ( ``ffind'' , 4970 , 4979 ) qui replace `generate' = 33 if inrange ( ``ffind'' , 5000 , 5199 ) qui replace `generate' = 34 if inrange ( ``ffind'' , 5200 , 5999 ) qui replace `generate' = 35 if inrange ( ``ffind'' , 6000 , 6999 ) qui replace `generate' = 36 if inrange ( ``ffind'' , 7000 , 8999 ) qui replace `generate' = 37 if inrange ( ``ffind'' , 9000 , 9999 ) qui replace `generate' = 38 if missing ( `generate' ) & ~ missing ( ``ffind'' ) } else if ``ftyp'' == 48 { label define `generate' 1 \"Agriculture\" 2 \"Food Products\" 3 \"Candy & Soda\" 4 \"Beer & Liquor\" 5 \"Tobacco Products\" 6 \"Recreation\" 7 \"Entertainment\" 8 \"Printing and Publishing\" 9 \"Consumer Goods\" 10 \"Apparel\" 11 \"Healthcare\" 12 \"Medical Equipment\" 13 \"Pharmaceutical Products\" 14 \"Chemicals\" 15 \"Rubber and Plastic Products\" 16 \"Textiles\" 17 \"Construction Materials\" 18 \"Construction\" 19 \"Steel Works Etc\" 20 \"Fabricated Products\" 21 \"Machinery\" 22 \"Electrical Equipment\" 23 \"Automobiles and Trucks\" 24 \"Aircraft\" 25 \"Shipbuilding, Railroad Equipment\" 26 \"Defense\" 27 \"Precious Metals\" 28 \"Non-Metallic and Industrial Metal Mining\" 29 \"Coal\" 30 \"Petroleum and Natural Gas\" 31 \"Utilities\" 32 \"Communication\" 33 \"Personal Services\" 34 \"Business Services\" 35 \"Computers\" 36 \"Electronic Equipment\" 37 \"Measuring and Control Equipment\" 38 \"Business Supplies\" 39 \"Shipping Containers\" 40 \"Transportation\" 41 \"Wholesale\" 42 \"Retail\" 43 \"Restaraunts, Hotels, Motels\" 44 \"Banking\" 45 \"Insurance\" 46 \"Real Estate\" 47 \"Trading\" 48 \"Almost Nothing\" label values `generate' `generate' qui replace `generate' = 1 if inrange ( ``ffind'' , 100 , 199 ) | inrange ( ``ffind'' , 200 , 299 ) | inrange ( ``ffind'' , 700 , 799 ) | inrange ( ``ffind'' , 910 , 919 ) | inrange ( ``ffind'' , 2048 , 2048 ) qui replace `generate' = 2 if inrange ( ``ffind'' , 2000 , 2009 ) | inrange ( ``ffind'' , 2010 , 2019 ) | inrange ( ``ffind'' , 2020 , 2029 ) | inrange ( ``ffind'' , 2030 , 2039 ) | inrange ( ``ffind'' , 2040 , 2046 ) | inrange ( ``ffind'' , 2050 , 2059 ) | inrange ( ``ffind'' , 2060 , 2063 ) | inrange ( ``ffind'' , 2070 , 2079 ) | inrange ( ``ffind'' , 2090 , 2092 ) | inrange ( ``ffind'' , 2095 , 2095 ) | inrange ( ``ffind'' , 2098 , 2099 ) qui replace `generate' = 3 if inrange ( ``ffind'' , 2064 , 2068 ) | inrange ( ``ffind'' , 2086 , 2086 ) | inrange ( ``ffind'' , 2087 , 2087 ) | inrange ( ``ffind'' , 2096 , 2096 ) | inrange ( ``ffind'' , 2097 , 2097 ) qui replace `generate' = 4 if inrange ( ``ffind'' , 2080 , 2080 ) | inrange ( ``ffind'' , 2082 , 2082 ) | inrange ( ``ffind'' , 2083 , 2083 ) | inrange ( ``ffind'' , 2084 , 2084 ) | inrange ( ``ffind'' , 2085 , 2085 ) qui replace `generate' = 5 if inrange ( ``ffind'' , 2100 , 2199 ) qui replace `generate' = 6 if inrange ( ``ffind'' , 920 , 999 ) | inrange ( ``ffind'' , 3650 , 3651 ) | inrange ( ``ffind'' , 3652 , 3652 ) | inrange ( ``ffind'' , 3732 , 3732 ) | inrange ( ``ffind'' , 3930 , 3931 ) | inrange ( ``ffind'' , 3940 , 3949 ) qui replace `generate' = 7 if inrange ( ``ffind'' , 7800 , 7829 ) | inrange ( ``ffind'' , 7830 , 7833 ) | inrange ( ``ffind'' , 7840 , 7841 ) | inrange ( ``ffind'' , 7900 , 7900 ) | inrange ( ``ffind'' , 7910 , 7911 ) | inrange ( ``ffind'' , 7920 , 7929 ) | inrange ( ``ffind'' , 7930 , 7933 ) | inrange ( ``ffind'' , 7940 , 7949 ) | inrange ( ``ffind'' , 7980 , 7980 ) | inrange ( ``ffind'' , 7990 , 7999 ) qui replace `generate' = 8 if inrange ( ``ffind'' , 2700 , 2709 ) | inrange ( ``ffind'' , 2710 , 2719 ) | inrange ( ``ffind'' , 2720 , 2729 ) | inrange ( ``ffind'' , 2730 , 2739 ) | inrange ( ``ffind'' , 2740 , 2749 ) | inrange ( ``ffind'' , 2770 , 2771 ) | inrange ( ``ffind'' , 2780 , 2789 ) | inrange ( ``ffind'' , 2790 , 2799 ) qui replace `generate' = 9 if inrange ( ``ffind'' , 2047 , 2047 ) | inrange ( ``ffind'' , 2391 , 2392 ) | inrange ( ``ffind'' , 2510 , 2519 ) | inrange ( ``ffind'' , 2590 , 2599 ) | inrange ( ``ffind'' , 2840 , 2843 ) | inrange ( ``ffind'' , 2844 , 2844 ) | inrange ( ``ffind'' , 3160 , 3161 ) | inrange ( ``ffind'' , 3170 , 3171 ) | inrange ( ``ffind'' , 3172 , 3172 ) | inrange ( ``ffind'' , 3190 , 3199 ) | inrange ( ``ffind'' , 3229 , 3229 ) | inrange ( ``ffind'' , 3260 , 3260 ) | inrange ( ``ffind'' , 3262 , 3263 ) | inrange ( ``ffind'' , 3269 , 3269 ) | inrange ( ``ffind'' , 3230 , 3231 ) | inrange ( ``ffind'' , 3630 , 3639 ) | inrange ( ``ffind'' , 3750 , 3751 ) | inrange ( ``ffind'' , 3800 , 3800 ) | inrange ( ``ffind'' , 3860 , 3861 ) | inrange ( ``ffind'' , 3870 , 3873 ) | inrange ( ``ffind'' , 3910 , 3911 ) | inrange ( ``ffind'' , 3914 , 3914 ) | inrange ( ``ffind'' , 3915 , 3915 ) | inrange ( ``ffind'' , 3960 , 3962 ) | inrange ( ``ffind'' , 3991 , 3991 ) | inrange ( ``ffind'' , 3995 , 3995 ) qui replace `generate' = 10 if inrange ( ``ffind'' , 2300 , 2390 ) | inrange ( ``ffind'' , 3020 , 3021 ) | inrange ( ``ffind'' , 3100 , 3111 ) | inrange ( ``ffind'' , 3130 , 3131 ) | inrange ( ``ffind'' , 3140 , 3149 ) | inrange ( ``ffind'' , 3150 , 3151 ) | inrange ( ``ffind'' , 3963 , 3965 ) qui replace `generate' = 11 if inrange ( ``ffind'' , 8000 , 8099 ) qui replace `generate' = 12 if inrange ( ``ffind'' , 3693 , 3693 ) | inrange ( ``ffind'' , 3840 , 3849 ) | inrange ( ``ffind'' , 3850 , 3851 ) qui replace `generate' = 13 if inrange ( ``ffind'' , 2830 , 2830 ) | inrange ( ``ffind'' , 2831 , 2831 ) | inrange ( ``ffind'' , 2833 , 2833 ) | inrange ( ``ffind'' , 2834 , 2834 ) | inrange ( ``ffind'' , 2835 , 2835 ) | inrange ( ``ffind'' , 2836 , 2836 ) qui replace `generate' = 14 if inrange ( ``ffind'' , 2800 , 2809 ) | inrange ( ``ffind'' , 2810 , 2819 ) | inrange ( ``ffind'' , 2820 , 2829 ) | inrange ( ``ffind'' , 2850 , 2859 ) | inrange ( ``ffind'' , 2860 , 2869 ) | inrange ( ``ffind'' , 2870 , 2879 ) | inrange ( ``ffind'' , 2890 , 2899 ) qui replace `generate' = 15 if inrange ( ``ffind'' , 3031 , 3031 ) | inrange ( ``ffind'' , 3041 , 3041 ) | inrange ( ``ffind'' , 3050 , 3053 ) | inrange ( ``ffind'' , 3060 , 3069 ) | inrange ( ``ffind'' , 3070 , 3079 ) | inrange ( ``ffind'' , 3080 , 3089 ) | inrange ( ``ffind'' , 3090 , 3099 ) qui replace `generate' = 16 if inrange ( ``ffind'' , 2200 , 2269 ) | inrange ( ``ffind'' , 2270 , 2279 ) | inrange ( ``ffind'' , 2280 , 2284 ) | inrange ( ``ffind'' , 2290 , 2295 ) | inrange ( ``ffind'' , 2297 , 2297 ) | inrange ( ``ffind'' , 2298 , 2298 ) | inrange ( ``ffind'' , 2299 , 2299 ) | inrange ( ``ffind'' , 2393 , 2395 ) | inrange ( ``ffind'' , 2397 , 2399 ) qui replace `generate' = 17 if inrange ( ``ffind'' , 800 , 899 ) | inrange ( ``ffind'' , 2400 , 2439 ) | inrange ( ``ffind'' , 2450 , 2459 ) | inrange ( ``ffind'' , 2490 , 2499 ) | inrange ( ``ffind'' , 2660 , 2661 ) | inrange ( ``ffind'' , 2950 , 2952 ) | inrange ( ``ffind'' , 3200 , 3200 ) | inrange ( ``ffind'' , 3210 , 3211 ) | inrange ( ``ffind'' , 3240 , 3241 ) | inrange ( ``ffind'' , 3250 , 3259 ) | inrange ( ``ffind'' , 3261 , 3261 ) | inrange ( ``ffind'' , 3264 , 3264 ) | inrange ( ``ffind'' , 3270 , 3275 ) | inrange ( ``ffind'' , 3280 , 3281 ) | inrange ( ``ffind'' , 3290 , 3293 ) | inrange ( ``ffind'' , 3295 , 3299 ) | inrange ( ``ffind'' , 3420 , 3429 ) | inrange ( ``ffind'' , 3430 , 3433 ) | inrange ( ``ffind'' , 3440 , 3441 ) | inrange ( ``ffind'' , 3442 , 3442 ) | inrange ( ``ffind'' , 3446 , 3446 ) | inrange ( ``ffind'' , 3448 , 3448 ) | inrange ( ``ffind'' , 3449 , 3449 ) | inrange ( ``ffind'' , 3450 , 3451 ) | inrange ( ``ffind'' , 3452 , 3452 ) | inrange ( ``ffind'' , 3490 , 3499 ) | inrange ( ``ffind'' , 3996 , 3996 ) qui replace `generate' = 18 if inrange ( ``ffind'' , 1500 , 1511 ) | inrange ( ``ffind'' , 1520 , 1529 ) | inrange ( ``ffind'' , 1530 , 1539 ) | inrange ( ``ffind'' , 1540 , 1549 ) | inrange ( ``ffind'' , 1600 , 1699 ) | inrange ( ``ffind'' , 1700 , 1799 ) qui replace `generate' = 19 if inrange ( ``ffind'' , 3300 , 3300 ) | inrange ( ``ffind'' , 3310 , 3317 ) | inrange ( ``ffind'' , 3320 , 3325 ) | inrange ( ``ffind'' , 3330 , 3339 ) | inrange ( ``ffind'' , 3340 , 3341 ) | inrange ( ``ffind'' , 3350 , 3357 ) | inrange ( ``ffind'' , 3360 , 3369 ) | inrange ( ``ffind'' , 3370 , 3379 ) | inrange ( ``ffind'' , 3390 , 3399 ) qui replace `generate' = 20 if inrange ( ``ffind'' , 3400 , 3400 ) | inrange ( ``ffind'' , 3443 , 3443 ) | inrange ( ``ffind'' , 3444 , 3444 ) | inrange ( ``ffind'' , 3460 , 3469 ) | inrange ( ``ffind'' , 3470 , 3479 ) qui replace `generate' = 21 if inrange ( ``ffind'' , 3510 , 3519 ) | inrange ( ``ffind'' , 3520 , 3529 ) | inrange ( ``ffind'' , 3530 , 3530 ) | inrange ( ``ffind'' , 3531 , 3531 ) | inrange ( ``ffind'' , 3532 , 3532 ) | inrange ( ``ffind'' , 3533 , 3533 ) | inrange ( ``ffind'' , 3534 , 3534 ) | inrange ( ``ffind'' , 3535 , 3535 ) | inrange ( ``ffind'' , 3536 , 3536 ) | inrange ( ``ffind'' , 3538 , 3538 ) | inrange ( ``ffind'' , 3540 , 3549 ) | inrange ( ``ffind'' , 3550 , 3559 ) | inrange ( ``ffind'' , 3560 , 3569 ) | inrange ( ``ffind'' , 3580 , 3580 ) | inrange ( ``ffind'' , 3581 , 3581 ) | inrange ( ``ffind'' , 3582 , 3582 ) | inrange ( ``ffind'' , 3585 , 3585 ) | inrange ( ``ffind'' , 3586 , 3586 ) | inrange ( ``ffind'' , 3589 , 3589 ) | inrange ( ``ffind'' , 3590 , 3599 ) qui replace `generate' = 22 if inrange ( ``ffind'' , 3600 , 3600 ) | inrange ( ``ffind'' , 3610 , 3613 ) | inrange ( ``ffind'' , 3620 , 3621 ) | inrange ( ``ffind'' , 3623 , 3629 ) | inrange ( ``ffind'' , 3640 , 3644 ) | inrange ( ``ffind'' , 3645 , 3645 ) | inrange ( ``ffind'' , 3646 , 3646 ) | inrange ( ``ffind'' , 3648 , 3649 ) | inrange ( ``ffind'' , 3660 , 3660 ) | inrange ( ``ffind'' , 3690 , 3690 ) | inrange ( ``ffind'' , 3691 , 3692 ) | inrange ( ``ffind'' , 3699 , 3699 ) qui replace `generate' = 23 if inrange ( ``ffind'' , 2296 , 2296 ) | inrange ( ``ffind'' , 2396 , 2396 ) | inrange ( ``ffind'' , 3010 , 3011 ) | inrange ( ``ffind'' , 3537 , 3537 ) | inrange ( ``ffind'' , 3647 , 3647 ) | inrange ( ``ffind'' , 3694 , 3694 ) | inrange ( ``ffind'' , 3700 , 3700 ) | inrange ( ``ffind'' , 3710 , 3710 ) | inrange ( ``ffind'' , 3711 , 3711 ) | inrange ( ``ffind'' , 3713 , 3713 ) | inrange ( ``ffind'' , 3714 , 3714 ) | inrange ( ``ffind'' , 3715 , 3715 ) | inrange ( ``ffind'' , 3716 , 3716 ) | inrange ( ``ffind'' , 3792 , 3792 ) | inrange ( ``ffind'' , 3790 , 3791 ) | inrange ( ``ffind'' , 3799 , 3799 ) qui replace `generate' = 24 if inrange ( ``ffind'' , 3720 , 3720 ) | inrange ( ``ffind'' , 3721 , 3721 ) | inrange ( ``ffind'' , 3723 , 3724 ) | inrange ( ``ffind'' , 3725 , 3725 ) | inrange ( ``ffind'' , 3728 , 3729 ) qui replace `generate' = 25 if inrange ( ``ffind'' , 3730 , 3731 ) | inrange ( ``ffind'' , 3740 , 3743 ) qui replace `generate' = 26 if inrange ( ``ffind'' , 3760 , 3769 ) | inrange ( ``ffind'' , 3795 , 3795 ) | inrange ( ``ffind'' , 3480 , 3489 ) qui replace `generate' = 27 if inrange ( ``ffind'' , 1040 , 1049 ) qui replace `generate' = 28 if inrange ( ``ffind'' , 1000 , 1009 ) | inrange ( ``ffind'' , 1010 , 1019 ) | inrange ( ``ffind'' , 1020 , 1029 ) | inrange ( ``ffind'' , 1030 , 1039 ) | inrange ( ``ffind'' , 1050 , 1059 ) | inrange ( ``ffind'' , 1060 , 1069 ) | inrange ( ``ffind'' , 1070 , 1079 ) | inrange ( ``ffind'' , 1080 , 1089 ) | inrange ( ``ffind'' , 1090 , 1099 ) | inrange ( ``ffind'' , 1100 , 1119 ) | inrange ( ``ffind'' , 1400 , 1499 ) qui replace `generate' = 29 if inrange ( ``ffind'' , 1200 , 1299 ) qui replace `generate' = 30 if inrange ( ``ffind'' , 1300 , 1300 ) | inrange ( ``ffind'' , 1310 , 1319 ) | inrange ( ``ffind'' , 1320 , 1329 ) | inrange ( ``ffind'' , 1330 , 1339 ) | inrange ( ``ffind'' , 1370 , 1379 ) | inrange ( ``ffind'' , 1380 , 1380 ) | inrange ( ``ffind'' , 1381 , 1381 ) | inrange ( ``ffind'' , 1382 , 1382 ) | inrange ( ``ffind'' , 1389 , 1389 ) | inrange ( ``ffind'' , 2900 , 2912 ) | inrange ( ``ffind'' , 2990 , 2999 ) qui replace `generate' = 31 if inrange ( ``ffind'' , 4900 , 4900 ) | inrange ( ``ffind'' , 4910 , 4911 ) | inrange ( ``ffind'' , 4920 , 4922 ) | inrange ( ``ffind'' , 4923 , 4923 ) | inrange ( ``ffind'' , 4924 , 4925 ) | inrange ( ``ffind'' , 4930 , 4931 ) | inrange ( ``ffind'' , 4932 , 4932 ) | inrange ( ``ffind'' , 4939 , 4939 ) | inrange ( ``ffind'' , 4940 , 4942 ) qui replace `generate' = 32 if inrange ( ``ffind'' , 4800 , 4800 ) | inrange ( ``ffind'' , 4810 , 4813 ) | inrange ( ``ffind'' , 4820 , 4822 ) | inrange ( ``ffind'' , 4830 , 4839 ) | inrange ( ``ffind'' , 4840 , 4841 ) | inrange ( ``ffind'' , 4880 , 4889 ) | inrange ( ``ffind'' , 4890 , 4890 ) | inrange ( ``ffind'' , 4891 , 4891 ) | inrange ( ``ffind'' , 4892 , 4892 ) | inrange ( ``ffind'' , 4899 , 4899 ) qui replace `generate' = 33 if inrange ( ``ffind'' , 7020 , 7021 ) | inrange ( ``ffind'' , 7030 , 7033 ) | inrange ( ``ffind'' , 7200 , 7200 ) | inrange ( ``ffind'' , 7210 , 7212 ) | inrange ( ``ffind'' , 7214 , 7214 ) | inrange ( ``ffind'' , 7215 , 7216 ) | inrange ( ``ffind'' , 7217 , 7217 ) | inrange ( ``ffind'' , 7219 , 7219 ) | inrange ( ``ffind'' , 7220 , 7221 ) | inrange ( ``ffind'' , 7230 , 7231 ) | inrange ( ``ffind'' , 7240 , 7241 ) | inrange ( ``ffind'' , 7250 , 7251 ) | inrange ( ``ffind'' , 7260 , 7269 ) | inrange ( ``ffind'' , 7270 , 7290 ) | inrange ( ``ffind'' , 7291 , 7291 ) | inrange ( ``ffind'' , 7292 , 7299 ) | inrange ( ``ffind'' , 7395 , 7395 ) | inrange ( ``ffind'' , 7500 , 7500 ) | inrange ( ``ffind'' , 7520 , 7529 ) | inrange ( ``ffind'' , 7530 , 7539 ) | inrange ( ``ffind'' , 7540 , 7549 ) | inrange ( ``ffind'' , 7600 , 7600 ) | inrange ( ``ffind'' , 7620 , 7620 ) | inrange ( ``ffind'' , 7622 , 7622 ) | inrange ( ``ffind'' , 7623 , 7623 ) | inrange ( ``ffind'' , 7629 , 7629 ) | inrange ( ``ffind'' , 7630 , 7631 ) | inrange ( ``ffind'' , 7640 , 7641 ) | inrange ( ``ffind'' , 7690 , 7699 ) | inrange ( ``ffind'' , 8100 , 8199 ) | inrange ( ``ffind'' , 8200 , 8299 ) | inrange ( ``ffind'' , 8300 , 8399 ) | inrange ( ``ffind'' , 8400 , 8499 ) | inrange ( ``ffind'' , 8600 , 8699 ) | inrange ( ``ffind'' , 8800 , 8899 ) | inrange ( ``ffind'' , 7510 , 7515 ) qui replace `generate' = 34 if inrange ( ``ffind'' , 2750 , 2759 ) | inrange ( ``ffind'' , 3993 , 3993 ) | inrange ( ``ffind'' , 7218 , 7218 ) | inrange ( ``ffind'' , 7300 , 7300 ) | inrange ( ``ffind'' , 7310 , 7319 ) | inrange ( ``ffind'' , 7320 , 7329 ) | inrange ( ``ffind'' , 7330 , 7339 ) | inrange ( ``ffind'' , 7340 , 7342 ) | inrange ( ``ffind'' , 7349 , 7349 ) | inrange ( ``ffind'' , 7350 , 7351 ) | inrange ( ``ffind'' , 7352 , 7352 ) | inrange ( ``ffind'' , 7353 , 7353 ) | inrange ( ``ffind'' , 7359 , 7359 ) | inrange ( ``ffind'' , 7360 , 7369 ) | inrange ( ``ffind'' , 7370 , 7372 ) | inrange ( ``ffind'' , 7374 , 7374 ) | inrange ( ``ffind'' , 7375 , 7375 ) | inrange ( ``ffind'' , 7376 , 7376 ) | inrange ( ``ffind'' , 7377 , 7377 ) | inrange ( ``ffind'' , 7378 , 7378 ) | inrange ( ``ffind'' , 7379 , 7379 ) | inrange ( ``ffind'' , 7380 , 7380 ) | inrange ( ``ffind'' , 7381 , 7382 ) | inrange ( ``ffind'' , 7383 , 7383 ) | inrange ( ``ffind'' , 7384 , 7384 ) | inrange ( ``ffind'' , 7385 , 7385 ) | inrange ( ``ffind'' , 7389 , 7390 ) | inrange ( ``ffind'' , 7391 , 7391 ) | inrange ( ``ffind'' , 7392 , 7392 ) | inrange ( ``ffind'' , 7393 , 7393 ) | inrange ( ``ffind'' , 7394 , 7394 ) | inrange ( ``ffind'' , 7396 , 7396 ) | inrange ( ``ffind'' , 7397 , 7397 ) | inrange ( ``ffind'' , 7399 , 7399 ) | inrange ( ``ffind'' , 7519 , 7519 ) | inrange ( ``ffind'' , 8700 , 8700 ) | inrange ( ``ffind'' , 8710 , 8713 ) | inrange ( ``ffind'' , 8720 , 8721 ) | inrange ( ``ffind'' , 8730 , 8734 ) | inrange ( ``ffind'' , 8740 , 8748 ) | inrange ( ``ffind'' , 8900 , 8910 ) | inrange ( ``ffind'' , 8911 , 8911 ) | inrange ( ``ffind'' , 8920 , 8999 ) | inrange ( ``ffind'' , 4220 , 4229 ) qui replace `generate' = 35 if inrange ( ``ffind'' , 3570 , 3579 ) | inrange ( ``ffind'' , 3680 , 3680 ) | inrange ( ``ffind'' , 3681 , 3681 ) | inrange ( ``ffind'' , 3682 , 3682 ) | inrange ( ``ffind'' , 3683 , 3683 ) | inrange ( ``ffind'' , 3684 , 3684 ) | inrange ( ``ffind'' , 3685 , 3685 ) | inrange ( ``ffind'' , 3686 , 3686 ) | inrange ( ``ffind'' , 3687 , 3687 ) | inrange ( ``ffind'' , 3688 , 3688 ) | inrange ( ``ffind'' , 3689 , 3689 ) | inrange ( ``ffind'' , 3695 , 3695 ) | inrange ( ``ffind'' , 7373 , 7373 ) qui replace `generate' = 36 if inrange ( ``ffind'' , 3622 , 3622 ) | inrange ( ``ffind'' , 3661 , 3661 ) | inrange ( ``ffind'' , 3662 , 3662 ) | inrange ( ``ffind'' , 3663 , 3663 ) | inrange ( ``ffind'' , 3664 , 3664 ) | inrange ( ``ffind'' , 3665 , 3665 ) | inrange ( ``ffind'' , 3666 , 3666 ) | inrange ( ``ffind'' , 3669 , 3669 ) | inrange ( ``ffind'' , 3670 , 3679 ) | inrange ( ``ffind'' , 3810 , 3810 ) | inrange ( ``ffind'' , 3812 , 3812 ) qui replace `generate' = 37 if inrange ( ``ffind'' , 3811 , 3811 ) | inrange ( ``ffind'' , 3820 , 3820 ) | inrange ( ``ffind'' , 3821 , 3821 ) | inrange ( ``ffind'' , 3822 , 3822 ) | inrange ( ``ffind'' , 3823 , 3823 ) | inrange ( ``ffind'' , 3824 , 3824 ) | inrange ( ``ffind'' , 3825 , 3825 ) | inrange ( ``ffind'' , 3826 , 3826 ) | inrange ( ``ffind'' , 3827 , 3827 ) | inrange ( ``ffind'' , 3829 , 3829 ) | inrange ( ``ffind'' , 3830 , 3839 ) qui replace `generate' = 38 if inrange ( ``ffind'' , 2520 , 2549 ) | inrange ( ``ffind'' , 2600 , 2639 ) | inrange ( ``ffind'' , 2670 , 2699 ) | inrange ( ``ffind'' , 2760 , 2761 ) | inrange ( ``ffind'' , 3950 , 3955 ) qui replace `generate' = 39 if inrange ( ``ffind'' , 2440 , 2449 ) | inrange ( ``ffind'' , 2640 , 2659 ) | inrange ( ``ffind'' , 3220 , 3221 ) | inrange ( ``ffind'' , 3410 , 3412 ) qui replace `generate' = 40 if inrange ( ``ffind'' , 4000 , 4013 ) | inrange ( ``ffind'' , 4040 , 4049 ) | inrange ( ``ffind'' , 4100 , 4100 ) | inrange ( ``ffind'' , 4110 , 4119 ) | inrange ( ``ffind'' , 4120 , 4121 ) | inrange ( ``ffind'' , 4130 , 4131 ) | inrange ( ``ffind'' , 4140 , 4142 ) | inrange ( ``ffind'' , 4150 , 4151 ) | inrange ( ``ffind'' , 4170 , 4173 ) | inrange ( ``ffind'' , 4190 , 4199 ) | inrange ( ``ffind'' , 4200 , 4200 ) | inrange ( ``ffind'' , 4210 , 4219 ) | inrange ( ``ffind'' , 4230 , 4231 ) | inrange ( ``ffind'' , 4240 , 4249 ) | inrange ( ``ffind'' , 4400 , 4499 ) | inrange ( ``ffind'' , 4500 , 4599 ) | inrange ( ``ffind'' , 4600 , 4699 ) | inrange ( ``ffind'' , 4700 , 4700 ) | inrange ( ``ffind'' , 4710 , 4712 ) | inrange ( ``ffind'' , 4720 , 4729 ) | inrange ( ``ffind'' , 4730 , 4739 ) | inrange ( ``ffind'' , 4740 , 4749 ) | inrange ( ``ffind'' , 4780 , 4780 ) | inrange ( ``ffind'' , 4782 , 4782 ) | inrange ( ``ffind'' , 4783 , 4783 ) | inrange ( ``ffind'' , 4784 , 4784 ) | inrange ( ``ffind'' , 4785 , 4785 ) | inrange ( ``ffind'' , 4789 , 4789 ) qui replace `generate' = 41 if inrange ( ``ffind'' , 5000 , 5000 ) | inrange ( ``ffind'' , 5010 , 5015 ) | inrange ( ``ffind'' , 5020 , 5023 ) | inrange ( ``ffind'' , 5030 , 5039 ) | inrange ( ``ffind'' , 5040 , 5042 ) | inrange ( ``ffind'' , 5043 , 5043 ) | inrange ( ``ffind'' , 5044 , 5044 ) | inrange ( ``ffind'' , 5045 , 5045 ) | inrange ( ``ffind'' , 5046 , 5046 ) | inrange ( ``ffind'' , 5047 , 5047 ) | inrange ( ``ffind'' , 5048 , 5048 ) | inrange ( ``ffind'' , 5049 , 5049 ) | inrange ( ``ffind'' , 5050 , 5059 ) | inrange ( ``ffind'' , 5060 , 5060 ) | inrange ( ``ffind'' , 5063 , 5063 ) | inrange ( ``ffind'' , 5064 , 5064 ) | inrange ( ``ffind'' , 5065 , 5065 ) | inrange ( ``ffind'' , 5070 , 5078 ) | inrange ( ``ffind'' , 5080 , 5080 ) | inrange ( ``ffind'' , 5081 , 5081 ) | inrange ( ``ffind'' , 5082 , 5082 ) | inrange ( ``ffind'' , 5083 , 5083 ) | inrange ( ``ffind'' , 5084 , 5084 ) | inrange ( ``ffind'' , 5085 , 5085 ) | inrange ( ``ffind'' , 5086 , 5087 ) | inrange ( ``ffind'' , 5088 , 5088 ) | inrange ( ``ffind'' , 5090 , 5090 ) | inrange ( ``ffind'' , 5091 , 5092 ) | inrange ( ``ffind'' , 5093 , 5093 ) | inrange ( ``ffind'' , 5094 , 5094 ) | inrange ( ``ffind'' , 5099 , 5099 ) | inrange ( ``ffind'' , 5100 , 5100 ) | inrange ( ``ffind'' , 5110 , 5113 ) | inrange ( ``ffind'' , 5120 , 5122 ) | inrange ( ``ffind'' , 5130 , 5139 ) | inrange ( ``ffind'' , 5140 , 5149 ) | inrange ( ``ffind'' , 5150 , 5159 ) | inrange ( ``ffind'' , 5160 , 5169 ) | inrange ( ``ffind'' , 5170 , 5172 ) | inrange ( ``ffind'' , 5180 , 5182 ) | inrange ( ``ffind'' , 5190 , 5199 ) qui replace `generate' = 42 if inrange ( ``ffind'' , 5200 , 5200 ) | inrange ( ``ffind'' , 5210 , 5219 ) | inrange ( ``ffind'' , 5220 , 5229 ) | inrange ( ``ffind'' , 5230 , 5231 ) | inrange ( ``ffind'' , 5250 , 5251 ) | inrange ( ``ffind'' , 5260 , 5261 ) | inrange ( ``ffind'' , 5270 , 5271 ) | inrange ( ``ffind'' , 5300 , 5300 ) | inrange ( ``ffind'' , 5310 , 5311 ) | inrange ( ``ffind'' , 5320 , 5320 ) | inrange ( ``ffind'' , 5330 , 5331 ) | inrange ( ``ffind'' , 5334 , 5334 ) | inrange ( ``ffind'' , 5340 , 5349 ) | inrange ( ``ffind'' , 5390 , 5399 ) | inrange ( ``ffind'' , 5400 , 5400 ) | inrange ( ``ffind'' , 5410 , 5411 ) | inrange ( ``ffind'' , 5412 , 5412 ) | inrange ( ``ffind'' , 5420 , 5429 ) | inrange ( ``ffind'' , 5430 , 5439 ) | inrange ( ``ffind'' , 5440 , 5449 ) | inrange ( ``ffind'' , 5450 , 5459 ) | inrange ( ``ffind'' , 5460 , 5469 ) | inrange ( ``ffind'' , 5490 , 5499 ) | inrange ( ``ffind'' , 5500 , 5500 ) | inrange ( ``ffind'' , 5510 , 5529 ) | inrange ( ``ffind'' , 5530 , 5539 ) | inrange ( ``ffind'' , 5540 , 5549 ) | inrange ( ``ffind'' , 5550 , 5559 ) | inrange ( ``ffind'' , 5560 , 5569 ) | inrange ( ``ffind'' , 5570 , 5579 ) | inrange ( ``ffind'' , 5590 , 5599 ) | inrange ( ``ffind'' , 5600 , 5699 ) | inrange ( ``ffind'' , 5700 , 5700 ) | inrange ( ``ffind'' , 5710 , 5719 ) | inrange ( ``ffind'' , 5720 , 5722 ) | inrange ( ``ffind'' , 5730 , 5733 ) | inrange ( ``ffind'' , 5734 , 5734 ) | inrange ( ``ffind'' , 5735 , 5735 ) | inrange ( ``ffind'' , 5736 , 5736 ) | inrange ( ``ffind'' , 5750 , 5799 ) | inrange ( ``ffind'' , 5900 , 5900 ) | inrange ( ``ffind'' , 5910 , 5912 ) | inrange ( ``ffind'' , 5920 , 5929 ) | inrange ( ``ffind'' , 5930 , 5932 ) | inrange ( ``ffind'' , 5940 , 5940 ) | inrange ( ``ffind'' , 5941 , 5941 ) | inrange ( ``ffind'' , 5942 , 5942 ) | inrange ( ``ffind'' , 5943 , 5943 ) | inrange ( ``ffind'' , 5944 , 5944 ) | inrange ( ``ffind'' , 5945 , 5945 ) | inrange ( ``ffind'' , 5946 , 5946 ) | inrange ( ``ffind'' , 5947 , 5947 ) | inrange ( ``ffind'' , 5948 , 5948 ) | inrange ( ``ffind'' , 5949 , 5949 ) | inrange ( ``ffind'' , 5950 , 5959 ) | inrange ( ``ffind'' , 5960 , 5969 ) | inrange ( ``ffind'' , 5970 , 5979 ) | inrange ( ``ffind'' , 5980 , 5989 ) | inrange ( ``ffind'' , 5990 , 5990 ) | inrange ( ``ffind'' , 5992 , 5992 ) | inrange ( ``ffind'' , 5993 , 5993 ) | inrange ( ``ffind'' , 5994 , 5994 ) | inrange ( ``ffind'' , 5995 , 5995 ) | inrange ( ``ffind'' , 5999 , 5999 ) qui replace `generate' = 43 if inrange ( ``ffind'' , 5800 , 5819 ) | inrange ( ``ffind'' , 5820 , 5829 ) | inrange ( ``ffind'' , 5890 , 5899 ) | inrange ( ``ffind'' , 7000 , 7000 ) | inrange ( ``ffind'' , 7010 , 7019 ) | inrange ( ``ffind'' , 7040 , 7049 ) | inrange ( ``ffind'' , 7213 , 7213 ) qui replace `generate' = 44 if inrange ( ``ffind'' , 6000 , 6000 ) | inrange ( ``ffind'' , 6010 , 6019 ) | inrange ( ``ffind'' , 6020 , 6020 ) | inrange ( ``ffind'' , 6021 , 6021 ) | inrange ( ``ffind'' , 6022 , 6022 ) | inrange ( ``ffind'' , 6023 , 6024 ) | inrange ( ``ffind'' , 6025 , 6025 ) | inrange ( ``ffind'' , 6026 , 6026 ) | inrange ( ``ffind'' , 6027 , 6027 ) | inrange ( ``ffind'' , 6028 , 6029 ) | inrange ( ``ffind'' , 6030 , 6036 ) | inrange ( ``ffind'' , 6040 , 6059 ) | inrange ( ``ffind'' , 6060 , 6062 ) | inrange ( ``ffind'' , 6080 , 6082 ) | inrange ( ``ffind'' , 6090 , 6099 ) | inrange ( ``ffind'' , 6100 , 6100 ) | inrange ( ``ffind'' , 6110 , 6111 ) | inrange ( ``ffind'' , 6112 , 6113 ) | inrange ( ``ffind'' , 6120 , 6129 ) | inrange ( ``ffind'' , 6130 , 6139 ) | inrange ( ``ffind'' , 6140 , 6149 ) | inrange ( ``ffind'' , 6150 , 6159 ) | inrange ( ``ffind'' , 6160 , 6169 ) | inrange ( ``ffind'' , 6170 , 6179 ) | inrange ( ``ffind'' , 6190 , 6199 ) qui replace `generate' = 45 if inrange ( ``ffind'' , 6300 , 6300 ) | inrange ( ``ffind'' , 6310 , 6319 ) | inrange ( ``ffind'' , 6320 , 6329 ) | inrange ( ``ffind'' , 6330 , 6331 ) | inrange ( ``ffind'' , 6350 , 6351 ) | inrange ( ``ffind'' , 6360 , 6361 ) | inrange ( ``ffind'' , 6370 , 6379 ) | inrange ( ``ffind'' , 6390 , 6399 ) | inrange ( ``ffind'' , 6400 , 6411 ) qui replace `generate' = 46 if inrange ( ``ffind'' , 6500 , 6500 ) | inrange ( ``ffind'' , 6510 , 6510 ) | inrange ( ``ffind'' , 6512 , 6512 ) | inrange ( ``ffind'' , 6513 , 6513 ) | inrange ( ``ffind'' , 6514 , 6514 ) | inrange ( ``ffind'' , 6515 , 6515 ) | inrange ( ``ffind'' , 6517 , 6519 ) | inrange ( ``ffind'' , 6520 , 6529 ) | inrange ( ``ffind'' , 6530 , 6531 ) | inrange ( ``ffind'' , 6532 , 6532 ) | inrange ( ``ffind'' , 6540 , 6541 ) | inrange ( ``ffind'' , 6550 , 6553 ) | inrange ( ``ffind'' , 6590 , 6599 ) | inrange ( ``ffind'' , 6610 , 6611 ) qui replace `generate' = 47 if inrange ( ``ffind'' , 6200 , 6299 ) | inrange ( ``ffind'' , 6700 , 6700 ) | inrange ( ``ffind'' , 6710 , 6719 ) | inrange ( ``ffind'' , 6720 , 6722 ) | inrange ( ``ffind'' , 6723 , 6723 ) | inrange ( ``ffind'' , 6724 , 6724 ) | inrange ( ``ffind'' , 6725 , 6725 ) | inrange ( ``ffind'' , 6726 , 6726 ) | inrange ( ``ffind'' , 6730 , 6733 ) | inrange ( ``ffind'' , 6740 , 6779 ) | inrange ( ``ffind'' , 6790 , 6791 ) | inrange ( ``ffind'' , 6792 , 6792 ) | inrange ( ``ffind'' , 6793 , 6793 ) | inrange ( ``ffind'' , 6794 , 6794 ) | inrange ( ``ffind'' , 6795 , 6795 ) | inrange ( ``ffind'' , 6798 , 6798 ) | inrange ( ``ffind'' , 6799 , 6799 ) qui replace `generate' = 48 if missing ( `generate' ) & ~ missing ( ``ffind'' ) } else if ``ftyp'' == 49 { label define `generate' 1 \"Agriculture\" 2 \"Food Products\" 3 \"Candy & Soda\" 4 \"Beer & Liquor\" 5 \"Tobacco Products\" 6 \"Recreation\" 7 \"Entertainment\" 8 \"Printing and Publishing\" 9 \"Consumer Goods\" 10 \"Apparel\" 11 \"Healthcare\" 12 \"Medical Equipment\" 13 \"Pharmaceutical Products\" 14 \"Chemicals\" 15 \"Rubber and Plastic Products\" 16 \"Textiles\" 17 \"Construction Materials\" 18 \"Construction\" 19 \"Steel Works Etc\" 20 \"Fabricated Products\" 21 \"Machinery\" 22 \"Electrical Equipment\" 23 \"Automobiles and Trucks\" 24 \"Aircraft\" 25 \"Shipbuilding, Railroad Equipment\" 26 \"Defense\" 27 \"Precious Metals\" 28 \"Non-Metallic and Industrial Metal Mining\" 29 \"Coal\" 30 \"Petroleum and Natural Gas\" 31 \"Utilities\" 32 \"Communication\" 33 \"Personal Services\" 34 \"Business Services\" 35 \"Computer Hardware\" 36 \"Computer Software\" 37 \"Electronic Equipment\" 38 \"Measuring and Control Equipment\" 39 \"Business Supplies\" 40 \"Shipping Containers\" 41 \"Transportation\" 42 \"Wholesale\" 43 \"Retail\" 44 \"Restaraunts, Hotels, Motels\" 45 \"Banking\" 46 \"Insurance\" 47 \"Real Estate\" 48 \"Trading\" 49 \"Almost Nothing\" label values `generate' `generate' qui replace `generate' = 1 if inrange ( ``ffind'' , 100 , 199 ) | inrange ( ``ffind'' , 200 , 299 ) | inrange ( ``ffind'' , 700 , 799 ) | inrange ( ``ffind'' , 910 , 919 ) | inrange ( ``ffind'' , 2048 , 2048 ) qui replace `generate' = 2 if inrange ( ``ffind'' , 2000 , 2009 ) | inrange ( ``ffind'' , 2010 , 2019 ) | inrange ( ``ffind'' , 2020 , 2029 ) | inrange ( ``ffind'' , 2030 , 2039 ) | inrange ( ``ffind'' , 2040 , 2046 ) | inrange ( ``ffind'' , 2050 , 2059 ) | inrange ( ``ffind'' , 2060 , 2063 ) | inrange ( ``ffind'' , 2070 , 2079 ) | inrange ( ``ffind'' , 2090 , 2092 ) | inrange ( ``ffind'' , 2095 , 2095 ) | inrange ( ``ffind'' , 2098 , 2099 ) qui replace `generate' = 3 if inrange ( ``ffind'' , 2064 , 2068 ) | inrange ( ``ffind'' , 2086 , 2086 ) | inrange ( ``ffind'' , 2087 , 2087 ) | inrange ( ``ffind'' , 2096 , 2096 ) | inrange ( ``ffind'' , 2097 , 2097 ) qui replace `generate' = 4 if inrange ( ``ffind'' , 2080 , 2080 ) | inrange ( ``ffind'' , 2082 , 2082 ) | inrange ( ``ffind'' , 2083 , 2083 ) | inrange ( ``ffind'' , 2084 , 2084 ) | inrange ( ``ffind'' , 2085 , 2085 ) qui replace `generate' = 5 if inrange ( ``ffind'' , 2100 , 2199 ) qui replace `generate' = 6 if inrange ( ``ffind'' , 920 , 999 ) | inrange ( ``ffind'' , 3650 , 3651 ) | inrange ( ``ffind'' , 3652 , 3652 ) | inrange ( ``ffind'' , 3732 , 3732 ) | inrange ( ``ffind'' , 3930 , 3931 ) | inrange ( ``ffind'' , 3940 , 3949 ) qui replace `generate' = 7 if inrange ( ``ffind'' , 7800 , 7829 ) | inrange ( ``ffind'' , 7830 , 7833 ) | inrange ( ``ffind'' , 7840 , 7841 ) | inrange ( ``ffind'' , 7900 , 7900 ) | inrange ( ``ffind'' , 7910 , 7911 ) | inrange ( ``ffind'' , 7920 , 7929 ) | inrange ( ``ffind'' , 7930 , 7933 ) | inrange ( ``ffind'' , 7940 , 7949 ) | inrange ( ``ffind'' , 7980 , 7980 ) | inrange ( ``ffind'' , 7990 , 7999 ) qui replace `generate' = 8 if inrange ( ``ffind'' , 2700 , 2709 ) | inrange ( ``ffind'' , 2710 , 2719 ) | inrange ( ``ffind'' , 2720 , 2729 ) | inrange ( ``ffind'' , 2730 , 2739 ) | inrange ( ``ffind'' , 2740 , 2749 ) | inrange ( ``ffind'' , 2770 , 2771 ) | inrange ( ``ffind'' , 2780 , 2789 ) | inrange ( ``ffind'' , 2790 , 2799 ) qui replace `generate' = 9 if inrange ( ``ffind'' , 2047 , 2047 ) | inrange ( ``ffind'' , 2391 , 2392 ) | inrange ( ``ffind'' , 2510 , 2519 ) | inrange ( ``ffind'' , 2590 , 2599 ) | inrange ( ``ffind'' , 2840 , 2843 ) | inrange ( ``ffind'' , 2844 , 2844 ) | inrange ( ``ffind'' , 3160 , 3161 ) | inrange ( ``ffind'' , 3170 , 3171 ) | inrange ( ``ffind'' , 3172 , 3172 ) | inrange ( ``ffind'' , 3190 , 3199 ) | inrange ( ``ffind'' , 3229 , 3229 ) | inrange ( ``ffind'' , 3260 , 3260 ) | inrange ( ``ffind'' , 3262 , 3263 ) | inrange ( ``ffind'' , 3269 , 3269 ) | inrange ( ``ffind'' , 3230 , 3231 ) | inrange ( ``ffind'' , 3630 , 3639 ) | inrange ( ``ffind'' , 3750 , 3751 ) | inrange ( ``ffind'' , 3800 , 3800 ) | inrange ( ``ffind'' , 3860 , 3861 ) | inrange ( ``ffind'' , 3870 , 3873 ) | inrange ( ``ffind'' , 3910 , 3911 ) | inrange ( ``ffind'' , 3914 , 3914 ) | inrange ( ``ffind'' , 3915 , 3915 ) | inrange ( ``ffind'' , 3960 , 3962 ) | inrange ( ``ffind'' , 3991 , 3991 ) | inrange ( ``ffind'' , 3995 , 3995 ) qui replace `generate' = 10 if inrange ( ``ffind'' , 2300 , 2390 ) | inrange ( ``ffind'' , 3020 , 3021 ) | inrange ( ``ffind'' , 3100 , 3111 ) | inrange ( ``ffind'' , 3130 , 3131 ) | inrange ( ``ffind'' , 3140 , 3149 ) | inrange ( ``ffind'' , 3150 , 3151 ) | inrange ( ``ffind'' , 3963 , 3965 ) qui replace `generate' = 11 if inrange ( ``ffind'' , 8000 , 8099 ) qui replace `generate' = 12 if inrange ( ``ffind'' , 3693 , 3693 ) | inrange ( ``ffind'' , 3840 , 3849 ) | inrange ( ``ffind'' , 3850 , 3851 ) qui replace `generate' = 13 if inrange ( ``ffind'' , 2830 , 2830 ) | inrange ( ``ffind'' , 2831 , 2831 ) | inrange ( ``ffind'' , 2833 , 2833 ) | inrange ( ``ffind'' , 2834 , 2834 ) | inrange ( ``ffind'' , 2835 , 2835 ) | inrange ( ``ffind'' , 2836 , 2836 ) qui replace `generate' = 14 if inrange ( ``ffind'' , 2800 , 2809 ) | inrange ( ``ffind'' , 2810 , 2819 ) | inrange ( ``ffind'' , 2820 , 2829 ) | inrange ( ``ffind'' , 2850 , 2859 ) | inrange ( ``ffind'' , 2860 , 2869 ) | inrange ( ``ffind'' , 2870 , 2879 ) | inrange ( ``ffind'' , 2890 , 2899 ) qui replace `generate' = 15 if inrange ( ``ffind'' , 3031 , 3031 ) | inrange ( ``ffind'' , 3041 , 3041 ) | inrange ( ``ffind'' , 3050 , 3053 ) | inrange ( ``ffind'' , 3060 , 3069 ) | inrange ( ``ffind'' , 3070 , 3079 ) | inrange ( ``ffind'' , 3080 , 3089 ) | inrange ( ``ffind'' , 3090 , 3099 ) qui replace `generate' = 16 if inrange ( ``ffind'' , 2200 , 2269 ) | inrange ( ``ffind'' , 2270 , 2279 ) | inrange ( ``ffind'' , 2280 , 2284 ) | inrange ( ``ffind'' , 2290 , 2295 ) | inrange ( ``ffind'' , 2297 , 2297 ) | inrange ( ``ffind'' , 2298 , 2298 ) | inrange ( ``ffind'' , 2299 , 2299 ) | inrange ( ``ffind'' , 2393 , 2395 ) | inrange ( ``ffind'' , 2397 , 2399 ) qui replace `generate' = 17 if inrange ( ``ffind'' , 800 , 899 ) | inrange ( ``ffind'' , 2400 , 2439 ) | inrange ( ``ffind'' , 2450 , 2459 ) | inrange ( ``ffind'' , 2490 , 2499 ) | inrange ( ``ffind'' , 2660 , 2661 ) | inrange ( ``ffind'' , 2950 , 2952 ) | inrange ( ``ffind'' , 3200 , 3200 ) | inrange ( ``ffind'' , 3210 , 3211 ) | inrange ( ``ffind'' , 3240 , 3241 ) | inrange ( ``ffind'' , 3250 , 3259 ) | inrange ( ``ffind'' , 3261 , 3261 ) | inrange ( ``ffind'' , 3264 , 3264 ) | inrange ( ``ffind'' , 3270 , 3275 ) | inrange ( ``ffind'' , 3280 , 3281 ) | inrange ( ``ffind'' , 3290 , 3293 ) | inrange ( ``ffind'' , 3295 , 3299 ) | inrange ( ``ffind'' , 3420 , 3429 ) | inrange ( ``ffind'' , 3430 , 3433 ) | inrange ( ``ffind'' , 3440 , 3441 ) | inrange ( ``ffind'' , 3442 , 3442 ) | inrange ( ``ffind'' , 3446 , 3446 ) | inrange ( ``ffind'' , 3448 , 3448 ) | inrange ( ``ffind'' , 3449 , 3449 ) | inrange ( ``ffind'' , 3450 , 3451 ) | inrange ( ``ffind'' , 3452 , 3452 ) | inrange ( ``ffind'' , 3490 , 3499 ) | inrange ( ``ffind'' , 3996 , 3996 ) qui replace `generate' = 18 if inrange ( ``ffind'' , 1500 , 1511 ) | inrange ( ``ffind'' , 1520 , 1529 ) | inrange ( ``ffind'' , 1530 , 1539 ) | inrange ( ``ffind'' , 1540 , 1549 ) | inrange ( ``ffind'' , 1600 , 1699 ) | inrange ( ``ffind'' , 1700 , 1799 ) qui replace `generate' = 19 if inrange ( ``ffind'' , 3300 , 3300 ) | inrange ( ``ffind'' , 3310 , 3317 ) | inrange ( ``ffind'' , 3320 , 3325 ) | inrange ( ``ffind'' , 3330 , 3339 ) | inrange ( ``ffind'' , 3340 , 3341 ) | inrange ( ``ffind'' , 3350 , 3357 ) | inrange ( ``ffind'' , 3360 , 3369 ) | inrange ( ``ffind'' , 3370 , 3379 ) | inrange ( ``ffind'' , 3390 , 3399 ) qui replace `generate' = 20 if inrange ( ``ffind'' , 3400 , 3400 ) | inrange ( ``ffind'' , 3443 , 3443 ) | inrange ( ``ffind'' , 3444 , 3444 ) | inrange ( ``ffind'' , 3460 , 3469 ) | inrange ( ``ffind'' , 3470 , 3479 ) qui replace `generate' = 21 if inrange ( ``ffind'' , 3510 , 3519 ) | inrange ( ``ffind'' , 3520 , 3529 ) | inrange ( ``ffind'' , 3530 , 3530 ) | inrange ( ``ffind'' , 3531 , 3531 ) | inrange ( ``ffind'' , 3532 , 3532 ) | inrange ( ``ffind'' , 3533 , 3533 ) | inrange ( ``ffind'' , 3534 , 3534 ) | inrange ( ``ffind'' , 3535 , 3535 ) | inrange ( ``ffind'' , 3536 , 3536 ) | inrange ( ``ffind'' , 3538 , 3538 ) | inrange ( ``ffind'' , 3540 , 3549 ) | inrange ( ``ffind'' , 3550 , 3559 ) | inrange ( ``ffind'' , 3560 , 3569 ) | inrange ( ``ffind'' , 3580 , 3580 ) | inrange ( ``ffind'' , 3581 , 3581 ) | inrange ( ``ffind'' , 3582 , 3582 ) | inrange ( ``ffind'' , 3585 , 3585 ) | inrange ( ``ffind'' , 3586 , 3586 ) | inrange ( ``ffind'' , 3589 , 3589 ) | inrange ( ``ffind'' , 3590 , 3599 ) qui replace `generate' = 22 if inrange ( ``ffind'' , 3600 , 3600 ) | inrange ( ``ffind'' , 3610 , 3613 ) | inrange ( ``ffind'' , 3620 , 3621 ) | inrange ( ``ffind'' , 3623 , 3629 ) | inrange ( ``ffind'' , 3640 , 3644 ) | inrange ( ``ffind'' , 3645 , 3645 ) | inrange ( ``ffind'' , 3646 , 3646 ) | inrange ( ``ffind'' , 3648 , 3649 ) | inrange ( ``ffind'' , 3660 , 3660 ) | inrange ( ``ffind'' , 3690 , 3690 ) | inrange ( ``ffind'' , 3691 , 3692 ) | inrange ( ``ffind'' , 3699 , 3699 ) qui replace `generate' = 23 if inrange ( ``ffind'' , 2296 , 2296 ) | inrange ( ``ffind'' , 2396 , 2396 ) | inrange ( ``ffind'' , 3010 , 3011 ) | inrange ( ``ffind'' , 3537 , 3537 ) | inrange ( ``ffind'' , 3647 , 3647 ) | inrange ( ``ffind'' , 3694 , 3694 ) | inrange ( ``ffind'' , 3700 , 3700 ) | inrange ( ``ffind'' , 3710 , 3710 ) | inrange ( ``ffind'' , 3711 , 3711 ) | inrange ( ``ffind'' , 3713 , 3713 ) | inrange ( ``ffind'' , 3714 , 3714 ) | inrange ( ``ffind'' , 3715 , 3715 ) | inrange ( ``ffind'' , 3716 , 3716 ) | inrange ( ``ffind'' , 3792 , 3792 ) | inrange ( ``ffind'' , 3790 , 3791 ) | inrange ( ``ffind'' , 3799 , 3799 ) qui replace `generate' = 24 if inrange ( ``ffind'' , 3720 , 3720 ) | inrange ( ``ffind'' , 3721 , 3721 ) | inrange ( ``ffind'' , 3723 , 3724 ) | inrange ( ``ffind'' , 3725 , 3725 ) | inrange ( ``ffind'' , 3728 , 3729 ) qui replace `generate' = 25 if inrange ( ``ffind'' , 3730 , 3731 ) | inrange ( ``ffind'' , 3740 , 3743 ) qui replace `generate' = 26 if inrange ( ``ffind'' , 3760 , 3769 ) | inrange ( ``ffind'' , 3795 , 3795 ) | inrange ( ``ffind'' , 3480 , 3489 ) qui replace `generate' = 27 if inrange ( ``ffind'' , 1040 , 1049 ) qui replace `generate' = 28 if inrange ( ``ffind'' , 1000 , 1009 ) | inrange ( ``ffind'' , 1010 , 1019 ) | inrange ( ``ffind'' , 1020 , 1029 ) | inrange ( ``ffind'' , 1030 , 1039 ) | inrange ( ``ffind'' , 1050 , 1059 ) | inrange ( ``ffind'' , 1060 , 1069 ) | inrange ( ``ffind'' , 1070 , 1079 ) | inrange ( ``ffind'' , 1080 , 1089 ) | inrange ( ``ffind'' , 1090 , 1099 ) | inrange ( ``ffind'' , 1100 , 1119 ) | inrange ( ``ffind'' , 1400 , 1499 ) qui replace `generate' = 29 if inrange ( ``ffind'' , 1200 , 1299 ) qui replace `generate' = 30 if inrange ( ``ffind'' , 1300 , 1300 ) | inrange ( ``ffind'' , 1310 , 1319 ) | inrange ( ``ffind'' , 1320 , 1329 ) | inrange ( ``ffind'' , 1330 , 1339 ) | inrange ( ``ffind'' , 1370 , 1379 ) | inrange ( ``ffind'' , 1380 , 1380 ) | inrange ( ``ffind'' , 1381 , 1381 ) | inrange ( ``ffind'' , 1382 , 1382 ) | inrange ( ``ffind'' , 1389 , 1389 ) | inrange ( ``ffind'' , 2900 , 2912 ) | inrange ( ``ffind'' , 2990 , 2999 ) qui replace `generate' = 31 if inrange ( ``ffind'' , 4900 , 4900 ) | inrange ( ``ffind'' , 4910 , 4911 ) | inrange ( ``ffind'' , 4920 , 4922 ) | inrange ( ``ffind'' , 4923 , 4923 ) | inrange ( ``ffind'' , 4924 , 4925 ) | inrange ( ``ffind'' , 4930 , 4931 ) | inrange ( ``ffind'' , 4932 , 4932 ) | inrange ( ``ffind'' , 4939 , 4939 ) | inrange ( ``ffind'' , 4940 , 4942 ) qui replace `generate' = 32 if inrange ( ``ffind'' , 4800 , 4800 ) | inrange ( ``ffind'' , 4810 , 4813 ) | inrange ( ``ffind'' , 4820 , 4822 ) | inrange ( ``ffind'' , 4830 , 4839 ) | inrange ( ``ffind'' , 4840 , 4841 ) | inrange ( ``ffind'' , 4880 , 4889 ) | inrange ( ``ffind'' , 4890 , 4890 ) | inrange ( ``ffind'' , 4891 , 4891 ) | inrange ( ``ffind'' , 4892 , 4892 ) | inrange ( ``ffind'' , 4899 , 4899 ) qui replace `generate' = 33 if inrange ( ``ffind'' , 7020 , 7021 ) | inrange ( ``ffind'' , 7030 , 7033 ) | inrange ( ``ffind'' , 7200 , 7200 ) | inrange ( ``ffind'' , 7210 , 7212 ) | inrange ( ``ffind'' , 7214 , 7214 ) | inrange ( ``ffind'' , 7215 , 7216 ) | inrange ( ``ffind'' , 7217 , 7217 ) | inrange ( ``ffind'' , 7219 , 7219 ) | inrange ( ``ffind'' , 7220 , 7221 ) | inrange ( ``ffind'' , 7230 , 7231 ) | inrange ( ``ffind'' , 7240 , 7241 ) | inrange ( ``ffind'' , 7250 , 7251 ) | inrange ( ``ffind'' , 7260 , 7269 ) | inrange ( ``ffind'' , 7270 , 7290 ) | inrange ( ``ffind'' , 7291 , 7291 ) | inrange ( ``ffind'' , 7292 , 7299 ) | inrange ( ``ffind'' , 7395 , 7395 ) | inrange ( ``ffind'' , 7500 , 7500 ) | inrange ( ``ffind'' , 7520 , 7529 ) | inrange ( ``ffind'' , 7530 , 7539 ) | inrange ( ``ffind'' , 7540 , 7549 ) | inrange ( ``ffind'' , 7600 , 7600 ) | inrange ( ``ffind'' , 7620 , 7620 ) | inrange ( ``ffind'' , 7622 , 7622 ) | inrange ( ``ffind'' , 7623 , 7623 ) | inrange ( ``ffind'' , 7629 , 7629 ) | inrange ( ``ffind'' , 7630 , 7631 ) | inrange ( ``ffind'' , 7640 , 7641 ) | inrange ( ``ffind'' , 7690 , 7699 ) | inrange ( ``ffind'' , 8100 , 8199 ) | inrange ( ``ffind'' , 8200 , 8299 ) | inrange ( ``ffind'' , 8300 , 8399 ) | inrange ( ``ffind'' , 8400 , 8499 ) | inrange ( ``ffind'' , 8600 , 8699 ) | inrange ( ``ffind'' , 8800 , 8899 ) | inrange ( ``ffind'' , 7510 , 7515 ) qui replace `generate' = 34 if inrange ( ``ffind'' , 2750 , 2759 ) | inrange ( ``ffind'' , 3993 , 3993 ) | inrange ( ``ffind'' , 7218 , 7218 ) | inrange ( ``ffind'' , 7300 , 7300 ) | inrange ( ``ffind'' , 7310 , 7319 ) | inrange ( ``ffind'' , 7320 , 7329 ) | inrange ( ``ffind'' , 7330 , 7339 ) | inrange ( ``ffind'' , 7340 , 7342 ) | inrange ( ``ffind'' , 7349 , 7349 ) | inrange ( ``ffind'' , 7350 , 7351 ) | inrange ( ``ffind'' , 7352 , 7352 ) | inrange ( ``ffind'' , 7353 , 7353 ) | inrange ( ``ffind'' , 7359 , 7359 ) | inrange ( ``ffind'' , 7360 , 7369 ) | inrange ( ``ffind'' , 7374 , 7374 ) | inrange ( ``ffind'' , 7376 , 7376 ) | inrange ( ``ffind'' , 7377 , 7377 ) | inrange ( ``ffind'' , 7378 , 7378 ) | inrange ( ``ffind'' , 7379 , 7379 ) | inrange ( ``ffind'' , 7380 , 7380 ) | inrange ( ``ffind'' , 7381 , 7382 ) | inrange ( ``ffind'' , 7383 , 7383 ) | inrange ( ``ffind'' , 7384 , 7384 ) | inrange ( ``ffind'' , 7385 , 7385 ) | inrange ( ``ffind'' , 7389 , 7390 ) | inrange ( ``ffind'' , 7391 , 7391 ) | inrange ( ``ffind'' , 7392 , 7392 ) | inrange ( ``ffind'' , 7393 , 7393 ) | inrange ( ``ffind'' , 7394 , 7394 ) | inrange ( ``ffind'' , 7396 , 7396 ) | inrange ( ``ffind'' , 7397 , 7397 ) | inrange ( ``ffind'' , 7399 , 7399 ) | inrange ( ``ffind'' , 7519 , 7519 ) | inrange ( ``ffind'' , 8700 , 8700 ) | inrange ( ``ffind'' , 8710 , 8713 ) | inrange ( ``ffind'' , 8720 , 8721 ) | inrange ( ``ffind'' , 8730 , 8734 ) | inrange ( ``ffind'' , 8740 , 8748 ) | inrange ( ``ffind'' , 8900 , 8910 ) | inrange ( ``ffind'' , 8911 , 8911 ) | inrange ( ``ffind'' , 8920 , 8999 ) | inrange ( ``ffind'' , 4220 , 4229 ) qui replace `generate' = 35 if inrange ( ``ffind'' , 3570 , 3579 ) | inrange ( ``ffind'' , 3680 , 3680 ) | inrange ( ``ffind'' , 3681 , 3681 ) | inrange ( ``ffind'' , 3682 , 3682 ) | inrange ( ``ffind'' , 3683 , 3683 ) | inrange ( ``ffind'' , 3684 , 3684 ) | inrange ( ``ffind'' , 3685 , 3685 ) | inrange ( ``ffind'' , 3686 , 3686 ) | inrange ( ``ffind'' , 3687 , 3687 ) | inrange ( ``ffind'' , 3688 , 3688 ) | inrange ( ``ffind'' , 3689 , 3689 ) | inrange ( ``ffind'' , 3695 , 3695 ) qui replace `generate' = 36 if inrange ( ``ffind'' , 7370 , 7372 ) | inrange ( ``ffind'' , 7375 , 7375 ) | inrange ( ``ffind'' , 7373 , 7373 ) qui replace `generate' = 37 if inrange ( ``ffind'' , 3622 , 3622 ) | inrange ( ``ffind'' , 3661 , 3661 ) | inrange ( ``ffind'' , 3662 , 3662 ) | inrange ( ``ffind'' , 3663 , 3663 ) | inrange ( ``ffind'' , 3664 , 3664 ) | inrange ( ``ffind'' , 3665 , 3665 ) | inrange ( ``ffind'' , 3666 , 3666 ) | inrange ( ``ffind'' , 3669 , 3669 ) | inrange ( ``ffind'' , 3670 , 3679 ) | inrange ( ``ffind'' , 3810 , 3810 ) | inrange ( ``ffind'' , 3812 , 3812 ) qui replace `generate' = 38 if inrange ( ``ffind'' , 3811 , 3811 ) | inrange ( ``ffind'' , 3820 , 3820 ) | inrange ( ``ffind'' , 3821 , 3821 ) | inrange ( ``ffind'' , 3822 , 3822 ) | inrange ( ``ffind'' , 3823 , 3823 ) | inrange ( ``ffind'' , 3824 , 3824 ) | inrange ( ``ffind'' , 3825 , 3825 ) | inrange ( ``ffind'' , 3826 , 3826 ) | inrange ( ``ffind'' , 3827 , 3827 ) | inrange ( ``ffind'' , 3829 , 3829 ) | inrange ( ``ffind'' , 3830 , 3839 ) qui replace `generate' = 39 if inrange ( ``ffind'' , 2520 , 2549 ) | inrange ( ``ffind'' , 2600 , 2639 ) | inrange ( ``ffind'' , 2670 , 2699 ) | inrange ( ``ffind'' , 2760 , 2761 ) | inrange ( ``ffind'' , 3950 , 3955 ) qui replace `generate' = 40 if inrange ( ``ffind'' , 2440 , 2449 ) | inrange ( ``ffind'' , 2640 , 2659 ) | inrange ( ``ffind'' , 3220 , 3221 ) | inrange ( ``ffind'' , 3410 , 3412 ) qui replace `generate' = 41 if inrange ( ``ffind'' , 4000 , 4013 ) | inrange ( ``ffind'' , 4040 , 4049 ) | inrange ( ``ffind'' , 4100 , 4100 ) | inrange ( ``ffind'' , 4110 , 4119 ) | inrange ( ``ffind'' , 4120 , 4121 ) | inrange ( ``ffind'' , 4130 , 4131 ) | inrange ( ``ffind'' , 4140 , 4142 ) | inrange ( ``ffind'' , 4150 , 4151 ) | inrange ( ``ffind'' , 4170 , 4173 ) | inrange ( ``ffind'' , 4190 , 4199 ) | inrange ( ``ffind'' , 4200 , 4200 ) | inrange ( ``ffind'' , 4210 , 4219 ) | inrange ( ``ffind'' , 4230 , 4231 ) | inrange ( ``ffind'' , 4240 , 4249 ) | inrange ( ``ffind'' , 4400 , 4499 ) | inrange ( ``ffind'' , 4500 , 4599 ) | inrange ( ``ffind'' , 4600 , 4699 ) | inrange ( ``ffind'' , 4700 , 4700 ) | inrange ( ``ffind'' , 4710 , 4712 ) | inrange ( ``ffind'' , 4720 , 4729 ) | inrange ( ``ffind'' , 4730 , 4739 ) | inrange ( ``ffind'' , 4740 , 4749 ) | inrange ( ``ffind'' , 4780 , 4780 ) | inrange ( ``ffind'' , 4782 , 4782 ) | inrange ( ``ffind'' , 4783 , 4783 ) | inrange ( ``ffind'' , 4784 , 4784 ) | inrange ( ``ffind'' , 4785 , 4785 ) | inrange ( ``ffind'' , 4789 , 4789 ) qui replace `generate' = 42 if inrange ( ``ffind'' , 5000 , 5000 ) | inrange ( ``ffind'' , 5010 , 5015 ) | inrange ( ``ffind'' , 5020 , 5023 ) | inrange ( ``ffind'' , 5030 , 5039 ) | inrange ( ``ffind'' , 5040 , 5042 ) | inrange ( ``ffind'' , 5043 , 5043 ) | inrange ( ``ffind'' , 5044 , 5044 ) | inrange ( ``ffind'' , 5045 , 5045 ) | inrange ( ``ffind'' , 5046 , 5046 ) | inrange ( ``ffind'' , 5047 , 5047 ) | inrange ( ``ffind'' , 5048 , 5048 ) | inrange ( ``ffind'' , 5049 , 5049 ) | inrange ( ``ffind'' , 5050 , 5059 ) | inrange ( ``ffind'' , 5060 , 5060 ) | inrange ( ``ffind'' , 5063 , 5063 ) | inrange ( ``ffind'' , 5064 , 5064 ) | inrange ( ``ffind'' , 5065 , 5065 ) | inrange ( ``ffind'' , 5070 , 5078 ) | inrange ( ``ffind'' , 5080 , 5080 ) | inrange ( ``ffind'' , 5081 , 5081 ) | inrange ( ``ffind'' , 5082 , 5082 ) | inrange ( ``ffind'' , 5083 , 5083 ) | inrange ( ``ffind'' , 5084 , 5084 ) | inrange ( ``ffind'' , 5085 , 5085 ) | inrange ( ``ffind'' , 5086 , 5087 ) | inrange ( ``ffind'' , 5088 , 5088 ) | inrange ( ``ffind'' , 5090 , 5090 ) | inrange ( ``ffind'' , 5091 , 5092 ) | inrange ( ``ffind'' , 5093 , 5093 ) | inrange ( ``ffind'' , 5094 , 5094 ) | inrange ( ``ffind'' , 5099 , 5099 ) | inrange ( ``ffind'' , 5100 , 5100 ) | inrange ( ``ffind'' , 5110 , 5113 ) | inrange ( ``ffind'' , 5120 , 5122 ) | inrange ( ``ffind'' , 5130 , 5139 ) | inrange ( ``ffind'' , 5140 , 5149 ) | inrange ( ``ffind'' , 5150 , 5159 ) | inrange ( ``ffind'' , 5160 , 5169 ) | inrange ( ``ffind'' , 5170 , 5172 ) | inrange ( ``ffind'' , 5180 , 5182 ) | inrange ( ``ffind'' , 5190 , 5199 ) qui replace `generate' = 43 if inrange ( ``ffind'' , 5200 , 5200 ) | inrange ( ``ffind'' , 5210 , 5219 ) | inrange ( ``ffind'' , 5220 , 5229 ) | inrange ( ``ffind'' , 5230 , 5231 ) | inrange ( ``ffind'' , 5250 , 5251 ) | inrange ( ``ffind'' , 5260 , 5261 ) | inrange ( ``ffind'' , 5270 , 5271 ) | inrange ( ``ffind'' , 5300 , 5300 ) | inrange ( ``ffind'' , 5310 , 5311 ) | inrange ( ``ffind'' , 5320 , 5320 ) | inrange ( ``ffind'' , 5330 , 5331 ) | inrange ( ``ffind'' , 5334 , 5334 ) | inrange ( ``ffind'' , 5340 , 5349 ) | inrange ( ``ffind'' , 5390 , 5399 ) | inrange ( ``ffind'' , 5400 , 5400 ) | inrange ( ``ffind'' , 5410 , 5411 ) | inrange ( ``ffind'' , 5412 , 5412 ) | inrange ( ``ffind'' , 5420 , 5429 ) | inrange ( ``ffind'' , 5430 , 5439 ) | inrange ( ``ffind'' , 5440 , 5449 ) | inrange ( ``ffind'' , 5450 , 5459 ) | inrange ( ``ffind'' , 5460 , 5469 ) | inrange ( ``ffind'' , 5490 , 5499 ) | inrange ( ``ffind'' , 5500 , 5500 ) | inrange ( ``ffind'' , 5510 , 5529 ) | inrange ( ``ffind'' , 5530 , 5539 ) | inrange ( ``ffind'' , 5540 , 5549 ) | inrange ( ``ffind'' , 5550 , 5559 ) | inrange ( ``ffind'' , 5560 , 5569 ) | inrange ( ``ffind'' , 5570 , 5579 ) | inrange ( ``ffind'' , 5590 , 5599 ) | inrange ( ``ffind'' , 5600 , 5699 ) | inrange ( ``ffind'' , 5700 , 5700 ) | inrange ( ``ffind'' , 5710 , 5719 ) | inrange ( ``ffind'' , 5720 , 5722 ) | inrange ( ``ffind'' , 5730 , 5733 ) | inrange ( ``ffind'' , 5734 , 5734 ) | inrange ( ``ffind'' , 5735 , 5735 ) | inrange ( ``ffind'' , 5736 , 5736 ) | inrange ( ``ffind'' , 5750 , 5799 ) | inrange ( ``ffind'' , 5900 , 5900 ) | inrange ( ``ffind'' , 5910 , 5912 ) | inrange ( ``ffind'' , 5920 , 5929 ) | inrange ( ``ffind'' , 5930 , 5932 ) | inrange ( ``ffind'' , 5940 , 5940 ) | inrange ( ``ffind'' , 5941 , 5941 ) | inrange ( ``ffind'' , 5942 , 5942 ) | inrange ( ``ffind'' , 5943 , 5943 ) | inrange ( ``ffind'' , 5944 , 5944 ) | inrange ( ``ffind'' , 5945 , 5945 ) | inrange ( ``ffind'' , 5946 , 5946 ) | inrange ( ``ffind'' , 5947 , 5947 ) | inrange ( ``ffind'' , 5948 , 5948 ) | inrange ( ``ffind'' , 5949 , 5949 ) | inrange ( ``ffind'' , 5950 , 5959 ) | inrange ( ``ffind'' , 5960 , 5969 ) | inrange ( ``ffind'' , 5970 , 5979 ) | inrange ( ``ffind'' , 5980 , 5989 ) | inrange ( ``ffind'' , 5990 , 5990 ) | inrange ( ``ffind'' , 5992 , 5992 ) | inrange ( ``ffind'' , 5993 , 5993 ) | inrange ( ``ffind'' , 5994 , 5994 ) | inrange ( ``ffind'' , 5995 , 5995 ) | inrange ( ``ffind'' , 5999 , 5999 ) qui replace `generate' = 44 if inrange ( ``ffind'' , 5800 , 5819 ) | inrange ( ``ffind'' , 5820 , 5829 ) | inrange ( ``ffind'' , 5890 , 5899 ) | inrange ( ``ffind'' , 7000 , 7000 ) | inrange ( ``ffind'' , 7010 , 7019 ) | inrange ( ``ffind'' , 7040 , 7049 ) | inrange ( ``ffind'' , 7213 , 7213 ) qui replace `generate' = 45 if inrange ( ``ffind'' , 6000 , 6000 ) | inrange ( ``ffind'' , 6010 , 6019 ) | inrange ( ``ffind'' , 6020 , 6020 ) | inrange ( ``ffind'' , 6021 , 6021 ) | inrange ( ``ffind'' , 6022 , 6022 ) | inrange ( ``ffind'' , 6023 , 6024 ) | inrange ( ``ffind'' , 6025 , 6025 ) | inrange ( ``ffind'' , 6026 , 6026 ) | inrange ( ``ffind'' , 6027 , 6027 ) | inrange ( ``ffind'' , 6028 , 6029 ) | inrange ( ``ffind'' , 6030 , 6036 ) | inrange ( ``ffind'' , 6040 , 6059 ) | inrange ( ``ffind'' , 6060 , 6062 ) | inrange ( ``ffind'' , 6080 , 6082 ) | inrange ( ``ffind'' , 6090 , 6099 ) | inrange ( ``ffind'' , 6100 , 6100 ) | inrange ( ``ffind'' , 6110 , 6111 ) | inrange ( ``ffind'' , 6112 , 6113 ) | inrange ( ``ffind'' , 6120 , 6129 ) | inrange ( ``ffind'' , 6130 , 6139 ) | inrange ( ``ffind'' , 6140 , 6149 ) | inrange ( ``ffind'' , 6150 , 6159 ) | inrange ( ``ffind'' , 6160 , 6169 ) | inrange ( ``ffind'' , 6170 , 6179 ) | inrange ( ``ffind'' , 6190 , 6199 ) qui replace `generate' = 46 if inrange ( ``ffind'' , 6300 , 6300 ) | inrange ( ``ffind'' , 6310 , 6319 ) | inrange ( ``ffind'' , 6320 , 6329 ) | inrange ( ``ffind'' , 6330 , 6331 ) | inrange ( ``ffind'' , 6350 , 6351 ) | inrange ( ``ffind'' , 6360 , 6361 ) | inrange ( ``ffind'' , 6370 , 6379 ) | inrange ( ``ffind'' , 6390 , 6399 ) | inrange ( ``ffind'' , 6400 , 6411 ) qui replace `generate' = 47 if inrange ( ``ffind'' , 6500 , 6500 ) | inrange ( ``ffind'' , 6510 , 6510 ) | inrange ( ``ffind'' , 6512 , 6512 ) | inrange ( ``ffind'' , 6513 , 6513 ) | inrange ( ``ffind'' , 6514 , 6514 ) | inrange ( ``ffind'' , 6515 , 6515 ) | inrange ( ``ffind'' , 6517 , 6519 ) | inrange ( ``ffind'' , 6520 , 6529 ) | inrange ( ``ffind'' , 6530 , 6531 ) | inrange ( ``ffind'' , 6532 , 6532 ) | inrange ( ``ffind'' , 6540 , 6541 ) | inrange ( ``ffind'' , 6550 , 6553 ) | inrange ( ``ffind'' , 6590 , 6599 ) | inrange ( ``ffind'' , 6610 , 6611 ) qui replace `generate' = 48 if inrange ( ``ffind'' , 6200 , 6299 ) | inrange ( ``ffind'' , 6700 , 6700 ) | inrange ( ``ffind'' , 6710 , 6719 ) | inrange ( ``ffind'' , 6720 , 6722 ) | inrange ( ``ffind'' , 6723 , 6723 ) | inrange ( ``ffind'' , 6724 , 6724 ) | inrange ( ``ffind'' , 6725 , 6725 ) | inrange ( ``ffind'' , 6726 , 6726 ) | inrange ( ``ffind'' , 6730 , 6733 ) | inrange ( ``ffind'' , 6740 , 6779 ) | inrange ( ``ffind'' , 6790 , 6791 ) | inrange ( ``ffind'' , 6792 , 6792 ) | inrange ( ``ffind'' , 6793 , 6793 ) | inrange ( ``ffind'' , 6794 , 6794 ) | inrange ( ``ffind'' , 6795 , 6795 ) | inrange ( ``ffind'' , 6798 , 6798 ) | inrange ( ``ffind'' , 6799 , 6799 ) qui replace `generate' = 49 if missing ( `generate' ) & ~ missing ( ``ffind'' ) } else { di as error \"Type must be 5, 10, 12, 17, 30, 38, 48 or 49\" exit 111 } end","title":"Generate Fama-French industry classification from SIC"},{"location":"posts/generate-fama-french-industry-classification-from-sic/#generate-fama-french-industry-classification-from-sic","text":"This STATA program creates the Fama-French industry classification from SIC code.","title":"Generate Fama-French Industry Classification From SIC"},{"location":"posts/generate-fama-french-industry-classification-from-sic/#basic-usage","text":"1 ffind sic, generate (\u201cFF48\u201d) type ( 48 ) where sic is SIC code, FF48 is the generated industry variable name, and we are using 48-industry classification. Alternatively, one can choose 5, 10, 12, 17, 30, 38 or 49 industries.","title":"Basic usage"},{"location":"posts/generate-fama-french-industry-classification-from-sic/#full-stata-code","text":"ffind.ado 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 /**************************************** * ffind.ado * Creates variable containing Fama-French * industry classification. * * Author: Judson Caskey, UCLA * December 9, 2007 * * Revised by Malcolm Wardlaw, Uiversity of Texas at Dallas (November 1, 2011) ****************************************/ capture program drop ffind program define ffind version 9.2 syntax varlist (min= 1 max= 1 numeric) [if] [in], Generate(string) Type(numlist max= 1 min= 1 ) tempvar ftyp tokenize \" `type' \" local `ftyp' = `1' * Check if generate is valid variable name capture confirm new variable `generate' if _rc != 0 { di as error \"Variable `generate' is invalid\" exit 111 } * Check type if ~ inlist ( ``ftyp'' , 5 , 10 , 12 , 17 , 30 , 38 , 48 , 49 ) { di as error \"Type must be 5, 10, 12, 17, 30, 38, 48 or 49\" exit 111 } * Set industries tempvar ffind tokenize \" `varlist' \" local `ffind' \" `1' \" qui gen `generate' =. label variable `generate' \"Fama-French industry code ( ``ftyp'' industries)\" capture label drop `generate' if ``ftyp'' == 5 { label define `generate' 1 \"Consumer Durables, NonDurables, Wholesale, Retail, and Some Services (Laundries, Repair Shops)\" 2 \"Manufacturing, Energy, and Utilities\" 3 \"Business Equipment, Telephone and Television Transmission\" 4 \"Healthcare, Medical Equipment, and Drugs\" 5 \"Other -- Mines, Constr, BldMt, Trans, Hotels, Bus Serv, Entertainment, Finance\" label values `generate' `generate' qui replace `generate' = 1 if inrange ( ``ffind'' , 100 , 999 ) | inrange ( ``ffind'' , 2000 , 2399 ) | inrange ( ``ffind'' , 2700 , 2749 ) | inrange ( ``ffind'' , 2770 , 2799 ) | inrange ( ``ffind'' , 3100 , 3199 ) | inrange ( ``ffind'' , 3940 , 3989 ) | inrange ( ``ffind'' , 2500 , 2519 ) | inrange ( ``ffind'' , 2590 , 2599 ) | inrange ( ``ffind'' , 3630 , 3659 ) | inrange ( ``ffind'' , 3710 , 3711 ) | inrange ( ``ffind'' , 3714 , 3714 ) | inrange ( ``ffind'' , 3716 , 3716 ) | inrange ( ``ffind'' , 3750 , 3751 ) | inrange ( ``ffind'' , 3792 , 3792 ) | inrange ( ``ffind'' , 3900 , 3939 ) | inrange ( ``ffind'' , 3990 , 3999 ) | inrange ( ``ffind'' , 5000 , 5999 ) | inrange ( ``ffind'' , 7200 , 7299 ) | inrange ( ``ffind'' , 7600 , 7699 ) qui replace `generate' = 2 if inrange ( ``ffind'' , 2520 , 2589 ) | inrange ( ``ffind'' , 2600 , 2699 ) | inrange ( ``ffind'' , 2750 , 2769 ) | inrange ( ``ffind'' , 2800 , 2829 ) | inrange ( ``ffind'' , 2840 , 2899 ) | inrange ( ``ffind'' , 3000 , 3099 ) | inrange ( ``ffind'' , 3200 , 3569 ) | inrange ( ``ffind'' , 3580 , 3629 ) | inrange ( ``ffind'' , 3700 , 3709 ) | inrange ( ``ffind'' , 3712 , 3713 ) | inrange ( ``ffind'' , 3715 , 3715 ) | inrange ( ``ffind'' , 3717 , 3749 ) | inrange ( ``ffind'' , 3752 , 3791 ) | inrange ( ``ffind'' , 3793 , 3799 ) | inrange ( ``ffind'' , 3830 , 3839 ) | inrange ( ``ffind'' , 3860 , 3899 ) | inrange ( ``ffind'' , 1200 , 1399 ) | inrange ( ``ffind'' , 2900 , 2999 ) | inrange ( ``ffind'' , 4900 , 4949 ) qui replace `generate' = 3 if inrange ( ``ffind'' , 3570 , 3579 ) | inrange ( ``ffind'' , 3622 , 3622 ) | inrange ( ``ffind'' , 3660 , 3692 ) | inrange ( ``ffind'' , 3694 , 3699 ) | inrange ( ``ffind'' , 3810 , 3839 ) | inrange ( ``ffind'' , 7370 , 7372 ) | inrange ( ``ffind'' , 7373 , 7373 ) | inrange ( ``ffind'' , 7374 , 7374 ) | inrange ( ``ffind'' , 7375 , 7375 ) | inrange ( ``ffind'' , 7376 , 7376 ) | inrange ( ``ffind'' , 7377 , 7377 ) | inrange ( ``ffind'' , 7378 , 7378 ) | inrange ( ``ffind'' , 7379 , 7379 ) | inrange ( ``ffind'' , 7391 , 7391 ) | inrange ( ``ffind'' , 8730 , 8734 ) | inrange ( ``ffind'' , 4800 , 4899 ) qui replace `generate' = 4 if inrange ( ``ffind'' , 2830 , 2839 ) | inrange ( ``ffind'' , 3693 , 3693 ) | inrange ( ``ffind'' , 3840 , 3859 ) | inrange ( ``ffind'' , 8000 , 8099 ) qui replace `generate' = 5 if missing ( `generate' ) & ~ missing ( ``ffind'' ) } else if ``ftyp'' == 10 { label define `generate' 1 \"Consumer NonDurables -- Food, Tobacco, Textiles, Apparel, Leather, Toys\" 2 \"Consumer Durables -- Cars, TV's, Furniture, Household Appliances\" 3 \"Manufacturing -- Machinery, Trucks, Planes, Chemicals, Off Furn, Paper, Com Printing\" 4 \"Oil, Gas, and Coal Extraction and Products\" 5 \"Business Equipment -- Computers, Software, and Electronic Equipment\" 6 \"Telephone and Television Transmission\" 7 \"Wholesale, Retail, and Some Services (Laundries, Repair Shops)\" 8 \"Healthcare, Medical Equipment, and Drugs\" 9 \"Utilities\" 10 \"Other -- Mines, Constr, BldMt, Trans, Hotels, Bus Serv, Entertainment, Finance\" label values `generate' `generate' qui replace `generate' = 1 if inrange ( ``ffind'' , 100 , 999 ) | inrange ( ``ffind'' , 2000 , 2399 ) | inrange ( ``ffind'' , 2700 , 2749 ) | inrange ( ``ffind'' , 2770 , 2799 ) | inrange ( ``ffind'' , 3100 , 3199 ) | inrange ( ``ffind'' , 3940 , 3989 ) qui replace `generate' = 2 if inrange ( ``ffind'' , 2500 , 2519 ) | inrange ( ``ffind'' , 2590 , 2599 ) | inrange ( ``ffind'' , 3630 , 3659 ) | inrange ( ``ffind'' , 3710 , 3711 ) | inrange ( ``ffind'' , 3714 , 3714 ) | inrange ( ``ffind'' , 3716 , 3716 ) | inrange ( ``ffind'' , 3750 , 3751 ) | inrange ( ``ffind'' , 3792 , 3792 ) | inrange ( ``ffind'' , 3900 , 3939 ) | inrange ( ``ffind'' , 3990 , 3999 ) qui replace `generate' = 3 if inrange ( ``ffind'' , 2520 , 2589 ) | inrange ( ``ffind'' , 2600 , 2699 ) | inrange ( ``ffind'' , 2750 , 2769 ) | inrange ( ``ffind'' , 2800 , 2829 ) | inrange ( ``ffind'' , 2840 , 2899 ) | inrange ( ``ffind'' , 3000 , 3099 ) | inrange ( ``ffind'' , 3200 , 3569 ) | inrange ( ``ffind'' , 3580 , 3629 ) | inrange ( ``ffind'' , 3700 , 3709 ) | inrange ( ``ffind'' , 3712 , 3713 ) | inrange ( ``ffind'' , 3715 , 3715 ) | inrange ( ``ffind'' , 3717 , 3749 ) | inrange ( ``ffind'' , 3752 , 3791 ) | inrange ( ``ffind'' , 3793 , 3799 ) | inrange ( ``ffind'' , 3830 , 3839 ) | inrange ( ``ffind'' , 3860 , 3899 ) qui replace `generate' = 4 if inrange ( ``ffind'' , 1200 , 1399 ) | inrange ( ``ffind'' , 2900 , 2999 ) qui replace `generate' = 5 if inrange ( ``ffind'' , 3570 , 3579 ) | inrange ( ``ffind'' , 3622 , 3622 ) | inrange ( ``ffind'' , 3660 , 3692 ) | inrange ( ``ffind'' , 3694 , 3699 ) | inrange ( ``ffind'' , 3810 , 3839 ) | inrange ( ``ffind'' , 7370 , 7372 ) | inrange ( ``ffind'' , 7373 , 7373 ) | inrange ( ``ffind'' , 7374 , 7374 ) | inrange ( ``ffind'' , 7375 , 7375 ) | inrange ( ``ffind'' , 7376 , 7376 ) | inrange ( ``ffind'' , 7377 , 7377 ) | inrange ( ``ffind'' , 7378 , 7378 ) | inrange ( ``ffind'' , 7379 , 7379 ) | inrange ( ``ffind'' , 7391 , 7391 ) | inrange ( ``ffind'' , 8730 , 8734 ) qui replace `generate' = 6 if inrange ( ``ffind'' , 4800 , 4899 ) qui replace `generate' = 7 if inrange ( ``ffind'' , 5000 , 5999 ) | inrange ( ``ffind'' , 7200 , 7299 ) | inrange ( ``ffind'' , 7600 , 7699 ) qui replace `generate' = 8 if inrange ( ``ffind'' , 2830 , 2839 ) | inrange ( ``ffind'' , 3693 , 3693 ) | inrange ( ``ffind'' , 3840 , 3859 ) | inrange ( ``ffind'' , 8000 , 8099 ) qui replace `generate' = 9 if inrange ( ``ffind'' , 4900 , 4949 ) qui replace `generate' = 10 if missing ( `generate' ) & ~ missing ( ``ffind'' ) } else if ``ftyp'' == 12 { label define `generate' 1 \"Consumer NonDurables -- Food, Tobacco, Textiles, Apparel, Leather, Toys\" 2 \"Consumer Durables -- Cars, TV's, Furniture, Household Appliances\" 3 \"Manufacturing -- Machinery, Trucks, Planes, Off Furn, Paper, Com Printing\" 4 \"Oil, Gas, and Coal Extraction and Products\" 5 \"Chemicals and Allied Products\" 6 \"Business Equipment -- Computers, Software, and Electronic Equipment\" 7 \"Telephone and Television Transmission\" 8 \"Utilities\" 9 \"Wholesale, Retail, and Some Services (Laundries, Repair Shops)\" 10 \"Healthcare, Medical Equipment, and Drugs\" 11 \"Finance\" 12 \"Other -- Mines, Constr, BldMt, Trans, Hotels, Bus Serv, Entertainment\" label values `generate' `generate' qui replace `generate' = 1 if inrange ( ``ffind'' , 100 , 999 ) | inrange ( ``ffind'' , 2000 , 2399 ) | inrange ( ``ffind'' , 2700 , 2749 ) | inrange ( ``ffind'' , 2770 , 2799 ) | inrange ( ``ffind'' , 3100 , 3199 ) | inrange ( ``ffind'' , 3940 , 3989 ) qui replace `generate' = 2 if inrange ( ``ffind'' , 2500 , 2519 ) | inrange ( ``ffind'' , 2590 , 2599 ) | inrange ( ``ffind'' , 3630 , 3659 ) | inrange ( ``ffind'' , 3710 , 3711 ) | inrange ( ``ffind'' , 3714 , 3714 ) | inrange ( ``ffind'' , 3716 , 3716 ) | inrange ( ``ffind'' , 3750 , 3751 ) | inrange ( ``ffind'' , 3792 , 3792 ) | inrange ( ``ffind'' , 3900 , 3939 ) | inrange ( ``ffind'' , 3990 , 3999 ) qui replace `generate' = 3 if inrange ( ``ffind'' , 2520 , 2589 ) | inrange ( ``ffind'' , 2600 , 2699 ) | inrange ( ``ffind'' , 2750 , 2769 ) | inrange ( ``ffind'' , 3000 , 3099 ) | inrange ( ``ffind'' , 3200 , 3569 ) | inrange ( ``ffind'' , 3580 , 3629 ) | inrange ( ``ffind'' , 3700 , 3709 ) | inrange ( ``ffind'' , 3712 , 3713 ) | inrange ( ``ffind'' , 3715 , 3715 ) | inrange ( ``ffind'' , 3717 , 3749 ) | inrange ( ``ffind'' , 3752 , 3791 ) | inrange ( ``ffind'' , 3793 , 3799 ) | inrange ( ``ffind'' , 3830 , 3839 ) | inrange ( ``ffind'' , 3860 , 3899 ) qui replace `generate' = 4 if inrange ( ``ffind'' , 1200 , 1399 ) | inrange ( ``ffind'' , 2900 , 2999 ) qui replace `generate' = 5 if inrange ( ``ffind'' , 2800 , 2829 ) | inrange ( ``ffind'' , 2840 , 2899 ) qui replace `generate' = 6 if inrange ( ``ffind'' , 3570 , 3579 ) | inrange ( ``ffind'' , 3660 , 3692 ) | inrange ( ``ffind'' , 3694 , 3699 ) | inrange ( ``ffind'' , 3810 , 3829 ) | inrange ( ``ffind'' , 7370 , 7379 ) qui replace `generate' = 7 if inrange ( ``ffind'' , 4800 , 4899 ) qui replace `generate' = 8 if inrange ( ``ffind'' , 4900 , 4949 ) qui replace `generate' = 9 if inrange ( ``ffind'' , 5000 , 5999 ) | inrange ( ``ffind'' , 7200 , 7299 ) | inrange ( ``ffind'' , 7600 , 7699 ) qui replace `generate' = 10 if inrange ( ``ffind'' , 2830 , 2839 ) | inrange ( ``ffind'' , 3693 , 3693 ) | inrange ( ``ffind'' , 3840 , 3859 ) | inrange ( ``ffind'' , 8000 , 8099 ) qui replace `generate' = 11 if inrange ( ``ffind'' , 6000 , 6999 ) qui replace `generate' = 12 if missing ( `generate' ) & ~ missing ( ``ffind'' ) } else if ``ftyp'' == 17 { label define `generate' 1 \"Food\" 2 \"Mining and Minerals\" 3 \"Oil and Petroleum Products\" 4 \"Textiles, Apparel & Footware\" 5 \"Consumer Durables\" 6 \"Chemicals\" 7 \"Drugs, Soap, Prfums, Tobacco\" 8 \"Construction and Construction Materials\" 9 \"Steel Works Etc\" 10 \"Fabricated Products\" 11 \"Machinery and Business Equipment\" 12 \"Automobiles\" 13 \"Transportation\" 14 \"Utilities\" 15 \"Retail Stores\" 16 \"Banks, Insurance Companies, and Other Financials\" 17 \"Other\" label values `generate' `generate' qui replace `generate' = 1 if inrange ( ``ffind'' , 100 , 199 ) | inrange ( ``ffind'' , 200 , 299 ) | inrange ( ``ffind'' , 700 , 799 ) | inrange ( ``ffind'' , 900 , 999 ) | inrange ( ``ffind'' , 2000 , 2009 ) | inrange ( ``ffind'' , 2010 , 2019 ) | inrange ( ``ffind'' , 2020 , 2029 ) | inrange ( ``ffind'' , 2030 , 2039 ) | inrange ( ``ffind'' , 2040 , 2046 ) | inrange ( ``ffind'' , 2047 , 2047 ) | inrange ( ``ffind'' , 2048 , 2048 ) | inrange ( ``ffind'' , 2050 , 2059 ) | inrange ( ``ffind'' , 2060 , 2063 ) | inrange ( ``ffind'' , 2064 , 2068 ) | inrange ( ``ffind'' , 2070 , 2079 ) | inrange ( ``ffind'' , 2080 , 2080 ) | inrange ( ``ffind'' , 2082 , 2082 ) | inrange ( ``ffind'' , 2083 , 2083 ) | inrange ( ``ffind'' , 2084 , 2084 ) | inrange ( ``ffind'' , 2085 , 2085 ) | inrange ( ``ffind'' , 2086 , 2086 ) | inrange ( ``ffind'' , 2087 , 2087 ) | inrange ( ``ffind'' , 2090 , 2092 ) | inrange ( ``ffind'' , 2095 , 2095 ) | inrange ( ``ffind'' , 2096 , 2096 ) | inrange ( ``ffind'' , 2097 , 2097 ) | inrange ( ``ffind'' , 2098 , 2099 ) | inrange ( ``ffind'' , 5140 , 5149 ) | inrange ( ``ffind'' , 5150 , 5159 ) | inrange ( ``ffind'' , 5180 , 5182 ) | inrange ( ``ffind'' , 5191 , 5191 ) qui replace `generate' = 2 if inrange ( ``ffind'' , 1000 , 1009 ) | inrange ( ``ffind'' , 1010 , 1019 ) | inrange ( ``ffind'' , 1020 , 1029 ) | inrange ( ``ffind'' , 1030 , 1039 ) | inrange ( ``ffind'' , 1040 , 1049 ) | inrange ( ``ffind'' , 1060 , 1069 ) | inrange ( ``ffind'' , 1080 , 1089 ) | inrange ( ``ffind'' , 1090 , 1099 ) | inrange ( ``ffind'' , 1200 , 1299 ) | inrange ( ``ffind'' , 1400 , 1499 ) | inrange ( ``ffind'' , 5050 , 5052 ) qui replace `generate' = 3 if inrange ( ``ffind'' , 1300 , 1300 ) | inrange ( ``ffind'' , 1310 , 1319 ) | inrange ( ``ffind'' , 1320 , 1329 ) | inrange ( ``ffind'' , 1380 , 1380 ) | inrange ( ``ffind'' , 1381 , 1381 ) | inrange ( ``ffind'' , 1382 , 1382 ) | inrange ( ``ffind'' , 1389 , 1389 ) | inrange ( ``ffind'' , 2900 , 2912 ) | inrange ( ``ffind'' , 5170 , 5172 ) qui replace `generate' = 4 if inrange ( ``ffind'' , 2200 , 2269 ) | inrange ( ``ffind'' , 2270 , 2279 ) | inrange ( ``ffind'' , 2280 , 2284 ) | inrange ( ``ffind'' , 2290 , 2295 ) | inrange ( ``ffind'' , 2296 , 2296 ) | inrange ( ``ffind'' , 2297 , 2297 ) | inrange ( ``ffind'' , 2298 , 2298 ) | inrange ( ``ffind'' , 2299 , 2299 ) | inrange ( ``ffind'' , 2300 , 2390 ) | inrange ( ``ffind'' , 2391 , 2392 ) | inrange ( ``ffind'' , 2393 , 2395 ) | inrange ( ``ffind'' , 2396 , 2396 ) | inrange ( ``ffind'' , 2397 , 2399 ) | inrange ( ``ffind'' , 3020 , 3021 ) | inrange ( ``ffind'' , 3100 , 3111 ) | inrange ( ``ffind'' , 3130 , 3131 ) | inrange ( ``ffind'' , 3140 , 3149 ) | inrange ( ``ffind'' , 3150 , 3151 ) | inrange ( ``ffind'' , 3963 , 3965 ) | inrange ( ``ffind'' , 5130 , 5139 ) qui replace `generate' = 5 if inrange ( ``ffind'' , 2510 , 2519 ) | inrange ( ``ffind'' , 2590 , 2599 ) | inrange ( ``ffind'' , 3060 , 3069 ) | inrange ( ``ffind'' , 3070 , 3079 ) | inrange ( ``ffind'' , 3080 , 3089 ) | inrange ( ``ffind'' , 3090 , 3099 ) | inrange ( ``ffind'' , 3630 , 3639 ) | inrange ( ``ffind'' , 3650 , 3651 ) | inrange ( ``ffind'' , 3652 , 3652 ) | inrange ( ``ffind'' , 3860 , 3861 ) | inrange ( ``ffind'' , 3870 , 3873 ) | inrange ( ``ffind'' , 3910 , 3911 ) | inrange ( ``ffind'' , 3914 , 3914 ) | inrange ( ``ffind'' , 3915 , 3915 ) | inrange ( ``ffind'' , 3930 , 3931 ) | inrange ( ``ffind'' , 3940 , 3949 ) | inrange ( ``ffind'' , 3960 , 3962 ) | inrange ( ``ffind'' , 5020 , 5023 ) | inrange ( ``ffind'' , 5064 , 5064 ) | inrange ( ``ffind'' , 5094 , 5094 ) | inrange ( ``ffind'' , 5099 , 5099 ) qui replace `generate' = 6 if inrange ( ``ffind'' , 2800 , 2809 ) | inrange ( ``ffind'' , 2810 , 2819 ) | inrange ( ``ffind'' , 2820 , 2829 ) | inrange ( ``ffind'' , 2860 , 2869 ) | inrange ( ``ffind'' , 2870 , 2879 ) | inrange ( ``ffind'' , 2890 , 2899 ) | inrange ( ``ffind'' , 5160 , 5169 ) qui replace `generate' = 7 if inrange ( ``ffind'' , 2100 , 2199 ) | inrange ( ``ffind'' , 2830 , 2830 ) | inrange ( ``ffind'' , 2831 , 2831 ) | inrange ( ``ffind'' , 2833 , 2833 ) | inrange ( ``ffind'' , 2834 , 2834 ) | inrange ( ``ffind'' , 2840 , 2843 ) | inrange ( ``ffind'' , 2844 , 2844 ) | inrange ( ``ffind'' , 5120 , 5122 ) | inrange ( ``ffind'' , 5194 , 5194 ) qui replace `generate' = 8 if inrange ( ``ffind'' , 800 , 899 ) | inrange ( ``ffind'' , 1500 , 1511 ) | inrange ( ``ffind'' , 1520 , 1529 ) | inrange ( ``ffind'' , 1530 , 1539 ) | inrange ( ``ffind'' , 1540 , 1549 ) | inrange ( ``ffind'' , 1600 , 1699 ) | inrange ( ``ffind'' , 1700 , 1799 ) | inrange ( ``ffind'' , 2400 , 2439 ) | inrange ( ``ffind'' , 2440 , 2449 ) | inrange ( ``ffind'' , 2450 , 2459 ) | inrange ( ``ffind'' , 2490 , 2499 ) | inrange ( ``ffind'' , 2850 , 2859 ) | inrange ( ``ffind'' , 2950 , 2952 ) | inrange ( ``ffind'' , 3200 , 3200 ) | inrange ( ``ffind'' , 3210 , 3211 ) | inrange ( ``ffind'' , 3240 , 3241 ) | inrange ( ``ffind'' , 3250 , 3259 ) | inrange ( ``ffind'' , 3261 , 3261 ) | inrange ( ``ffind'' , 3264 , 3264 ) | inrange ( ``ffind'' , 3270 , 3275 ) | inrange ( ``ffind'' , 3280 , 3281 ) | inrange ( ``ffind'' , 3290 , 3293 ) | inrange ( ``ffind'' , 3420 , 3429 ) | inrange ( ``ffind'' , 3430 , 3433 ) | inrange ( ``ffind'' , 3440 , 3441 ) | inrange ( ``ffind'' , 3442 , 3442 ) | inrange ( ``ffind'' , 3446 , 3446 ) | inrange ( ``ffind'' , 3448 , 3448 ) | inrange ( ``ffind'' , 3449 , 3449 ) | inrange ( ``ffind'' , 3450 , 3451 ) | inrange ( ``ffind'' , 3452 , 3452 ) | inrange ( ``ffind'' , 5030 , 5039 ) | inrange ( ``ffind'' , 5070 , 5078 ) | inrange ( ``ffind'' , 5198 , 5198 ) | inrange ( ``ffind'' , 5210 , 5211 ) | inrange ( ``ffind'' , 5230 , 5231 ) | inrange ( ``ffind'' , 5250 , 5251 ) qui replace `generate' = 9 if inrange ( ``ffind'' , 3300 , 3300 ) | inrange ( ``ffind'' , 3310 , 3317 ) | inrange ( ``ffind'' , 3320 , 3325 ) | inrange ( ``ffind'' , 3330 , 3339 ) | inrange ( ``ffind'' , 3340 , 3341 ) | inrange ( ``ffind'' , 3350 , 3357 ) | inrange ( ``ffind'' , 3360 , 3369 ) | inrange ( ``ffind'' , 3390 , 3399 ) qui replace `generate' = 10 if inrange ( ``ffind'' , 3410 , 3412 ) | inrange ( ``ffind'' , 3443 , 3443 ) | inrange ( ``ffind'' , 3444 , 3444 ) | inrange ( ``ffind'' , 3460 , 3469 ) | inrange ( ``ffind'' , 3470 , 3479 ) | inrange ( ``ffind'' , 3480 , 3489 ) | inrange ( ``ffind'' , 3490 , 3499 ) qui replace `generate' = 11 if inrange ( ``ffind'' , 3510 , 3519 ) | inrange ( ``ffind'' , 3520 , 3529 ) | inrange ( ``ffind'' , 3530 , 3530 ) | inrange ( ``ffind'' , 3531 , 3531 ) | inrange ( ``ffind'' , 3532 , 3532 ) | inrange ( ``ffind'' , 3533 , 3533 ) | inrange ( ``ffind'' , 3534 , 3534 ) | inrange ( ``ffind'' , 3535 , 3535 ) | inrange ( ``ffind'' , 3536 , 3536 ) | inrange ( ``ffind'' , 3540 , 3549 ) | inrange ( ``ffind'' , 3550 , 3559 ) | inrange ( ``ffind'' , 3560 , 3569 ) | inrange ( ``ffind'' , 3570 , 3579 ) | inrange ( ``ffind'' , 3580 , 3580 ) | inrange ( ``ffind'' , 3581 , 3581 ) | inrange ( ``ffind'' , 3582 , 3582 ) | inrange ( ``ffind'' , 3585 , 3585 ) | inrange ( ``ffind'' , 3586 , 3586 ) | inrange ( ``ffind'' , 3589 , 3589 ) | inrange ( ``ffind'' , 3590 , 3599 ) | inrange ( ``ffind'' , 3600 , 3600 ) | inrange ( ``ffind'' , 3610 , 3613 ) | inrange ( ``ffind'' , 3620 , 3621 ) | inrange ( ``ffind'' , 3622 , 3622 ) | inrange ( ``ffind'' , 3623 , 3629 ) | inrange ( ``ffind'' , 3670 , 3679 ) | inrange ( ``ffind'' , 3680 , 3680 ) | inrange ( ``ffind'' , 3681 , 3681 ) | inrange ( ``ffind'' , 3682 , 3682 ) | inrange ( ``ffind'' , 3683 , 3683 ) | inrange ( ``ffind'' , 3684 , 3684 ) | inrange ( ``ffind'' , 3685 , 3685 ) | inrange ( ``ffind'' , 3686 , 3686 ) | inrange ( ``ffind'' , 3687 , 3687 ) | inrange ( ``ffind'' , 3688 , 3688 ) | inrange ( ``ffind'' , 3689 , 3689 ) | inrange ( ``ffind'' , 3690 , 3690 ) | inrange ( ``ffind'' , 3691 , 3692 ) | inrange ( ``ffind'' , 3693 , 3693 ) | inrange ( ``ffind'' , 3694 , 3694 ) | inrange ( ``ffind'' , 3695 , 3695 ) | inrange ( ``ffind'' , 3699 , 3699 ) | inrange ( ``ffind'' , 3810 , 3810 ) | inrange ( ``ffind'' , 3811 , 3811 ) | inrange ( ``ffind'' , 3812 , 3812 ) | inrange ( ``ffind'' , 3820 , 3820 ) | inrange ( ``ffind'' , 3821 , 3821 ) | inrange ( ``ffind'' , 3822 , 3822 ) | inrange ( ``ffind'' , 3823 , 3823 ) | inrange ( ``ffind'' , 3824 , 3824 ) | inrange ( ``ffind'' , 3825 , 3825 ) | inrange ( ``ffind'' , 3826 , 3826 ) | inrange ( ``ffind'' , 3827 , 3827 ) | inrange ( ``ffind'' , 3829 , 3829 ) | inrange ( ``ffind'' , 3830 , 3839 ) | inrange ( ``ffind'' , 3950 , 3955 ) | inrange ( ``ffind'' , 5060 , 5060 ) | inrange ( ``ffind'' , 5063 , 5063 ) | inrange ( ``ffind'' , 5065 , 5065 ) | inrange ( ``ffind'' , 5080 , 5080 ) | inrange ( ``ffind'' , 5081 , 5081 ) qui replace `generate' = 12 if inrange ( ``ffind'' , 3710 , 3710 ) | inrange ( ``ffind'' , 3711 , 3711 ) | inrange ( ``ffind'' , 3714 , 3714 ) | inrange ( ``ffind'' , 3716 , 3716 ) | inrange ( ``ffind'' , 3750 , 3751 ) | inrange ( ``ffind'' , 3792 , 3792 ) | inrange ( ``ffind'' , 5010 , 5015 ) | inrange ( ``ffind'' , 5510 , 5521 ) | inrange ( ``ffind'' , 5530 , 5531 ) | inrange ( ``ffind'' , 5560 , 5561 ) | inrange ( ``ffind'' , 5570 , 5571 ) | inrange ( ``ffind'' , 5590 , 5599 ) qui replace `generate' = 13 if inrange ( ``ffind'' , 3713 , 3713 ) | inrange ( ``ffind'' , 3715 , 3715 ) | inrange ( ``ffind'' , 3720 , 3720 ) | inrange ( ``ffind'' , 3721 , 3721 ) | inrange ( ``ffind'' , 3724 , 3724 ) | inrange ( ``ffind'' , 3725 , 3725 ) | inrange ( ``ffind'' , 3728 , 3728 ) | inrange ( ``ffind'' , 3730 , 3731 ) | inrange ( ``ffind'' , 3732 , 3732 ) | inrange ( ``ffind'' , 3740 , 3743 ) | inrange ( ``ffind'' , 3760 , 3769 ) | inrange ( ``ffind'' , 3790 , 3790 ) | inrange ( ``ffind'' , 3795 , 3795 ) | inrange ( ``ffind'' , 3799 , 3799 ) | inrange ( ``ffind'' , 4000 , 4013 ) | inrange ( ``ffind'' , 4100 , 4100 ) | inrange ( ``ffind'' , 4110 , 4119 ) | inrange ( ``ffind'' , 4120 , 4121 ) | inrange ( ``ffind'' , 4130 , 4131 ) | inrange ( ``ffind'' , 4140 , 4142 ) | inrange ( ``ffind'' , 4150 , 4151 ) | inrange ( ``ffind'' , 4170 , 4173 ) | inrange ( ``ffind'' , 4190 , 4199 ) | inrange ( ``ffind'' , 4200 , 4200 ) | inrange ( ``ffind'' , 4210 , 4219 ) | inrange ( ``ffind'' , 4220 , 4229 ) | inrange ( ``ffind'' , 4230 , 4231 ) | inrange ( ``ffind'' , 4400 , 4499 ) | inrange ( ``ffind'' , 4500 , 4599 ) | inrange ( ``ffind'' , 4600 , 4699 ) | inrange ( ``ffind'' , 4700 , 4700 ) | inrange ( ``ffind'' , 4710 , 4712 ) | inrange ( ``ffind'' , 4720 , 4729 ) | inrange ( ``ffind'' , 4730 , 4739 ) | inrange ( ``ffind'' , 4740 , 4742 ) | inrange ( ``ffind'' , 4780 , 4780 ) | inrange ( ``ffind'' , 4783 , 4783 ) | inrange ( ``ffind'' , 4785 , 4785 ) | inrange ( ``ffind'' , 4789 , 4789 ) qui replace `generate' = 14 if inrange ( ``ffind'' , 4900 , 4900 ) | inrange ( ``ffind'' , 4910 , 4911 ) | inrange ( ``ffind'' , 4920 , 4922 ) | inrange ( ``ffind'' , 4923 , 4923 ) | inrange ( ``ffind'' , 4924 , 4925 ) | inrange ( ``ffind'' , 4930 , 4931 ) | inrange ( ``ffind'' , 4932 , 4932 ) | inrange ( ``ffind'' , 4939 , 4939 ) | inrange ( ``ffind'' , 4940 , 4942 ) qui replace `generate' = 15 if inrange ( ``ffind'' , 5260 , 5261 ) | inrange ( ``ffind'' , 5270 , 5271 ) | inrange ( ``ffind'' , 5300 , 5300 ) | inrange ( ``ffind'' , 5310 , 5311 ) | inrange ( ``ffind'' , 5320 , 5320 ) | inrange ( ``ffind'' , 5330 , 5331 ) | inrange ( ``ffind'' , 5334 , 5334 ) | inrange ( ``ffind'' , 5390 , 5399 ) | inrange ( ``ffind'' , 5400 , 5400 ) | inrange ( ``ffind'' , 5410 , 5411 ) | inrange ( ``ffind'' , 5412 , 5412 ) | inrange ( ``ffind'' , 5420 , 5421 ) | inrange ( ``ffind'' , 5430 , 5431 ) | inrange ( ``ffind'' , 5440 , 5441 ) | inrange ( ``ffind'' , 5450 , 5451 ) | inrange ( ``ffind'' , 5460 , 5461 ) | inrange ( ``ffind'' , 5490 , 5499 ) | inrange ( ``ffind'' , 5540 , 5541 ) | inrange ( ``ffind'' , 5550 , 5551 ) | inrange ( ``ffind'' , 5600 , 5699 ) | inrange ( ``ffind'' , 5700 , 5700 ) | inrange ( ``ffind'' , 5710 , 5719 ) | inrange ( ``ffind'' , 5720 , 5722 ) | inrange ( ``ffind'' , 5730 , 5733 ) | inrange ( ``ffind'' , 5734 , 5734 ) | inrange ( ``ffind'' , 5735 , 5735 ) | inrange ( ``ffind'' , 5736 , 5736 ) | inrange ( ``ffind'' , 5750 , 5750 ) | inrange ( ``ffind'' , 5800 , 5813 ) | inrange ( ``ffind'' , 5890 , 5890 ) | inrange ( ``ffind'' , 5900 , 5900 ) | inrange ( ``ffind'' , 5910 , 5912 ) | inrange ( ``ffind'' , 5920 , 5921 ) | inrange ( ``ffind'' , 5930 , 5932 ) | inrange ( ``ffind'' , 5940 , 5940 ) | inrange ( ``ffind'' , 5941 , 5941 ) | inrange ( ``ffind'' , 5942 , 5942 ) | inrange ( ``ffind'' , 5943 , 5943 ) | inrange ( ``ffind'' , 5944 , 5944 ) | inrange ( ``ffind'' , 5945 , 5945 ) | inrange ( ``ffind'' , 5946 , 5946 ) | inrange ( ``ffind'' , 5947 , 5947 ) | inrange ( ``ffind'' , 5948 , 5948 ) | inrange ( ``ffind'' , 5949 , 5949 ) | inrange ( ``ffind'' , 5960 , 5963 ) | inrange ( ``ffind'' , 5980 , 5989 ) | inrange ( ``ffind'' , 5990 , 5990 ) | inrange ( ``ffind'' , 5992 , 5992 ) | inrange ( ``ffind'' , 5993 , 5993 ) | inrange ( ``ffind'' , 5994 , 5994 ) | inrange ( ``ffind'' , 5995 , 5995 ) | inrange ( ``ffind'' , 5999 , 5999 ) qui replace `generate' = 16 if inrange ( ``ffind'' , 6010 , 6019 ) | inrange ( ``ffind'' , 6020 , 6020 ) | inrange ( ``ffind'' , 6021 , 6021 ) | inrange ( ``ffind'' , 6022 , 6022 ) | inrange ( ``ffind'' , 6023 , 6023 ) | inrange ( ``ffind'' , 6025 , 6025 ) | inrange ( ``ffind'' , 6026 , 6026 ) | inrange ( ``ffind'' , 6028 , 6029 ) | inrange ( ``ffind'' , 6030 , 6036 ) | inrange ( ``ffind'' , 6040 , 6049 ) | inrange ( ``ffind'' , 6050 , 6059 ) | inrange ( ``ffind'' , 6060 , 6062 ) | inrange ( ``ffind'' , 6080 , 6082 ) | inrange ( ``ffind'' , 6090 , 6099 ) | inrange ( ``ffind'' , 6100 , 6100 ) | inrange ( ``ffind'' , 6110 , 6111 ) | inrange ( ``ffind'' , 6112 , 6112 ) | inrange ( ``ffind'' , 6120 , 6129 ) | inrange ( ``ffind'' , 6140 , 6149 ) | inrange ( ``ffind'' , 6150 , 6159 ) | inrange ( ``ffind'' , 6160 , 6163 ) | inrange ( ``ffind'' , 6172 , 6172 ) | inrange ( ``ffind'' , 6199 , 6199 ) | inrange ( ``ffind'' , 6200 , 6299 ) | inrange ( ``ffind'' , 6300 , 6300 ) | inrange ( ``ffind'' , 6310 , 6312 ) | inrange ( ``ffind'' , 6320 , 6324 ) | inrange ( ``ffind'' , 6330 , 6331 ) | inrange ( ``ffind'' , 6350 , 6351 ) | inrange ( ``ffind'' , 6360 , 6361 ) | inrange ( ``ffind'' , 6370 , 6371 ) | inrange ( ``ffind'' , 6390 , 6399 ) | inrange ( ``ffind'' , 6400 , 6411 ) | inrange ( ``ffind'' , 6500 , 6500 ) | inrange ( ``ffind'' , 6510 , 6510 ) | inrange ( ``ffind'' , 6512 , 6512 ) | inrange ( ``ffind'' , 6513 , 6513 ) | inrange ( ``ffind'' , 6514 , 6514 ) | inrange ( ``ffind'' , 6515 , 6515 ) | inrange ( ``ffind'' , 6517 , 6519 ) | inrange ( ``ffind'' , 6530 , 6531 ) | inrange ( ``ffind'' , 6532 , 6532 ) | inrange ( ``ffind'' , 6540 , 6541 ) | inrange ( ``ffind'' , 6550 , 6553 ) | inrange ( ``ffind'' , 6611 , 6611 ) | inrange ( ``ffind'' , 6700 , 6700 ) | inrange ( ``ffind'' , 6710 , 6719 ) | inrange ( ``ffind'' , 6720 , 6722 ) | inrange ( ``ffind'' , 6723 , 6723 ) | inrange ( ``ffind'' , 6724 , 6724 ) | inrange ( ``ffind'' , 6725 , 6725 ) | inrange ( ``ffind'' , 6726 , 6726 ) | inrange ( ``ffind'' , 6730 , 6733 ) | inrange ( ``ffind'' , 6790 , 6790 ) | inrange ( ``ffind'' , 6792 , 6792 ) | inrange ( ``ffind'' , 6794 , 6794 ) | inrange ( ``ffind'' , 6795 , 6795 ) | inrange ( ``ffind'' , 6798 , 6798 ) | inrange ( ``ffind'' , 6799 , 6799 ) qui replace `generate' = 17 if missing ( `generate' ) & ~ missing ( ``ffind'' ) } else if ``ftyp'' == 30 { label define `generate' 1 \"Food Products\" 2 \"Beer & Liquor\" 3 \"Tobacco Products\" 4 \"Recreation\" 5 \"Printing and Publishing\" 6 \"Consumer Goods\" 7 \"Apparel\" 8 \"Healthcare, Medical Equipment, Pharmaceutical Products\" 9 \"Chemicals\" 10 \"Textiles\" 11 \"Construction and Construction Materials\" 12 \"Steel Works Etc\" 13 \"Fabricated Products and Machinery\" 14 \"Electrical Equipment\" 15 \"Automobiles and Trucks\" 16 \"Aircraft, ships, and railroad equipment\" 17 \"Precious Metals, Non-Metallic, and Industrial Metal Mining\" 18 \"Coal\" 19 \"Petroleum and Natural Gas\" 20 \"Utilities\" 21 \"Communication\" 22 \"Personal and Business Services\" 23 \"Business Equipment\" 24 \"Business Supplies and Shipping Containers\" 25 \"Transportation\" 26 \"Wholesale\" 27 \"Retail\" 28 \"Restaraunts, Hotels, Motels\" 29 \"Banking, Insurance, Real Estate, Trading\" 30 \"Everything Else\" label values `generate' `generate' qui replace `generate' = 1 if inrange ( ``ffind'' , 100 , 199 ) | inrange ( ``ffind'' , 200 , 299 ) | inrange ( ``ffind'' , 700 , 799 ) | inrange ( ``ffind'' , 910 , 919 ) | inrange ( ``ffind'' , 2000 , 2009 ) | inrange ( ``ffind'' , 2010 , 2019 ) | inrange ( ``ffind'' , 2020 , 2029 ) | inrange ( ``ffind'' , 2030 , 2039 ) | inrange ( ``ffind'' , 2040 , 2046 ) | inrange ( ``ffind'' , 2048 , 2048 ) | inrange ( ``ffind'' , 2050 , 2059 ) | inrange ( ``ffind'' , 2060 , 2063 ) | inrange ( ``ffind'' , 2064 , 2068 ) | inrange ( ``ffind'' , 2070 , 2079 ) | inrange ( ``ffind'' , 2086 , 2086 ) | inrange ( ``ffind'' , 2087 , 2087 ) | inrange ( ``ffind'' , 2090 , 2092 ) | inrange ( ``ffind'' , 2095 , 2095 ) | inrange ( ``ffind'' , 2096 , 2096 ) | inrange ( ``ffind'' , 2097 , 2097 ) | inrange ( ``ffind'' , 2098 , 2099 ) qui replace `generate' = 2 if inrange ( ``ffind'' , 2080 , 2080 ) | inrange ( ``ffind'' , 2082 , 2082 ) | inrange ( ``ffind'' , 2083 , 2083 ) | inrange ( ``ffind'' , 2084 , 2084 ) | inrange ( ``ffind'' , 2085 , 2085 ) qui replace `generate' = 3 if inrange ( ``ffind'' , 2100 , 2199 ) qui replace `generate' = 4 if inrange ( ``ffind'' , 920 , 999 ) | inrange ( ``ffind'' , 3650 , 3651 ) | inrange ( ``ffind'' , 3652 , 3652 ) | inrange ( ``ffind'' , 3732 , 3732 ) | inrange ( ``ffind'' , 3930 , 3931 ) | inrange ( ``ffind'' , 3940 , 3949 ) | inrange ( ``ffind'' , 7800 , 7829 ) | inrange ( ``ffind'' , 7830 , 7833 ) | inrange ( ``ffind'' , 7840 , 7841 ) | inrange ( ``ffind'' , 7900 , 7900 ) | inrange ( ``ffind'' , 7910 , 7911 ) | inrange ( ``ffind'' , 7920 , 7929 ) | inrange ( ``ffind'' , 7930 , 7933 ) | inrange ( ``ffind'' , 7940 , 7949 ) | inrange ( ``ffind'' , 7980 , 7980 ) | inrange ( ``ffind'' , 7990 , 7999 ) qui replace `generate' = 5 if inrange ( ``ffind'' , 2700 , 2709 ) | inrange ( ``ffind'' , 2710 , 2719 ) | inrange ( ``ffind'' , 2720 , 2729 ) | inrange ( ``ffind'' , 2730 , 2739 ) | inrange ( ``ffind'' , 2740 , 2749 ) | inrange ( ``ffind'' , 2750 , 2759 ) | inrange ( ``ffind'' , 2770 , 2771 ) | inrange ( ``ffind'' , 2780 , 2789 ) | inrange ( ``ffind'' , 2790 , 2799 ) | inrange ( ``ffind'' , 3993 , 3993 ) qui replace `generate' = 6 if inrange ( ``ffind'' , 2047 , 2047 ) | inrange ( ``ffind'' , 2391 , 2392 ) | inrange ( ``ffind'' , 2510 , 2519 ) | inrange ( ``ffind'' , 2590 , 2599 ) | inrange ( ``ffind'' , 2840 , 2843 ) | inrange ( ``ffind'' , 2844 , 2844 ) | inrange ( ``ffind'' , 3160 , 3161 ) | inrange ( ``ffind'' , 3170 , 3171 ) | inrange ( ``ffind'' , 3172 , 3172 ) | inrange ( ``ffind'' , 3190 , 3199 ) | inrange ( ``ffind'' , 3229 , 3229 ) | inrange ( ``ffind'' , 3260 , 3260 ) | inrange ( ``ffind'' , 3262 , 3263 ) | inrange ( ``ffind'' , 3269 , 3269 ) | inrange ( ``ffind'' , 3230 , 3231 ) | inrange ( ``ffind'' , 3630 , 3639 ) | inrange ( ``ffind'' , 3750 , 3751 ) | inrange ( ``ffind'' , 3800 , 3800 ) | inrange ( ``ffind'' , 3860 , 3861 ) | inrange ( ``ffind'' , 3870 , 3873 ) | inrange ( ``ffind'' , 3910 , 3911 ) | inrange ( ``ffind'' , 3914 , 3914 ) | inrange ( ``ffind'' , 3915 , 3915 ) | inrange ( ``ffind'' , 3960 , 3962 ) | inrange ( ``ffind'' , 3991 , 3991 ) | inrange ( ``ffind'' , 3995 , 3995 ) qui replace `generate' = 7 if inrange ( ``ffind'' , 2300 , 2390 ) | inrange ( ``ffind'' , 3020 , 3021 ) | inrange ( ``ffind'' , 3100 , 3111 ) | inrange ( ``ffind'' , 3130 , 3131 ) | inrange ( ``ffind'' , 3140 , 3149 ) | inrange ( ``ffind'' , 3150 , 3151 ) | inrange ( ``ffind'' , 3963 , 3965 ) qui replace `generate' = 8 if inrange ( ``ffind'' , 2830 , 2830 ) | inrange ( ``ffind'' , 2831 , 2831 ) | inrange ( ``ffind'' , 2833 , 2833 ) | inrange ( ``ffind'' , 2834 , 2834 ) | inrange ( ``ffind'' , 2835 , 2835 ) | inrange ( ``ffind'' , 2836 , 2836 ) | inrange ( ``ffind'' , 3693 , 3693 ) | inrange ( ``ffind'' , 3840 , 3849 ) | inrange ( ``ffind'' , 3850 , 3851 ) | inrange ( ``ffind'' , 8000 , 8099 ) qui replace `generate' = 9 if inrange ( ``ffind'' , 2800 , 2809 ) | inrange ( ``ffind'' , 2810 , 2819 ) | inrange ( ``ffind'' , 2820 , 2829 ) | inrange ( ``ffind'' , 2850 , 2859 ) | inrange ( ``ffind'' , 2860 , 2869 ) | inrange ( ``ffind'' , 2870 , 2879 ) | inrange ( ``ffind'' , 2890 , 2899 ) qui replace `generate' = 10 if inrange ( ``ffind'' , 2200 , 2269 ) | inrange ( ``ffind'' , 2270 , 2279 ) | inrange ( ``ffind'' , 2280 , 2284 ) | inrange ( ``ffind'' , 2290 , 2295 ) | inrange ( ``ffind'' , 2297 , 2297 ) | inrange ( ``ffind'' , 2298 , 2298 ) | inrange ( ``ffind'' , 2299 , 2299 ) | inrange ( ``ffind'' , 2393 , 2395 ) | inrange ( ``ffind'' , 2397 , 2399 ) qui replace `generate' = 11 if inrange ( ``ffind'' , 800 , 899 ) | inrange ( ``ffind'' , 1500 , 1511 ) | inrange ( ``ffind'' , 1520 , 1529 ) | inrange ( ``ffind'' , 1530 , 1539 ) | inrange ( ``ffind'' , 1540 , 1549 ) | inrange ( ``ffind'' , 1600 , 1699 ) | inrange ( ``ffind'' , 1700 , 1799 ) | inrange ( ``ffind'' , 2400 , 2439 ) | inrange ( ``ffind'' , 2450 , 2459 ) | inrange ( ``ffind'' , 2490 , 2499 ) | inrange ( ``ffind'' , 2660 , 2661 ) | inrange ( ``ffind'' , 2950 , 2952 ) | inrange ( ``ffind'' , 3200 , 3200 ) | inrange ( ``ffind'' , 3210 , 3211 ) | inrange ( ``ffind'' , 3240 , 3241 ) | inrange ( ``ffind'' , 3250 , 3259 ) | inrange ( ``ffind'' , 3261 , 3261 ) | inrange ( ``ffind'' , 3264 , 3264 ) | inrange ( ``ffind'' , 3270 , 3275 ) | inrange ( ``ffind'' , 3280 , 3281 ) | inrange ( ``ffind'' , 3290 , 3293 ) | inrange ( ``ffind'' , 3295 , 3299 ) | inrange ( ``ffind'' , 3420 , 3429 ) | inrange ( ``ffind'' , 3430 , 3433 ) | inrange ( ``ffind'' , 3440 , 3441 ) | inrange ( ``ffind'' , 3442 , 3442 ) | inrange ( ``ffind'' , 3446 , 3446 ) | inrange ( ``ffind'' , 3448 , 3448 ) | inrange ( ``ffind'' , 3449 , 3449 ) | inrange ( ``ffind'' , 3450 , 3451 ) | inrange ( ``ffind'' , 3452 , 3452 ) | inrange ( ``ffind'' , 3490 , 3499 ) | inrange ( ``ffind'' , 3996 , 3996 ) qui replace `generate' = 12 if inrange ( ``ffind'' , 3300 , 3300 ) | inrange ( ``ffind'' , 3310 , 3317 ) | inrange ( ``ffind'' , 3320 , 3325 ) | inrange ( ``ffind'' , 3330 , 3339 ) | inrange ( ``ffind'' , 3340 , 3341 ) | inrange ( ``ffind'' , 3350 , 3357 ) | inrange ( ``ffind'' , 3360 , 3369 ) | inrange ( ``ffind'' , 3370 , 3379 ) | inrange ( ``ffind'' , 3390 , 3399 ) qui replace `generate' = 13 if inrange ( ``ffind'' , 3400 , 3400 ) | inrange ( ``ffind'' , 3443 , 3443 ) | inrange ( ``ffind'' , 3444 , 3444 ) | inrange ( ``ffind'' , 3460 , 3469 ) | inrange ( ``ffind'' , 3470 , 3479 ) | inrange ( ``ffind'' , 3510 , 3519 ) | inrange ( ``ffind'' , 3520 , 3529 ) | inrange ( ``ffind'' , 3530 , 3530 ) | inrange ( ``ffind'' , 3531 , 3531 ) | inrange ( ``ffind'' , 3532 , 3532 ) | inrange ( ``ffind'' , 3533 , 3533 ) | inrange ( ``ffind'' , 3534 , 3534 ) | inrange ( ``ffind'' , 3535 , 3535 ) | inrange ( ``ffind'' , 3536 , 3536 ) | inrange ( ``ffind'' , 3538 , 3538 ) | inrange ( ``ffind'' , 3540 , 3549 ) | inrange ( ``ffind'' , 3550 , 3559 ) | inrange ( ``ffind'' , 3560 , 3569 ) | inrange ( ``ffind'' , 3580 , 3580 ) | inrange ( ``ffind'' , 3581 , 3581 ) | inrange ( ``ffind'' , 3582 , 3582 ) | inrange ( ``ffind'' , 3585 , 3585 ) | inrange ( ``ffind'' , 3586 , 3586 ) | inrange ( ``ffind'' , 3589 , 3589 ) | inrange ( ``ffind'' , 3590 , 3599 ) qui replace `generate' = 14 if inrange ( ``ffind'' , 3600 , 3600 ) | inrange ( ``ffind'' , 3610 , 3613 ) | inrange ( ``ffind'' , 3620 , 3621 ) | inrange ( ``ffind'' , 3623 , 3629 ) | inrange ( ``ffind'' , 3640 , 3644 ) | inrange ( ``ffind'' , 3645 , 3645 ) | inrange ( ``ffind'' , 3646 , 3646 ) | inrange ( ``ffind'' , 3648 , 3649 ) | inrange ( ``ffind'' , 3660 , 3660 ) | inrange ( ``ffind'' , 3690 , 3690 ) | inrange ( ``ffind'' , 3691 , 3692 ) | inrange ( ``ffind'' , 3699 , 3699 ) qui replace `generate' = 15 if inrange ( ``ffind'' , 2296 , 2296 ) | inrange ( ``ffind'' , 2396 , 2396 ) | inrange ( ``ffind'' , 3010 , 3011 ) | inrange ( ``ffind'' , 3537 , 3537 ) | inrange ( ``ffind'' , 3647 , 3647 ) | inrange ( ``ffind'' , 3694 , 3694 ) | inrange ( ``ffind'' , 3700 , 3700 ) | inrange ( ``ffind'' , 3710 , 3710 ) | inrange ( ``ffind'' , 3711 , 3711 ) | inrange ( ``ffind'' , 3713 , 3713 ) | inrange ( ``ffind'' , 3714 , 3714 ) | inrange ( ``ffind'' , 3715 , 3715 ) | inrange ( ``ffind'' , 3716 , 3716 ) | inrange ( ``ffind'' , 3792 , 3792 ) | inrange ( ``ffind'' , 3790 , 3791 ) | inrange ( ``ffind'' , 3799 , 3799 ) qui replace `generate' = 16 if inrange ( ``ffind'' , 3720 , 3720 ) | inrange ( ``ffind'' , 3721 , 3721 ) | inrange ( ``ffind'' , 3723 , 3724 ) | inrange ( ``ffind'' , 3725 , 3725 ) | inrange ( ``ffind'' , 3728 , 3729 ) | inrange ( ``ffind'' , 3730 , 3731 ) | inrange ( ``ffind'' , 3740 , 3743 ) qui replace `generate' = 17 if inrange ( ``ffind'' , 1000 , 1009 ) | inrange ( ``ffind'' , 1010 , 1019 ) | inrange ( ``ffind'' , 1020 , 1029 ) | inrange ( ``ffind'' , 1030 , 1039 ) | inrange ( ``ffind'' , 1040 , 1049 ) | inrange ( ``ffind'' , 1050 , 1059 ) | inrange ( ``ffind'' , 1060 , 1069 ) | inrange ( ``ffind'' , 1070 , 1079 ) | inrange ( ``ffind'' , 1080 , 1089 ) | inrange ( ``ffind'' , 1090 , 1099 ) | inrange ( ``ffind'' , 1100 , 1119 ) | inrange ( ``ffind'' , 1400 , 1499 ) qui replace `generate' = 18 if inrange ( ``ffind'' , 1200 , 1299 ) qui replace `generate' = 19 if inrange ( ``ffind'' , 1300 , 1300 ) | inrange ( ``ffind'' , 1310 , 1319 ) | inrange ( ``ffind'' , 1320 , 1329 ) | inrange ( ``ffind'' , 1330 , 1339 ) | inrange ( ``ffind'' , 1370 , 1379 ) | inrange ( ``ffind'' , 1380 , 1380 ) | inrange ( ``ffind'' , 1381 , 1381 ) | inrange ( ``ffind'' , 1382 , 1382 ) | inrange ( ``ffind'' , 1389 , 1389 ) | inrange ( ``ffind'' , 2900 , 2912 ) | inrange ( ``ffind'' , 2990 , 2999 ) qui replace `generate' = 20 if inrange ( ``ffind'' , 4900 , 4900 ) | inrange ( ``ffind'' , 4910 , 4911 ) | inrange ( ``ffind'' , 4920 , 4922 ) | inrange ( ``ffind'' , 4923 , 4923 ) | inrange ( ``ffind'' , 4924 , 4925 ) | inrange ( ``ffind'' , 4930 , 4931 ) | inrange ( ``ffind'' , 4932 , 4932 ) | inrange ( ``ffind'' , 4939 , 4939 ) | inrange ( ``ffind'' , 4940 , 4942 ) qui replace `generate' = 21 if inrange ( ``ffind'' , 4800 , 4800 ) | inrange ( ``ffind'' , 4810 , 4813 ) | inrange ( ``ffind'' , 4820 , 4822 ) | inrange ( ``ffind'' , 4830 , 4839 ) | inrange ( ``ffind'' , 4840 , 4841 ) | inrange ( ``ffind'' , 4880 , 4889 ) | inrange ( ``ffind'' , 4890 , 4890 ) | inrange ( ``ffind'' , 4891 , 4891 ) | inrange ( ``ffind'' , 4892 , 4892 ) | inrange ( ``ffind'' , 4899 , 4899 ) qui replace `generate' = 22 if inrange ( ``ffind'' , 7020 , 7021 ) | inrange ( ``ffind'' , 7030 , 7033 ) | inrange ( ``ffind'' , 7200 , 7200 ) | inrange ( ``ffind'' , 7210 , 7212 ) | inrange ( ``ffind'' , 7214 , 7214 ) | inrange ( ``ffind'' , 7215 , 7216 ) | inrange ( ``ffind'' , 7217 , 7217 ) | inrange ( ``ffind'' , 7218 , 7218 ) | inrange ( ``ffind'' , 7219 , 7219 ) | inrange ( ``ffind'' , 7220 , 7221 ) | inrange ( ``ffind'' , 7230 , 7231 ) | inrange ( ``ffind'' , 7240 , 7241 ) | inrange ( ``ffind'' , 7250 , 7251 ) | inrange ( ``ffind'' , 7260 , 7269 ) | inrange ( ``ffind'' , 7270 , 7290 ) | inrange ( ``ffind'' , 7291 , 7291 ) | inrange ( ``ffind'' , 7292 , 7299 ) | inrange ( ``ffind'' , 7300 , 7300 ) | inrange ( ``ffind'' , 7310 , 7319 ) | inrange ( ``ffind'' , 7320 , 7329 ) | inrange ( ``ffind'' , 7330 , 7339 ) | inrange ( ``ffind'' , 7340 , 7342 ) | inrange ( ``ffind'' , 7349 , 7349 ) | inrange ( ``ffind'' , 7350 , 7351 ) | inrange ( ``ffind'' , 7352 , 7352 ) | inrange ( ``ffind'' , 7353 , 7353 ) | inrange ( ``ffind'' , 7359 , 7359 ) | inrange ( ``ffind'' , 7360 , 7369 ) | inrange ( ``ffind'' , 7370 , 7372 ) | inrange ( ``ffind'' , 7374 , 7374 ) | inrange ( ``ffind'' , 7375 , 7375 ) | inrange ( ``ffind'' , 7376 , 7376 ) | inrange ( ``ffind'' , 7377 , 7377 ) | inrange ( ``ffind'' , 7378 , 7378 ) | inrange ( ``ffind'' , 7379 , 7379 ) | inrange ( ``ffind'' , 7380 , 7380 ) | inrange ( ``ffind'' , 7381 , 7382 ) | inrange ( ``ffind'' , 7383 , 7383 ) | inrange ( ``ffind'' , 7384 , 7384 ) | inrange ( ``ffind'' , 7385 , 7385 ) | inrange ( ``ffind'' , 7389 , 7390 ) | inrange ( ``ffind'' , 7391 , 7391 ) | inrange ( ``ffind'' , 7392 , 7392 ) | inrange ( ``ffind'' , 7393 , 7393 ) | inrange ( ``ffind'' , 7394 , 7394 ) | inrange ( ``ffind'' , 7395 , 7395 ) | inrange ( ``ffind'' , 7396 , 7396 ) | inrange ( ``ffind'' , 7397 , 7397 ) | inrange ( ``ffind'' , 7399 , 7399 ) | inrange ( ``ffind'' , 7500 , 7500 ) | inrange ( ``ffind'' , 7510 , 7519 ) | inrange ( ``ffind'' , 7520 , 7529 ) | inrange ( ``ffind'' , 7530 , 7539 ) | inrange ( ``ffind'' , 7540 , 7549 ) | inrange ( ``ffind'' , 7600 , 7600 ) | inrange ( ``ffind'' , 7620 , 7620 ) | inrange ( ``ffind'' , 7622 , 7622 ) | inrange ( ``ffind'' , 7623 , 7623 ) | inrange ( ``ffind'' , 7629 , 7629 ) | inrange ( ``ffind'' , 7630 , 7631 ) | inrange ( ``ffind'' , 7640 , 7641 ) | inrange ( ``ffind'' , 7690 , 7699 ) | inrange ( ``ffind'' , 8100 , 8199 ) | inrange ( ``ffind'' , 8200 , 8299 ) | inrange ( ``ffind'' , 8300 , 8399 ) | inrange ( ``ffind'' , 8400 , 8499 ) | inrange ( ``ffind'' , 8600 , 8699 ) | inrange ( ``ffind'' , 8700 , 8700 ) | inrange ( ``ffind'' , 8710 , 8713 ) | inrange ( ``ffind'' , 8720 , 8721 ) | inrange ( ``ffind'' , 8730 , 8734 ) | inrange ( ``ffind'' , 8740 , 8748 ) | inrange ( ``ffind'' , 8800 , 8899 ) | inrange ( ``ffind'' , 8900 , 8910 ) | inrange ( ``ffind'' , 8911 , 8911 ) | inrange ( ``ffind'' , 8920 , 8999 ) qui replace `generate' = 23 if inrange ( ``ffind'' , 3570 , 3579 ) | inrange ( ``ffind'' , 3622 , 3622 ) | inrange ( ``ffind'' , 3661 , 3661 ) | inrange ( ``ffind'' , 3662 , 3662 ) | inrange ( ``ffind'' , 3663 , 3663 ) | inrange ( ``ffind'' , 3664 , 3664 ) | inrange ( ``ffind'' , 3665 , 3665 ) | inrange ( ``ffind'' , 3666 , 3666 ) | inrange ( ``ffind'' , 3669 , 3669 ) | inrange ( ``ffind'' , 3670 , 3679 ) | inrange ( ``ffind'' , 3680 , 3680 ) | inrange ( ``ffind'' , 3681 , 3681 ) | inrange ( ``ffind'' , 3682 , 3682 ) | inrange ( ``ffind'' , 3683 , 3683 ) | inrange ( ``ffind'' , 3684 , 3684 ) | inrange ( ``ffind'' , 3685 , 3685 ) | inrange ( ``ffind'' , 3686 , 3686 ) | inrange ( ``ffind'' , 3687 , 3687 ) | inrange ( ``ffind'' , 3688 , 3688 ) | inrange ( ``ffind'' , 3689 , 3689 ) | inrange ( ``ffind'' , 3695 , 3695 ) | inrange ( ``ffind'' , 3810 , 3810 ) | inrange ( ``ffind'' , 3811 , 3811 ) | inrange ( ``ffind'' , 3812 , 3812 ) | inrange ( ``ffind'' , 3820 , 3820 ) | inrange ( ``ffind'' , 3821 , 3821 ) | inrange ( ``ffind'' , 3822 , 3822 ) | inrange ( ``ffind'' , 3823 , 3823 ) | inrange ( ``ffind'' , 3824 , 3824 ) | inrange ( ``ffind'' , 3825 , 3825 ) | inrange ( ``ffind'' , 3826 , 3826 ) | inrange ( ``ffind'' , 3827 , 3827 ) | inrange ( ``ffind'' , 3829 , 3829 ) | inrange ( ``ffind'' , 3830 , 3839 ) | inrange ( ``ffind'' , 7373 , 7373 ) qui replace `generate' = 24 if inrange ( ``ffind'' , 2440 , 2449 ) | inrange ( ``ffind'' , 2520 , 2549 ) | inrange ( ``ffind'' , 2600 , 2639 ) | inrange ( ``ffind'' , 2640 , 2659 ) | inrange ( ``ffind'' , 2670 , 2699 ) | inrange ( ``ffind'' , 2760 , 2761 ) | inrange ( ``ffind'' , 3220 , 3221 ) | inrange ( ``ffind'' , 3410 , 3412 ) | inrange ( ``ffind'' , 3950 , 3955 ) qui replace `generate' = 25 if inrange ( ``ffind'' , 4000 , 4013 ) | inrange ( ``ffind'' , 4040 , 4049 ) | inrange ( ``ffind'' , 4100 , 4100 ) | inrange ( ``ffind'' , 4110 , 4119 ) | inrange ( ``ffind'' , 4120 , 4121 ) | inrange ( ``ffind'' , 4130 , 4131 ) | inrange ( ``ffind'' , 4140 , 4142 ) | inrange ( ``ffind'' , 4150 , 4151 ) | inrange ( ``ffind'' , 4170 , 4173 ) | inrange ( ``ffind'' , 4190 , 4199 ) | inrange ( ``ffind'' , 4200 , 4200 ) | inrange ( ``ffind'' , 4210 , 4219 ) | inrange ( ``ffind'' , 4220 , 4229 ) | inrange ( ``ffind'' , 4230 , 4231 ) | inrange ( ``ffind'' , 4240 , 4249 ) | inrange ( ``ffind'' , 4400 , 4499 ) | inrange ( ``ffind'' , 4500 , 4599 ) | inrange ( ``ffind'' , 4600 , 4699 ) | inrange ( ``ffind'' , 4700 , 4700 ) | inrange ( ``ffind'' , 4710 , 4712 ) | inrange ( ``ffind'' , 4720 , 4729 ) | inrange ( ``ffind'' , 4730 , 4739 ) | inrange ( ``ffind'' , 4740 , 4749 ) | inrange ( ``ffind'' , 4780 , 4780 ) | inrange ( ``ffind'' , 4782 , 4782 ) | inrange ( ``ffind'' , 4783 , 4783 ) | inrange ( ``ffind'' , 4784 , 4784 ) | inrange ( ``ffind'' , 4785 , 4785 ) | inrange ( ``ffind'' , 4789 , 4789 ) qui replace `generate' = 26 if inrange ( ``ffind'' , 5000 , 5000 ) | inrange ( ``ffind'' , 5010 , 5015 ) | inrange ( ``ffind'' , 5020 , 5023 ) | inrange ( ``ffind'' , 5030 , 5039 ) | inrange ( ``ffind'' , 5040 , 5042 ) | inrange ( ``ffind'' , 5043 , 5043 ) | inrange ( ``ffind'' , 5044 , 5044 ) | inrange ( ``ffind'' , 5045 , 5045 ) | inrange ( ``ffind'' , 5046 , 5046 ) | inrange ( ``ffind'' , 5047 , 5047 ) | inrange ( ``ffind'' , 5048 , 5048 ) | inrange ( ``ffind'' , 5049 , 5049 ) | inrange ( ``ffind'' , 5050 , 5059 ) | inrange ( ``ffind'' , 5060 , 5060 ) | inrange ( ``ffind'' , 5063 , 5063 ) | inrange ( ``ffind'' , 5064 , 5064 ) | inrange ( ``ffind'' , 5065 , 5065 ) | inrange ( ``ffind'' , 5070 , 5078 ) | inrange ( ``ffind'' , 5080 , 5080 ) | inrange ( ``ffind'' , 5081 , 5081 ) | inrange ( ``ffind'' , 5082 , 5082 ) | inrange ( ``ffind'' , 5083 , 5083 ) | inrange ( ``ffind'' , 5084 , 5084 ) | inrange ( ``ffind'' , 5085 , 5085 ) | inrange ( ``ffind'' , 5086 , 5087 ) | inrange ( ``ffind'' , 5088 , 5088 ) | inrange ( ``ffind'' , 5090 , 5090 ) | inrange ( ``ffind'' , 5091 , 5092 ) | inrange ( ``ffind'' , 5093 , 5093 ) | inrange ( ``ffind'' , 5094 , 5094 ) | inrange ( ``ffind'' , 5099 , 5099 ) | inrange ( ``ffind'' , 5100 , 5100 ) | inrange ( ``ffind'' , 5110 , 5113 ) | inrange ( ``ffind'' , 5120 , 5122 ) | inrange ( ``ffind'' , 5130 , 5139 ) | inrange ( ``ffind'' , 5140 , 5149 ) | inrange ( ``ffind'' , 5150 , 5159 ) | inrange ( ``ffind'' , 5160 , 5169 ) | inrange ( ``ffind'' , 5170 , 5172 ) | inrange ( ``ffind'' , 5180 , 5182 ) | inrange ( ``ffind'' , 5190 , 5199 ) qui replace `generate' = 27 if inrange ( ``ffind'' , 5200 , 5200 ) | inrange ( ``ffind'' , 5210 , 5219 ) | inrange ( ``ffind'' , 5220 , 5229 ) | inrange ( ``ffind'' , 5230 , 5231 ) | inrange ( ``ffind'' , 5250 , 5251 ) | inrange ( ``ffind'' , 5260 , 5261 ) | inrange ( ``ffind'' , 5270 , 5271 ) | inrange ( ``ffind'' , 5300 , 5300 ) | inrange ( ``ffind'' , 5310 , 5311 ) | inrange ( ``ffind'' , 5320 , 5320 ) | inrange ( ``ffind'' , 5330 , 5331 ) | inrange ( ``ffind'' , 5334 , 5334 ) | inrange ( ``ffind'' , 5340 , 5349 ) | inrange ( ``ffind'' , 5390 , 5399 ) | inrange ( ``ffind'' , 5400 , 5400 ) | inrange ( ``ffind'' , 5410 , 5411 ) | inrange ( ``ffind'' , 5412 , 5412 ) | inrange ( ``ffind'' , 5420 , 5429 ) | inrange ( ``ffind'' , 5430 , 5439 ) | inrange ( ``ffind'' , 5440 , 5449 ) | inrange ( ``ffind'' , 5450 , 5459 ) | inrange ( ``ffind'' , 5460 , 5469 ) | inrange ( ``ffind'' , 5490 , 5499 ) | inrange ( ``ffind'' , 5500 , 5500 ) | inrange ( ``ffind'' , 5510 , 5529 ) | inrange ( ``ffind'' , 5530 , 5539 ) | inrange ( ``ffind'' , 5540 , 5549 ) | inrange ( ``ffind'' , 5550 , 5559 ) | inrange ( ``ffind'' , 5560 , 5569 ) | inrange ( ``ffind'' , 5570 , 5579 ) | inrange ( ``ffind'' , 5590 , 5599 ) | inrange ( ``ffind'' , 5600 , 5699 ) | inrange ( ``ffind'' , 5700 , 5700 ) | inrange ( ``ffind'' , 5710 , 5719 ) | inrange ( ``ffind'' , 5720 , 5722 ) | inrange ( ``ffind'' , 5730 , 5733 ) | inrange ( ``ffind'' , 5734 , 5734 ) | inrange ( ``ffind'' , 5735 , 5735 ) | inrange ( ``ffind'' , 5736 , 5736 ) | inrange ( ``ffind'' , 5750 , 5799 ) | inrange ( ``ffind'' , 5900 , 5900 ) | inrange ( ``ffind'' , 5910 , 5912 ) | inrange ( ``ffind'' , 5920 , 5929 ) | inrange ( ``ffind'' , 5930 , 5932 ) | inrange ( ``ffind'' , 5940 , 5940 ) | inrange ( ``ffind'' , 5941 , 5941 ) | inrange ( ``ffind'' , 5942 , 5942 ) | inrange ( ``ffind'' , 5943 , 5943 ) | inrange ( ``ffind'' , 5944 , 5944 ) | inrange ( ``ffind'' , 5945 , 5945 ) | inrange ( ``ffind'' , 5946 , 5946 ) | inrange ( ``ffind'' , 5947 , 5947 ) | inrange ( ``ffind'' , 5948 , 5948 ) | inrange ( ``ffind'' , 5949 , 5949 ) | inrange ( ``ffind'' , 5950 , 5959 ) | inrange ( ``ffind'' , 5960 , 5969 ) | inrange ( ``ffind'' , 5970 , 5979 ) | inrange ( ``ffind'' , 5980 , 5989 ) | inrange ( ``ffind'' , 5990 , 5990 ) | inrange ( ``ffind'' , 5992 , 5992 ) | inrange ( ``ffind'' , 5993 , 5993 ) | inrange ( ``ffind'' , 5994 , 5994 ) | inrange ( ``ffind'' , 5995 , 5995 ) | inrange ( ``ffind'' , 5999 , 5999 ) qui replace `generate' = 28 if inrange ( ``ffind'' , 5800 , 5819 ) | inrange ( ``ffind'' , 5820 , 5829 ) | inrange ( ``ffind'' , 5890 , 5899 ) | inrange ( ``ffind'' , 7000 , 7000 ) | inrange ( ``ffind'' , 7010 , 7019 ) | inrange ( ``ffind'' , 7040 , 7049 ) | inrange ( ``ffind'' , 7213 , 7213 ) qui replace `generate' = 29 if inrange ( ``ffind'' , 6000 , 6000 ) | inrange ( ``ffind'' , 6010 , 6019 ) | inrange ( ``ffind'' , 6020 , 6020 ) | inrange ( ``ffind'' , 6021 , 6021 ) | inrange ( ``ffind'' , 6022 , 6022 ) | inrange ( ``ffind'' , 6023 , 6024 ) | inrange ( ``ffind'' , 6025 , 6025 ) | inrange ( ``ffind'' , 6026 , 6026 ) | inrange ( ``ffind'' , 6027 , 6027 ) | inrange ( ``ffind'' , 6028 , 6029 ) | inrange ( ``ffind'' , 6030 , 6036 ) | inrange ( ``ffind'' , 6040 , 6059 ) | inrange ( ``ffind'' , 6060 , 6062 ) | inrange ( ``ffind'' , 6080 , 6082 ) | inrange ( ``ffind'' , 6090 , 6099 ) | inrange ( ``ffind'' , 6100 , 6100 ) | inrange ( ``ffind'' , 6110 , 6111 ) | inrange ( ``ffind'' , 6112 , 6113 ) | inrange ( ``ffind'' , 6120 , 6129 ) | inrange ( ``ffind'' , 6130 , 6139 ) | inrange ( ``ffind'' , 6140 , 6149 ) | inrange ( ``ffind'' , 6150 , 6159 ) | inrange ( ``ffind'' , 6160 , 6169 ) | inrange ( ``ffind'' , 6170 , 6179 ) | inrange ( ``ffind'' , 6190 , 6199 ) | inrange ( ``ffind'' , 6200 , 6299 ) | inrange ( ``ffind'' , 6300 , 6300 ) | inrange ( ``ffind'' , 6310 , 6319 ) | inrange ( ``ffind'' , 6320 , 6329 ) | inrange ( ``ffind'' , 6330 , 6331 ) | inrange ( ``ffind'' , 6350 , 6351 ) | inrange ( ``ffind'' , 6360 , 6361 ) | inrange ( ``ffind'' , 6370 , 6379 ) | inrange ( ``ffind'' , 6390 , 6399 ) | inrange ( ``ffind'' , 6400 , 6411 ) | inrange ( ``ffind'' , 6500 , 6500 ) | inrange ( ``ffind'' , 6510 , 6510 ) | inrange ( ``ffind'' , 6512 , 6512 ) | inrange ( ``ffind'' , 6513 , 6513 ) | inrange ( ``ffind'' , 6514 , 6514 ) | inrange ( ``ffind'' , 6515 , 6515 ) | inrange ( ``ffind'' , 6517 , 6519 ) | inrange ( ``ffind'' , 6520 , 6529 ) | inrange ( ``ffind'' , 6530 , 6531 ) | inrange ( ``ffind'' , 6532 , 6532 ) | inrange ( ``ffind'' , 6540 , 6541 ) | inrange ( ``ffind'' , 6550 , 6553 ) | inrange ( ``ffind'' , 6590 , 6599 ) | inrange ( ``ffind'' , 6610 , 6611 ) | inrange ( ``ffind'' , 6700 , 6700 ) | inrange ( ``ffind'' , 6710 , 6719 ) | inrange ( ``ffind'' , 6720 , 6722 ) | inrange ( ``ffind'' , 6723 , 6723 ) | inrange ( ``ffind'' , 6724 , 6724 ) | inrange ( ``ffind'' , 6725 , 6725 ) | inrange ( ``ffind'' , 6726 , 6726 ) | inrange ( ``ffind'' , 6730 , 6733 ) | inrange ( ``ffind'' , 6740 , 6779 ) | inrange ( ``ffind'' , 6790 , 6791 ) | inrange ( ``ffind'' , 6792 , 6792 ) | inrange ( ``ffind'' , 6793 , 6793 ) | inrange ( ``ffind'' , 6794 , 6794 ) | inrange ( ``ffind'' , 6795 , 6795 ) | inrange ( ``ffind'' , 6798 , 6798 ) | inrange ( ``ffind'' , 6799 , 6799 ) qui replace `generate' = 30 if missing ( `generate' ) & ~ missing ( ``ffind'' ) } else if ``ftyp'' == 38 { label define `generate' 1 \"Agriculture, forestry, and fishing\" 2 \"Mining\" 3 \"Oil and Gas Extraction\" 4 \"Nonmetalic Minerals Except Fuels\" 5 \"Construction\" 6 \"Food and Kindred Products\" 7 \"Tobacco Products\" 8 \"Textile Mill Products\" 9 \"Apparel and other Textile Products\" 10 \"Lumber and Wood Products\" 11 \"Furniture and Fixtures\" 12 \"Paper and Allied Products\" 13 \"Printing and Publishing\" 14 \"Chemicals and Allied Products\" 15 \"Petroleum and Coal Products\" 16 \"Rubber and Miscellaneous Plastics Products\" 17 \"Leather and Leather Products\" 18 \"Stone, Clay and Glass Products\" 19 \"Primary Metal Industries\" 20 \"Fabricated Metal Products\" 21 \"Machinery, Except Electrical\" 22 \"Electrical and Electronic Equipment\" 23 \"Transportation Equipment\" 24 \"Instruments and Related Products\" 25 \"Miscellaneous Manufacturing Industries\" 26 \"Transportation\" 27 \"Telephone and Telegraph Communication\" 28 \"Radio and Television Broadcasting\" 29 \"Electric, Gas, and Water Supply\" 30 \"Sanitary Services\" 31 \"Steam Supply\" 32 \"Irrigation Systems\" 33 \"Wholesale\" 34 \"Retail Stores\" 35 \"Finance, Insurance, and Real Estate\" 36 \"Services\" 37 \"Public Administration\" 38 \"Almost Nothing\" label values `generate' `generate' qui replace `generate' = 1 if inrange ( ``ffind'' , 100 , 999 ) qui replace `generate' = 2 if inrange ( ``ffind'' , 1000 , 1299 ) qui replace `generate' = 3 if inrange ( ``ffind'' , 1300 , 1399 ) qui replace `generate' = 4 if inrange ( ``ffind'' , 1400 , 1499 ) qui replace `generate' = 5 if inrange ( ``ffind'' , 1500 , 1799 ) qui replace `generate' = 6 if inrange ( ``ffind'' , 2000 , 2099 ) qui replace `generate' = 7 if inrange ( ``ffind'' , 2100 , 2199 ) qui replace `generate' = 8 if inrange ( ``ffind'' , 2200 , 2299 ) qui replace `generate' = 9 if inrange ( ``ffind'' , 2300 , 2399 ) qui replace `generate' = 10 if inrange ( ``ffind'' , 2400 , 2499 ) qui replace `generate' = 11 if inrange ( ``ffind'' , 2500 , 2599 ) qui replace `generate' = 12 if inrange ( ``ffind'' , 2600 , 2661 ) qui replace `generate' = 13 if inrange ( ``ffind'' , 2700 , 2799 ) qui replace `generate' = 14 if inrange ( ``ffind'' , 2800 , 2899 ) qui replace `generate' = 15 if inrange ( ``ffind'' , 2900 , 2999 ) qui replace `generate' = 16 if inrange ( ``ffind'' , 3000 , 3099 ) qui replace `generate' = 17 if inrange ( ``ffind'' , 3100 , 3199 ) qui replace `generate' = 18 if inrange ( ``ffind'' , 3200 , 3299 ) qui replace `generate' = 19 if inrange ( ``ffind'' , 3300 , 3399 ) qui replace `generate' = 20 if inrange ( ``ffind'' , 3400 , 3499 ) qui replace `generate' = 21 if inrange ( ``ffind'' , 3500 , 3599 ) qui replace `generate' = 22 if inrange ( ``ffind'' , 3600 , 3699 ) qui replace `generate' = 23 if inrange ( ``ffind'' , 3700 , 3799 ) qui replace `generate' = 24 if inrange ( ``ffind'' , 3800 , 3879 ) qui replace `generate' = 25 if inrange ( ``ffind'' , 3900 , 3999 ) qui replace `generate' = 26 if inrange ( ``ffind'' , 4000 , 4799 ) qui replace `generate' = 27 if inrange ( ``ffind'' , 4800 , 4829 ) qui replace `generate' = 28 if inrange ( ``ffind'' , 4830 , 4899 ) qui replace `generate' = 29 if inrange ( ``ffind'' , 4900 , 4949 ) qui replace `generate' = 30 if inrange ( ``ffind'' , 4950 , 4959 ) qui replace `generate' = 31 if inrange ( ``ffind'' , 4960 , 4969 ) qui replace `generate' = 32 if inrange ( ``ffind'' , 4970 , 4979 ) qui replace `generate' = 33 if inrange ( ``ffind'' , 5000 , 5199 ) qui replace `generate' = 34 if inrange ( ``ffind'' , 5200 , 5999 ) qui replace `generate' = 35 if inrange ( ``ffind'' , 6000 , 6999 ) qui replace `generate' = 36 if inrange ( ``ffind'' , 7000 , 8999 ) qui replace `generate' = 37 if inrange ( ``ffind'' , 9000 , 9999 ) qui replace `generate' = 38 if missing ( `generate' ) & ~ missing ( ``ffind'' ) } else if ``ftyp'' == 48 { label define `generate' 1 \"Agriculture\" 2 \"Food Products\" 3 \"Candy & Soda\" 4 \"Beer & Liquor\" 5 \"Tobacco Products\" 6 \"Recreation\" 7 \"Entertainment\" 8 \"Printing and Publishing\" 9 \"Consumer Goods\" 10 \"Apparel\" 11 \"Healthcare\" 12 \"Medical Equipment\" 13 \"Pharmaceutical Products\" 14 \"Chemicals\" 15 \"Rubber and Plastic Products\" 16 \"Textiles\" 17 \"Construction Materials\" 18 \"Construction\" 19 \"Steel Works Etc\" 20 \"Fabricated Products\" 21 \"Machinery\" 22 \"Electrical Equipment\" 23 \"Automobiles and Trucks\" 24 \"Aircraft\" 25 \"Shipbuilding, Railroad Equipment\" 26 \"Defense\" 27 \"Precious Metals\" 28 \"Non-Metallic and Industrial Metal Mining\" 29 \"Coal\" 30 \"Petroleum and Natural Gas\" 31 \"Utilities\" 32 \"Communication\" 33 \"Personal Services\" 34 \"Business Services\" 35 \"Computers\" 36 \"Electronic Equipment\" 37 \"Measuring and Control Equipment\" 38 \"Business Supplies\" 39 \"Shipping Containers\" 40 \"Transportation\" 41 \"Wholesale\" 42 \"Retail\" 43 \"Restaraunts, Hotels, Motels\" 44 \"Banking\" 45 \"Insurance\" 46 \"Real Estate\" 47 \"Trading\" 48 \"Almost Nothing\" label values `generate' `generate' qui replace `generate' = 1 if inrange ( ``ffind'' , 100 , 199 ) | inrange ( ``ffind'' , 200 , 299 ) | inrange ( ``ffind'' , 700 , 799 ) | inrange ( ``ffind'' , 910 , 919 ) | inrange ( ``ffind'' , 2048 , 2048 ) qui replace `generate' = 2 if inrange ( ``ffind'' , 2000 , 2009 ) | inrange ( ``ffind'' , 2010 , 2019 ) | inrange ( ``ffind'' , 2020 , 2029 ) | inrange ( ``ffind'' , 2030 , 2039 ) | inrange ( ``ffind'' , 2040 , 2046 ) | inrange ( ``ffind'' , 2050 , 2059 ) | inrange ( ``ffind'' , 2060 , 2063 ) | inrange ( ``ffind'' , 2070 , 2079 ) | inrange ( ``ffind'' , 2090 , 2092 ) | inrange ( ``ffind'' , 2095 , 2095 ) | inrange ( ``ffind'' , 2098 , 2099 ) qui replace `generate' = 3 if inrange ( ``ffind'' , 2064 , 2068 ) | inrange ( ``ffind'' , 2086 , 2086 ) | inrange ( ``ffind'' , 2087 , 2087 ) | inrange ( ``ffind'' , 2096 , 2096 ) | inrange ( ``ffind'' , 2097 , 2097 ) qui replace `generate' = 4 if inrange ( ``ffind'' , 2080 , 2080 ) | inrange ( ``ffind'' , 2082 , 2082 ) | inrange ( ``ffind'' , 2083 , 2083 ) | inrange ( ``ffind'' , 2084 , 2084 ) | inrange ( ``ffind'' , 2085 , 2085 ) qui replace `generate' = 5 if inrange ( ``ffind'' , 2100 , 2199 ) qui replace `generate' = 6 if inrange ( ``ffind'' , 920 , 999 ) | inrange ( ``ffind'' , 3650 , 3651 ) | inrange ( ``ffind'' , 3652 , 3652 ) | inrange ( ``ffind'' , 3732 , 3732 ) | inrange ( ``ffind'' , 3930 , 3931 ) | inrange ( ``ffind'' , 3940 , 3949 ) qui replace `generate' = 7 if inrange ( ``ffind'' , 7800 , 7829 ) | inrange ( ``ffind'' , 7830 , 7833 ) | inrange ( ``ffind'' , 7840 , 7841 ) | inrange ( ``ffind'' , 7900 , 7900 ) | inrange ( ``ffind'' , 7910 , 7911 ) | inrange ( ``ffind'' , 7920 , 7929 ) | inrange ( ``ffind'' , 7930 , 7933 ) | inrange ( ``ffind'' , 7940 , 7949 ) | inrange ( ``ffind'' , 7980 , 7980 ) | inrange ( ``ffind'' , 7990 , 7999 ) qui replace `generate' = 8 if inrange ( ``ffind'' , 2700 , 2709 ) | inrange ( ``ffind'' , 2710 , 2719 ) | inrange ( ``ffind'' , 2720 , 2729 ) | inrange ( ``ffind'' , 2730 , 2739 ) | inrange ( ``ffind'' , 2740 , 2749 ) | inrange ( ``ffind'' , 2770 , 2771 ) | inrange ( ``ffind'' , 2780 , 2789 ) | inrange ( ``ffind'' , 2790 , 2799 ) qui replace `generate' = 9 if inrange ( ``ffind'' , 2047 , 2047 ) | inrange ( ``ffind'' , 2391 , 2392 ) | inrange ( ``ffind'' , 2510 , 2519 ) | inrange ( ``ffind'' , 2590 , 2599 ) | inrange ( ``ffind'' , 2840 , 2843 ) | inrange ( ``ffind'' , 2844 , 2844 ) | inrange ( ``ffind'' , 3160 , 3161 ) | inrange ( ``ffind'' , 3170 , 3171 ) | inrange ( ``ffind'' , 3172 , 3172 ) | inrange ( ``ffind'' , 3190 , 3199 ) | inrange ( ``ffind'' , 3229 , 3229 ) | inrange ( ``ffind'' , 3260 , 3260 ) | inrange ( ``ffind'' , 3262 , 3263 ) | inrange ( ``ffind'' , 3269 , 3269 ) | inrange ( ``ffind'' , 3230 , 3231 ) | inrange ( ``ffind'' , 3630 , 3639 ) | inrange ( ``ffind'' , 3750 , 3751 ) | inrange ( ``ffind'' , 3800 , 3800 ) | inrange ( ``ffind'' , 3860 , 3861 ) | inrange ( ``ffind'' , 3870 , 3873 ) | inrange ( ``ffind'' , 3910 , 3911 ) | inrange ( ``ffind'' , 3914 , 3914 ) | inrange ( ``ffind'' , 3915 , 3915 ) | inrange ( ``ffind'' , 3960 , 3962 ) | inrange ( ``ffind'' , 3991 , 3991 ) | inrange ( ``ffind'' , 3995 , 3995 ) qui replace `generate' = 10 if inrange ( ``ffind'' , 2300 , 2390 ) | inrange ( ``ffind'' , 3020 , 3021 ) | inrange ( ``ffind'' , 3100 , 3111 ) | inrange ( ``ffind'' , 3130 , 3131 ) | inrange ( ``ffind'' , 3140 , 3149 ) | inrange ( ``ffind'' , 3150 , 3151 ) | inrange ( ``ffind'' , 3963 , 3965 ) qui replace `generate' = 11 if inrange ( ``ffind'' , 8000 , 8099 ) qui replace `generate' = 12 if inrange ( ``ffind'' , 3693 , 3693 ) | inrange ( ``ffind'' , 3840 , 3849 ) | inrange ( ``ffind'' , 3850 , 3851 ) qui replace `generate' = 13 if inrange ( ``ffind'' , 2830 , 2830 ) | inrange ( ``ffind'' , 2831 , 2831 ) | inrange ( ``ffind'' , 2833 , 2833 ) | inrange ( ``ffind'' , 2834 , 2834 ) | inrange ( ``ffind'' , 2835 , 2835 ) | inrange ( ``ffind'' , 2836 , 2836 ) qui replace `generate' = 14 if inrange ( ``ffind'' , 2800 , 2809 ) | inrange ( ``ffind'' , 2810 , 2819 ) | inrange ( ``ffind'' , 2820 , 2829 ) | inrange ( ``ffind'' , 2850 , 2859 ) | inrange ( ``ffind'' , 2860 , 2869 ) | inrange ( ``ffind'' , 2870 , 2879 ) | inrange ( ``ffind'' , 2890 , 2899 ) qui replace `generate' = 15 if inrange ( ``ffind'' , 3031 , 3031 ) | inrange ( ``ffind'' , 3041 , 3041 ) | inrange ( ``ffind'' , 3050 , 3053 ) | inrange ( ``ffind'' , 3060 , 3069 ) | inrange ( ``ffind'' , 3070 , 3079 ) | inrange ( ``ffind'' , 3080 , 3089 ) | inrange ( ``ffind'' , 3090 , 3099 ) qui replace `generate' = 16 if inrange ( ``ffind'' , 2200 , 2269 ) | inrange ( ``ffind'' , 2270 , 2279 ) | inrange ( ``ffind'' , 2280 , 2284 ) | inrange ( ``ffind'' , 2290 , 2295 ) | inrange ( ``ffind'' , 2297 , 2297 ) | inrange ( ``ffind'' , 2298 , 2298 ) | inrange ( ``ffind'' , 2299 , 2299 ) | inrange ( ``ffind'' , 2393 , 2395 ) | inrange ( ``ffind'' , 2397 , 2399 ) qui replace `generate' = 17 if inrange ( ``ffind'' , 800 , 899 ) | inrange ( ``ffind'' , 2400 , 2439 ) | inrange ( ``ffind'' , 2450 , 2459 ) | inrange ( ``ffind'' , 2490 , 2499 ) | inrange ( ``ffind'' , 2660 , 2661 ) | inrange ( ``ffind'' , 2950 , 2952 ) | inrange ( ``ffind'' , 3200 , 3200 ) | inrange ( ``ffind'' , 3210 , 3211 ) | inrange ( ``ffind'' , 3240 , 3241 ) | inrange ( ``ffind'' , 3250 , 3259 ) | inrange ( ``ffind'' , 3261 , 3261 ) | inrange ( ``ffind'' , 3264 , 3264 ) | inrange ( ``ffind'' , 3270 , 3275 ) | inrange ( ``ffind'' , 3280 , 3281 ) | inrange ( ``ffind'' , 3290 , 3293 ) | inrange ( ``ffind'' , 3295 , 3299 ) | inrange ( ``ffind'' , 3420 , 3429 ) | inrange ( ``ffind'' , 3430 , 3433 ) | inrange ( ``ffind'' , 3440 , 3441 ) | inrange ( ``ffind'' , 3442 , 3442 ) | inrange ( ``ffind'' , 3446 , 3446 ) | inrange ( ``ffind'' , 3448 , 3448 ) | inrange ( ``ffind'' , 3449 , 3449 ) | inrange ( ``ffind'' , 3450 , 3451 ) | inrange ( ``ffind'' , 3452 , 3452 ) | inrange ( ``ffind'' , 3490 , 3499 ) | inrange ( ``ffind'' , 3996 , 3996 ) qui replace `generate' = 18 if inrange ( ``ffind'' , 1500 , 1511 ) | inrange ( ``ffind'' , 1520 , 1529 ) | inrange ( ``ffind'' , 1530 , 1539 ) | inrange ( ``ffind'' , 1540 , 1549 ) | inrange ( ``ffind'' , 1600 , 1699 ) | inrange ( ``ffind'' , 1700 , 1799 ) qui replace `generate' = 19 if inrange ( ``ffind'' , 3300 , 3300 ) | inrange ( ``ffind'' , 3310 , 3317 ) | inrange ( ``ffind'' , 3320 , 3325 ) | inrange ( ``ffind'' , 3330 , 3339 ) | inrange ( ``ffind'' , 3340 , 3341 ) | inrange ( ``ffind'' , 3350 , 3357 ) | inrange ( ``ffind'' , 3360 , 3369 ) | inrange ( ``ffind'' , 3370 , 3379 ) | inrange ( ``ffind'' , 3390 , 3399 ) qui replace `generate' = 20 if inrange ( ``ffind'' , 3400 , 3400 ) | inrange ( ``ffind'' , 3443 , 3443 ) | inrange ( ``ffind'' , 3444 , 3444 ) | inrange ( ``ffind'' , 3460 , 3469 ) | inrange ( ``ffind'' , 3470 , 3479 ) qui replace `generate' = 21 if inrange ( ``ffind'' , 3510 , 3519 ) | inrange ( ``ffind'' , 3520 , 3529 ) | inrange ( ``ffind'' , 3530 , 3530 ) | inrange ( ``ffind'' , 3531 , 3531 ) | inrange ( ``ffind'' , 3532 , 3532 ) | inrange ( ``ffind'' , 3533 , 3533 ) | inrange ( ``ffind'' , 3534 , 3534 ) | inrange ( ``ffind'' , 3535 , 3535 ) | inrange ( ``ffind'' , 3536 , 3536 ) | inrange ( ``ffind'' , 3538 , 3538 ) | inrange ( ``ffind'' , 3540 , 3549 ) | inrange ( ``ffind'' , 3550 , 3559 ) | inrange ( ``ffind'' , 3560 , 3569 ) | inrange ( ``ffind'' , 3580 , 3580 ) | inrange ( ``ffind'' , 3581 , 3581 ) | inrange ( ``ffind'' , 3582 , 3582 ) | inrange ( ``ffind'' , 3585 , 3585 ) | inrange ( ``ffind'' , 3586 , 3586 ) | inrange ( ``ffind'' , 3589 , 3589 ) | inrange ( ``ffind'' , 3590 , 3599 ) qui replace `generate' = 22 if inrange ( ``ffind'' , 3600 , 3600 ) | inrange ( ``ffind'' , 3610 , 3613 ) | inrange ( ``ffind'' , 3620 , 3621 ) | inrange ( ``ffind'' , 3623 , 3629 ) | inrange ( ``ffind'' , 3640 , 3644 ) | inrange ( ``ffind'' , 3645 , 3645 ) | inrange ( ``ffind'' , 3646 , 3646 ) | inrange ( ``ffind'' , 3648 , 3649 ) | inrange ( ``ffind'' , 3660 , 3660 ) | inrange ( ``ffind'' , 3690 , 3690 ) | inrange ( ``ffind'' , 3691 , 3692 ) | inrange ( ``ffind'' , 3699 , 3699 ) qui replace `generate' = 23 if inrange ( ``ffind'' , 2296 , 2296 ) | inrange ( ``ffind'' , 2396 , 2396 ) | inrange ( ``ffind'' , 3010 , 3011 ) | inrange ( ``ffind'' , 3537 , 3537 ) | inrange ( ``ffind'' , 3647 , 3647 ) | inrange ( ``ffind'' , 3694 , 3694 ) | inrange ( ``ffind'' , 3700 , 3700 ) | inrange ( ``ffind'' , 3710 , 3710 ) | inrange ( ``ffind'' , 3711 , 3711 ) | inrange ( ``ffind'' , 3713 , 3713 ) | inrange ( ``ffind'' , 3714 , 3714 ) | inrange ( ``ffind'' , 3715 , 3715 ) | inrange ( ``ffind'' , 3716 , 3716 ) | inrange ( ``ffind'' , 3792 , 3792 ) | inrange ( ``ffind'' , 3790 , 3791 ) | inrange ( ``ffind'' , 3799 , 3799 ) qui replace `generate' = 24 if inrange ( ``ffind'' , 3720 , 3720 ) | inrange ( ``ffind'' , 3721 , 3721 ) | inrange ( ``ffind'' , 3723 , 3724 ) | inrange ( ``ffind'' , 3725 , 3725 ) | inrange ( ``ffind'' , 3728 , 3729 ) qui replace `generate' = 25 if inrange ( ``ffind'' , 3730 , 3731 ) | inrange ( ``ffind'' , 3740 , 3743 ) qui replace `generate' = 26 if inrange ( ``ffind'' , 3760 , 3769 ) | inrange ( ``ffind'' , 3795 , 3795 ) | inrange ( ``ffind'' , 3480 , 3489 ) qui replace `generate' = 27 if inrange ( ``ffind'' , 1040 , 1049 ) qui replace `generate' = 28 if inrange ( ``ffind'' , 1000 , 1009 ) | inrange ( ``ffind'' , 1010 , 1019 ) | inrange ( ``ffind'' , 1020 , 1029 ) | inrange ( ``ffind'' , 1030 , 1039 ) | inrange ( ``ffind'' , 1050 , 1059 ) | inrange ( ``ffind'' , 1060 , 1069 ) | inrange ( ``ffind'' , 1070 , 1079 ) | inrange ( ``ffind'' , 1080 , 1089 ) | inrange ( ``ffind'' , 1090 , 1099 ) | inrange ( ``ffind'' , 1100 , 1119 ) | inrange ( ``ffind'' , 1400 , 1499 ) qui replace `generate' = 29 if inrange ( ``ffind'' , 1200 , 1299 ) qui replace `generate' = 30 if inrange ( ``ffind'' , 1300 , 1300 ) | inrange ( ``ffind'' , 1310 , 1319 ) | inrange ( ``ffind'' , 1320 , 1329 ) | inrange ( ``ffind'' , 1330 , 1339 ) | inrange ( ``ffind'' , 1370 , 1379 ) | inrange ( ``ffind'' , 1380 , 1380 ) | inrange ( ``ffind'' , 1381 , 1381 ) | inrange ( ``ffind'' , 1382 , 1382 ) | inrange ( ``ffind'' , 1389 , 1389 ) | inrange ( ``ffind'' , 2900 , 2912 ) | inrange ( ``ffind'' , 2990 , 2999 ) qui replace `generate' = 31 if inrange ( ``ffind'' , 4900 , 4900 ) | inrange ( ``ffind'' , 4910 , 4911 ) | inrange ( ``ffind'' , 4920 , 4922 ) | inrange ( ``ffind'' , 4923 , 4923 ) | inrange ( ``ffind'' , 4924 , 4925 ) | inrange ( ``ffind'' , 4930 , 4931 ) | inrange ( ``ffind'' , 4932 , 4932 ) | inrange ( ``ffind'' , 4939 , 4939 ) | inrange ( ``ffind'' , 4940 , 4942 ) qui replace `generate' = 32 if inrange ( ``ffind'' , 4800 , 4800 ) | inrange ( ``ffind'' , 4810 , 4813 ) | inrange ( ``ffind'' , 4820 , 4822 ) | inrange ( ``ffind'' , 4830 , 4839 ) | inrange ( ``ffind'' , 4840 , 4841 ) | inrange ( ``ffind'' , 4880 , 4889 ) | inrange ( ``ffind'' , 4890 , 4890 ) | inrange ( ``ffind'' , 4891 , 4891 ) | inrange ( ``ffind'' , 4892 , 4892 ) | inrange ( ``ffind'' , 4899 , 4899 ) qui replace `generate' = 33 if inrange ( ``ffind'' , 7020 , 7021 ) | inrange ( ``ffind'' , 7030 , 7033 ) | inrange ( ``ffind'' , 7200 , 7200 ) | inrange ( ``ffind'' , 7210 , 7212 ) | inrange ( ``ffind'' , 7214 , 7214 ) | inrange ( ``ffind'' , 7215 , 7216 ) | inrange ( ``ffind'' , 7217 , 7217 ) | inrange ( ``ffind'' , 7219 , 7219 ) | inrange ( ``ffind'' , 7220 , 7221 ) | inrange ( ``ffind'' , 7230 , 7231 ) | inrange ( ``ffind'' , 7240 , 7241 ) | inrange ( ``ffind'' , 7250 , 7251 ) | inrange ( ``ffind'' , 7260 , 7269 ) | inrange ( ``ffind'' , 7270 , 7290 ) | inrange ( ``ffind'' , 7291 , 7291 ) | inrange ( ``ffind'' , 7292 , 7299 ) | inrange ( ``ffind'' , 7395 , 7395 ) | inrange ( ``ffind'' , 7500 , 7500 ) | inrange ( ``ffind'' , 7520 , 7529 ) | inrange ( ``ffind'' , 7530 , 7539 ) | inrange ( ``ffind'' , 7540 , 7549 ) | inrange ( ``ffind'' , 7600 , 7600 ) | inrange ( ``ffind'' , 7620 , 7620 ) | inrange ( ``ffind'' , 7622 , 7622 ) | inrange ( ``ffind'' , 7623 , 7623 ) | inrange ( ``ffind'' , 7629 , 7629 ) | inrange ( ``ffind'' , 7630 , 7631 ) | inrange ( ``ffind'' , 7640 , 7641 ) | inrange ( ``ffind'' , 7690 , 7699 ) | inrange ( ``ffind'' , 8100 , 8199 ) | inrange ( ``ffind'' , 8200 , 8299 ) | inrange ( ``ffind'' , 8300 , 8399 ) | inrange ( ``ffind'' , 8400 , 8499 ) | inrange ( ``ffind'' , 8600 , 8699 ) | inrange ( ``ffind'' , 8800 , 8899 ) | inrange ( ``ffind'' , 7510 , 7515 ) qui replace `generate' = 34 if inrange ( ``ffind'' , 2750 , 2759 ) | inrange ( ``ffind'' , 3993 , 3993 ) | inrange ( ``ffind'' , 7218 , 7218 ) | inrange ( ``ffind'' , 7300 , 7300 ) | inrange ( ``ffind'' , 7310 , 7319 ) | inrange ( ``ffind'' , 7320 , 7329 ) | inrange ( ``ffind'' , 7330 , 7339 ) | inrange ( ``ffind'' , 7340 , 7342 ) | inrange ( ``ffind'' , 7349 , 7349 ) | inrange ( ``ffind'' , 7350 , 7351 ) | inrange ( ``ffind'' , 7352 , 7352 ) | inrange ( ``ffind'' , 7353 , 7353 ) | inrange ( ``ffind'' , 7359 , 7359 ) | inrange ( ``ffind'' , 7360 , 7369 ) | inrange ( ``ffind'' , 7370 , 7372 ) | inrange ( ``ffind'' , 7374 , 7374 ) | inrange ( ``ffind'' , 7375 , 7375 ) | inrange ( ``ffind'' , 7376 , 7376 ) | inrange ( ``ffind'' , 7377 , 7377 ) | inrange ( ``ffind'' , 7378 , 7378 ) | inrange ( ``ffind'' , 7379 , 7379 ) | inrange ( ``ffind'' , 7380 , 7380 ) | inrange ( ``ffind'' , 7381 , 7382 ) | inrange ( ``ffind'' , 7383 , 7383 ) | inrange ( ``ffind'' , 7384 , 7384 ) | inrange ( ``ffind'' , 7385 , 7385 ) | inrange ( ``ffind'' , 7389 , 7390 ) | inrange ( ``ffind'' , 7391 , 7391 ) | inrange ( ``ffind'' , 7392 , 7392 ) | inrange ( ``ffind'' , 7393 , 7393 ) | inrange ( ``ffind'' , 7394 , 7394 ) | inrange ( ``ffind'' , 7396 , 7396 ) | inrange ( ``ffind'' , 7397 , 7397 ) | inrange ( ``ffind'' , 7399 , 7399 ) | inrange ( ``ffind'' , 7519 , 7519 ) | inrange ( ``ffind'' , 8700 , 8700 ) | inrange ( ``ffind'' , 8710 , 8713 ) | inrange ( ``ffind'' , 8720 , 8721 ) | inrange ( ``ffind'' , 8730 , 8734 ) | inrange ( ``ffind'' , 8740 , 8748 ) | inrange ( ``ffind'' , 8900 , 8910 ) | inrange ( ``ffind'' , 8911 , 8911 ) | inrange ( ``ffind'' , 8920 , 8999 ) | inrange ( ``ffind'' , 4220 , 4229 ) qui replace `generate' = 35 if inrange ( ``ffind'' , 3570 , 3579 ) | inrange ( ``ffind'' , 3680 , 3680 ) | inrange ( ``ffind'' , 3681 , 3681 ) | inrange ( ``ffind'' , 3682 , 3682 ) | inrange ( ``ffind'' , 3683 , 3683 ) | inrange ( ``ffind'' , 3684 , 3684 ) | inrange ( ``ffind'' , 3685 , 3685 ) | inrange ( ``ffind'' , 3686 , 3686 ) | inrange ( ``ffind'' , 3687 , 3687 ) | inrange ( ``ffind'' , 3688 , 3688 ) | inrange ( ``ffind'' , 3689 , 3689 ) | inrange ( ``ffind'' , 3695 , 3695 ) | inrange ( ``ffind'' , 7373 , 7373 ) qui replace `generate' = 36 if inrange ( ``ffind'' , 3622 , 3622 ) | inrange ( ``ffind'' , 3661 , 3661 ) | inrange ( ``ffind'' , 3662 , 3662 ) | inrange ( ``ffind'' , 3663 , 3663 ) | inrange ( ``ffind'' , 3664 , 3664 ) | inrange ( ``ffind'' , 3665 , 3665 ) | inrange ( ``ffind'' , 3666 , 3666 ) | inrange ( ``ffind'' , 3669 , 3669 ) | inrange ( ``ffind'' , 3670 , 3679 ) | inrange ( ``ffind'' , 3810 , 3810 ) | inrange ( ``ffind'' , 3812 , 3812 ) qui replace `generate' = 37 if inrange ( ``ffind'' , 3811 , 3811 ) | inrange ( ``ffind'' , 3820 , 3820 ) | inrange ( ``ffind'' , 3821 , 3821 ) | inrange ( ``ffind'' , 3822 , 3822 ) | inrange ( ``ffind'' , 3823 , 3823 ) | inrange ( ``ffind'' , 3824 , 3824 ) | inrange ( ``ffind'' , 3825 , 3825 ) | inrange ( ``ffind'' , 3826 , 3826 ) | inrange ( ``ffind'' , 3827 , 3827 ) | inrange ( ``ffind'' , 3829 , 3829 ) | inrange ( ``ffind'' , 3830 , 3839 ) qui replace `generate' = 38 if inrange ( ``ffind'' , 2520 , 2549 ) | inrange ( ``ffind'' , 2600 , 2639 ) | inrange ( ``ffind'' , 2670 , 2699 ) | inrange ( ``ffind'' , 2760 , 2761 ) | inrange ( ``ffind'' , 3950 , 3955 ) qui replace `generate' = 39 if inrange ( ``ffind'' , 2440 , 2449 ) | inrange ( ``ffind'' , 2640 , 2659 ) | inrange ( ``ffind'' , 3220 , 3221 ) | inrange ( ``ffind'' , 3410 , 3412 ) qui replace `generate' = 40 if inrange ( ``ffind'' , 4000 , 4013 ) | inrange ( ``ffind'' , 4040 , 4049 ) | inrange ( ``ffind'' , 4100 , 4100 ) | inrange ( ``ffind'' , 4110 , 4119 ) | inrange ( ``ffind'' , 4120 , 4121 ) | inrange ( ``ffind'' , 4130 , 4131 ) | inrange ( ``ffind'' , 4140 , 4142 ) | inrange ( ``ffind'' , 4150 , 4151 ) | inrange ( ``ffind'' , 4170 , 4173 ) | inrange ( ``ffind'' , 4190 , 4199 ) | inrange ( ``ffind'' , 4200 , 4200 ) | inrange ( ``ffind'' , 4210 , 4219 ) | inrange ( ``ffind'' , 4230 , 4231 ) | inrange ( ``ffind'' , 4240 , 4249 ) | inrange ( ``ffind'' , 4400 , 4499 ) | inrange ( ``ffind'' , 4500 , 4599 ) | inrange ( ``ffind'' , 4600 , 4699 ) | inrange ( ``ffind'' , 4700 , 4700 ) | inrange ( ``ffind'' , 4710 , 4712 ) | inrange ( ``ffind'' , 4720 , 4729 ) | inrange ( ``ffind'' , 4730 , 4739 ) | inrange ( ``ffind'' , 4740 , 4749 ) | inrange ( ``ffind'' , 4780 , 4780 ) | inrange ( ``ffind'' , 4782 , 4782 ) | inrange ( ``ffind'' , 4783 , 4783 ) | inrange ( ``ffind'' , 4784 , 4784 ) | inrange ( ``ffind'' , 4785 , 4785 ) | inrange ( ``ffind'' , 4789 , 4789 ) qui replace `generate' = 41 if inrange ( ``ffind'' , 5000 , 5000 ) | inrange ( ``ffind'' , 5010 , 5015 ) | inrange ( ``ffind'' , 5020 , 5023 ) | inrange ( ``ffind'' , 5030 , 5039 ) | inrange ( ``ffind'' , 5040 , 5042 ) | inrange ( ``ffind'' , 5043 , 5043 ) | inrange ( ``ffind'' , 5044 , 5044 ) | inrange ( ``ffind'' , 5045 , 5045 ) | inrange ( ``ffind'' , 5046 , 5046 ) | inrange ( ``ffind'' , 5047 , 5047 ) | inrange ( ``ffind'' , 5048 , 5048 ) | inrange ( ``ffind'' , 5049 , 5049 ) | inrange ( ``ffind'' , 5050 , 5059 ) | inrange ( ``ffind'' , 5060 , 5060 ) | inrange ( ``ffind'' , 5063 , 5063 ) | inrange ( ``ffind'' , 5064 , 5064 ) | inrange ( ``ffind'' , 5065 , 5065 ) | inrange ( ``ffind'' , 5070 , 5078 ) | inrange ( ``ffind'' , 5080 , 5080 ) | inrange ( ``ffind'' , 5081 , 5081 ) | inrange ( ``ffind'' , 5082 , 5082 ) | inrange ( ``ffind'' , 5083 , 5083 ) | inrange ( ``ffind'' , 5084 , 5084 ) | inrange ( ``ffind'' , 5085 , 5085 ) | inrange ( ``ffind'' , 5086 , 5087 ) | inrange ( ``ffind'' , 5088 , 5088 ) | inrange ( ``ffind'' , 5090 , 5090 ) | inrange ( ``ffind'' , 5091 , 5092 ) | inrange ( ``ffind'' , 5093 , 5093 ) | inrange ( ``ffind'' , 5094 , 5094 ) | inrange ( ``ffind'' , 5099 , 5099 ) | inrange ( ``ffind'' , 5100 , 5100 ) | inrange ( ``ffind'' , 5110 , 5113 ) | inrange ( ``ffind'' , 5120 , 5122 ) | inrange ( ``ffind'' , 5130 , 5139 ) | inrange ( ``ffind'' , 5140 , 5149 ) | inrange ( ``ffind'' , 5150 , 5159 ) | inrange ( ``ffind'' , 5160 , 5169 ) | inrange ( ``ffind'' , 5170 , 5172 ) | inrange ( ``ffind'' , 5180 , 5182 ) | inrange ( ``ffind'' , 5190 , 5199 ) qui replace `generate' = 42 if inrange ( ``ffind'' , 5200 , 5200 ) | inrange ( ``ffind'' , 5210 , 5219 ) | inrange ( ``ffind'' , 5220 , 5229 ) | inrange ( ``ffind'' , 5230 , 5231 ) | inrange ( ``ffind'' , 5250 , 5251 ) | inrange ( ``ffind'' , 5260 , 5261 ) | inrange ( ``ffind'' , 5270 , 5271 ) | inrange ( ``ffind'' , 5300 , 5300 ) | inrange ( ``ffind'' , 5310 , 5311 ) | inrange ( ``ffind'' , 5320 , 5320 ) | inrange ( ``ffind'' , 5330 , 5331 ) | inrange ( ``ffind'' , 5334 , 5334 ) | inrange ( ``ffind'' , 5340 , 5349 ) | inrange ( ``ffind'' , 5390 , 5399 ) | inrange ( ``ffind'' , 5400 , 5400 ) | inrange ( ``ffind'' , 5410 , 5411 ) | inrange ( ``ffind'' , 5412 , 5412 ) | inrange ( ``ffind'' , 5420 , 5429 ) | inrange ( ``ffind'' , 5430 , 5439 ) | inrange ( ``ffind'' , 5440 , 5449 ) | inrange ( ``ffind'' , 5450 , 5459 ) | inrange ( ``ffind'' , 5460 , 5469 ) | inrange ( ``ffind'' , 5490 , 5499 ) | inrange ( ``ffind'' , 5500 , 5500 ) | inrange ( ``ffind'' , 5510 , 5529 ) | inrange ( ``ffind'' , 5530 , 5539 ) | inrange ( ``ffind'' , 5540 , 5549 ) | inrange ( ``ffind'' , 5550 , 5559 ) | inrange ( ``ffind'' , 5560 , 5569 ) | inrange ( ``ffind'' , 5570 , 5579 ) | inrange ( ``ffind'' , 5590 , 5599 ) | inrange ( ``ffind'' , 5600 , 5699 ) | inrange ( ``ffind'' , 5700 , 5700 ) | inrange ( ``ffind'' , 5710 , 5719 ) | inrange ( ``ffind'' , 5720 , 5722 ) | inrange ( ``ffind'' , 5730 , 5733 ) | inrange ( ``ffind'' , 5734 , 5734 ) | inrange ( ``ffind'' , 5735 , 5735 ) | inrange ( ``ffind'' , 5736 , 5736 ) | inrange ( ``ffind'' , 5750 , 5799 ) | inrange ( ``ffind'' , 5900 , 5900 ) | inrange ( ``ffind'' , 5910 , 5912 ) | inrange ( ``ffind'' , 5920 , 5929 ) | inrange ( ``ffind'' , 5930 , 5932 ) | inrange ( ``ffind'' , 5940 , 5940 ) | inrange ( ``ffind'' , 5941 , 5941 ) | inrange ( ``ffind'' , 5942 , 5942 ) | inrange ( ``ffind'' , 5943 , 5943 ) | inrange ( ``ffind'' , 5944 , 5944 ) | inrange ( ``ffind'' , 5945 , 5945 ) | inrange ( ``ffind'' , 5946 , 5946 ) | inrange ( ``ffind'' , 5947 , 5947 ) | inrange ( ``ffind'' , 5948 , 5948 ) | inrange ( ``ffind'' , 5949 , 5949 ) | inrange ( ``ffind'' , 5950 , 5959 ) | inrange ( ``ffind'' , 5960 , 5969 ) | inrange ( ``ffind'' , 5970 , 5979 ) | inrange ( ``ffind'' , 5980 , 5989 ) | inrange ( ``ffind'' , 5990 , 5990 ) | inrange ( ``ffind'' , 5992 , 5992 ) | inrange ( ``ffind'' , 5993 , 5993 ) | inrange ( ``ffind'' , 5994 , 5994 ) | inrange ( ``ffind'' , 5995 , 5995 ) | inrange ( ``ffind'' , 5999 , 5999 ) qui replace `generate' = 43 if inrange ( ``ffind'' , 5800 , 5819 ) | inrange ( ``ffind'' , 5820 , 5829 ) | inrange ( ``ffind'' , 5890 , 5899 ) | inrange ( ``ffind'' , 7000 , 7000 ) | inrange ( ``ffind'' , 7010 , 7019 ) | inrange ( ``ffind'' , 7040 , 7049 ) | inrange ( ``ffind'' , 7213 , 7213 ) qui replace `generate' = 44 if inrange ( ``ffind'' , 6000 , 6000 ) | inrange ( ``ffind'' , 6010 , 6019 ) | inrange ( ``ffind'' , 6020 , 6020 ) | inrange ( ``ffind'' , 6021 , 6021 ) | inrange ( ``ffind'' , 6022 , 6022 ) | inrange ( ``ffind'' , 6023 , 6024 ) | inrange ( ``ffind'' , 6025 , 6025 ) | inrange ( ``ffind'' , 6026 , 6026 ) | inrange ( ``ffind'' , 6027 , 6027 ) | inrange ( ``ffind'' , 6028 , 6029 ) | inrange ( ``ffind'' , 6030 , 6036 ) | inrange ( ``ffind'' , 6040 , 6059 ) | inrange ( ``ffind'' , 6060 , 6062 ) | inrange ( ``ffind'' , 6080 , 6082 ) | inrange ( ``ffind'' , 6090 , 6099 ) | inrange ( ``ffind'' , 6100 , 6100 ) | inrange ( ``ffind'' , 6110 , 6111 ) | inrange ( ``ffind'' , 6112 , 6113 ) | inrange ( ``ffind'' , 6120 , 6129 ) | inrange ( ``ffind'' , 6130 , 6139 ) | inrange ( ``ffind'' , 6140 , 6149 ) | inrange ( ``ffind'' , 6150 , 6159 ) | inrange ( ``ffind'' , 6160 , 6169 ) | inrange ( ``ffind'' , 6170 , 6179 ) | inrange ( ``ffind'' , 6190 , 6199 ) qui replace `generate' = 45 if inrange ( ``ffind'' , 6300 , 6300 ) | inrange ( ``ffind'' , 6310 , 6319 ) | inrange ( ``ffind'' , 6320 , 6329 ) | inrange ( ``ffind'' , 6330 , 6331 ) | inrange ( ``ffind'' , 6350 , 6351 ) | inrange ( ``ffind'' , 6360 , 6361 ) | inrange ( ``ffind'' , 6370 , 6379 ) | inrange ( ``ffind'' , 6390 , 6399 ) | inrange ( ``ffind'' , 6400 , 6411 ) qui replace `generate' = 46 if inrange ( ``ffind'' , 6500 , 6500 ) | inrange ( ``ffind'' , 6510 , 6510 ) | inrange ( ``ffind'' , 6512 , 6512 ) | inrange ( ``ffind'' , 6513 , 6513 ) | inrange ( ``ffind'' , 6514 , 6514 ) | inrange ( ``ffind'' , 6515 , 6515 ) | inrange ( ``ffind'' , 6517 , 6519 ) | inrange ( ``ffind'' , 6520 , 6529 ) | inrange ( ``ffind'' , 6530 , 6531 ) | inrange ( ``ffind'' , 6532 , 6532 ) | inrange ( ``ffind'' , 6540 , 6541 ) | inrange ( ``ffind'' , 6550 , 6553 ) | inrange ( ``ffind'' , 6590 , 6599 ) | inrange ( ``ffind'' , 6610 , 6611 ) qui replace `generate' = 47 if inrange ( ``ffind'' , 6200 , 6299 ) | inrange ( ``ffind'' , 6700 , 6700 ) | inrange ( ``ffind'' , 6710 , 6719 ) | inrange ( ``ffind'' , 6720 , 6722 ) | inrange ( ``ffind'' , 6723 , 6723 ) | inrange ( ``ffind'' , 6724 , 6724 ) | inrange ( ``ffind'' , 6725 , 6725 ) | inrange ( ``ffind'' , 6726 , 6726 ) | inrange ( ``ffind'' , 6730 , 6733 ) | inrange ( ``ffind'' , 6740 , 6779 ) | inrange ( ``ffind'' , 6790 , 6791 ) | inrange ( ``ffind'' , 6792 , 6792 ) | inrange ( ``ffind'' , 6793 , 6793 ) | inrange ( ``ffind'' , 6794 , 6794 ) | inrange ( ``ffind'' , 6795 , 6795 ) | inrange ( ``ffind'' , 6798 , 6798 ) | inrange ( ``ffind'' , 6799 , 6799 ) qui replace `generate' = 48 if missing ( `generate' ) & ~ missing ( ``ffind'' ) } else if ``ftyp'' == 49 { label define `generate' 1 \"Agriculture\" 2 \"Food Products\" 3 \"Candy & Soda\" 4 \"Beer & Liquor\" 5 \"Tobacco Products\" 6 \"Recreation\" 7 \"Entertainment\" 8 \"Printing and Publishing\" 9 \"Consumer Goods\" 10 \"Apparel\" 11 \"Healthcare\" 12 \"Medical Equipment\" 13 \"Pharmaceutical Products\" 14 \"Chemicals\" 15 \"Rubber and Plastic Products\" 16 \"Textiles\" 17 \"Construction Materials\" 18 \"Construction\" 19 \"Steel Works Etc\" 20 \"Fabricated Products\" 21 \"Machinery\" 22 \"Electrical Equipment\" 23 \"Automobiles and Trucks\" 24 \"Aircraft\" 25 \"Shipbuilding, Railroad Equipment\" 26 \"Defense\" 27 \"Precious Metals\" 28 \"Non-Metallic and Industrial Metal Mining\" 29 \"Coal\" 30 \"Petroleum and Natural Gas\" 31 \"Utilities\" 32 \"Communication\" 33 \"Personal Services\" 34 \"Business Services\" 35 \"Computer Hardware\" 36 \"Computer Software\" 37 \"Electronic Equipment\" 38 \"Measuring and Control Equipment\" 39 \"Business Supplies\" 40 \"Shipping Containers\" 41 \"Transportation\" 42 \"Wholesale\" 43 \"Retail\" 44 \"Restaraunts, Hotels, Motels\" 45 \"Banking\" 46 \"Insurance\" 47 \"Real Estate\" 48 \"Trading\" 49 \"Almost Nothing\" label values `generate' `generate' qui replace `generate' = 1 if inrange ( ``ffind'' , 100 , 199 ) | inrange ( ``ffind'' , 200 , 299 ) | inrange ( ``ffind'' , 700 , 799 ) | inrange ( ``ffind'' , 910 , 919 ) | inrange ( ``ffind'' , 2048 , 2048 ) qui replace `generate' = 2 if inrange ( ``ffind'' , 2000 , 2009 ) | inrange ( ``ffind'' , 2010 , 2019 ) | inrange ( ``ffind'' , 2020 , 2029 ) | inrange ( ``ffind'' , 2030 , 2039 ) | inrange ( ``ffind'' , 2040 , 2046 ) | inrange ( ``ffind'' , 2050 , 2059 ) | inrange ( ``ffind'' , 2060 , 2063 ) | inrange ( ``ffind'' , 2070 , 2079 ) | inrange ( ``ffind'' , 2090 , 2092 ) | inrange ( ``ffind'' , 2095 , 2095 ) | inrange ( ``ffind'' , 2098 , 2099 ) qui replace `generate' = 3 if inrange ( ``ffind'' , 2064 , 2068 ) | inrange ( ``ffind'' , 2086 , 2086 ) | inrange ( ``ffind'' , 2087 , 2087 ) | inrange ( ``ffind'' , 2096 , 2096 ) | inrange ( ``ffind'' , 2097 , 2097 ) qui replace `generate' = 4 if inrange ( ``ffind'' , 2080 , 2080 ) | inrange ( ``ffind'' , 2082 , 2082 ) | inrange ( ``ffind'' , 2083 , 2083 ) | inrange ( ``ffind'' , 2084 , 2084 ) | inrange ( ``ffind'' , 2085 , 2085 ) qui replace `generate' = 5 if inrange ( ``ffind'' , 2100 , 2199 ) qui replace `generate' = 6 if inrange ( ``ffind'' , 920 , 999 ) | inrange ( ``ffind'' , 3650 , 3651 ) | inrange ( ``ffind'' , 3652 , 3652 ) | inrange ( ``ffind'' , 3732 , 3732 ) | inrange ( ``ffind'' , 3930 , 3931 ) | inrange ( ``ffind'' , 3940 , 3949 ) qui replace `generate' = 7 if inrange ( ``ffind'' , 7800 , 7829 ) | inrange ( ``ffind'' , 7830 , 7833 ) | inrange ( ``ffind'' , 7840 , 7841 ) | inrange ( ``ffind'' , 7900 , 7900 ) | inrange ( ``ffind'' , 7910 , 7911 ) | inrange ( ``ffind'' , 7920 , 7929 ) | inrange ( ``ffind'' , 7930 , 7933 ) | inrange ( ``ffind'' , 7940 , 7949 ) | inrange ( ``ffind'' , 7980 , 7980 ) | inrange ( ``ffind'' , 7990 , 7999 ) qui replace `generate' = 8 if inrange ( ``ffind'' , 2700 , 2709 ) | inrange ( ``ffind'' , 2710 , 2719 ) | inrange ( ``ffind'' , 2720 , 2729 ) | inrange ( ``ffind'' , 2730 , 2739 ) | inrange ( ``ffind'' , 2740 , 2749 ) | inrange ( ``ffind'' , 2770 , 2771 ) | inrange ( ``ffind'' , 2780 , 2789 ) | inrange ( ``ffind'' , 2790 , 2799 ) qui replace `generate' = 9 if inrange ( ``ffind'' , 2047 , 2047 ) | inrange ( ``ffind'' , 2391 , 2392 ) | inrange ( ``ffind'' , 2510 , 2519 ) | inrange ( ``ffind'' , 2590 , 2599 ) | inrange ( ``ffind'' , 2840 , 2843 ) | inrange ( ``ffind'' , 2844 , 2844 ) | inrange ( ``ffind'' , 3160 , 3161 ) | inrange ( ``ffind'' , 3170 , 3171 ) | inrange ( ``ffind'' , 3172 , 3172 ) | inrange ( ``ffind'' , 3190 , 3199 ) | inrange ( ``ffind'' , 3229 , 3229 ) | inrange ( ``ffind'' , 3260 , 3260 ) | inrange ( ``ffind'' , 3262 , 3263 ) | inrange ( ``ffind'' , 3269 , 3269 ) | inrange ( ``ffind'' , 3230 , 3231 ) | inrange ( ``ffind'' , 3630 , 3639 ) | inrange ( ``ffind'' , 3750 , 3751 ) | inrange ( ``ffind'' , 3800 , 3800 ) | inrange ( ``ffind'' , 3860 , 3861 ) | inrange ( ``ffind'' , 3870 , 3873 ) | inrange ( ``ffind'' , 3910 , 3911 ) | inrange ( ``ffind'' , 3914 , 3914 ) | inrange ( ``ffind'' , 3915 , 3915 ) | inrange ( ``ffind'' , 3960 , 3962 ) | inrange ( ``ffind'' , 3991 , 3991 ) | inrange ( ``ffind'' , 3995 , 3995 ) qui replace `generate' = 10 if inrange ( ``ffind'' , 2300 , 2390 ) | inrange ( ``ffind'' , 3020 , 3021 ) | inrange ( ``ffind'' , 3100 , 3111 ) | inrange ( ``ffind'' , 3130 , 3131 ) | inrange ( ``ffind'' , 3140 , 3149 ) | inrange ( ``ffind'' , 3150 , 3151 ) | inrange ( ``ffind'' , 3963 , 3965 ) qui replace `generate' = 11 if inrange ( ``ffind'' , 8000 , 8099 ) qui replace `generate' = 12 if inrange ( ``ffind'' , 3693 , 3693 ) | inrange ( ``ffind'' , 3840 , 3849 ) | inrange ( ``ffind'' , 3850 , 3851 ) qui replace `generate' = 13 if inrange ( ``ffind'' , 2830 , 2830 ) | inrange ( ``ffind'' , 2831 , 2831 ) | inrange ( ``ffind'' , 2833 , 2833 ) | inrange ( ``ffind'' , 2834 , 2834 ) | inrange ( ``ffind'' , 2835 , 2835 ) | inrange ( ``ffind'' , 2836 , 2836 ) qui replace `generate' = 14 if inrange ( ``ffind'' , 2800 , 2809 ) | inrange ( ``ffind'' , 2810 , 2819 ) | inrange ( ``ffind'' , 2820 , 2829 ) | inrange ( ``ffind'' , 2850 , 2859 ) | inrange ( ``ffind'' , 2860 , 2869 ) | inrange ( ``ffind'' , 2870 , 2879 ) | inrange ( ``ffind'' , 2890 , 2899 ) qui replace `generate' = 15 if inrange ( ``ffind'' , 3031 , 3031 ) | inrange ( ``ffind'' , 3041 , 3041 ) | inrange ( ``ffind'' , 3050 , 3053 ) | inrange ( ``ffind'' , 3060 , 3069 ) | inrange ( ``ffind'' , 3070 , 3079 ) | inrange ( ``ffind'' , 3080 , 3089 ) | inrange ( ``ffind'' , 3090 , 3099 ) qui replace `generate' = 16 if inrange ( ``ffind'' , 2200 , 2269 ) | inrange ( ``ffind'' , 2270 , 2279 ) | inrange ( ``ffind'' , 2280 , 2284 ) | inrange ( ``ffind'' , 2290 , 2295 ) | inrange ( ``ffind'' , 2297 , 2297 ) | inrange ( ``ffind'' , 2298 , 2298 ) | inrange ( ``ffind'' , 2299 , 2299 ) | inrange ( ``ffind'' , 2393 , 2395 ) | inrange ( ``ffind'' , 2397 , 2399 ) qui replace `generate' = 17 if inrange ( ``ffind'' , 800 , 899 ) | inrange ( ``ffind'' , 2400 , 2439 ) | inrange ( ``ffind'' , 2450 , 2459 ) | inrange ( ``ffind'' , 2490 , 2499 ) | inrange ( ``ffind'' , 2660 , 2661 ) | inrange ( ``ffind'' , 2950 , 2952 ) | inrange ( ``ffind'' , 3200 , 3200 ) | inrange ( ``ffind'' , 3210 , 3211 ) | inrange ( ``ffind'' , 3240 , 3241 ) | inrange ( ``ffind'' , 3250 , 3259 ) | inrange ( ``ffind'' , 3261 , 3261 ) | inrange ( ``ffind'' , 3264 , 3264 ) | inrange ( ``ffind'' , 3270 , 3275 ) | inrange ( ``ffind'' , 3280 , 3281 ) | inrange ( ``ffind'' , 3290 , 3293 ) | inrange ( ``ffind'' , 3295 , 3299 ) | inrange ( ``ffind'' , 3420 , 3429 ) | inrange ( ``ffind'' , 3430 , 3433 ) | inrange ( ``ffind'' , 3440 , 3441 ) | inrange ( ``ffind'' , 3442 , 3442 ) | inrange ( ``ffind'' , 3446 , 3446 ) | inrange ( ``ffind'' , 3448 , 3448 ) | inrange ( ``ffind'' , 3449 , 3449 ) | inrange ( ``ffind'' , 3450 , 3451 ) | inrange ( ``ffind'' , 3452 , 3452 ) | inrange ( ``ffind'' , 3490 , 3499 ) | inrange ( ``ffind'' , 3996 , 3996 ) qui replace `generate' = 18 if inrange ( ``ffind'' , 1500 , 1511 ) | inrange ( ``ffind'' , 1520 , 1529 ) | inrange ( ``ffind'' , 1530 , 1539 ) | inrange ( ``ffind'' , 1540 , 1549 ) | inrange ( ``ffind'' , 1600 , 1699 ) | inrange ( ``ffind'' , 1700 , 1799 ) qui replace `generate' = 19 if inrange ( ``ffind'' , 3300 , 3300 ) | inrange ( ``ffind'' , 3310 , 3317 ) | inrange ( ``ffind'' , 3320 , 3325 ) | inrange ( ``ffind'' , 3330 , 3339 ) | inrange ( ``ffind'' , 3340 , 3341 ) | inrange ( ``ffind'' , 3350 , 3357 ) | inrange ( ``ffind'' , 3360 , 3369 ) | inrange ( ``ffind'' , 3370 , 3379 ) | inrange ( ``ffind'' , 3390 , 3399 ) qui replace `generate' = 20 if inrange ( ``ffind'' , 3400 , 3400 ) | inrange ( ``ffind'' , 3443 , 3443 ) | inrange ( ``ffind'' , 3444 , 3444 ) | inrange ( ``ffind'' , 3460 , 3469 ) | inrange ( ``ffind'' , 3470 , 3479 ) qui replace `generate' = 21 if inrange ( ``ffind'' , 3510 , 3519 ) | inrange ( ``ffind'' , 3520 , 3529 ) | inrange ( ``ffind'' , 3530 , 3530 ) | inrange ( ``ffind'' , 3531 , 3531 ) | inrange ( ``ffind'' , 3532 , 3532 ) | inrange ( ``ffind'' , 3533 , 3533 ) | inrange ( ``ffind'' , 3534 , 3534 ) | inrange ( ``ffind'' , 3535 , 3535 ) | inrange ( ``ffind'' , 3536 , 3536 ) | inrange ( ``ffind'' , 3538 , 3538 ) | inrange ( ``ffind'' , 3540 , 3549 ) | inrange ( ``ffind'' , 3550 , 3559 ) | inrange ( ``ffind'' , 3560 , 3569 ) | inrange ( ``ffind'' , 3580 , 3580 ) | inrange ( ``ffind'' , 3581 , 3581 ) | inrange ( ``ffind'' , 3582 , 3582 ) | inrange ( ``ffind'' , 3585 , 3585 ) | inrange ( ``ffind'' , 3586 , 3586 ) | inrange ( ``ffind'' , 3589 , 3589 ) | inrange ( ``ffind'' , 3590 , 3599 ) qui replace `generate' = 22 if inrange ( ``ffind'' , 3600 , 3600 ) | inrange ( ``ffind'' , 3610 , 3613 ) | inrange ( ``ffind'' , 3620 , 3621 ) | inrange ( ``ffind'' , 3623 , 3629 ) | inrange ( ``ffind'' , 3640 , 3644 ) | inrange ( ``ffind'' , 3645 , 3645 ) | inrange ( ``ffind'' , 3646 , 3646 ) | inrange ( ``ffind'' , 3648 , 3649 ) | inrange ( ``ffind'' , 3660 , 3660 ) | inrange ( ``ffind'' , 3690 , 3690 ) | inrange ( ``ffind'' , 3691 , 3692 ) | inrange ( ``ffind'' , 3699 , 3699 ) qui replace `generate' = 23 if inrange ( ``ffind'' , 2296 , 2296 ) | inrange ( ``ffind'' , 2396 , 2396 ) | inrange ( ``ffind'' , 3010 , 3011 ) | inrange ( ``ffind'' , 3537 , 3537 ) | inrange ( ``ffind'' , 3647 , 3647 ) | inrange ( ``ffind'' , 3694 , 3694 ) | inrange ( ``ffind'' , 3700 , 3700 ) | inrange ( ``ffind'' , 3710 , 3710 ) | inrange ( ``ffind'' , 3711 , 3711 ) | inrange ( ``ffind'' , 3713 , 3713 ) | inrange ( ``ffind'' , 3714 , 3714 ) | inrange ( ``ffind'' , 3715 , 3715 ) | inrange ( ``ffind'' , 3716 , 3716 ) | inrange ( ``ffind'' , 3792 , 3792 ) | inrange ( ``ffind'' , 3790 , 3791 ) | inrange ( ``ffind'' , 3799 , 3799 ) qui replace `generate' = 24 if inrange ( ``ffind'' , 3720 , 3720 ) | inrange ( ``ffind'' , 3721 , 3721 ) | inrange ( ``ffind'' , 3723 , 3724 ) | inrange ( ``ffind'' , 3725 , 3725 ) | inrange ( ``ffind'' , 3728 , 3729 ) qui replace `generate' = 25 if inrange ( ``ffind'' , 3730 , 3731 ) | inrange ( ``ffind'' , 3740 , 3743 ) qui replace `generate' = 26 if inrange ( ``ffind'' , 3760 , 3769 ) | inrange ( ``ffind'' , 3795 , 3795 ) | inrange ( ``ffind'' , 3480 , 3489 ) qui replace `generate' = 27 if inrange ( ``ffind'' , 1040 , 1049 ) qui replace `generate' = 28 if inrange ( ``ffind'' , 1000 , 1009 ) | inrange ( ``ffind'' , 1010 , 1019 ) | inrange ( ``ffind'' , 1020 , 1029 ) | inrange ( ``ffind'' , 1030 , 1039 ) | inrange ( ``ffind'' , 1050 , 1059 ) | inrange ( ``ffind'' , 1060 , 1069 ) | inrange ( ``ffind'' , 1070 , 1079 ) | inrange ( ``ffind'' , 1080 , 1089 ) | inrange ( ``ffind'' , 1090 , 1099 ) | inrange ( ``ffind'' , 1100 , 1119 ) | inrange ( ``ffind'' , 1400 , 1499 ) qui replace `generate' = 29 if inrange ( ``ffind'' , 1200 , 1299 ) qui replace `generate' = 30 if inrange ( ``ffind'' , 1300 , 1300 ) | inrange ( ``ffind'' , 1310 , 1319 ) | inrange ( ``ffind'' , 1320 , 1329 ) | inrange ( ``ffind'' , 1330 , 1339 ) | inrange ( ``ffind'' , 1370 , 1379 ) | inrange ( ``ffind'' , 1380 , 1380 ) | inrange ( ``ffind'' , 1381 , 1381 ) | inrange ( ``ffind'' , 1382 , 1382 ) | inrange ( ``ffind'' , 1389 , 1389 ) | inrange ( ``ffind'' , 2900 , 2912 ) | inrange ( ``ffind'' , 2990 , 2999 ) qui replace `generate' = 31 if inrange ( ``ffind'' , 4900 , 4900 ) | inrange ( ``ffind'' , 4910 , 4911 ) | inrange ( ``ffind'' , 4920 , 4922 ) | inrange ( ``ffind'' , 4923 , 4923 ) | inrange ( ``ffind'' , 4924 , 4925 ) | inrange ( ``ffind'' , 4930 , 4931 ) | inrange ( ``ffind'' , 4932 , 4932 ) | inrange ( ``ffind'' , 4939 , 4939 ) | inrange ( ``ffind'' , 4940 , 4942 ) qui replace `generate' = 32 if inrange ( ``ffind'' , 4800 , 4800 ) | inrange ( ``ffind'' , 4810 , 4813 ) | inrange ( ``ffind'' , 4820 , 4822 ) | inrange ( ``ffind'' , 4830 , 4839 ) | inrange ( ``ffind'' , 4840 , 4841 ) | inrange ( ``ffind'' , 4880 , 4889 ) | inrange ( ``ffind'' , 4890 , 4890 ) | inrange ( ``ffind'' , 4891 , 4891 ) | inrange ( ``ffind'' , 4892 , 4892 ) | inrange ( ``ffind'' , 4899 , 4899 ) qui replace `generate' = 33 if inrange ( ``ffind'' , 7020 , 7021 ) | inrange ( ``ffind'' , 7030 , 7033 ) | inrange ( ``ffind'' , 7200 , 7200 ) | inrange ( ``ffind'' , 7210 , 7212 ) | inrange ( ``ffind'' , 7214 , 7214 ) | inrange ( ``ffind'' , 7215 , 7216 ) | inrange ( ``ffind'' , 7217 , 7217 ) | inrange ( ``ffind'' , 7219 , 7219 ) | inrange ( ``ffind'' , 7220 , 7221 ) | inrange ( ``ffind'' , 7230 , 7231 ) | inrange ( ``ffind'' , 7240 , 7241 ) | inrange ( ``ffind'' , 7250 , 7251 ) | inrange ( ``ffind'' , 7260 , 7269 ) | inrange ( ``ffind'' , 7270 , 7290 ) | inrange ( ``ffind'' , 7291 , 7291 ) | inrange ( ``ffind'' , 7292 , 7299 ) | inrange ( ``ffind'' , 7395 , 7395 ) | inrange ( ``ffind'' , 7500 , 7500 ) | inrange ( ``ffind'' , 7520 , 7529 ) | inrange ( ``ffind'' , 7530 , 7539 ) | inrange ( ``ffind'' , 7540 , 7549 ) | inrange ( ``ffind'' , 7600 , 7600 ) | inrange ( ``ffind'' , 7620 , 7620 ) | inrange ( ``ffind'' , 7622 , 7622 ) | inrange ( ``ffind'' , 7623 , 7623 ) | inrange ( ``ffind'' , 7629 , 7629 ) | inrange ( ``ffind'' , 7630 , 7631 ) | inrange ( ``ffind'' , 7640 , 7641 ) | inrange ( ``ffind'' , 7690 , 7699 ) | inrange ( ``ffind'' , 8100 , 8199 ) | inrange ( ``ffind'' , 8200 , 8299 ) | inrange ( ``ffind'' , 8300 , 8399 ) | inrange ( ``ffind'' , 8400 , 8499 ) | inrange ( ``ffind'' , 8600 , 8699 ) | inrange ( ``ffind'' , 8800 , 8899 ) | inrange ( ``ffind'' , 7510 , 7515 ) qui replace `generate' = 34 if inrange ( ``ffind'' , 2750 , 2759 ) | inrange ( ``ffind'' , 3993 , 3993 ) | inrange ( ``ffind'' , 7218 , 7218 ) | inrange ( ``ffind'' , 7300 , 7300 ) | inrange ( ``ffind'' , 7310 , 7319 ) | inrange ( ``ffind'' , 7320 , 7329 ) | inrange ( ``ffind'' , 7330 , 7339 ) | inrange ( ``ffind'' , 7340 , 7342 ) | inrange ( ``ffind'' , 7349 , 7349 ) | inrange ( ``ffind'' , 7350 , 7351 ) | inrange ( ``ffind'' , 7352 , 7352 ) | inrange ( ``ffind'' , 7353 , 7353 ) | inrange ( ``ffind'' , 7359 , 7359 ) | inrange ( ``ffind'' , 7360 , 7369 ) | inrange ( ``ffind'' , 7374 , 7374 ) | inrange ( ``ffind'' , 7376 , 7376 ) | inrange ( ``ffind'' , 7377 , 7377 ) | inrange ( ``ffind'' , 7378 , 7378 ) | inrange ( ``ffind'' , 7379 , 7379 ) | inrange ( ``ffind'' , 7380 , 7380 ) | inrange ( ``ffind'' , 7381 , 7382 ) | inrange ( ``ffind'' , 7383 , 7383 ) | inrange ( ``ffind'' , 7384 , 7384 ) | inrange ( ``ffind'' , 7385 , 7385 ) | inrange ( ``ffind'' , 7389 , 7390 ) | inrange ( ``ffind'' , 7391 , 7391 ) | inrange ( ``ffind'' , 7392 , 7392 ) | inrange ( ``ffind'' , 7393 , 7393 ) | inrange ( ``ffind'' , 7394 , 7394 ) | inrange ( ``ffind'' , 7396 , 7396 ) | inrange ( ``ffind'' , 7397 , 7397 ) | inrange ( ``ffind'' , 7399 , 7399 ) | inrange ( ``ffind'' , 7519 , 7519 ) | inrange ( ``ffind'' , 8700 , 8700 ) | inrange ( ``ffind'' , 8710 , 8713 ) | inrange ( ``ffind'' , 8720 , 8721 ) | inrange ( ``ffind'' , 8730 , 8734 ) | inrange ( ``ffind'' , 8740 , 8748 ) | inrange ( ``ffind'' , 8900 , 8910 ) | inrange ( ``ffind'' , 8911 , 8911 ) | inrange ( ``ffind'' , 8920 , 8999 ) | inrange ( ``ffind'' , 4220 , 4229 ) qui replace `generate' = 35 if inrange ( ``ffind'' , 3570 , 3579 ) | inrange ( ``ffind'' , 3680 , 3680 ) | inrange ( ``ffind'' , 3681 , 3681 ) | inrange ( ``ffind'' , 3682 , 3682 ) | inrange ( ``ffind'' , 3683 , 3683 ) | inrange ( ``ffind'' , 3684 , 3684 ) | inrange ( ``ffind'' , 3685 , 3685 ) | inrange ( ``ffind'' , 3686 , 3686 ) | inrange ( ``ffind'' , 3687 , 3687 ) | inrange ( ``ffind'' , 3688 , 3688 ) | inrange ( ``ffind'' , 3689 , 3689 ) | inrange ( ``ffind'' , 3695 , 3695 ) qui replace `generate' = 36 if inrange ( ``ffind'' , 7370 , 7372 ) | inrange ( ``ffind'' , 7375 , 7375 ) | inrange ( ``ffind'' , 7373 , 7373 ) qui replace `generate' = 37 if inrange ( ``ffind'' , 3622 , 3622 ) | inrange ( ``ffind'' , 3661 , 3661 ) | inrange ( ``ffind'' , 3662 , 3662 ) | inrange ( ``ffind'' , 3663 , 3663 ) | inrange ( ``ffind'' , 3664 , 3664 ) | inrange ( ``ffind'' , 3665 , 3665 ) | inrange ( ``ffind'' , 3666 , 3666 ) | inrange ( ``ffind'' , 3669 , 3669 ) | inrange ( ``ffind'' , 3670 , 3679 ) | inrange ( ``ffind'' , 3810 , 3810 ) | inrange ( ``ffind'' , 3812 , 3812 ) qui replace `generate' = 38 if inrange ( ``ffind'' , 3811 , 3811 ) | inrange ( ``ffind'' , 3820 , 3820 ) | inrange ( ``ffind'' , 3821 , 3821 ) | inrange ( ``ffind'' , 3822 , 3822 ) | inrange ( ``ffind'' , 3823 , 3823 ) | inrange ( ``ffind'' , 3824 , 3824 ) | inrange ( ``ffind'' , 3825 , 3825 ) | inrange ( ``ffind'' , 3826 , 3826 ) | inrange ( ``ffind'' , 3827 , 3827 ) | inrange ( ``ffind'' , 3829 , 3829 ) | inrange ( ``ffind'' , 3830 , 3839 ) qui replace `generate' = 39 if inrange ( ``ffind'' , 2520 , 2549 ) | inrange ( ``ffind'' , 2600 , 2639 ) | inrange ( ``ffind'' , 2670 , 2699 ) | inrange ( ``ffind'' , 2760 , 2761 ) | inrange ( ``ffind'' , 3950 , 3955 ) qui replace `generate' = 40 if inrange ( ``ffind'' , 2440 , 2449 ) | inrange ( ``ffind'' , 2640 , 2659 ) | inrange ( ``ffind'' , 3220 , 3221 ) | inrange ( ``ffind'' , 3410 , 3412 ) qui replace `generate' = 41 if inrange ( ``ffind'' , 4000 , 4013 ) | inrange ( ``ffind'' , 4040 , 4049 ) | inrange ( ``ffind'' , 4100 , 4100 ) | inrange ( ``ffind'' , 4110 , 4119 ) | inrange ( ``ffind'' , 4120 , 4121 ) | inrange ( ``ffind'' , 4130 , 4131 ) | inrange ( ``ffind'' , 4140 , 4142 ) | inrange ( ``ffind'' , 4150 , 4151 ) | inrange ( ``ffind'' , 4170 , 4173 ) | inrange ( ``ffind'' , 4190 , 4199 ) | inrange ( ``ffind'' , 4200 , 4200 ) | inrange ( ``ffind'' , 4210 , 4219 ) | inrange ( ``ffind'' , 4230 , 4231 ) | inrange ( ``ffind'' , 4240 , 4249 ) | inrange ( ``ffind'' , 4400 , 4499 ) | inrange ( ``ffind'' , 4500 , 4599 ) | inrange ( ``ffind'' , 4600 , 4699 ) | inrange ( ``ffind'' , 4700 , 4700 ) | inrange ( ``ffind'' , 4710 , 4712 ) | inrange ( ``ffind'' , 4720 , 4729 ) | inrange ( ``ffind'' , 4730 , 4739 ) | inrange ( ``ffind'' , 4740 , 4749 ) | inrange ( ``ffind'' , 4780 , 4780 ) | inrange ( ``ffind'' , 4782 , 4782 ) | inrange ( ``ffind'' , 4783 , 4783 ) | inrange ( ``ffind'' , 4784 , 4784 ) | inrange ( ``ffind'' , 4785 , 4785 ) | inrange ( ``ffind'' , 4789 , 4789 ) qui replace `generate' = 42 if inrange ( ``ffind'' , 5000 , 5000 ) | inrange ( ``ffind'' , 5010 , 5015 ) | inrange ( ``ffind'' , 5020 , 5023 ) | inrange ( ``ffind'' , 5030 , 5039 ) | inrange ( ``ffind'' , 5040 , 5042 ) | inrange ( ``ffind'' , 5043 , 5043 ) | inrange ( ``ffind'' , 5044 , 5044 ) | inrange ( ``ffind'' , 5045 , 5045 ) | inrange ( ``ffind'' , 5046 , 5046 ) | inrange ( ``ffind'' , 5047 , 5047 ) | inrange ( ``ffind'' , 5048 , 5048 ) | inrange ( ``ffind'' , 5049 , 5049 ) | inrange ( ``ffind'' , 5050 , 5059 ) | inrange ( ``ffind'' , 5060 , 5060 ) | inrange ( ``ffind'' , 5063 , 5063 ) | inrange ( ``ffind'' , 5064 , 5064 ) | inrange ( ``ffind'' , 5065 , 5065 ) | inrange ( ``ffind'' , 5070 , 5078 ) | inrange ( ``ffind'' , 5080 , 5080 ) | inrange ( ``ffind'' , 5081 , 5081 ) | inrange ( ``ffind'' , 5082 , 5082 ) | inrange ( ``ffind'' , 5083 , 5083 ) | inrange ( ``ffind'' , 5084 , 5084 ) | inrange ( ``ffind'' , 5085 , 5085 ) | inrange ( ``ffind'' , 5086 , 5087 ) | inrange ( ``ffind'' , 5088 , 5088 ) | inrange ( ``ffind'' , 5090 , 5090 ) | inrange ( ``ffind'' , 5091 , 5092 ) | inrange ( ``ffind'' , 5093 , 5093 ) | inrange ( ``ffind'' , 5094 , 5094 ) | inrange ( ``ffind'' , 5099 , 5099 ) | inrange ( ``ffind'' , 5100 , 5100 ) | inrange ( ``ffind'' , 5110 , 5113 ) | inrange ( ``ffind'' , 5120 , 5122 ) | inrange ( ``ffind'' , 5130 , 5139 ) | inrange ( ``ffind'' , 5140 , 5149 ) | inrange ( ``ffind'' , 5150 , 5159 ) | inrange ( ``ffind'' , 5160 , 5169 ) | inrange ( ``ffind'' , 5170 , 5172 ) | inrange ( ``ffind'' , 5180 , 5182 ) | inrange ( ``ffind'' , 5190 , 5199 ) qui replace `generate' = 43 if inrange ( ``ffind'' , 5200 , 5200 ) | inrange ( ``ffind'' , 5210 , 5219 ) | inrange ( ``ffind'' , 5220 , 5229 ) | inrange ( ``ffind'' , 5230 , 5231 ) | inrange ( ``ffind'' , 5250 , 5251 ) | inrange ( ``ffind'' , 5260 , 5261 ) | inrange ( ``ffind'' , 5270 , 5271 ) | inrange ( ``ffind'' , 5300 , 5300 ) | inrange ( ``ffind'' , 5310 , 5311 ) | inrange ( ``ffind'' , 5320 , 5320 ) | inrange ( ``ffind'' , 5330 , 5331 ) | inrange ( ``ffind'' , 5334 , 5334 ) | inrange ( ``ffind'' , 5340 , 5349 ) | inrange ( ``ffind'' , 5390 , 5399 ) | inrange ( ``ffind'' , 5400 , 5400 ) | inrange ( ``ffind'' , 5410 , 5411 ) | inrange ( ``ffind'' , 5412 , 5412 ) | inrange ( ``ffind'' , 5420 , 5429 ) | inrange ( ``ffind'' , 5430 , 5439 ) | inrange ( ``ffind'' , 5440 , 5449 ) | inrange ( ``ffind'' , 5450 , 5459 ) | inrange ( ``ffind'' , 5460 , 5469 ) | inrange ( ``ffind'' , 5490 , 5499 ) | inrange ( ``ffind'' , 5500 , 5500 ) | inrange ( ``ffind'' , 5510 , 5529 ) | inrange ( ``ffind'' , 5530 , 5539 ) | inrange ( ``ffind'' , 5540 , 5549 ) | inrange ( ``ffind'' , 5550 , 5559 ) | inrange ( ``ffind'' , 5560 , 5569 ) | inrange ( ``ffind'' , 5570 , 5579 ) | inrange ( ``ffind'' , 5590 , 5599 ) | inrange ( ``ffind'' , 5600 , 5699 ) | inrange ( ``ffind'' , 5700 , 5700 ) | inrange ( ``ffind'' , 5710 , 5719 ) | inrange ( ``ffind'' , 5720 , 5722 ) | inrange ( ``ffind'' , 5730 , 5733 ) | inrange ( ``ffind'' , 5734 , 5734 ) | inrange ( ``ffind'' , 5735 , 5735 ) | inrange ( ``ffind'' , 5736 , 5736 ) | inrange ( ``ffind'' , 5750 , 5799 ) | inrange ( ``ffind'' , 5900 , 5900 ) | inrange ( ``ffind'' , 5910 , 5912 ) | inrange ( ``ffind'' , 5920 , 5929 ) | inrange ( ``ffind'' , 5930 , 5932 ) | inrange ( ``ffind'' , 5940 , 5940 ) | inrange ( ``ffind'' , 5941 , 5941 ) | inrange ( ``ffind'' , 5942 , 5942 ) | inrange ( ``ffind'' , 5943 , 5943 ) | inrange ( ``ffind'' , 5944 , 5944 ) | inrange ( ``ffind'' , 5945 , 5945 ) | inrange ( ``ffind'' , 5946 , 5946 ) | inrange ( ``ffind'' , 5947 , 5947 ) | inrange ( ``ffind'' , 5948 , 5948 ) | inrange ( ``ffind'' , 5949 , 5949 ) | inrange ( ``ffind'' , 5950 , 5959 ) | inrange ( ``ffind'' , 5960 , 5969 ) | inrange ( ``ffind'' , 5970 , 5979 ) | inrange ( ``ffind'' , 5980 , 5989 ) | inrange ( ``ffind'' , 5990 , 5990 ) | inrange ( ``ffind'' , 5992 , 5992 ) | inrange ( ``ffind'' , 5993 , 5993 ) | inrange ( ``ffind'' , 5994 , 5994 ) | inrange ( ``ffind'' , 5995 , 5995 ) | inrange ( ``ffind'' , 5999 , 5999 ) qui replace `generate' = 44 if inrange ( ``ffind'' , 5800 , 5819 ) | inrange ( ``ffind'' , 5820 , 5829 ) | inrange ( ``ffind'' , 5890 , 5899 ) | inrange ( ``ffind'' , 7000 , 7000 ) | inrange ( ``ffind'' , 7010 , 7019 ) | inrange ( ``ffind'' , 7040 , 7049 ) | inrange ( ``ffind'' , 7213 , 7213 ) qui replace `generate' = 45 if inrange ( ``ffind'' , 6000 , 6000 ) | inrange ( ``ffind'' , 6010 , 6019 ) | inrange ( ``ffind'' , 6020 , 6020 ) | inrange ( ``ffind'' , 6021 , 6021 ) | inrange ( ``ffind'' , 6022 , 6022 ) | inrange ( ``ffind'' , 6023 , 6024 ) | inrange ( ``ffind'' , 6025 , 6025 ) | inrange ( ``ffind'' , 6026 , 6026 ) | inrange ( ``ffind'' , 6027 , 6027 ) | inrange ( ``ffind'' , 6028 , 6029 ) | inrange ( ``ffind'' , 6030 , 6036 ) | inrange ( ``ffind'' , 6040 , 6059 ) | inrange ( ``ffind'' , 6060 , 6062 ) | inrange ( ``ffind'' , 6080 , 6082 ) | inrange ( ``ffind'' , 6090 , 6099 ) | inrange ( ``ffind'' , 6100 , 6100 ) | inrange ( ``ffind'' , 6110 , 6111 ) | inrange ( ``ffind'' , 6112 , 6113 ) | inrange ( ``ffind'' , 6120 , 6129 ) | inrange ( ``ffind'' , 6130 , 6139 ) | inrange ( ``ffind'' , 6140 , 6149 ) | inrange ( ``ffind'' , 6150 , 6159 ) | inrange ( ``ffind'' , 6160 , 6169 ) | inrange ( ``ffind'' , 6170 , 6179 ) | inrange ( ``ffind'' , 6190 , 6199 ) qui replace `generate' = 46 if inrange ( ``ffind'' , 6300 , 6300 ) | inrange ( ``ffind'' , 6310 , 6319 ) | inrange ( ``ffind'' , 6320 , 6329 ) | inrange ( ``ffind'' , 6330 , 6331 ) | inrange ( ``ffind'' , 6350 , 6351 ) | inrange ( ``ffind'' , 6360 , 6361 ) | inrange ( ``ffind'' , 6370 , 6379 ) | inrange ( ``ffind'' , 6390 , 6399 ) | inrange ( ``ffind'' , 6400 , 6411 ) qui replace `generate' = 47 if inrange ( ``ffind'' , 6500 , 6500 ) | inrange ( ``ffind'' , 6510 , 6510 ) | inrange ( ``ffind'' , 6512 , 6512 ) | inrange ( ``ffind'' , 6513 , 6513 ) | inrange ( ``ffind'' , 6514 , 6514 ) | inrange ( ``ffind'' , 6515 , 6515 ) | inrange ( ``ffind'' , 6517 , 6519 ) | inrange ( ``ffind'' , 6520 , 6529 ) | inrange ( ``ffind'' , 6530 , 6531 ) | inrange ( ``ffind'' , 6532 , 6532 ) | inrange ( ``ffind'' , 6540 , 6541 ) | inrange ( ``ffind'' , 6550 , 6553 ) | inrange ( ``ffind'' , 6590 , 6599 ) | inrange ( ``ffind'' , 6610 , 6611 ) qui replace `generate' = 48 if inrange ( ``ffind'' , 6200 , 6299 ) | inrange ( ``ffind'' , 6700 , 6700 ) | inrange ( ``ffind'' , 6710 , 6719 ) | inrange ( ``ffind'' , 6720 , 6722 ) | inrange ( ``ffind'' , 6723 , 6723 ) | inrange ( ``ffind'' , 6724 , 6724 ) | inrange ( ``ffind'' , 6725 , 6725 ) | inrange ( ``ffind'' , 6726 , 6726 ) | inrange ( ``ffind'' , 6730 , 6733 ) | inrange ( ``ffind'' , 6740 , 6779 ) | inrange ( ``ffind'' , 6790 , 6791 ) | inrange ( ``ffind'' , 6792 , 6792 ) | inrange ( ``ffind'' , 6793 , 6793 ) | inrange ( ``ffind'' , 6794 , 6794 ) | inrange ( ``ffind'' , 6795 , 6795 ) | inrange ( ``ffind'' , 6798 , 6798 ) | inrange ( ``ffind'' , 6799 , 6799 ) qui replace `generate' = 49 if missing ( `generate' ) & ~ missing ( ``ffind'' ) } else { di as error \"Type must be 5, 10, 12, 17, 30, 38, 48 or 49\" exit 111 } end","title":"Full Stata code"},{"location":"posts/get-bank-holding-company-financials/","text":"Bank Holing Company Financials from FR Y-9C \u00b6 Extract BHC balance sheet data \u00b6 This is the SAS macro I write to consolidate and extract BHC's balance sheet data from WRDS Bank Regulatory database. It creates a bhcf dataset in the work directory. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 %macro bhc_financials(loopdatestart,loopdateend); /* Specify the variables to extract */ %let vars=rssd9999 rssd9001 rssd9007 rssd9008 bhck2170 bhck3210; %let loopdatestart= %sysfunc ( inputn( &loopdatestart ,anydtdte9.)); %let loopdateend= %sysfunc ( inputn( &loopdateend ,anydtdte9.)); %let dif= %sysfunc ( intck( month, &loopdatestart , &loopdateend )); %let dats=; %do i= 0 %to &dif ; %let date= %sysfunc ( intnx( month, &loopdatestart , &i ,e)); %let month= %sysfunc ( month( &date ),z2.); %let year= %sysfunc ( year( &date )); %if &month = 3 or &month = 6 or &month = 9 or &month = 12 %then %do ; %let dats= &dats bank . bhcf &year&month ; %end ; %end ; %put &dats ; data bhcf( keep = &vars ); set &dats ; rssd9999 = input ( put (rssd9999, 8 .), yymmdd10.); /* reporting date */ rssd9007 = input ( put (rssd9007, 8 .), yymmdd10.); /* date start */ rssd9008 = input ( put (rssd9008, 8 .), yymmdd10.); /* date end */ format rssd9999 date9.; format rssd9007 date9.; format rssd9008 date9.; where rssd9999 between rssd9007 and rssd9008 ; run; %mend bhc_financials; %bhc_financials (01jan1990,01dec2000); Warning RSSD dates are not always available, in which case lines 18-24 should be removed. Merge with Compustat/CRSP \u00b6 The firm identifier in the Y-9C data is RSSD9001 . To merge the BHC's balance sheet data with Compustat/CRSP, I use the PERMCO-RSSD link table by the Federal Reserve Bank of New York. 1 I saved the most recent copy in my server, and formatted it so that it can used directly. It is available at https://mingze-gao.com/data/download/crsp_20181231.csv . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 %let beg_yr = 1986 ; %let end_yr = 2018 ; proc sql; create table lnk as select * from crsp . ccmxpf_lnkhist where linktype in ( \"LU\" , \"LC\" ) and ( &end_yr +1 >= year( linkdt) or linkdt = .B) and ( &beg_yr -1 <= year( linkenddt) or linkenddt = .E) order by gvkey, linkdt ; quit; /* PERMCO-RSSD link table by New York FED */ filename csv url \"https://mingze-gao.com/data/download/crsp_20181231.csv\" ; proc import datafile=csv out =work . crsp_20181231 dbms=csv replace ; run; proc sql; create table gvkey_permno_permco_rssd as select * from lnk join crsp_20181231 as fed on lnk . lpermco=fed . permco ; quit; Note Please run these programs on the WRDS cloud. You'll need to modify them in order to run locally with SAS/Connect. https://www.newyorkfed.org/research/banking_research/datasets.html \u21a9","title":"Bank holding companies' financials from FR Y-9C"},{"location":"posts/get-bank-holding-company-financials/#bank-holing-company-financials-from-fr-y-9c","text":"","title":"Bank Holing Company Financials from FR Y-9C"},{"location":"posts/get-bank-holding-company-financials/#extract-bhc-balance-sheet-data","text":"This is the SAS macro I write to consolidate and extract BHC's balance sheet data from WRDS Bank Regulatory database. It creates a bhcf dataset in the work directory. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 %macro bhc_financials(loopdatestart,loopdateend); /* Specify the variables to extract */ %let vars=rssd9999 rssd9001 rssd9007 rssd9008 bhck2170 bhck3210; %let loopdatestart= %sysfunc ( inputn( &loopdatestart ,anydtdte9.)); %let loopdateend= %sysfunc ( inputn( &loopdateend ,anydtdte9.)); %let dif= %sysfunc ( intck( month, &loopdatestart , &loopdateend )); %let dats=; %do i= 0 %to &dif ; %let date= %sysfunc ( intnx( month, &loopdatestart , &i ,e)); %let month= %sysfunc ( month( &date ),z2.); %let year= %sysfunc ( year( &date )); %if &month = 3 or &month = 6 or &month = 9 or &month = 12 %then %do ; %let dats= &dats bank . bhcf &year&month ; %end ; %end ; %put &dats ; data bhcf( keep = &vars ); set &dats ; rssd9999 = input ( put (rssd9999, 8 .), yymmdd10.); /* reporting date */ rssd9007 = input ( put (rssd9007, 8 .), yymmdd10.); /* date start */ rssd9008 = input ( put (rssd9008, 8 .), yymmdd10.); /* date end */ format rssd9999 date9.; format rssd9007 date9.; format rssd9008 date9.; where rssd9999 between rssd9007 and rssd9008 ; run; %mend bhc_financials; %bhc_financials (01jan1990,01dec2000); Warning RSSD dates are not always available, in which case lines 18-24 should be removed.","title":"Extract BHC balance sheet data"},{"location":"posts/get-bank-holding-company-financials/#merge-with-compustatcrsp","text":"The firm identifier in the Y-9C data is RSSD9001 . To merge the BHC's balance sheet data with Compustat/CRSP, I use the PERMCO-RSSD link table by the Federal Reserve Bank of New York. 1 I saved the most recent copy in my server, and formatted it so that it can used directly. It is available at https://mingze-gao.com/data/download/crsp_20181231.csv . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 %let beg_yr = 1986 ; %let end_yr = 2018 ; proc sql; create table lnk as select * from crsp . ccmxpf_lnkhist where linktype in ( \"LU\" , \"LC\" ) and ( &end_yr +1 >= year( linkdt) or linkdt = .B) and ( &beg_yr -1 <= year( linkenddt) or linkenddt = .E) order by gvkey, linkdt ; quit; /* PERMCO-RSSD link table by New York FED */ filename csv url \"https://mingze-gao.com/data/download/crsp_20181231.csv\" ; proc import datafile=csv out =work . crsp_20181231 dbms=csv replace ; run; proc sql; create table gvkey_permno_permco_rssd as select * from lnk join crsp_20181231 as fed on lnk . lpermco=fed . permco ; quit; Note Please run these programs on the WRDS cloud. You'll need to modify them in order to run locally with SAS/Connect. https://www.newyorkfed.org/research/banking_research/datasets.html \u21a9","title":"Merge with Compustat/CRSP"},{"location":"posts/identify-chinese-state-owned-enterprise-using-csmar/","text":"Many research papers on Chinese firms include a control variable that indicates if the firm is a state-owned enterprise (SOE). This is important as SOEs and non-SOEs differ in many aspects and may have structural differences. This post documents the way to construct this indicator variable from the CSMAR databases. Specifically, we need the CSMAR China Listed Firms Shareholders - Controlling Shareholders dataset. On WRDS, this dataset is named hld_contrshr , located at /wrds/csmar/sasdata/hld . Inside this dataset there're a few variables identifying the ultimate controlling shareholder. s0701b : ultimate controlling shareholder. s0702b : nature of ultimate controlling shareholder. According to the CSMAR documentation, s0702b can be one of the following. Apparently, s0702b=1100 means the firm is a SOE. Code Type 1000 Enterprise business unit 1100 State-owned Enterprise 1210 Collective-owned enterprises 1200 Private Enterprises 1220 Enterprises with funds from Hong Kong, Macau and Taiwan 1230 Foreign-funded enterprises 2000 Administrative departments or institutions 2100 Central institution 2120 Local institution 2500 Social Organization 3000 Natural Persons 3110 Domestic natural persons 3120 Natural person from Hong Kong, Macao and Taiwan 3200 Foreign natural person 9999 Other Princeton University Library has another guide on other ways to identify Chinese SOE.","title":"Identify Chinese State-Owned Enterprise using CSMAR"},{"location":"posts/legao-to-make-your-own-lego-mosaics/","text":"LeGao to Make Your Own LEGO Mosaics \u00b6 I made an online app that turns a picture into a LEGO mosaic, available at mingze-gao.com/legao . A few weeks ago, I went to the new LEGO flagship store at Bondi with my fiancee, Sherry, and we were impressed by the LEGO Mosaics -- Sydney Harbour Bridge and Opera House in sunset, designed by Ryan McNaught (photo credit: jaysbrickblog.com). This mosaic is made of 62,300 bricks and took 282 hours to build. Every single pixel is a 1x1 LEGO brick! We love it so much so that I'm thinking of making one myself and use it to decorate a wall in our apartment in the future. To begin this endeavour, I'll need a handy tool to convert pictures to LEGO mosaic so that I can have a preview and the data to assemble laterly. It turns out that there's already an open-source library named legofy for this job. So I borrowed it and wrote a small Flask app on my server to do the magic. I wrote the frontend using React and Ant Design , and picked up the React Hooks along the way. It was great fun. I named it using a combination of LEGO and my surname Gao , so, LeGao . Now, LeGao is served at mingze-gao.com/legao . A preview is as below: Users can upload an image(<5MB) and decide on which palette to use and how many 1x1 bricks the output image should have for its longest axis. This is useful when we need to make a LEGO mosaic in real world, as a 1x1 brick's dimension is about 8mm x 8mm. The output image can be downloaded, no problem. All images will be deleted from my server after 5 minutes since upload/creation for privacy concern and the fact that my server doesn't have a big storage. LeGao also tells you about how many bricks you'll need to assemble the mosaic, if you really want to. Then you can easily order the bricks online or visit a store to purchase them all~","title":"LeGao to make your own LEGO mosaics"},{"location":"posts/legao-to-make-your-own-lego-mosaics/#legao-to-make-your-own-lego-mosaics","text":"I made an online app that turns a picture into a LEGO mosaic, available at mingze-gao.com/legao . A few weeks ago, I went to the new LEGO flagship store at Bondi with my fiancee, Sherry, and we were impressed by the LEGO Mosaics -- Sydney Harbour Bridge and Opera House in sunset, designed by Ryan McNaught (photo credit: jaysbrickblog.com). This mosaic is made of 62,300 bricks and took 282 hours to build. Every single pixel is a 1x1 LEGO brick! We love it so much so that I'm thinking of making one myself and use it to decorate a wall in our apartment in the future. To begin this endeavour, I'll need a handy tool to convert pictures to LEGO mosaic so that I can have a preview and the data to assemble laterly. It turns out that there's already an open-source library named legofy for this job. So I borrowed it and wrote a small Flask app on my server to do the magic. I wrote the frontend using React and Ant Design , and picked up the React Hooks along the way. It was great fun. I named it using a combination of LEGO and my surname Gao , so, LeGao . Now, LeGao is served at mingze-gao.com/legao . A preview is as below: Users can upload an image(<5MB) and decide on which palette to use and how many 1x1 bricks the output image should have for its longest axis. This is useful when we need to make a LEGO mosaic in real world, as a 1x1 brick's dimension is about 8mm x 8mm. The output image can be downloaded, no problem. All images will be deleted from my server after 5 minutes since upload/creation for privacy concern and the fact that my server doesn't have a big storage. LeGao also tells you about how many bricks you'll need to assemble the mosaic, if you really want to. Then you can easily order the bricks online or visit a store to purchase them all~","title":"LeGao to Make Your Own LEGO Mosaics"},{"location":"posts/merge-compustat-and-crsp/","text":"Merge Compustat and CRSP \u00b6 Using the CRSP/Compustat Merged Database (CCM) to extract data is one of the fundamental steps in most finance studies. Here I document several SAS programs for annual, quarterly and monthly data, inspired by and adapted from several examples from the WRDS. 1 GVKEY-PERMNO link table \u00b6 First, we need to create a GVKEY-PERMNO link table. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 %let beg_yr = 2000 ; %let end_yr = 2003 ; proc sql; create table lnk as select * from crsp . ccmxpf_lnkhist where /* See below for a description of the link types */ linktype in ( \"LU\" , \"LC\" ) and /* Extend the period to deal with fiscal year issues */ /* Note that the \".B\" and \".E\" missing value codes represent the */ /* earliest possible beginning date and latest possible end date */ /* of the Link Date range, respectively. */ ( &end_yr +1 >= year( linkdt) or linkdt = .B) and ( &beg_yr -1 <= year( linkenddt) or linkenddt = .E) order by gvkey, linkdt ; quit; Link Type Description LC Link research complete (after extensive research by CRSP). Standard connection between databases. LU Link is unresearched by CRSP. It is established by comparing the Compustat and historical CRSP CUSIPs. LU represents the most popular link type. LS Link valid for this security only. 2 LX Link to a security that trades on foreign exchange not included in CRSP data. LD Duplicate link to a security. Two GVKEYs map to a single PERMNO ( PERMCO ) during the same period, and this link should not be used. Almost all of these cases happened before 1990. LN Primary link exists but Compustat does not have prices. 3 NR No link available; confirmed by research. NU No link available; not yet confirmed. According to WRDS's support page: Primary link types ( LC , LU and LS ) account for 41% of the links in CCM. Secondary link types ( LX , LD and LN ) account for only 2%. Non-matching link types ( NR and NU ) account for the rest 57%, which is expected because of the different coverage of the two databases. Generally, using LC and LU should be sufficient. Compustat Annual and CRSP \u00b6 Example ccmfunda.sas . 1 2 3 4 5 6 7 8 9 10 11 12 13 proc sql; create table mydata as select * from lnk, comp . funda ( keep =gvkey fyear datadate indfmt datafmt popsrc consol sale) as cst where indfmt= 'INDL' and datafmt= 'STD' and popsrc= 'D' and consol= 'C' and lnk . gvkey = cst . gvkey and ( &beg_yr <= fyear <= &end_yr ) and (linkdt <= cst . datadate or linkdt = .B) and (cst . datadate <= linkenddt or linkenddt = .E) ; quit; Compustat Quarterly and CRSP \u00b6 Example ccmfundq.sas . 1 2 3 4 5 6 7 8 9 10 11 12 13 proc sql; create table mydata as select * from lnk, comp . fundq ( keep =gvkey fyearq datadate indfmt datafmt popsrc consol saley saleq) as cst where indfmt= 'INDL' and datafmt= 'STD' and popsrc= 'D' and consol= 'C' and lnk . gvkey = cst . gvkey and ( &beg_yr <= fyearq <= &end_yr ) and (linkdt <= cst . datadate or linkdt = .B) and (cst . datadate <= linkenddt or linkenddt = .E) ; quit; Compustat Monthly and CRSP \u00b6 To be done. WRDS Overview of CRSP/COMPUSTAT Merged: https://wrds-www.wharton.upenn.edu/pages/support/manuals-and-overviews/crsp/crspcompustat-merged-ccm/wrds-overview-crspcompustat-merged-ccm/ Use CRSP-Compustat Merged Table to Add Permno to Compustat Data: https://wrds-www.wharton.upenn.edu/pages/support/research-wrds/macros/wrds-macro-ccm/ Merging CRSP and Compustat Data: https://wrds-www.wharton.upenn.edu/pages/support/applications/linking-databases/linking-crsp-and-compustat/ \u21a9 Other CRSP PERMNOs with the same PERMCO will link to other GVKEYs . LS links mainly relate to ETFs where a single CRSP PERMCO links to multiple Compustat GVKEYs . In Compustat, even though they may belong to the same investment company (e.g. ISHARES), ETFs are presented with different GVKEYs and CRSP flags this situation. \u21a9 Prices are used to check the accuracy of the link. For linktype LN there is no price information available even on a quarterly or annual basis. The user will have to decide whether or not to include these links. \u21a9","title":"Merge Compustat and CRSP"},{"location":"posts/merge-compustat-and-crsp/#merge-compustat-and-crsp","text":"Using the CRSP/Compustat Merged Database (CCM) to extract data is one of the fundamental steps in most finance studies. Here I document several SAS programs for annual, quarterly and monthly data, inspired by and adapted from several examples from the WRDS. 1","title":"Merge Compustat and CRSP"},{"location":"posts/merge-compustat-and-crsp/#gvkey-permno-link-table","text":"First, we need to create a GVKEY-PERMNO link table. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 %let beg_yr = 2000 ; %let end_yr = 2003 ; proc sql; create table lnk as select * from crsp . ccmxpf_lnkhist where /* See below for a description of the link types */ linktype in ( \"LU\" , \"LC\" ) and /* Extend the period to deal with fiscal year issues */ /* Note that the \".B\" and \".E\" missing value codes represent the */ /* earliest possible beginning date and latest possible end date */ /* of the Link Date range, respectively. */ ( &end_yr +1 >= year( linkdt) or linkdt = .B) and ( &beg_yr -1 <= year( linkenddt) or linkenddt = .E) order by gvkey, linkdt ; quit; Link Type Description LC Link research complete (after extensive research by CRSP). Standard connection between databases. LU Link is unresearched by CRSP. It is established by comparing the Compustat and historical CRSP CUSIPs. LU represents the most popular link type. LS Link valid for this security only. 2 LX Link to a security that trades on foreign exchange not included in CRSP data. LD Duplicate link to a security. Two GVKEYs map to a single PERMNO ( PERMCO ) during the same period, and this link should not be used. Almost all of these cases happened before 1990. LN Primary link exists but Compustat does not have prices. 3 NR No link available; confirmed by research. NU No link available; not yet confirmed. According to WRDS's support page: Primary link types ( LC , LU and LS ) account for 41% of the links in CCM. Secondary link types ( LX , LD and LN ) account for only 2%. Non-matching link types ( NR and NU ) account for the rest 57%, which is expected because of the different coverage of the two databases. Generally, using LC and LU should be sufficient.","title":"GVKEY-PERMNO link table"},{"location":"posts/merge-compustat-and-crsp/#compustat-annual-and-crsp","text":"Example ccmfunda.sas . 1 2 3 4 5 6 7 8 9 10 11 12 13 proc sql; create table mydata as select * from lnk, comp . funda ( keep =gvkey fyear datadate indfmt datafmt popsrc consol sale) as cst where indfmt= 'INDL' and datafmt= 'STD' and popsrc= 'D' and consol= 'C' and lnk . gvkey = cst . gvkey and ( &beg_yr <= fyear <= &end_yr ) and (linkdt <= cst . datadate or linkdt = .B) and (cst . datadate <= linkenddt or linkenddt = .E) ; quit;","title":"Compustat Annual and CRSP"},{"location":"posts/merge-compustat-and-crsp/#compustat-quarterly-and-crsp","text":"Example ccmfundq.sas . 1 2 3 4 5 6 7 8 9 10 11 12 13 proc sql; create table mydata as select * from lnk, comp . fundq ( keep =gvkey fyearq datadate indfmt datafmt popsrc consol saley saleq) as cst where indfmt= 'INDL' and datafmt= 'STD' and popsrc= 'D' and consol= 'C' and lnk . gvkey = cst . gvkey and ( &beg_yr <= fyearq <= &end_yr ) and (linkdt <= cst . datadate or linkdt = .B) and (cst . datadate <= linkenddt or linkenddt = .E) ; quit;","title":"Compustat Quarterly and CRSP"},{"location":"posts/merge-compustat-and-crsp/#compustat-monthly-and-crsp","text":"To be done. WRDS Overview of CRSP/COMPUSTAT Merged: https://wrds-www.wharton.upenn.edu/pages/support/manuals-and-overviews/crsp/crspcompustat-merged-ccm/wrds-overview-crspcompustat-merged-ccm/ Use CRSP-Compustat Merged Table to Add Permno to Compustat Data: https://wrds-www.wharton.upenn.edu/pages/support/research-wrds/macros/wrds-macro-ccm/ Merging CRSP and Compustat Data: https://wrds-www.wharton.upenn.edu/pages/support/applications/linking-databases/linking-crsp-and-compustat/ \u21a9 Other CRSP PERMNOs with the same PERMCO will link to other GVKEYs . LS links mainly relate to ETFs where a single CRSP PERMCO links to multiple Compustat GVKEYs . In Compustat, even though they may belong to the same investment company (e.g. ISHARES), ETFs are presented with different GVKEYs and CRSP flags this situation. \u21a9 Prices are used to check the accuracy of the link. For linktype LN there is no price information available even on a quarterly or annual basis. The user will have to decide whether or not to include these links. \u21a9","title":"Compustat Monthly and CRSP"},{"location":"posts/merger_acquisition_deals_from_sdc_platinum/","text":"Download M&A Deals from SDC Platinum \u00b6 Thomson One Banker SDC Platinum database provides comprehensive M&A transaction data from early 1980s, and is perhaps the most widely used M&A database in the world. This post documents the steps of downloading M&A deals from the SDC Platinum database. Specifically, I show how to download the complete M&A data where: both the acquiror and the target are US firms, the acquiror is a public firm or a private firm, the target is a public firm, a private firm, or a subsidiary, the deal value is at least $1m, and the form of the deal is a acquisition, a merger or an acquisition of majority interest. Interface of SDC Platinum \u00b6 The screenshot below is the interface we'll see on launch of SDC Platinum. Click on Login and we'll be asked to enter our initials and a project name for billing purpose. Click on Login and you'll be asked to enter your initials and a project name for billing purpose. Database Selection \u00b6 Since we're interested in M&A deals, select the Mergers & Acquisitions tab and check US Targets , so that we'll be searching in the domestic mergers database. Then select the sample period, e.g. for the entire 2020 calendar year. Apply Filters on M&A Deals \u00b6 Now we can apply various filters on the M&A deals we want to download. We can quickly add some filters on the target's and acquiror's nation, and make sure we check the Action to be Select not Exclude . Under the Deal tab, we set the deal value to be at least $1m. In case we couldn't find the desired filtering variable, we can head to All Items tab and search manually. We add restrictions on acquiror and target public status here. Lastly, for the Form of the Deal, we restrict to A Acquisition (Stock), M Merger (Stock or Assets) and AM Acquisition of Majority Interest (Stock). We do not want to include deals that are acquisition of partial interest, recapitalization or repurchases in this case. Our search requests should now look like below. Strongly recommended saving this session for later reuse. Specify Deal Variables to Download \u00b6 Our effort so far is only shortlisting the M&A deals that we're interested in. We now need to specify the relevant deal variables to download by creating a new custom report. As before, we can check those variables in the Basics tab or search under All Items tab. Once done, we format the report like below by arranging the order of the variables. This order is preserved when exported to spreadsheet. One note here is that each page has a maximum width of 160, so we need to insert page at proper places. It does not affect the layout of output spreadsheet. It also recommended to save the custom report for later reuse. Finally, it's time to execute the requests and download the M&A deal data. Final Note \u00b6 As a final remark, the downloaded spreadsheet can be imported into SAS and matched with CRSP/Compustat using CUSIP and Ticker (SDC doesn't have permno or gvkey ). First, merge the SDC CUSIP with the first 6-digit CUSIP in CRSP or Compustat; if no match, then use SDC Primary Ticker Symbol to match with the ticker symbol in CRSP or Compustat.","title":"Download M&A deals from SDC Platinum"},{"location":"posts/merger_acquisition_deals_from_sdc_platinum/#download-ma-deals-from-sdc-platinum","text":"Thomson One Banker SDC Platinum database provides comprehensive M&A transaction data from early 1980s, and is perhaps the most widely used M&A database in the world. This post documents the steps of downloading M&A deals from the SDC Platinum database. Specifically, I show how to download the complete M&A data where: both the acquiror and the target are US firms, the acquiror is a public firm or a private firm, the target is a public firm, a private firm, or a subsidiary, the deal value is at least $1m, and the form of the deal is a acquisition, a merger or an acquisition of majority interest.","title":"Download M&amp;A Deals from SDC Platinum"},{"location":"posts/merger_acquisition_deals_from_sdc_platinum/#interface-of-sdc-platinum","text":"The screenshot below is the interface we'll see on launch of SDC Platinum. Click on Login and we'll be asked to enter our initials and a project name for billing purpose. Click on Login and you'll be asked to enter your initials and a project name for billing purpose.","title":"Interface of SDC Platinum"},{"location":"posts/merger_acquisition_deals_from_sdc_platinum/#database-selection","text":"Since we're interested in M&A deals, select the Mergers & Acquisitions tab and check US Targets , so that we'll be searching in the domestic mergers database. Then select the sample period, e.g. for the entire 2020 calendar year.","title":"Database Selection"},{"location":"posts/merger_acquisition_deals_from_sdc_platinum/#apply-filters-on-ma-deals","text":"Now we can apply various filters on the M&A deals we want to download. We can quickly add some filters on the target's and acquiror's nation, and make sure we check the Action to be Select not Exclude . Under the Deal tab, we set the deal value to be at least $1m. In case we couldn't find the desired filtering variable, we can head to All Items tab and search manually. We add restrictions on acquiror and target public status here. Lastly, for the Form of the Deal, we restrict to A Acquisition (Stock), M Merger (Stock or Assets) and AM Acquisition of Majority Interest (Stock). We do not want to include deals that are acquisition of partial interest, recapitalization or repurchases in this case. Our search requests should now look like below. Strongly recommended saving this session for later reuse.","title":"Apply Filters on M&amp;A Deals"},{"location":"posts/merger_acquisition_deals_from_sdc_platinum/#specify-deal-variables-to-download","text":"Our effort so far is only shortlisting the M&A deals that we're interested in. We now need to specify the relevant deal variables to download by creating a new custom report. As before, we can check those variables in the Basics tab or search under All Items tab. Once done, we format the report like below by arranging the order of the variables. This order is preserved when exported to spreadsheet. One note here is that each page has a maximum width of 160, so we need to insert page at proper places. It does not affect the layout of output spreadsheet. It also recommended to save the custom report for later reuse. Finally, it's time to execute the requests and download the M&A deal data.","title":"Specify Deal Variables to Download"},{"location":"posts/merger_acquisition_deals_from_sdc_platinum/#final-note","text":"As a final remark, the downloaded spreadsheet can be imported into SAS and matched with CRSP/Compustat using CUSIP and Ticker (SDC doesn't have permno or gvkey ). First, merge the SDC CUSIP with the first 6-digit CUSIP in CRSP or Compustat; if no match, then use SDC Primary Ticker Symbol to match with the ticker symbol in CRSP or Compustat.","title":"Final Note"},{"location":"posts/minimum-variance-hedge-ratio/","text":"Minimum Variance Hedge Ratio \u00b6 This note briefly explains what's the minimum variance hedge ratio and how to derive it in a cross hedge, where the asset to be hedged is not the same as underlying asset. The Hedge Ratio h h \u00b6 The hedge ratio h h is the ratio of the size of the hedging position to the exposure of the asset to be hedged: N_A N_A : the units of asset held to be hedged ( A A ), i.e. the risk exposure. N_F N_F : the units of the underlying asset hedged with futures ( A' A' ). Note that the underlying asset A' A' may not be the same as the asset to be hedged A A . In a cross hedge, the underlying of the futures is different from the asset to be hedge. h=\\frac{N_F}{N_A}=\\frac{\\text{size of hedging position}}{\\text{size of exposure}} h=\\frac{N_F}{N_A}=\\frac{\\text{size of hedging position}}{\\text{size of exposure}} Apparently, if we vary h h , the variance (risk) of the combined hedged position will also change. The (Optimal) Minimum-Variance Hedge Ratio h^* h^* \u00b6 Our objective in hedging is to manage the variance (risk) of our position, making it as low as possible by setting the hedge ratio h h to be the optimal hedge ratio h^* h^* that minimises the variance of the combined hedged position. Hedge where A'=A A'=A \u00b6 It's relatively easy when the underlying asset of the futures ( A' A' ) is the same as the asset to be hedged ( A A ), as they have a perfect correlation and the same variance. Thus, as long as the hedge ratio h=1 h=1 , where the size of hedging position equals the exposure of the asset held, the perfect correlation and same variance ensure the value changes in the hedging position offset the changes in the value of asset to be hedged, so that the variance of the hedged position is minimum at zero (ignoring other basis risks). This means, the optimal minimum-variance hedge ratio h^*=1 h^*=1 . Cross Hedge where A' \\neq A A' \\neq A \u00b6 When the underlying asset of the futures ( A' A' ) differ from asset to be hedged ( A A ), the optimal hedge ratio h^* h^* that minimises the portfolio variance is not necessarily 1 anymore. Let's now derive h^* h^* . S_t S_t : the spot price of the asset to be hedged at time t=1,2 t=1,2 . F_t F_t : the price of the futures at time t=1,2 t=1,2 . \\sigma_S \\sigma_S : the standard deviation of \\Delta S=S_2 - S_1 \\Delta S=S_2 - S_1 . \\sigma_F \\sigma_F : the standard deviation of \\Delta F=F_2 - F_1 \\Delta F=F_2 - F_1 . \\rho \\rho : the correlation coefficient between \\Delta S \\Delta S and \\Delta F \\Delta F . Let's consider a short hedge , where we long S_t S_t and short h\\times F_t h\\times F_t , hence\uff1a Combined position C=S_t-h\\times F_t C=S_t-h\\times F_t \\Delta C=\\Delta S_t-h\\times \\Delta F_t \\Delta C=\\Delta S_t-h\\times \\Delta F_t The optimal hedge ratio h^* h^* is the hedge ratio that minimises the variance of \\Delta C \\Delta C . h^* =\\underset{h}{\\operatorname{argmin}} \\text{Var}(\\Delta C) =\\underset{h}{\\operatorname{argmin}} \\text{Var}(\\Delta S_t-h\\times \\Delta F_t) h^* =\\underset{h}{\\operatorname{argmin}} \\text{Var}(\\Delta C) =\\underset{h}{\\operatorname{argmin}} \\text{Var}(\\Delta S_t-h\\times \\Delta F_t) We also know that \\text{Var}(\\Delta S_t-h\\times \\Delta F_t) = \\sigma^2_S + h^2\\sigma^2_F - 2h(\\rho \\sigma_S \\sigma_F) \\text{Var}(\\Delta S_t-h\\times \\Delta F_t) = \\sigma^2_S + h^2\\sigma^2_F - 2h(\\rho \\sigma_S \\sigma_F) To minimise the variance, the first-order condition (FOC) is that \\frac{\\partial \\text{Var}(\\Delta C)}{\\partial h}=2h\\sigma^2_F-2(\\rho \\sigma_S \\sigma_F)=0 \\frac{\\partial \\text{Var}(\\Delta C)}{\\partial h}=2h\\sigma^2_F-2(\\rho \\sigma_S \\sigma_F)=0 The optimal hedge ratio h^* h^* is the h h that solves the FOC above. Therefore, h^* = \\rho \\frac{\\sigma_S}{\\sigma_F} h^* = \\rho \\frac{\\sigma_S}{\\sigma_F} Intuition \u00b6 The optimal hedge ratio h^* h^* describes the optimal N_F/N_A N_F/N_A , so that the optimal size of the hedging position: N_F^* = h^* \\times N_A N_F^* = h^* \\times N_A If F F changes by 1%, S S is expected to change by h^* h^* %. If S S changes by 1%, F F is expected to change by (1/h^*) (1/h^*) %. If \\rho=1 \\rho=1 and \\sigma_F=\\sigma_S \\sigma_F=\\sigma_S , then h^*=1 h^*=1 : F F and S S always change in the same way by the same size. Holding the same amount of F F as S S gives the perfect hedge. If \\rho=1 \\rho=1 and \\sigma_F=2\\sigma_S \\sigma_F=2\\sigma_S , then h^*=0.5 h^*=0.5 : F F always changes twice as much as S S . Holding half as much of F F as S S gives the perfect hedge. If \\rho<1 \\rho<1 , then h^* h^* depends on \\rho \\rho and {\\sigma_S}/{\\sigma_F} {\\sigma_S}/{\\sigma_F} : F F is expected to change by (1/h^*) (1/h^*) % when S S changes by 1%. Holding h^* h^* as much of F F as S S gives an imperfect hedge where the value of the hedging position is expected to offset the change in S S .","title":"Minimum variance hedge ratio"},{"location":"posts/minimum-variance-hedge-ratio/#minimum-variance-hedge-ratio","text":"This note briefly explains what's the minimum variance hedge ratio and how to derive it in a cross hedge, where the asset to be hedged is not the same as underlying asset.","title":"Minimum Variance Hedge Ratio"},{"location":"posts/minimum-variance-hedge-ratio/#the-hedge-ratio-hh","text":"The hedge ratio h h is the ratio of the size of the hedging position to the exposure of the asset to be hedged: N_A N_A : the units of asset held to be hedged ( A A ), i.e. the risk exposure. N_F N_F : the units of the underlying asset hedged with futures ( A' A' ). Note that the underlying asset A' A' may not be the same as the asset to be hedged A A . In a cross hedge, the underlying of the futures is different from the asset to be hedge. h=\\frac{N_F}{N_A}=\\frac{\\text{size of hedging position}}{\\text{size of exposure}} h=\\frac{N_F}{N_A}=\\frac{\\text{size of hedging position}}{\\text{size of exposure}} Apparently, if we vary h h , the variance (risk) of the combined hedged position will also change.","title":"The Hedge Ratio hh"},{"location":"posts/minimum-variance-hedge-ratio/#the-optimal-minimum-variance-hedge-ratio-hh","text":"Our objective in hedging is to manage the variance (risk) of our position, making it as low as possible by setting the hedge ratio h h to be the optimal hedge ratio h^* h^* that minimises the variance of the combined hedged position.","title":"The (Optimal) Minimum-Variance Hedge Ratio h^*h^*"},{"location":"posts/minimum-variance-hedge-ratio/#hedge-where-aaaa","text":"It's relatively easy when the underlying asset of the futures ( A' A' ) is the same as the asset to be hedged ( A A ), as they have a perfect correlation and the same variance. Thus, as long as the hedge ratio h=1 h=1 , where the size of hedging position equals the exposure of the asset held, the perfect correlation and same variance ensure the value changes in the hedging position offset the changes in the value of asset to be hedged, so that the variance of the hedged position is minimum at zero (ignoring other basis risks). This means, the optimal minimum-variance hedge ratio h^*=1 h^*=1 .","title":"Hedge where A'=AA'=A"},{"location":"posts/minimum-variance-hedge-ratio/#cross-hedge-where-a-neq-aa-neq-a","text":"When the underlying asset of the futures ( A' A' ) differ from asset to be hedged ( A A ), the optimal hedge ratio h^* h^* that minimises the portfolio variance is not necessarily 1 anymore. Let's now derive h^* h^* . S_t S_t : the spot price of the asset to be hedged at time t=1,2 t=1,2 . F_t F_t : the price of the futures at time t=1,2 t=1,2 . \\sigma_S \\sigma_S : the standard deviation of \\Delta S=S_2 - S_1 \\Delta S=S_2 - S_1 . \\sigma_F \\sigma_F : the standard deviation of \\Delta F=F_2 - F_1 \\Delta F=F_2 - F_1 . \\rho \\rho : the correlation coefficient between \\Delta S \\Delta S and \\Delta F \\Delta F . Let's consider a short hedge , where we long S_t S_t and short h\\times F_t h\\times F_t , hence\uff1a Combined position C=S_t-h\\times F_t C=S_t-h\\times F_t \\Delta C=\\Delta S_t-h\\times \\Delta F_t \\Delta C=\\Delta S_t-h\\times \\Delta F_t The optimal hedge ratio h^* h^* is the hedge ratio that minimises the variance of \\Delta C \\Delta C . h^* =\\underset{h}{\\operatorname{argmin}} \\text{Var}(\\Delta C) =\\underset{h}{\\operatorname{argmin}} \\text{Var}(\\Delta S_t-h\\times \\Delta F_t) h^* =\\underset{h}{\\operatorname{argmin}} \\text{Var}(\\Delta C) =\\underset{h}{\\operatorname{argmin}} \\text{Var}(\\Delta S_t-h\\times \\Delta F_t) We also know that \\text{Var}(\\Delta S_t-h\\times \\Delta F_t) = \\sigma^2_S + h^2\\sigma^2_F - 2h(\\rho \\sigma_S \\sigma_F) \\text{Var}(\\Delta S_t-h\\times \\Delta F_t) = \\sigma^2_S + h^2\\sigma^2_F - 2h(\\rho \\sigma_S \\sigma_F) To minimise the variance, the first-order condition (FOC) is that \\frac{\\partial \\text{Var}(\\Delta C)}{\\partial h}=2h\\sigma^2_F-2(\\rho \\sigma_S \\sigma_F)=0 \\frac{\\partial \\text{Var}(\\Delta C)}{\\partial h}=2h\\sigma^2_F-2(\\rho \\sigma_S \\sigma_F)=0 The optimal hedge ratio h^* h^* is the h h that solves the FOC above. Therefore, h^* = \\rho \\frac{\\sigma_S}{\\sigma_F} h^* = \\rho \\frac{\\sigma_S}{\\sigma_F}","title":"Cross Hedge where A' \\neq AA' \\neq A"},{"location":"posts/minimum-variance-hedge-ratio/#intuition","text":"The optimal hedge ratio h^* h^* describes the optimal N_F/N_A N_F/N_A , so that the optimal size of the hedging position: N_F^* = h^* \\times N_A N_F^* = h^* \\times N_A If F F changes by 1%, S S is expected to change by h^* h^* %. If S S changes by 1%, F F is expected to change by (1/h^*) (1/h^*) %. If \\rho=1 \\rho=1 and \\sigma_F=\\sigma_S \\sigma_F=\\sigma_S , then h^*=1 h^*=1 : F F and S S always change in the same way by the same size. Holding the same amount of F F as S S gives the perfect hedge. If \\rho=1 \\rho=1 and \\sigma_F=2\\sigma_S \\sigma_F=2\\sigma_S , then h^*=0.5 h^*=0.5 : F F always changes twice as much as S S . Holding half as much of F F as S S gives the perfect hedge. If \\rho<1 \\rho<1 , then h^* h^* depends on \\rho \\rho and {\\sigma_S}/{\\sigma_F} {\\sigma_S}/{\\sigma_F} : F F is expected to change by (1/h^*) (1/h^*) % when S S changes by 1%. Holding h^* h^* as much of F F as S S gives an imperfect hedge where the value of the hedging position is expected to offset the change in S S .","title":"Intuition"},{"location":"posts/never-use-a-brain-wallet/","text":"Never Use a Brain Wallet \u00b6 Among many reasons why people find it hard to use cryptocurrency there's a simple one -- memorising the private key is too hard. So, people invented brain wallet , which turns a string of words into a private key and thus wallet. It's genius in that now a user needs only to memorise whatever he or she used to create the wallet. You can turn your name, phone number, DoB, favourite quote, lover's home address, ..., literally anything into a cryptocurrency wallet. However, this also means that if someone else successfully guessed the passphrase you used, they can sweep all the coins you have! Python brain wallet for Bitcoin \u00b6 After a little bit of research, I've put together a simple brain wallet Python script that turns any input string to a legal Bitcoin private key and its address. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 import codecs import hashlib import ecdsa class BrainWallet : @staticmethod def generate_address_from_passphrase ( passphrase ): private_key = str ( hashlib . sha256 ( passphrase . encode ( 'utf-8' )) . hexdigest ()) address = BrainWallet . generate_address_from_private_key ( private_key ) return private_key , address @staticmethod def generate_address_from_private_key ( private_key ): public_key = BrainWallet . __private_to_public ( private_key ) address = BrainWallet . __public_to_address ( public_key ) return address @staticmethod def __private_to_public ( private_key ): private_key_bytes = codecs . decode ( private_key , 'hex' ) # Get ECDSA public key key = ecdsa . SigningKey . from_string ( private_key_bytes , curve = ecdsa . SECP256k1 ) . verifying_key key_bytes = key . to_string () key_hex = codecs . encode ( key_bytes , 'hex' ) # Add bitcoin byte bitcoin_byte = b '04' public_key = bitcoin_byte + key_hex return public_key @staticmethod def __public_to_address ( public_key ): public_key_bytes = codecs . decode ( public_key , 'hex' ) # Run SHA256 for the public key sha256_bpk = hashlib . sha256 ( public_key_bytes ) sha256_bpk_digest = sha256_bpk . digest () # Run ripemd160 for the SHA256 ripemd160_bpk = hashlib . new ( 'ripemd160' ) ripemd160_bpk . update ( sha256_bpk_digest ) ripemd160_bpk_digest = ripemd160_bpk . digest () ripemd160_bpk_hex = codecs . encode ( ripemd160_bpk_digest , 'hex' ) # Add network byte network_byte = b '00' network_bitcoin_public_key = network_byte + ripemd160_bpk_hex network_bitcoin_public_key_bytes = codecs . decode ( network_bitcoin_public_key , 'hex' ) # Double SHA256 to get checksum sha256_nbpk = hashlib . sha256 ( network_bitcoin_public_key_bytes ) sha256_nbpk_digest = sha256_nbpk . digest () sha256_2_nbpk = hashlib . sha256 ( sha256_nbpk_digest ) sha256_2_nbpk_digest = sha256_2_nbpk . digest () sha256_2_hex = codecs . encode ( sha256_2_nbpk_digest , 'hex' ) checksum = sha256_2_hex [: 8 ] # Concatenate public key and checksum to get the address address_hex = ( network_bitcoin_public_key + checksum ) . decode ( 'utf-8' ) wallet = BrainWallet . base58 ( address_hex ) return wallet @staticmethod def base58 ( address_hex ): alphabet = '123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz' b58_string = '' # Get the number of leading zeros and convert hex to decimal leading_zeros = len ( address_hex ) - len ( address_hex . lstrip ( '0' )) # Convert hex to decimal address_int = int ( address_hex , 16 ) # Append digits to the start of string while address_int > 0 : digit = address_int % 58 digit_char = alphabet [ digit ] b58_string = digit_char + b58_string address_int //= 58 # Add '1' for each 2 leading zeros ones = leading_zeros // 2 for one in range ( ones ): b58_string = '1' + b58_string return b58_string Easily \" cracking \" a wallet \u00b6 Let me show you some really easy-to-guess passphrases and their associated private keys and addresses. As an example, the code below uses \"password\" as the input passphrase and derives the private key and address from it. 81 82 83 84 85 86 passphrase = 'password' wallet = BrainWallet () private_key , address = wallet . generate_address_from_passphrase ( passphrase ) print ( f 'passphrase: { passphrase } ' ) print ( f 'private key: { private_key } ' ) print ( f 'address: { address } ' ) The output is: 1 2 3 passphrase : password private key : 5e884898 da28047151d0e56f8dc6292773603d0d6aabbdd62a11ef721d1542d8 address : 16 ga2uqnF1NqpAuQeeg7sTCAdtDUwDyJav As at May 22, 2019, this address has 45,014 transactions with a total of 0.3563 BTC (of course the balance is zero)! You can check its current balance at blockchain.com . Also, congratulations, you are now one of the many owners of this address/wallet. So next time you observe some coins transfered to it, you'll be able to use it as well (though I don't suggest you to do so)! Some other \"cracked\" wallets \u00b6 I explored a little bit more and it's surprising to find out how easy it is to crack a wallet this way. Below is a table of some passphrases and their associated keys and addresses. Passphrase Private Key Address Used satoshi da2876b3eb31edb4436fa4650673fc6f01f90de2f1793c4ec332b2387b09726f 1ADJqstUMBB5zFquWg19UqZ7Zc6ePCpzLE True bitcoin 6b88c087247aa2f07ee1c5956b8e1a9f4c7f892a70e324f1bb3d161e05ca107b 1E984zyYbNmeuumzEdqT8VSL8QGJi3byAD True hello world b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9 1CS8g7nwaxPPprb4vqcTVdLCuCRirsbsMb True testing cf80cd8aed482d5d1527d7dc72fceff84e6326592848447d2dc0b0e87dfc9a90 1JdDsbYYRSpsTnBVgenruULVeUjt5z6WnR True god 5723360ef11043a879520412e9ad897e0ebcb99cc820ec363bfecc9d751a1a99 1KxmSmcMTmPvU1qSLYpJLrqnSzBoQ53NXN True terminator aa802f654e3ae7aaa1b73f8724056a05e2691accea8dd90057916080f84d7e93 18kvt3D6K1CG8MxGP6ke7q6vLU5NGpLZdR True abc ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad 1NEwmNSC7w9nZeASngHCd43Bc5eC2FmXpn True And a lot of swear words are used as well, but I'm just going to skip them. Apart from the single world and short phrases, some people do use famous quotes. As an example, see this one from A Tale of Two Cities : it was the best of times it was the worst of times Its corresponding private key is af8da705bfd95621983e5cf4232ac1ca0c79b47122e3defd8a98fa9a4387d985 and its address is 17WenQJaYvqCNumebQU54TsixWtQ1GQ4ND . It has received 1 BTC in total but again the balance is zero, lol. Concluding remark \u00b6 Never use a brain wallet . Because if you can think of it, someone else might also be able to come up with same passphrase. But, if you are comfortable or absolutely sure that your passphrase is secret, feel free to use the script above and make yourself a wallet. \ud83d\ude0f","title":"Never use a brain wallet"},{"location":"posts/never-use-a-brain-wallet/#never-use-a-brain-wallet","text":"Among many reasons why people find it hard to use cryptocurrency there's a simple one -- memorising the private key is too hard. So, people invented brain wallet , which turns a string of words into a private key and thus wallet. It's genius in that now a user needs only to memorise whatever he or she used to create the wallet. You can turn your name, phone number, DoB, favourite quote, lover's home address, ..., literally anything into a cryptocurrency wallet. However, this also means that if someone else successfully guessed the passphrase you used, they can sweep all the coins you have!","title":"Never Use a Brain Wallet"},{"location":"posts/never-use-a-brain-wallet/#python-brain-wallet-for-bitcoin","text":"After a little bit of research, I've put together a simple brain wallet Python script that turns any input string to a legal Bitcoin private key and its address. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 import codecs import hashlib import ecdsa class BrainWallet : @staticmethod def generate_address_from_passphrase ( passphrase ): private_key = str ( hashlib . sha256 ( passphrase . encode ( 'utf-8' )) . hexdigest ()) address = BrainWallet . generate_address_from_private_key ( private_key ) return private_key , address @staticmethod def generate_address_from_private_key ( private_key ): public_key = BrainWallet . __private_to_public ( private_key ) address = BrainWallet . __public_to_address ( public_key ) return address @staticmethod def __private_to_public ( private_key ): private_key_bytes = codecs . decode ( private_key , 'hex' ) # Get ECDSA public key key = ecdsa . SigningKey . from_string ( private_key_bytes , curve = ecdsa . SECP256k1 ) . verifying_key key_bytes = key . to_string () key_hex = codecs . encode ( key_bytes , 'hex' ) # Add bitcoin byte bitcoin_byte = b '04' public_key = bitcoin_byte + key_hex return public_key @staticmethod def __public_to_address ( public_key ): public_key_bytes = codecs . decode ( public_key , 'hex' ) # Run SHA256 for the public key sha256_bpk = hashlib . sha256 ( public_key_bytes ) sha256_bpk_digest = sha256_bpk . digest () # Run ripemd160 for the SHA256 ripemd160_bpk = hashlib . new ( 'ripemd160' ) ripemd160_bpk . update ( sha256_bpk_digest ) ripemd160_bpk_digest = ripemd160_bpk . digest () ripemd160_bpk_hex = codecs . encode ( ripemd160_bpk_digest , 'hex' ) # Add network byte network_byte = b '00' network_bitcoin_public_key = network_byte + ripemd160_bpk_hex network_bitcoin_public_key_bytes = codecs . decode ( network_bitcoin_public_key , 'hex' ) # Double SHA256 to get checksum sha256_nbpk = hashlib . sha256 ( network_bitcoin_public_key_bytes ) sha256_nbpk_digest = sha256_nbpk . digest () sha256_2_nbpk = hashlib . sha256 ( sha256_nbpk_digest ) sha256_2_nbpk_digest = sha256_2_nbpk . digest () sha256_2_hex = codecs . encode ( sha256_2_nbpk_digest , 'hex' ) checksum = sha256_2_hex [: 8 ] # Concatenate public key and checksum to get the address address_hex = ( network_bitcoin_public_key + checksum ) . decode ( 'utf-8' ) wallet = BrainWallet . base58 ( address_hex ) return wallet @staticmethod def base58 ( address_hex ): alphabet = '123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz' b58_string = '' # Get the number of leading zeros and convert hex to decimal leading_zeros = len ( address_hex ) - len ( address_hex . lstrip ( '0' )) # Convert hex to decimal address_int = int ( address_hex , 16 ) # Append digits to the start of string while address_int > 0 : digit = address_int % 58 digit_char = alphabet [ digit ] b58_string = digit_char + b58_string address_int //= 58 # Add '1' for each 2 leading zeros ones = leading_zeros // 2 for one in range ( ones ): b58_string = '1' + b58_string return b58_string","title":"Python brain wallet for Bitcoin"},{"location":"posts/never-use-a-brain-wallet/#easily-cracking-a-wallet","text":"Let me show you some really easy-to-guess passphrases and their associated private keys and addresses. As an example, the code below uses \"password\" as the input passphrase and derives the private key and address from it. 81 82 83 84 85 86 passphrase = 'password' wallet = BrainWallet () private_key , address = wallet . generate_address_from_passphrase ( passphrase ) print ( f 'passphrase: { passphrase } ' ) print ( f 'private key: { private_key } ' ) print ( f 'address: { address } ' ) The output is: 1 2 3 passphrase : password private key : 5e884898 da28047151d0e56f8dc6292773603d0d6aabbdd62a11ef721d1542d8 address : 16 ga2uqnF1NqpAuQeeg7sTCAdtDUwDyJav As at May 22, 2019, this address has 45,014 transactions with a total of 0.3563 BTC (of course the balance is zero)! You can check its current balance at blockchain.com . Also, congratulations, you are now one of the many owners of this address/wallet. So next time you observe some coins transfered to it, you'll be able to use it as well (though I don't suggest you to do so)!","title":"Easily \"cracking\" a wallet"},{"location":"posts/never-use-a-brain-wallet/#some-other-cracked-wallets","text":"I explored a little bit more and it's surprising to find out how easy it is to crack a wallet this way. Below is a table of some passphrases and their associated keys and addresses. Passphrase Private Key Address Used satoshi da2876b3eb31edb4436fa4650673fc6f01f90de2f1793c4ec332b2387b09726f 1ADJqstUMBB5zFquWg19UqZ7Zc6ePCpzLE True bitcoin 6b88c087247aa2f07ee1c5956b8e1a9f4c7f892a70e324f1bb3d161e05ca107b 1E984zyYbNmeuumzEdqT8VSL8QGJi3byAD True hello world b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9 1CS8g7nwaxPPprb4vqcTVdLCuCRirsbsMb True testing cf80cd8aed482d5d1527d7dc72fceff84e6326592848447d2dc0b0e87dfc9a90 1JdDsbYYRSpsTnBVgenruULVeUjt5z6WnR True god 5723360ef11043a879520412e9ad897e0ebcb99cc820ec363bfecc9d751a1a99 1KxmSmcMTmPvU1qSLYpJLrqnSzBoQ53NXN True terminator aa802f654e3ae7aaa1b73f8724056a05e2691accea8dd90057916080f84d7e93 18kvt3D6K1CG8MxGP6ke7q6vLU5NGpLZdR True abc ba7816bf8f01cfea414140de5dae2223b00361a396177a9cb410ff61f20015ad 1NEwmNSC7w9nZeASngHCd43Bc5eC2FmXpn True And a lot of swear words are used as well, but I'm just going to skip them. Apart from the single world and short phrases, some people do use famous quotes. As an example, see this one from A Tale of Two Cities : it was the best of times it was the worst of times Its corresponding private key is af8da705bfd95621983e5cf4232ac1ca0c79b47122e3defd8a98fa9a4387d985 and its address is 17WenQJaYvqCNumebQU54TsixWtQ1GQ4ND . It has received 1 BTC in total but again the balance is zero, lol.","title":"Some other \"cracked\" wallets"},{"location":"posts/never-use-a-brain-wallet/#concluding-remark","text":"Never use a brain wallet . Because if you can think of it, someone else might also be able to come up with same passphrase. But, if you are comfortable or absolutely sure that your passphrase is secret, feel free to use the script above and make yourself a wallet. \ud83d\ude0f","title":"Concluding remark"},{"location":"posts/python-shared-memory-in-multiprocessing/","text":"Python Shared Memory in Multiprocessing \u00b6 Python 3.8 introduced a new module multiprocessing.shared_memory that provides shared memory for direct access across processes. My test shows that it significantly reduces the memory usage, which also speeds up the program by reducing the costs of copying and moving things around. 1 Test \u00b6 In this test, I generated a 240MB numpy.recarray from a pandas.DataFrame with datetime , int and str typed columns. I used numpy.recarray because it can preserve the dtype of each column, so that later I can reconstruct the same array from the buffer of shared memory. I performed a simple numpy.nansum on the numeric column of the data using two methods. The first method uses multiprocessing.shared_memory where the 4 spawned processes directly access the data in the shared memory. The second method passes the data to the spawned processes, which effectly means each process will have a separate copy of the data. Test Result \u00b6 A quick run of the test code below shows that the first method based on shared_memory uses minimal memory (peak usage is 0.33MB) and is much faster (2.09s) than the second one where the entire data is copied and passed into each process (peak memory usage of 1.8G and takes 216s). More importantly, the memory usage under the second method is consistently high. Test Code \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 from multiprocessing.shared_memory import SharedMemory from multiprocessing.managers import SharedMemoryManager from concurrent.futures import ProcessPoolExecutor , as_completed from multiprocessing import current_process , cpu_count , Process from datetime import datetime import numpy as np import pandas as pd import tracemalloc import time def work_with_shared_memory ( shm_name , shape , dtype ): print ( f 'With SharedMemory: { current_process () =} ' ) # Locate the shared memory by its name shm = SharedMemory ( shm_name ) # Create the np.recarray from the buffer of the shared memory np_array = np . recarray ( shape = shape , dtype = dtype , buf = shm . buf ) return np . nansum ( np_array . val ) def work_no_shared_memory ( np_array : np . recarray ): print ( f 'No SharedMemory: { current_process () =} ' ) # Without shared memory, the np_array is copied into the child process return np . nansum ( np_array . val ) if __name__ == \"__main__\" : # Make a large data frame with date, float and character columns a = [ ( datetime . today (), 1 , 'string' ), ( datetime . today (), np . nan , 'abc' ), ] * 5000000 df = pd . DataFrame ( a , columns = [ 'date' , 'val' , 'character_col' ]) # Convert into numpy recarray to preserve the dtypes np_array = df . to_records ( index = False ) del df shape , dtype = np_array . shape , np_array . dtype print ( f \"np_array's size= { np_array . nbytes / 1e6 } MB\" ) # With shared memory # Start tracking memory usage tracemalloc . start () start_time = time . time () with SharedMemoryManager () as smm : # Create a shared memory of size np_arry.nbytes shm = smm . SharedMemory ( np_array . nbytes ) # Create a np.recarray using the buffer of shm shm_np_array = np . recarray ( shape = shape , dtype = dtype , buf = shm . buf ) # Copy the data into the shared memory np . copyto ( shm_np_array , np_array ) # Spawn some processes to do some work with ProcessPoolExecutor ( cpu_count ()) as exe : fs = [ exe . submit ( work_with_shared_memory , shm . name , shape , dtype ) for _ in range ( cpu_count ())] for _ in as_completed ( fs ): pass # Check memory usage current , peak = tracemalloc . get_traced_memory () print ( f \"Current memory usage { current / 1e6 } MB; Peak: { peak / 1e6 } MB\" ) print ( f 'Time elapsed: { time . time () - start_time : .2f } s' ) tracemalloc . stop () # Without shared memory tracemalloc . start () start_time = time . time () with ProcessPoolExecutor ( cpu_count ()) as exe : fs = [ exe . submit ( work_no_shared_memory , np_array ) for _ in range ( cpu_count ())] for _ in as_completed ( fs ): pass # Check memory usage current , peak = tracemalloc . get_traced_memory () print ( f \"Current memory usage { current / 1e6 } MB; Peak: { peak / 1e6 } MB\" ) print ( f 'Time elapsed: { time . time () - start_time : .2f } s' ) tracemalloc . stop () Important Note \u00b6 Warning A very important note about using multiprocessing.shared_memory , as at June 2020, is that the numpy.ndarray cannot have a dtype=dtype('O') . That is, the dtype cannot be dtype(object) . If it is, there will be a segmentation fault when child processes try to access the shared memory. I'm not sure if it is a bug, because if the shared memory is accessed from within the main process then there will not be any problem. This test is performed on a 2017 12-inch MacBook with 1.3 GHz Dual-Core Intel Core i5 and 8 GB 1867 MHz LPDDR3 RAM. \u21a9","title":"Python Shared Memory in Multiprocessing"},{"location":"posts/python-shared-memory-in-multiprocessing/#python-shared-memory-in-multiprocessing","text":"Python 3.8 introduced a new module multiprocessing.shared_memory that provides shared memory for direct access across processes. My test shows that it significantly reduces the memory usage, which also speeds up the program by reducing the costs of copying and moving things around. 1","title":"Python Shared Memory in Multiprocessing"},{"location":"posts/python-shared-memory-in-multiprocessing/#test","text":"In this test, I generated a 240MB numpy.recarray from a pandas.DataFrame with datetime , int and str typed columns. I used numpy.recarray because it can preserve the dtype of each column, so that later I can reconstruct the same array from the buffer of shared memory. I performed a simple numpy.nansum on the numeric column of the data using two methods. The first method uses multiprocessing.shared_memory where the 4 spawned processes directly access the data in the shared memory. The second method passes the data to the spawned processes, which effectly means each process will have a separate copy of the data.","title":"Test"},{"location":"posts/python-shared-memory-in-multiprocessing/#test-result","text":"A quick run of the test code below shows that the first method based on shared_memory uses minimal memory (peak usage is 0.33MB) and is much faster (2.09s) than the second one where the entire data is copied and passed into each process (peak memory usage of 1.8G and takes 216s). More importantly, the memory usage under the second method is consistently high.","title":"Test Result"},{"location":"posts/python-shared-memory-in-multiprocessing/#test-code","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 from multiprocessing.shared_memory import SharedMemory from multiprocessing.managers import SharedMemoryManager from concurrent.futures import ProcessPoolExecutor , as_completed from multiprocessing import current_process , cpu_count , Process from datetime import datetime import numpy as np import pandas as pd import tracemalloc import time def work_with_shared_memory ( shm_name , shape , dtype ): print ( f 'With SharedMemory: { current_process () =} ' ) # Locate the shared memory by its name shm = SharedMemory ( shm_name ) # Create the np.recarray from the buffer of the shared memory np_array = np . recarray ( shape = shape , dtype = dtype , buf = shm . buf ) return np . nansum ( np_array . val ) def work_no_shared_memory ( np_array : np . recarray ): print ( f 'No SharedMemory: { current_process () =} ' ) # Without shared memory, the np_array is copied into the child process return np . nansum ( np_array . val ) if __name__ == \"__main__\" : # Make a large data frame with date, float and character columns a = [ ( datetime . today (), 1 , 'string' ), ( datetime . today (), np . nan , 'abc' ), ] * 5000000 df = pd . DataFrame ( a , columns = [ 'date' , 'val' , 'character_col' ]) # Convert into numpy recarray to preserve the dtypes np_array = df . to_records ( index = False ) del df shape , dtype = np_array . shape , np_array . dtype print ( f \"np_array's size= { np_array . nbytes / 1e6 } MB\" ) # With shared memory # Start tracking memory usage tracemalloc . start () start_time = time . time () with SharedMemoryManager () as smm : # Create a shared memory of size np_arry.nbytes shm = smm . SharedMemory ( np_array . nbytes ) # Create a np.recarray using the buffer of shm shm_np_array = np . recarray ( shape = shape , dtype = dtype , buf = shm . buf ) # Copy the data into the shared memory np . copyto ( shm_np_array , np_array ) # Spawn some processes to do some work with ProcessPoolExecutor ( cpu_count ()) as exe : fs = [ exe . submit ( work_with_shared_memory , shm . name , shape , dtype ) for _ in range ( cpu_count ())] for _ in as_completed ( fs ): pass # Check memory usage current , peak = tracemalloc . get_traced_memory () print ( f \"Current memory usage { current / 1e6 } MB; Peak: { peak / 1e6 } MB\" ) print ( f 'Time elapsed: { time . time () - start_time : .2f } s' ) tracemalloc . stop () # Without shared memory tracemalloc . start () start_time = time . time () with ProcessPoolExecutor ( cpu_count ()) as exe : fs = [ exe . submit ( work_no_shared_memory , np_array ) for _ in range ( cpu_count ())] for _ in as_completed ( fs ): pass # Check memory usage current , peak = tracemalloc . get_traced_memory () print ( f \"Current memory usage { current / 1e6 } MB; Peak: { peak / 1e6 } MB\" ) print ( f 'Time elapsed: { time . time () - start_time : .2f } s' ) tracemalloc . stop ()","title":"Test Code"},{"location":"posts/python-shared-memory-in-multiprocessing/#important-note","text":"Warning A very important note about using multiprocessing.shared_memory , as at June 2020, is that the numpy.ndarray cannot have a dtype=dtype('O') . That is, the dtype cannot be dtype(object) . If it is, there will be a segmentation fault when child processes try to access the shared memory. I'm not sure if it is a bug, because if the shared memory is accessed from within the main process then there will not be any problem. This test is performed on a 2017 12-inch MacBook with 1.3 GHz Dual-Core Intel Core i5 and 8 GB 1867 MHz LPDDR3 RAM. \u21a9","title":"Important Note"},{"location":"posts/reconciliation-of-black-scholes-variants/","text":"Reconciliation of Black-Scholes Variants \u00b6 This note is just to show that the different variants of Black-Scholes formula in textbook and tutorial solutions are in fact the same. S S : Underlying share price t t : Time to maturity \\sigma \\sigma : Standard deviation of underlying share price K K : Exercise price r_f r_f : Risk-free rate Variant 1 \u00b6 This is the one shown in our formula sheet, and is also the traditional presentation of Black-Scholes model. \\begin{equation} C=SN(d_1)-N(d_2)Ke^{-r_f t} \\end{equation} \\begin{equation} C=SN(d_1)-N(d_2)Ke^{-r_f t} \\end{equation} \\begin{equation} d_1=\\frac{ln(\\frac{S}{K})+(r_f+\\frac{\\sigma^2}{2})t}{\\sigma \\sqrt{t}} \\end{equation} \\begin{equation} d_1=\\frac{ln(\\frac{S}{K})+(r_f+\\frac{\\sigma^2}{2})t}{\\sigma \\sqrt{t}} \\end{equation} \\begin{equation} d_2=d_1 - \\sigma \\sqrt{t} \\end{equation} \\begin{equation} d_2=d_1 - \\sigma \\sqrt{t} \\end{equation} Variant 2 \u00b6 This one comes from textbook, and looks slightly different in that PV(K) PV(K) replaces K K in the natural logarithm. \\begin{equation} C=SN(d_1)-N(d_2)PV(K) \\end{equation} \\begin{equation} C=SN(d_1)-N(d_2)PV(K) \\end{equation} \\begin{equation} d_1=\\frac{ln(\\frac{S}{PV(K)})}{\\sigma \\sqrt{t}}+\\frac{\\sigma \\sqrt{t}}{2} \\end{equation} \\begin{equation} d_1=\\frac{ln(\\frac{S}{PV(K)})}{\\sigma \\sqrt{t}}+\\frac{\\sigma \\sqrt{t}}{2} \\end{equation} \\begin{equation} d_2=d_1 - \\sigma \\sqrt{t} \\end{equation} \\begin{equation} d_2=d_1 - \\sigma \\sqrt{t} \\end{equation} However, it's in fact easy to show that d_1 d_1 in eq. (5) is the same as in eq. (2): Under continuous compounding, PV(K)=Ke^{-r_f t} PV(K)=Ke^{-r_f t} : \\begin{align} d_1 &=\\frac{ln(\\frac{S}{PV(K)})}{\\sigma \\sqrt{t}}+\\frac{\\sigma \\sqrt{t}}{2}\\newline &=\\frac{ln(\\frac{S}{Ke^{-r_f t}})}{\\sigma \\sqrt{t}} +\\frac{\\frac{\\sigma^2}{2}t}{\\sigma \\sqrt{t}}\\newline &=\\frac{ln(\\frac{S}{Ke^{-r_f t}})+\\frac{\\sigma^2}{2}t}{\\sigma \\sqrt{t}}\\newline &=\\frac{ln(\\frac{S}{K})+r_f t+\\frac{\\sigma^2}{2}t}{\\sigma \\sqrt{t}}\\newline &=\\frac{ln(\\frac{S}{K})+(r_f+\\frac{\\sigma^2}{2})t}{\\sigma \\sqrt{t}}=eq. (2) \\end{align} \\begin{align} d_1 &=\\frac{ln(\\frac{S}{PV(K)})}{\\sigma \\sqrt{t}}+\\frac{\\sigma \\sqrt{t}}{2}\\newline &=\\frac{ln(\\frac{S}{Ke^{-r_f t}})}{\\sigma \\sqrt{t}} +\\frac{\\frac{\\sigma^2}{2}t}{\\sigma \\sqrt{t}}\\newline &=\\frac{ln(\\frac{S}{Ke^{-r_f t}})+\\frac{\\sigma^2}{2}t}{\\sigma \\sqrt{t}}\\newline &=\\frac{ln(\\frac{S}{K})+r_f t+\\frac{\\sigma^2}{2}t}{\\sigma \\sqrt{t}}\\newline &=\\frac{ln(\\frac{S}{K})+(r_f+\\frac{\\sigma^2}{2})t}{\\sigma \\sqrt{t}}=eq. (2) \\end{align} Therefore, the two variants are effectively the same under continuous compounding.","title":"Reconciliation of Black-Scholes variants"},{"location":"posts/reconciliation-of-black-scholes-variants/#reconciliation-of-black-scholes-variants","text":"This note is just to show that the different variants of Black-Scholes formula in textbook and tutorial solutions are in fact the same. S S : Underlying share price t t : Time to maturity \\sigma \\sigma : Standard deviation of underlying share price K K : Exercise price r_f r_f : Risk-free rate","title":"Reconciliation of Black-Scholes Variants"},{"location":"posts/reconciliation-of-black-scholes-variants/#variant-1","text":"This is the one shown in our formula sheet, and is also the traditional presentation of Black-Scholes model. \\begin{equation} C=SN(d_1)-N(d_2)Ke^{-r_f t} \\end{equation} \\begin{equation} C=SN(d_1)-N(d_2)Ke^{-r_f t} \\end{equation} \\begin{equation} d_1=\\frac{ln(\\frac{S}{K})+(r_f+\\frac{\\sigma^2}{2})t}{\\sigma \\sqrt{t}} \\end{equation} \\begin{equation} d_1=\\frac{ln(\\frac{S}{K})+(r_f+\\frac{\\sigma^2}{2})t}{\\sigma \\sqrt{t}} \\end{equation} \\begin{equation} d_2=d_1 - \\sigma \\sqrt{t} \\end{equation} \\begin{equation} d_2=d_1 - \\sigma \\sqrt{t} \\end{equation}","title":"Variant 1"},{"location":"posts/reconciliation-of-black-scholes-variants/#variant-2","text":"This one comes from textbook, and looks slightly different in that PV(K) PV(K) replaces K K in the natural logarithm. \\begin{equation} C=SN(d_1)-N(d_2)PV(K) \\end{equation} \\begin{equation} C=SN(d_1)-N(d_2)PV(K) \\end{equation} \\begin{equation} d_1=\\frac{ln(\\frac{S}{PV(K)})}{\\sigma \\sqrt{t}}+\\frac{\\sigma \\sqrt{t}}{2} \\end{equation} \\begin{equation} d_1=\\frac{ln(\\frac{S}{PV(K)})}{\\sigma \\sqrt{t}}+\\frac{\\sigma \\sqrt{t}}{2} \\end{equation} \\begin{equation} d_2=d_1 - \\sigma \\sqrt{t} \\end{equation} \\begin{equation} d_2=d_1 - \\sigma \\sqrt{t} \\end{equation} However, it's in fact easy to show that d_1 d_1 in eq. (5) is the same as in eq. (2): Under continuous compounding, PV(K)=Ke^{-r_f t} PV(K)=Ke^{-r_f t} : \\begin{align} d_1 &=\\frac{ln(\\frac{S}{PV(K)})}{\\sigma \\sqrt{t}}+\\frac{\\sigma \\sqrt{t}}{2}\\newline &=\\frac{ln(\\frac{S}{Ke^{-r_f t}})}{\\sigma \\sqrt{t}} +\\frac{\\frac{\\sigma^2}{2}t}{\\sigma \\sqrt{t}}\\newline &=\\frac{ln(\\frac{S}{Ke^{-r_f t}})+\\frac{\\sigma^2}{2}t}{\\sigma \\sqrt{t}}\\newline &=\\frac{ln(\\frac{S}{K})+r_f t+\\frac{\\sigma^2}{2}t}{\\sigma \\sqrt{t}}\\newline &=\\frac{ln(\\frac{S}{K})+(r_f+\\frac{\\sigma^2}{2})t}{\\sigma \\sqrt{t}}=eq. (2) \\end{align} \\begin{align} d_1 &=\\frac{ln(\\frac{S}{PV(K)})}{\\sigma \\sqrt{t}}+\\frac{\\sigma \\sqrt{t}}{2}\\newline &=\\frac{ln(\\frac{S}{Ke^{-r_f t}})}{\\sigma \\sqrt{t}} +\\frac{\\frac{\\sigma^2}{2}t}{\\sigma \\sqrt{t}}\\newline &=\\frac{ln(\\frac{S}{Ke^{-r_f t}})+\\frac{\\sigma^2}{2}t}{\\sigma \\sqrt{t}}\\newline &=\\frac{ln(\\frac{S}{K})+r_f t+\\frac{\\sigma^2}{2}t}{\\sigma \\sqrt{t}}\\newline &=\\frac{ln(\\frac{S}{K})+(r_f+\\frac{\\sigma^2}{2})t}{\\sigma \\sqrt{t}}=eq. (2) \\end{align} Therefore, the two variants are effectively the same under continuous compounding.","title":"Variant 2"},{"location":"posts/textual-analysis-on-sec-filings/","text":"Textual Analysis on SEC Filings \u00b6 Nowadays top journals favour more granular studies. Sometimes it's useful to dig into the raw SEC filings and perform textual analysis. This note documents how I download all historical SEC filings via EDGAR and conduct some textual analyses. Tip If you don't require a very customized textual analysis, you should try for example SeekEdgar.com . 1. Build a master index of SEC filings \u00b6 I use the python-edgar to download quarterly zipped index files to ./edgar-idx . 1 2 3 $ mkdir ~/edgar && cd ~/edgar $ git clone https://github.com/edouardswiac/python-edgar.git $ python ./python-edgar/run.py -d ./edgar-idx Then merge the downloaded tsv files into a master file using cat . 1 2 $ cat ./edgar-idx/*.tsv > ./edgar-idx/master.tsv $ du -h ./edgar-idx/master.tsv The resulting master.tsv is about 2.6G as at Feb 2020. I then use the following python script to build a SQLite database for more efficient query. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 # Load index files in `edgar-idx` to a sqlite database. import sqlite3 EDGAR_BASE = \"https://www.sec.gov/Archives/\" def parse ( line ): # each line: \"cik|firm_name|file_type|date|url_txt|url_html\" # an example: # \"99780|TRINITY INDUSTRIES INC|8-K|2020-01-15|edgar/data/99780/0000099780-\\ # 20-000008.txt|edgar/data/99780/0000099780-20-000008-index.html\" line = tuple ( line . split ( '|' )[: 5 ]) l = list ( line ) l [ - 1 ] = EDGAR_BASE + l [ - 1 ] return tuple ( l ) if __name__ == '__main__' : conn = sqlite3 . connect ( r \"edgar-idx.sqlite3\" ) c = conn . cursor () c . execute ( '''CREATE TABLE IF NOT EXISTS edgar_idx (cik TEXT, firm_name TEXT, file_type TEXT, date DATE, url TEXT, PRIMARY KEY(cik, file_type, date));''' ) filename = './edgar-idx/master.tsv' with open ( filename , 'r' ) as f : lines = f . readlines () data = [ parse ( line ) for line in lines ] c . executemany ( 'INSERT OR IGNORE INTO edgar_idx \\ (cik, firm_name, file_type, date, url) VALUES (?,?,?,?,?)' , data ) conn . commit () conn . close () 2. Download filings from EDGAR \u00b6 I write the following script to download filings from EDGAR. Note that this script is only a skeleton. The full implementation has proper logging, speed control and detailed error handling. For example, you'll need to keep track of failures and re-download them later. Warning As per SEC's policy, you should limit concurrent requests to below 10 per second. Hence, there is no need to use a proxy pool, such as Scylla . This example script download all 8-K files to ./data/{cik}/{file_type}/{date}.txt.gz . Compression is highly recommended unless you've TBs of free disk space! 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 # Download all 8-K filings. import os import sqlite3 import requests import concurrent.futures import gzip import tqdm def download ( job ): cik , _ , file_type , date , url = job try : res = requests . get ( url ) filename = f './data/ { cik } / { file_type } / { date } .txt.gz' if res . status_code == 200 : with gzip . open ( filename , 'wb' ) as f : f . write ( res . content ) except Exception : pass if __name__ == \"__main__\" : # select what to download conn = sqlite3 . connect ( r \"edgar-idx.sqlite3\" ) c = conn . cursor () c . execute ( 'SELECT * FROM edgar_idx WHERE file_type=\"8-K\";' ) jobs = c . fetchall () conn . close () # start downloading progress = tqdm . tqdm ( total = len ( jobs )) futures = [] with concurrent . futures . ThreadPoolExecutor ( max_workers = 16 ) as exe : for job in jobs : cik , _ , file_type , date , url = job filename = f './data/ { cik } / { file_type } / { date } .txt.gz' os . makedirs ( os . path . dirname ( filename ), exist_ok = True ) if os . path . exists ( filename ): progress . update () else : f = exe . submit ( download , job ) f . add_done_callback ( progress . update ) futures . append ( f ) for f in concurrent . futures . as_completed ( futures ): pass 3. Example textual analyses \u00b6 The downloaded txt files are the text version of filings htmls, which generally are well structured. Specifically, each filing is structured as: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 < SEC-DOCUMENT > < SEC-HEADER ></ SEC-HEADER > < DOCUMENT > < TYPE > < SEQUENCE > < FILENAME > < DESCRIPTION > < TEXT > </ TEXT > </ DESCRIPTION > </ FILENAME > </ SEQUENCE > </ TYPE > </ DOCUMENT > < DOCUMENT ></ DOCUMENT > < DOCUMENT ></ DOCUMENT > ... </ SEC-DOCUMENT > Example 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 < SEC-DOCUMENT > < SEC-HEADER ></ SEC-HEADER > < DOCUMENT > < TYPE > 8-K < SEQUENCE > 1 < FILENAME > f13478e8vk.htm < DESCRIPTION > FORM 8-K < TEXT > ... </ TEXT > </ DESCRIPTION > </ FILENAME > </ SEQUENCE > </ TYPE > </ DOCUMENT > < DOCUMENT > < TYPE > EX-99.1 < SEQUENCE > 2 < FILENAME > f13478exv99w1.htm < DESCRIPTION > EXHIBIT 99.1 < TEXT > ... </ TEXT > </ DESCRIPTION > </ FILENAME > </ SEQUENCE > </ TYPE > </ DOCUMENT > < DOCUMENT ></ DOCUMENT > ... </ SEC-DOCUMENT > 3.1 Extract all items reported in 8-K filings since 2004 \u00b6 Since 2004, SEC requires companies to file 8-K within 4 business days of many types of events. For a short description, see SEC's fast answer to Form 8-K . The detailed instruction (PDF) is available at here . To extract all items reported in each filing since 2004, there are several ways. First, I can use a regular expression to extract all \"Item X.XX\" from the 8-K <DOCUMENT> . Or, I can take advantage of the information in <SEC-HEADER> . Below is an example <SEC-HEADER> 1 , of which the lines of ITEM INFORMATION actually describe the items reported in the filing. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 < SEC-HEADER > 0000079732-02-000036.hdr.sgml : 20020802 < ACCEPTANCE-DATETIME > 20020802082752 ACCESSION NUMBER: 0000079732-02-000036 CONFORMED SUBMISSION TYPE: 8-K PUBLIC DOCUMENT COUNT: 4 CONFORMED PERIOD OF REPORT: 20020801 ITEM INFORMATION: Changes in control of registrant ITEM INFORMATION: Financial statements and exhibits FILED AS OF DATE: 20020802 FILER: COMPANY DATA: COMPANY CONFORMED NAME: ATLANTIC CITY ELECTRIC CO CENTRAL INDEX KEY: 0000008192 STANDARD INDUSTRIAL CLASSIFICATION: ELECTRIC SERVICES [4911] IRS NUMBER: 210398280 STATE OF INCORPORATION: NJ FISCAL YEAR END: 1231 FILING VALUES: FORM TYPE: 8-K SEC ACT: 1934 Act SEC FILE NUMBER: 001-03559 FILM NUMBER: 02717802 BUSINESS ADDRESS: STREET 1: 800 KING STREET STREET 2: PO BOX 231 CITY: WILMINGTON STATE: DE ZIP: 19899 BUSINESS PHONE: 6096454100 MAIL ADDRESS: STREET 1: 800 KING STREET STREET 2: PO BOX 231 CITY: WILMINGTON STATE: DE ZIP: 19899 </ SEC-HEADER > Following this strategy, I write the code below to extract all items reported in 8-K filings since 2004. I didn't use regex for this task because the text portion of the filing is actually dirty. For instance, you'll need to remove all html tags, and be careful about the \"non-breaking space\", &nbsp; , etc. My experience is that using <SEC-HEADER> for this task is the best. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 # Extract all items reported in 8-K filings since 2004. import os import gzip import tqdm import sqlite3 import concurrent.futures BASE_DIR = './data' FILE_TYPE = '8-K' DB = \"result.sqlite3\" def walk_dirpath ( cik , file_type ): \"\"\" Yield paths of all files for a given cik and file type \"\"\" for root , _ , files in os . walk ( os . path . join ( BASE_DIR , cik , file_type )): for filename in files : yield os . path . join ( root , filename ) def regsearch ( cik ): matches = [] for filepath in walk_dirpath ( cik , FILE_TYPE ): date = os . path . split ( filepath )[ 1 ] . strip ( '.txt.gz' ) if int ( date . split ( '-' )[ 0 ]) < 2004 : continue with gzip . open ( filepath , 'rb' ) as f : data = f . readlines () ls = [ l for l in data if l . startswith ( b 'ITEM INFORMATION' )] for l in ls : item = l . decode () . replace ( ' \\t ' , '' ) . replace ( 'ITEM INFORMATION:' , '' ) if len ( item . strip ()): matches . append (( cik , FILE_TYPE , date , item . strip ())) return matches if __name__ == \"__main__\" : conn = sqlite3 . connect ( DB ) c = conn . cursor () c . execute ( '''CREATE TABLE IF NOT EXISTS files_all_items (cik TEXT, file_type TEXT, date DATE, item TEXT, PRIMARY KEY(cik, file_type, date, item));''' ) conn . commit () _ , ciks , _ = next ( os . walk ( BASE_DIR )) progress = tqdm . tqdm ( total = len ( ciks )) with concurrent . futures . ProcessPoolExecutor ( max_workers = 16 ) as exe : futures = [ exe . submit ( regsearch , cik ) for cik in ciks ] for f in concurrent . futures . as_completed ( futures ): res = f . result () c . executemany ( \"INSERT OR IGNORE INTO files_all_items \\ (cik, file_type, date, item) VALUES (?,?,?,?)\" , res ) conn . commit () progress . update () conn . close () 3.2 Find all 8-K filings with Item 1.01 and/or Item 2.03 \u00b6 To get those filings that have either : Item 1.01 Entry into a Material Definitive Agreement, or Item 2.03 Creation of a Direct Financial Obligation or an Obligation under an Off-Balance Sheet Arrangement of a Registrant I run the following SQL query: 1 2 3 4 5 6 7 8 -- SQLite CREATE TABLE ` files_with_items_101_or_203 ` AS SELECT DISTINCT cik , file_type , date FROM ` files_all_items ` WHERE instr ( lower ( item ), \"creation of a direct financial obligation\" ) > 0 OR instr ( lower ( item ), \"entry into a material definitive agreement\" ) > 0 ORDER BY cik , file_type , date ; To get those with both items, use the following query: 1 2 3 4 5 6 7 8 9 10 -- SQLite CREATE TABLE ` files_with_items_101_and_203 ` AS SELECT cik , file_type , date FROM ` files_all_items ` WHERE instr ( lower ( item ), \"creation of a direct financial obligation\" ) > 0 OR instr ( lower ( item ), \"entry into a material definitive agreement\" ) > 0 GROUP BY cik , file_type , date HAVING count ( * ) > 1 ORDER BY cik , file_type , date ; 3.3 Nini, Smith and Sufi (2009) \u00b6 This example code finds the appearance of any of the 10 search words used in \"Creditor control rights and firm investment policy\" by Nini, Smith and Sufi (JFE 2009), which is used to identify the loan contracts as attached in the SEC filing. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 import re import os import sys import gzip import tqdm import sqlite3 import logging import concurrent.futures logging . basicConfig ( stream = sys . stdout , level = logging . WARN ) BASE_DIR = './data' FILE_TYPE = '10-Q' DB = \"result.sqlite3\" # Regex pattern used to remove html tags cleanr = re . compile ( b '<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});' ) # Regex pattern used to find the appearance of any of the 10 search words used # in \"Creditor control rights and firm investment policy\" # by Nini, Smith and Sufi (JFE 2009) # pat_10_words = r\"CREDIT FACILITY|REVOLVING CREDIT|(CREDIT|LOAN|(LOAN (AND|&) \\ # SECURITY)|(FINANCING (AND|&) SECURITY)|CREDIT (AND|&) GUARANTEE) AGREEMENT\" NSS_10_words = [ 'credit facility' , 'revolving credit' , 'credit agreement' , 'loan agreement' , 'loan and security agreement' , 'loan & security agreement' , 'credit and guarantee agreement' , 'credit & guarantee agreement' , 'financing and security agreement' , 'financing & security agreement' ] NSS_10_words_str = '|' . join ([ word . upper () for word in NSS_10_words ]) pat_10_words = re . compile ( NSS_10_words_str . encode ()) # Regex pattern used in this search pattern = pat_10_words def walk_dirpath ( cik , file_type ): \"\"\" Yield paths of all files for a given cik and file type \"\"\" for root , _ , files in os . walk ( os . path . join ( BASE_DIR , cik , file_type )): for filename in files : yield os . path . join ( root , filename ) def regsearch ( cik ): matches = [] for filepath in walk_dirpath ( cik , FILE_TYPE ): date = os . path . split ( filepath )[ 1 ] . strip ( '.txt.gz' ) try : with gzip . open ( filepath , 'rb' ) as f : data = b ' ' . join ( f . read () . splitlines ()) data = re . sub ( cleanr , b '' , data ) match = pattern . search ( data ) if match : matches . append (( cik , FILE_TYPE , date )) logging . info ( f ' { filepath } , { match . group () } ' ) except Exception as e : logging . error ( f 'failed at { filepath } , { e } ' ) return matches if __name__ == \"__main__\" : conn = sqlite3 . connect ( DB ) c = conn . cursor () # create a table to store the indices c . execute ( '''CREATE TABLE IF NOT EXISTS files_with_10_words (cik TEXT, file_type TEXT, date DATE, PRIMARY KEY(cik, file_type, date));''' ) conn . commit () _ , ciks , _ = next ( os . walk ( BASE_DIR )) progress = tqdm . tqdm ( total = len ( ciks )) with concurrent . futures . ProcessPoolExecutor ( max_workers = 16 ) as exe : futures = [ exe . submit ( regsearch , cik ) for cik in ciks ] for f in concurrent . futures . as_completed ( futures ): matches = f . result () c . executemany ( \"INSERT OR IGNORE INTO files_with_10_words \\ (cik, file_type, date) VALUES (?,?,?)\" , matches ) conn . commit () progress . update () conn . close () logging . info ( 'complete' ) The original file is at https://www.sec.gov/Archives/edgar/data/0000008192/0000079732-02-000036.txt \u21a9","title":"Texutal analysis on SEC filings"},{"location":"posts/textual-analysis-on-sec-filings/#textual-analysis-on-sec-filings","text":"Nowadays top journals favour more granular studies. Sometimes it's useful to dig into the raw SEC filings and perform textual analysis. This note documents how I download all historical SEC filings via EDGAR and conduct some textual analyses. Tip If you don't require a very customized textual analysis, you should try for example SeekEdgar.com .","title":"Textual Analysis on SEC Filings"},{"location":"posts/textual-analysis-on-sec-filings/#1-build-a-master-index-of-sec-filings","text":"I use the python-edgar to download quarterly zipped index files to ./edgar-idx . 1 2 3 $ mkdir ~/edgar && cd ~/edgar $ git clone https://github.com/edouardswiac/python-edgar.git $ python ./python-edgar/run.py -d ./edgar-idx Then merge the downloaded tsv files into a master file using cat . 1 2 $ cat ./edgar-idx/*.tsv > ./edgar-idx/master.tsv $ du -h ./edgar-idx/master.tsv The resulting master.tsv is about 2.6G as at Feb 2020. I then use the following python script to build a SQLite database for more efficient query. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 # Load index files in `edgar-idx` to a sqlite database. import sqlite3 EDGAR_BASE = \"https://www.sec.gov/Archives/\" def parse ( line ): # each line: \"cik|firm_name|file_type|date|url_txt|url_html\" # an example: # \"99780|TRINITY INDUSTRIES INC|8-K|2020-01-15|edgar/data/99780/0000099780-\\ # 20-000008.txt|edgar/data/99780/0000099780-20-000008-index.html\" line = tuple ( line . split ( '|' )[: 5 ]) l = list ( line ) l [ - 1 ] = EDGAR_BASE + l [ - 1 ] return tuple ( l ) if __name__ == '__main__' : conn = sqlite3 . connect ( r \"edgar-idx.sqlite3\" ) c = conn . cursor () c . execute ( '''CREATE TABLE IF NOT EXISTS edgar_idx (cik TEXT, firm_name TEXT, file_type TEXT, date DATE, url TEXT, PRIMARY KEY(cik, file_type, date));''' ) filename = './edgar-idx/master.tsv' with open ( filename , 'r' ) as f : lines = f . readlines () data = [ parse ( line ) for line in lines ] c . executemany ( 'INSERT OR IGNORE INTO edgar_idx \\ (cik, firm_name, file_type, date, url) VALUES (?,?,?,?,?)' , data ) conn . commit () conn . close ()","title":"1. Build a master index of SEC filings"},{"location":"posts/textual-analysis-on-sec-filings/#2-download-filings-from-edgar","text":"I write the following script to download filings from EDGAR. Note that this script is only a skeleton. The full implementation has proper logging, speed control and detailed error handling. For example, you'll need to keep track of failures and re-download them later. Warning As per SEC's policy, you should limit concurrent requests to below 10 per second. Hence, there is no need to use a proxy pool, such as Scylla . This example script download all 8-K files to ./data/{cik}/{file_type}/{date}.txt.gz . Compression is highly recommended unless you've TBs of free disk space! 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 # Download all 8-K filings. import os import sqlite3 import requests import concurrent.futures import gzip import tqdm def download ( job ): cik , _ , file_type , date , url = job try : res = requests . get ( url ) filename = f './data/ { cik } / { file_type } / { date } .txt.gz' if res . status_code == 200 : with gzip . open ( filename , 'wb' ) as f : f . write ( res . content ) except Exception : pass if __name__ == \"__main__\" : # select what to download conn = sqlite3 . connect ( r \"edgar-idx.sqlite3\" ) c = conn . cursor () c . execute ( 'SELECT * FROM edgar_idx WHERE file_type=\"8-K\";' ) jobs = c . fetchall () conn . close () # start downloading progress = tqdm . tqdm ( total = len ( jobs )) futures = [] with concurrent . futures . ThreadPoolExecutor ( max_workers = 16 ) as exe : for job in jobs : cik , _ , file_type , date , url = job filename = f './data/ { cik } / { file_type } / { date } .txt.gz' os . makedirs ( os . path . dirname ( filename ), exist_ok = True ) if os . path . exists ( filename ): progress . update () else : f = exe . submit ( download , job ) f . add_done_callback ( progress . update ) futures . append ( f ) for f in concurrent . futures . as_completed ( futures ): pass","title":"2. Download filings from EDGAR"},{"location":"posts/textual-analysis-on-sec-filings/#3-example-textual-analyses","text":"The downloaded txt files are the text version of filings htmls, which generally are well structured. Specifically, each filing is structured as: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 < SEC-DOCUMENT > < SEC-HEADER ></ SEC-HEADER > < DOCUMENT > < TYPE > < SEQUENCE > < FILENAME > < DESCRIPTION > < TEXT > </ TEXT > </ DESCRIPTION > </ FILENAME > </ SEQUENCE > </ TYPE > </ DOCUMENT > < DOCUMENT ></ DOCUMENT > < DOCUMENT ></ DOCUMENT > ... </ SEC-DOCUMENT > Example 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 < SEC-DOCUMENT > < SEC-HEADER ></ SEC-HEADER > < DOCUMENT > < TYPE > 8-K < SEQUENCE > 1 < FILENAME > f13478e8vk.htm < DESCRIPTION > FORM 8-K < TEXT > ... </ TEXT > </ DESCRIPTION > </ FILENAME > </ SEQUENCE > </ TYPE > </ DOCUMENT > < DOCUMENT > < TYPE > EX-99.1 < SEQUENCE > 2 < FILENAME > f13478exv99w1.htm < DESCRIPTION > EXHIBIT 99.1 < TEXT > ... </ TEXT > </ DESCRIPTION > </ FILENAME > </ SEQUENCE > </ TYPE > </ DOCUMENT > < DOCUMENT ></ DOCUMENT > ... </ SEC-DOCUMENT >","title":"3. Example textual analyses"},{"location":"posts/textual-analysis-on-sec-filings/#31-extract-all-items-reported-in-8-k-filings-since-2004","text":"Since 2004, SEC requires companies to file 8-K within 4 business days of many types of events. For a short description, see SEC's fast answer to Form 8-K . The detailed instruction (PDF) is available at here . To extract all items reported in each filing since 2004, there are several ways. First, I can use a regular expression to extract all \"Item X.XX\" from the 8-K <DOCUMENT> . Or, I can take advantage of the information in <SEC-HEADER> . Below is an example <SEC-HEADER> 1 , of which the lines of ITEM INFORMATION actually describe the items reported in the filing. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 < SEC-HEADER > 0000079732-02-000036.hdr.sgml : 20020802 < ACCEPTANCE-DATETIME > 20020802082752 ACCESSION NUMBER: 0000079732-02-000036 CONFORMED SUBMISSION TYPE: 8-K PUBLIC DOCUMENT COUNT: 4 CONFORMED PERIOD OF REPORT: 20020801 ITEM INFORMATION: Changes in control of registrant ITEM INFORMATION: Financial statements and exhibits FILED AS OF DATE: 20020802 FILER: COMPANY DATA: COMPANY CONFORMED NAME: ATLANTIC CITY ELECTRIC CO CENTRAL INDEX KEY: 0000008192 STANDARD INDUSTRIAL CLASSIFICATION: ELECTRIC SERVICES [4911] IRS NUMBER: 210398280 STATE OF INCORPORATION: NJ FISCAL YEAR END: 1231 FILING VALUES: FORM TYPE: 8-K SEC ACT: 1934 Act SEC FILE NUMBER: 001-03559 FILM NUMBER: 02717802 BUSINESS ADDRESS: STREET 1: 800 KING STREET STREET 2: PO BOX 231 CITY: WILMINGTON STATE: DE ZIP: 19899 BUSINESS PHONE: 6096454100 MAIL ADDRESS: STREET 1: 800 KING STREET STREET 2: PO BOX 231 CITY: WILMINGTON STATE: DE ZIP: 19899 </ SEC-HEADER > Following this strategy, I write the code below to extract all items reported in 8-K filings since 2004. I didn't use regex for this task because the text portion of the filing is actually dirty. For instance, you'll need to remove all html tags, and be careful about the \"non-breaking space\", &nbsp; , etc. My experience is that using <SEC-HEADER> for this task is the best. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 # Extract all items reported in 8-K filings since 2004. import os import gzip import tqdm import sqlite3 import concurrent.futures BASE_DIR = './data' FILE_TYPE = '8-K' DB = \"result.sqlite3\" def walk_dirpath ( cik , file_type ): \"\"\" Yield paths of all files for a given cik and file type \"\"\" for root , _ , files in os . walk ( os . path . join ( BASE_DIR , cik , file_type )): for filename in files : yield os . path . join ( root , filename ) def regsearch ( cik ): matches = [] for filepath in walk_dirpath ( cik , FILE_TYPE ): date = os . path . split ( filepath )[ 1 ] . strip ( '.txt.gz' ) if int ( date . split ( '-' )[ 0 ]) < 2004 : continue with gzip . open ( filepath , 'rb' ) as f : data = f . readlines () ls = [ l for l in data if l . startswith ( b 'ITEM INFORMATION' )] for l in ls : item = l . decode () . replace ( ' \\t ' , '' ) . replace ( 'ITEM INFORMATION:' , '' ) if len ( item . strip ()): matches . append (( cik , FILE_TYPE , date , item . strip ())) return matches if __name__ == \"__main__\" : conn = sqlite3 . connect ( DB ) c = conn . cursor () c . execute ( '''CREATE TABLE IF NOT EXISTS files_all_items (cik TEXT, file_type TEXT, date DATE, item TEXT, PRIMARY KEY(cik, file_type, date, item));''' ) conn . commit () _ , ciks , _ = next ( os . walk ( BASE_DIR )) progress = tqdm . tqdm ( total = len ( ciks )) with concurrent . futures . ProcessPoolExecutor ( max_workers = 16 ) as exe : futures = [ exe . submit ( regsearch , cik ) for cik in ciks ] for f in concurrent . futures . as_completed ( futures ): res = f . result () c . executemany ( \"INSERT OR IGNORE INTO files_all_items \\ (cik, file_type, date, item) VALUES (?,?,?,?)\" , res ) conn . commit () progress . update () conn . close ()","title":"3.1 Extract all items reported in 8-K filings since 2004"},{"location":"posts/textual-analysis-on-sec-filings/#32-find-all-8-k-filings-with-item-101-andor-item-203","text":"To get those filings that have either : Item 1.01 Entry into a Material Definitive Agreement, or Item 2.03 Creation of a Direct Financial Obligation or an Obligation under an Off-Balance Sheet Arrangement of a Registrant I run the following SQL query: 1 2 3 4 5 6 7 8 -- SQLite CREATE TABLE ` files_with_items_101_or_203 ` AS SELECT DISTINCT cik , file_type , date FROM ` files_all_items ` WHERE instr ( lower ( item ), \"creation of a direct financial obligation\" ) > 0 OR instr ( lower ( item ), \"entry into a material definitive agreement\" ) > 0 ORDER BY cik , file_type , date ; To get those with both items, use the following query: 1 2 3 4 5 6 7 8 9 10 -- SQLite CREATE TABLE ` files_with_items_101_and_203 ` AS SELECT cik , file_type , date FROM ` files_all_items ` WHERE instr ( lower ( item ), \"creation of a direct financial obligation\" ) > 0 OR instr ( lower ( item ), \"entry into a material definitive agreement\" ) > 0 GROUP BY cik , file_type , date HAVING count ( * ) > 1 ORDER BY cik , file_type , date ;","title":"3.2 Find all 8-K filings with Item 1.01 and/or Item 2.03"},{"location":"posts/textual-analysis-on-sec-filings/#33-nini-smith-and-sufi-2009","text":"This example code finds the appearance of any of the 10 search words used in \"Creditor control rights and firm investment policy\" by Nini, Smith and Sufi (JFE 2009), which is used to identify the loan contracts as attached in the SEC filing. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 import re import os import sys import gzip import tqdm import sqlite3 import logging import concurrent.futures logging . basicConfig ( stream = sys . stdout , level = logging . WARN ) BASE_DIR = './data' FILE_TYPE = '10-Q' DB = \"result.sqlite3\" # Regex pattern used to remove html tags cleanr = re . compile ( b '<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});' ) # Regex pattern used to find the appearance of any of the 10 search words used # in \"Creditor control rights and firm investment policy\" # by Nini, Smith and Sufi (JFE 2009) # pat_10_words = r\"CREDIT FACILITY|REVOLVING CREDIT|(CREDIT|LOAN|(LOAN (AND|&) \\ # SECURITY)|(FINANCING (AND|&) SECURITY)|CREDIT (AND|&) GUARANTEE) AGREEMENT\" NSS_10_words = [ 'credit facility' , 'revolving credit' , 'credit agreement' , 'loan agreement' , 'loan and security agreement' , 'loan & security agreement' , 'credit and guarantee agreement' , 'credit & guarantee agreement' , 'financing and security agreement' , 'financing & security agreement' ] NSS_10_words_str = '|' . join ([ word . upper () for word in NSS_10_words ]) pat_10_words = re . compile ( NSS_10_words_str . encode ()) # Regex pattern used in this search pattern = pat_10_words def walk_dirpath ( cik , file_type ): \"\"\" Yield paths of all files for a given cik and file type \"\"\" for root , _ , files in os . walk ( os . path . join ( BASE_DIR , cik , file_type )): for filename in files : yield os . path . join ( root , filename ) def regsearch ( cik ): matches = [] for filepath in walk_dirpath ( cik , FILE_TYPE ): date = os . path . split ( filepath )[ 1 ] . strip ( '.txt.gz' ) try : with gzip . open ( filepath , 'rb' ) as f : data = b ' ' . join ( f . read () . splitlines ()) data = re . sub ( cleanr , b '' , data ) match = pattern . search ( data ) if match : matches . append (( cik , FILE_TYPE , date )) logging . info ( f ' { filepath } , { match . group () } ' ) except Exception as e : logging . error ( f 'failed at { filepath } , { e } ' ) return matches if __name__ == \"__main__\" : conn = sqlite3 . connect ( DB ) c = conn . cursor () # create a table to store the indices c . execute ( '''CREATE TABLE IF NOT EXISTS files_with_10_words (cik TEXT, file_type TEXT, date DATE, PRIMARY KEY(cik, file_type, date));''' ) conn . commit () _ , ciks , _ = next ( os . walk ( BASE_DIR )) progress = tqdm . tqdm ( total = len ( ciks )) with concurrent . futures . ProcessPoolExecutor ( max_workers = 16 ) as exe : futures = [ exe . submit ( regsearch , cik ) for cik in ciks ] for f in concurrent . futures . as_completed ( futures ): matches = f . result () c . executemany ( \"INSERT OR IGNORE INTO files_with_10_words \\ (cik, file_type, date) VALUES (?,?,?)\" , matches ) conn . commit () progress . update () conn . close () logging . info ( 'complete' ) The original file is at https://www.sec.gov/Archives/edgar/data/0000008192/0000079732-02-000036.txt \u21a9","title":"3.3 Nini, Smith and Sufi (2009)"},{"location":"posts/use-sas-macros-on-wrds/","text":"Use SAS Macros on WRDS \u00b6 The Wharton Research Data Services (WRDS) provides quite a handful of SAS macros that can be used directly. This article explains how to use those handy macros on WRDS when you use remote submission to run your code on the WRDS cloud. Lastly, it explains how to load and use third-party SAS macros from a URL. Prerequisite \u00b6 Before everything, just make sure that this autoexec.sas is located in the home folder on your WRDS cloud. 1 2 3 4 * The library name definitions below are used by SAS; * Assign default libref for WRDS (Wharton Research Data Services); %include '/wrds/lib/utility/wrdslib.sas' ; options sasautos=( '/wrds/wrdsmacros/' , SASAUTOS) MAUTOSOURCE; This code runs automatically when you've connected to the WRDS cloud. The first line assigns the default library references for you to use, e.g. comp for Compustat. The second line makes available the macros. A list of these handy macros is available at the WRDS documentation . If you don't have this SAS code in the home folder, simply create one there or you can choose to include these two lines of code in your remotely submitted code. Simple usage \u00b6 Let's say we want to winsorize a dataset by using the macro provided by WRDS ( full code ). Below is an example of winsorizing Total Assets AT of Compustat sample by fiscal year from 1980 to 2018. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 %let wrds=wrds-cloud . wharton . upenn . edu 4016 ; options comamid=TCP remote=WRDS; signon username=_prompt_; rsubmit; /* Create a dataset in the work directory */ data work . funda( keep =gvkey fyear at); set comp . funda; if 1980 <= fyear <= 2018 ; /* Generic filter */ if indfmt= 'INDL' and datafmt= 'STD' and popsrc= 'D' and consol= 'C' ; run; /* Invoke the macro */ /* The documentation is available at: https://wrds-www.wharton.upenn.edu/pages/support/research-wrds/macros/wrds-macros-winsorize/ */ %WINSORIZE (INSET=funda,OUTSET=funda_w,SORTVAR=fyear,VARS=at,PERC1= 1 ,TRIM= 0 ); /* Before the winsorization */ proc means data=work . funda; by fyear; var at; output out =funda_before_win min= mean= max= / autoname ; run; /* After the winsorization */ proc means data=work . funda_w; by fyear; var at; output out =funda_after_win min= mean= max= / autoname ; run; proc print data=funda_before_win ; proc print data=funda_after_win ; run; endrsubmit; signoff; Invoking the macro is as simple as a single line: 32 %WINSORIZE (INSET=funda,OUTSET=funda_w,SORTVAR=fyear,VARS=at,PERC1= 1 ,TRIM= 0 ); However, one thing to note about this particular winsorization macro by WRDS is that a variable named a is used in line 57 and 59. So if the INSET has a variable named a as well, there\u2019ll be possible data integrity issue. Hence, I prefer to use another version described in my other post Winsorization in SAS . Load SAS macros from URL \u00b6 I tend to collect and store all useful macros on my personal server, hence I don't need to worry about a loss of or changes to the macros. To use these macros, simply include them before invoking. 1 2 filename winsor url \"https://mingze-gao.com/utils/winsor.sas\" ; %include winsor; Then, I can simply call winsor as below. 3 4 %let winsVars = tac inv_at_l drev drevadj ppe roa; %winsor (dsetin=work . funda, dsetout=work . funda_wins, byvar=fyear, vars= &winsVars , type=winsor, pctl= 1 99 );","title":"Use SAS macros on WRDS"},{"location":"posts/use-sas-macros-on-wrds/#use-sas-macros-on-wrds","text":"The Wharton Research Data Services (WRDS) provides quite a handful of SAS macros that can be used directly. This article explains how to use those handy macros on WRDS when you use remote submission to run your code on the WRDS cloud. Lastly, it explains how to load and use third-party SAS macros from a URL.","title":"Use SAS Macros on WRDS"},{"location":"posts/use-sas-macros-on-wrds/#prerequisite","text":"Before everything, just make sure that this autoexec.sas is located in the home folder on your WRDS cloud. 1 2 3 4 * The library name definitions below are used by SAS; * Assign default libref for WRDS (Wharton Research Data Services); %include '/wrds/lib/utility/wrdslib.sas' ; options sasautos=( '/wrds/wrdsmacros/' , SASAUTOS) MAUTOSOURCE; This code runs automatically when you've connected to the WRDS cloud. The first line assigns the default library references for you to use, e.g. comp for Compustat. The second line makes available the macros. A list of these handy macros is available at the WRDS documentation . If you don't have this SAS code in the home folder, simply create one there or you can choose to include these two lines of code in your remotely submitted code.","title":"Prerequisite"},{"location":"posts/use-sas-macros-on-wrds/#simple-usage","text":"Let's say we want to winsorize a dataset by using the macro provided by WRDS ( full code ). Below is an example of winsorizing Total Assets AT of Compustat sample by fiscal year from 1980 to 2018. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 %let wrds=wrds-cloud . wharton . upenn . edu 4016 ; options comamid=TCP remote=WRDS; signon username=_prompt_; rsubmit; /* Create a dataset in the work directory */ data work . funda( keep =gvkey fyear at); set comp . funda; if 1980 <= fyear <= 2018 ; /* Generic filter */ if indfmt= 'INDL' and datafmt= 'STD' and popsrc= 'D' and consol= 'C' ; run; /* Invoke the macro */ /* The documentation is available at: https://wrds-www.wharton.upenn.edu/pages/support/research-wrds/macros/wrds-macros-winsorize/ */ %WINSORIZE (INSET=funda,OUTSET=funda_w,SORTVAR=fyear,VARS=at,PERC1= 1 ,TRIM= 0 ); /* Before the winsorization */ proc means data=work . funda; by fyear; var at; output out =funda_before_win min= mean= max= / autoname ; run; /* After the winsorization */ proc means data=work . funda_w; by fyear; var at; output out =funda_after_win min= mean= max= / autoname ; run; proc print data=funda_before_win ; proc print data=funda_after_win ; run; endrsubmit; signoff; Invoking the macro is as simple as a single line: 32 %WINSORIZE (INSET=funda,OUTSET=funda_w,SORTVAR=fyear,VARS=at,PERC1= 1 ,TRIM= 0 ); However, one thing to note about this particular winsorization macro by WRDS is that a variable named a is used in line 57 and 59. So if the INSET has a variable named a as well, there\u2019ll be possible data integrity issue. Hence, I prefer to use another version described in my other post Winsorization in SAS .","title":"Simple usage"},{"location":"posts/use-sas-macros-on-wrds/#load-sas-macros-from-url","text":"I tend to collect and store all useful macros on my personal server, hence I don't need to worry about a loss of or changes to the macros. To use these macros, simply include them before invoking. 1 2 filename winsor url \"https://mingze-gao.com/utils/winsor.sas\" ; %include winsor; Then, I can simply call winsor as below. 3 4 %let winsVars = tac inv_at_l drev drevadj ppe roa; %winsor (dsetin=work . funda, dsetout=work . funda_wins, byvar=fyear, vars= &winsVars , type=winsor, pctl= 1 99 );","title":"Load SAS macros from URL"},{"location":"posts/what-it-takes-to-be-a-ceo/","text":"What it takes to be a CEO? A fun survey of literature. \u00b6 Taking up the position of CEO means more than pressure from the board and investors. You\u2019ll also face heavy scrutiny from academia. Whether or not a firm\u2019s hiring and compensation committees use them as a reference, here are some of the findings that you may want to be aware of. Upon birth \u00b6 There are many things determined when you\u2019re born. It\u2019ll be naive to think that they matter less than anything else. A starter example is the Journal of Financial Economics paper \"Are CEOs born leaders? Lessons from traits of a million individuals\" by Adams, Keloharju and Knupfer (2018) . 1. Birthday (month) \u00b6 Birth month affects school entry, which affects whether you are relatively older in the class. If you are born after the cutoff month, you'll have to wait for another year for entry. But this extra year buys you some more time to develop, which makes you more confident than the younger peers. This increased confidence is linked to adult labor market outcomes. Bai, Ma, Mullally and Solomon (2019 JFE) find that in mutual fund industry, it's associated with better stock selection and fund performance. These relatively older fund managers also appear more confident in photographs and display more confident behaviours: making larger bets, window dressing their holdings less, and so on. 2. Birth order \u00b6 The birth order also matters: negative associations between birth order and intelligence level have been found in numerous studies. More frankly, first born kids tend to have higher IQ scores. Kristensen and Bjerkedal (2007 Science) show that this is more dependent on social rank in the family where they receive more-favorable family interaction and stimulation. However, birth order is still the most prominent observable factor. Custodio and Siegel (2018) published a working paper where they find CEOs are more likely to be the first-born child of their family, and the results hold for both family and non-family firms, though thankfully the advantage of being first-born seems to decay over time. 3. Gender \u00b6 Studies on CEO gender difference and its relation with firm risk-taking, capital allocation, accounting conservatism, corporate social responsibility, and so on are plenty. Genearlly it is shown that male executives are overconfident relative to female executives (Huang and Kisgen, 2013 JFE) , and we know that overconfidence is not necessarily a good thing. Firms run by female CEOs use lower leverage and have less volative earnings, (Faccio, Marchica and Mura 2016 JCF) , and there are a lot more differences in terms of firm operational, financial, and M&A performances. Tate and Yang (2015 JFE) show that female leaders cultivate more female-friendly cultures inside their firms. Moreover, (having) a female director may bring a firm more access to external finance. Goldman Sachs announced on 23 January 2020 that they won't take companies public anymore unless they have at least one \"diverse\" board member. 4. Hometown \u00b6 Everyone has some sort of hometown biases as well as hometown advantages. For example, Jiang, Qian and Yonker (2019 JFQA) find that CEOs are over twice as likely to acquire targets located in the states of their childhood homes than similar targets elsewhere. Smaller such deals are on average destorying shareholder value but bigger ones tend to be value enhancing. They conclude that CEOs may seek private benefits when acquiring small targets in their hometown but can also avoid poor deals due to hometown advantages. In a Chinese study, Kong, Pan, Tian and Zhang (2020 JCF) show that CEO's hometown connections increase access to trade credit and such effect is more pronounced for non-SOEs and firms in poor regions. In another Chinese study on commercial banks, Bian, Ji and Zhang (2019 JBF) find that a higher degree of dialect similarity between chairman and the CEO is associated with a higher ROA, ROE and a lower cost-to-income ratio, but is not with bank risks, CEO pay or lower pay-performance sensitivity. They conclude that speaking a similar dialect with the chairman doesn't undermine monitoring and reduces agency costs. 5. Cultural heritage \u00b6 The place where you're born has even more profound implications through cultural heritage. Nguyen, Hagendorff and Eshraghi (2018 RFS) show that following shocks to industry competition, firms led by CEOs who are second- or third-generation immigrants are associated with a 6.2% higher profitability compared with the average firm. Their analysis attributes this effect to various cultural values that prevail in a CEO\u2019s ancestral country of origin. Through an epidemiological approach, Liu (2016 JFE) show that a corruption culture of corporate insiders' country of ancestry is associated with higher likelihood of earnings management, accounting fraud, option backdating and opportunistic insider trading. Early in life \u00b6 Many early life experiences are closely linked to natural and family endowment, yet others may be random and exogenous. Either way, early life experience is something that will have an impact on CEO behaviours later on. 1. Education \u00b6 No doubt education matters for everyone including CEO. Custodio and Metzger (2014 JFE) find that financial expert CEOs tend to be hired by more mature firms. Firms with financial expert CEOs hold less cash, more debt and engage in more share repurchases. They are able to raise external funds even when credit conditions are tight and their investments are less sensitive to cash flows. On the other hand, CEOs with an engineering (or scientific) education display higher investment-cash flow sensitivity ( Malmendier and Tate (2005 JFE) ). Similar findings appear in banking sector as shown by King, Srivastav and Williams (2016 JCF) focusing on CEO's MBA quality. Moreover, education offers more than just knowledge and skills. Although Khanna, Kim and Lu (2015 JF) do not find evidence that connections and network ties developed during education are associated with corporate fraud, such CEO connectedness certainly affect information sharing, investments and so on. Wang and Yin (2018 JCF) find that CEOs tend to initiate more, larger and better M&A deals where target firms are headquarted in those states where they received their undergraduate and graduate degrees. 2. Disaster experience \u00b6 People are shaped by their experiences and disasters are a major one. Several Chinese studies have shown that CEOs who have experienced famine are more risk-averse and hold more cash. They conduct less takeovers, but the M&A deals tend to perform better when they do according to Zhang (2017 PBFJ) . Such risk aversion can sometimes be good as Hu, Li and Luo (2019 PBFJ) find that firms governed by CEOs experienced great famine have higher market value during crisis. But generally speaking this effect is mitigated by higher education background and is weaker in SOEs, as well as for CEOs who also experienced economic reform, which is shown to increase CEO's risk tolerance by Hao, Wang, Chou and Ko (2018 IRF) . American CEOs, for sure, are no exception. A famous Journal of Finance paper \"what doesn't kill you will only make you more risk-loving\" by Bernile, Bhagwat and Rau (2016) concludes like its title. But more importantly, CEOs who experienced fatal disasters without extremely negative consequences lead firms more aggressively, whereas CEOs who witness the extreme downside of disasters behave more conservatively. 3. Academic, military and other experiences \u00b6 Apart from previous industry experience, researchers also examined the role of many other executive experiences. Shen, Lan, Xiong, Lv and Jian (2019 Economic Modelling) find that top management team's academic experience promotes corporate innovations and attribute the effect to improved internal control level and reduced information asymmetry. Benmelech and Frydman (2015 JFE) find that military service could make CEOs pursue lower coporate investment, and military CEOs are less likely to be involved in corporate fraudulent activity, performing better during industry downturns. Personality traits \u00b6 1. Masculinity \u00b6 Masculinity is a long-studied factor in many fields of research and there're also many interesting papers specifically on male CEOs. Since CEO testosterone levels cannot be tested directly, a common proxy in the literature is the facial width-to-height ratio (fWHR). Jia, Van Lent and Zeng (2014 JAR) find that a higher fWHR of a male CEO, representing more masculine faces, is associated with more misreporting, predicts his firm's likelihood of being subject to SEC enforcement action and incidence of insider trading and option backdating. They also find that executive's facial masculinity is associated the likelihood of being named as a perpetrator by SEC. In a forthcoming European Financial Management paper by Kamiya, Kim and Park (2018) , male CEOs' facial masculinity is found to be related to higher stock return volatility, higher financial leverage and more M&A activities. A paper at the 2018 Academy of Managment Annual Meeting by Joshi, Misangyi, Rizzi and Neely (2018) , however, find that masculinity does not have a direct effect on the firm's operational performance. The researchers also find that masculinity worked to the detriment of CEOs in female-dominated industries; less masculine CEOs also performed poorly in highly male-dominated environments. 2. Sensation-seeking, corruption and frugality \u00b6 In \"desperate\" search for proxies and signals of CEO/manager quality and traits, studies have turned to some really interesting areas such as the cars they drive and whether they can fly airplanes. Brown, Lu, Ray and Teo (2018 JF) show that sensation-seeking hedge fund managers who own powerful sports cars take on more investment risks but do not deliver higher returns. \"Red Ferrari syndrome\", as described by Business Insider, February 2016 . Unfortunately, some investors themselves are susceptible to sensation seeking and hence fuel the demand for such managers. Mironov (2015 JFE) has an interesting study and finds that if you can get away from a traffic violation through bribe, as a manager, you may deliver some outperformance through, for instance, tax evasion, because corruption sometimes promotes efficiency. Sunder, Sunder and Zhang (2017 JFE) look at pilot CEOs who fly airplanes as a hobby and find that they are significantly associated with better corporate innovation outcomes. They conclude that sensation seeking combines risk taking with a desire to pursue novel experiencecs and has been associated with creativity. Davidson, Dey and Smith (2015 JFE) even hired private investigators to collect data on executives' legal infractions and ownership of real estate, boats, luxury vehicles and motocycles. They find no direct evidence of a relation between executives' frugality and the propensity to perpetrate fraud. But there will be a relatively loose control environment characterized by relatively high and increasing probabilities of other insiders perpetrating fraud and unintentional material reporting errors during unfrugal CEOs' reigns. 3. Creativity and innovation \u00b6 One in five U.S. high-technology firms are led by CEOs with hands-on innovation experience as inventors. Islam and Zein (2020 JFE) show that firms led by \u201cInventor CEOs\u201d are associated with higher quality innovation, especially when the CEO is a high-impact inventor. During an inventor CEO's tenure, firms file a greater number of patents and more valuable patents in technology classes where the CEO's hands-on experience lies. It is possible that such inventor CEOs are more capable of evaluating, selecting and executing innovative investment projects. Family, marriage and fidelity \u00b6 1. Newborns and loss of family members \u00b6 \"Corporate executives managing some of the largest public companies in the U.S. are shaped by their daughters\". Cronqvist and Yu (2017 JFE) find that when a firm\u2019s CEO has a daughter, the corporate social responsibility rating (CSR) is about 9.1% higher, compared to a median firm. This finding perhaps reveals another plausibly exogenous determinant of CEO's styles. On the other hand, a loss of important family member poses a significant negative shock. In the 2020 AFA Annual Meeting, I encountered a paper by Liu, Shu, Sulaeman and Yeung (2019) who find that after deaths in the family, bereaved managers take significantly less risk. Firms managed by bereaved CEOs exhibit lower capital expenditures, fewer acquisitions, lower debt issuance and lower CEO ownership after the bereavement events. 2. Marriage, divorce and (in)fidelity \u00b6 While previous studies focused on the cultural background of the CEOs themselves, another paper I encountered in AFA Annual Meeting by Antoniou, Cuculiza, Kumar and Yang (2019) incorporates CEO spouses into the research. They show that the high uncertainty avoidance of CEO spouses will influence CEOs\u2019 personal uncertainty avoidance, and then lead to less corporate risk-taking. Larcker, McCall and Tayan (2013) show that CEO's divorce is impactful because it causes loss of control due to sale of stocks for divorce settlement, affects productivity, and attitude towards defaults. One final interesting paper I want to mention to conclude this post is \"the geography of financial miscoundct\" by Parsons, Sulaeman and Titman (2018 JF) . In 2015, the website Ashley Madison , whose target clients are married people seeking an extramarital affair, was hacked and there was a leak of 40 million user account data of name, address and billing information. The researchers use the data to measure the intensity of spousal infidelity of a local area and find that financial misconducts are strongly related to unfaithfulness in the city. Final note \u00b6 This short survey of CEO literature is not meant to be comprehensive, but to list a few very interesting papers that I find fun to read. I guess the message is that being a CEO means a lot more than managing the firm and stakeholders, and shareholders also need to open their minds and eyes. A funny example. Next time hiring a CEO, other things equal, maybe you'll want a female immigrant who is the first-born kid and born in August, attended certain schools in certain areas, experienced natural diasters, served in military before, has a daughter and no sports cars, knows how to fly airplanes, loyal to her spouse from certain countries, and whose all family members are live and well...","title":"What it takes to be a CEO? A fun survey of literature"},{"location":"posts/what-it-takes-to-be-a-ceo/#what-it-takes-to-be-a-ceo-a-fun-survey-of-literature","text":"Taking up the position of CEO means more than pressure from the board and investors. You\u2019ll also face heavy scrutiny from academia. Whether or not a firm\u2019s hiring and compensation committees use them as a reference, here are some of the findings that you may want to be aware of.","title":"What it takes to be a CEO? A fun survey of literature."},{"location":"posts/what-it-takes-to-be-a-ceo/#upon-birth","text":"There are many things determined when you\u2019re born. It\u2019ll be naive to think that they matter less than anything else. A starter example is the Journal of Financial Economics paper \"Are CEOs born leaders? Lessons from traits of a million individuals\" by Adams, Keloharju and Knupfer (2018) .","title":"Upon birth"},{"location":"posts/what-it-takes-to-be-a-ceo/#1-birthday-month","text":"Birth month affects school entry, which affects whether you are relatively older in the class. If you are born after the cutoff month, you'll have to wait for another year for entry. But this extra year buys you some more time to develop, which makes you more confident than the younger peers. This increased confidence is linked to adult labor market outcomes. Bai, Ma, Mullally and Solomon (2019 JFE) find that in mutual fund industry, it's associated with better stock selection and fund performance. These relatively older fund managers also appear more confident in photographs and display more confident behaviours: making larger bets, window dressing their holdings less, and so on.","title":"1. Birthday (month)"},{"location":"posts/what-it-takes-to-be-a-ceo/#2-birth-order","text":"The birth order also matters: negative associations between birth order and intelligence level have been found in numerous studies. More frankly, first born kids tend to have higher IQ scores. Kristensen and Bjerkedal (2007 Science) show that this is more dependent on social rank in the family where they receive more-favorable family interaction and stimulation. However, birth order is still the most prominent observable factor. Custodio and Siegel (2018) published a working paper where they find CEOs are more likely to be the first-born child of their family, and the results hold for both family and non-family firms, though thankfully the advantage of being first-born seems to decay over time.","title":"2. Birth order"},{"location":"posts/what-it-takes-to-be-a-ceo/#3-gender","text":"Studies on CEO gender difference and its relation with firm risk-taking, capital allocation, accounting conservatism, corporate social responsibility, and so on are plenty. Genearlly it is shown that male executives are overconfident relative to female executives (Huang and Kisgen, 2013 JFE) , and we know that overconfidence is not necessarily a good thing. Firms run by female CEOs use lower leverage and have less volative earnings, (Faccio, Marchica and Mura 2016 JCF) , and there are a lot more differences in terms of firm operational, financial, and M&A performances. Tate and Yang (2015 JFE) show that female leaders cultivate more female-friendly cultures inside their firms. Moreover, (having) a female director may bring a firm more access to external finance. Goldman Sachs announced on 23 January 2020 that they won't take companies public anymore unless they have at least one \"diverse\" board member.","title":"3. Gender"},{"location":"posts/what-it-takes-to-be-a-ceo/#4-hometown","text":"Everyone has some sort of hometown biases as well as hometown advantages. For example, Jiang, Qian and Yonker (2019 JFQA) find that CEOs are over twice as likely to acquire targets located in the states of their childhood homes than similar targets elsewhere. Smaller such deals are on average destorying shareholder value but bigger ones tend to be value enhancing. They conclude that CEOs may seek private benefits when acquiring small targets in their hometown but can also avoid poor deals due to hometown advantages. In a Chinese study, Kong, Pan, Tian and Zhang (2020 JCF) show that CEO's hometown connections increase access to trade credit and such effect is more pronounced for non-SOEs and firms in poor regions. In another Chinese study on commercial banks, Bian, Ji and Zhang (2019 JBF) find that a higher degree of dialect similarity between chairman and the CEO is associated with a higher ROA, ROE and a lower cost-to-income ratio, but is not with bank risks, CEO pay or lower pay-performance sensitivity. They conclude that speaking a similar dialect with the chairman doesn't undermine monitoring and reduces agency costs.","title":"4. Hometown"},{"location":"posts/what-it-takes-to-be-a-ceo/#5-cultural-heritage","text":"The place where you're born has even more profound implications through cultural heritage. Nguyen, Hagendorff and Eshraghi (2018 RFS) show that following shocks to industry competition, firms led by CEOs who are second- or third-generation immigrants are associated with a 6.2% higher profitability compared with the average firm. Their analysis attributes this effect to various cultural values that prevail in a CEO\u2019s ancestral country of origin. Through an epidemiological approach, Liu (2016 JFE) show that a corruption culture of corporate insiders' country of ancestry is associated with higher likelihood of earnings management, accounting fraud, option backdating and opportunistic insider trading.","title":"5. Cultural heritage"},{"location":"posts/what-it-takes-to-be-a-ceo/#early-in-life","text":"Many early life experiences are closely linked to natural and family endowment, yet others may be random and exogenous. Either way, early life experience is something that will have an impact on CEO behaviours later on.","title":"Early in life"},{"location":"posts/what-it-takes-to-be-a-ceo/#1-education","text":"No doubt education matters for everyone including CEO. Custodio and Metzger (2014 JFE) find that financial expert CEOs tend to be hired by more mature firms. Firms with financial expert CEOs hold less cash, more debt and engage in more share repurchases. They are able to raise external funds even when credit conditions are tight and their investments are less sensitive to cash flows. On the other hand, CEOs with an engineering (or scientific) education display higher investment-cash flow sensitivity ( Malmendier and Tate (2005 JFE) ). Similar findings appear in banking sector as shown by King, Srivastav and Williams (2016 JCF) focusing on CEO's MBA quality. Moreover, education offers more than just knowledge and skills. Although Khanna, Kim and Lu (2015 JF) do not find evidence that connections and network ties developed during education are associated with corporate fraud, such CEO connectedness certainly affect information sharing, investments and so on. Wang and Yin (2018 JCF) find that CEOs tend to initiate more, larger and better M&A deals where target firms are headquarted in those states where they received their undergraduate and graduate degrees.","title":"1. Education"},{"location":"posts/what-it-takes-to-be-a-ceo/#2-disaster-experience","text":"People are shaped by their experiences and disasters are a major one. Several Chinese studies have shown that CEOs who have experienced famine are more risk-averse and hold more cash. They conduct less takeovers, but the M&A deals tend to perform better when they do according to Zhang (2017 PBFJ) . Such risk aversion can sometimes be good as Hu, Li and Luo (2019 PBFJ) find that firms governed by CEOs experienced great famine have higher market value during crisis. But generally speaking this effect is mitigated by higher education background and is weaker in SOEs, as well as for CEOs who also experienced economic reform, which is shown to increase CEO's risk tolerance by Hao, Wang, Chou and Ko (2018 IRF) . American CEOs, for sure, are no exception. A famous Journal of Finance paper \"what doesn't kill you will only make you more risk-loving\" by Bernile, Bhagwat and Rau (2016) concludes like its title. But more importantly, CEOs who experienced fatal disasters without extremely negative consequences lead firms more aggressively, whereas CEOs who witness the extreme downside of disasters behave more conservatively.","title":"2. Disaster experience"},{"location":"posts/what-it-takes-to-be-a-ceo/#3-academic-military-and-other-experiences","text":"Apart from previous industry experience, researchers also examined the role of many other executive experiences. Shen, Lan, Xiong, Lv and Jian (2019 Economic Modelling) find that top management team's academic experience promotes corporate innovations and attribute the effect to improved internal control level and reduced information asymmetry. Benmelech and Frydman (2015 JFE) find that military service could make CEOs pursue lower coporate investment, and military CEOs are less likely to be involved in corporate fraudulent activity, performing better during industry downturns.","title":"3. Academic, military and other experiences"},{"location":"posts/what-it-takes-to-be-a-ceo/#personality-traits","text":"","title":"Personality traits"},{"location":"posts/what-it-takes-to-be-a-ceo/#1-masculinity","text":"Masculinity is a long-studied factor in many fields of research and there're also many interesting papers specifically on male CEOs. Since CEO testosterone levels cannot be tested directly, a common proxy in the literature is the facial width-to-height ratio (fWHR). Jia, Van Lent and Zeng (2014 JAR) find that a higher fWHR of a male CEO, representing more masculine faces, is associated with more misreporting, predicts his firm's likelihood of being subject to SEC enforcement action and incidence of insider trading and option backdating. They also find that executive's facial masculinity is associated the likelihood of being named as a perpetrator by SEC. In a forthcoming European Financial Management paper by Kamiya, Kim and Park (2018) , male CEOs' facial masculinity is found to be related to higher stock return volatility, higher financial leverage and more M&A activities. A paper at the 2018 Academy of Managment Annual Meeting by Joshi, Misangyi, Rizzi and Neely (2018) , however, find that masculinity does not have a direct effect on the firm's operational performance. The researchers also find that masculinity worked to the detriment of CEOs in female-dominated industries; less masculine CEOs also performed poorly in highly male-dominated environments.","title":"1. Masculinity"},{"location":"posts/what-it-takes-to-be-a-ceo/#2-sensation-seeking-corruption-and-frugality","text":"In \"desperate\" search for proxies and signals of CEO/manager quality and traits, studies have turned to some really interesting areas such as the cars they drive and whether they can fly airplanes. Brown, Lu, Ray and Teo (2018 JF) show that sensation-seeking hedge fund managers who own powerful sports cars take on more investment risks but do not deliver higher returns. \"Red Ferrari syndrome\", as described by Business Insider, February 2016 . Unfortunately, some investors themselves are susceptible to sensation seeking and hence fuel the demand for such managers. Mironov (2015 JFE) has an interesting study and finds that if you can get away from a traffic violation through bribe, as a manager, you may deliver some outperformance through, for instance, tax evasion, because corruption sometimes promotes efficiency. Sunder, Sunder and Zhang (2017 JFE) look at pilot CEOs who fly airplanes as a hobby and find that they are significantly associated with better corporate innovation outcomes. They conclude that sensation seeking combines risk taking with a desire to pursue novel experiencecs and has been associated with creativity. Davidson, Dey and Smith (2015 JFE) even hired private investigators to collect data on executives' legal infractions and ownership of real estate, boats, luxury vehicles and motocycles. They find no direct evidence of a relation between executives' frugality and the propensity to perpetrate fraud. But there will be a relatively loose control environment characterized by relatively high and increasing probabilities of other insiders perpetrating fraud and unintentional material reporting errors during unfrugal CEOs' reigns.","title":"2. Sensation-seeking, corruption and frugality"},{"location":"posts/what-it-takes-to-be-a-ceo/#3-creativity-and-innovation","text":"One in five U.S. high-technology firms are led by CEOs with hands-on innovation experience as inventors. Islam and Zein (2020 JFE) show that firms led by \u201cInventor CEOs\u201d are associated with higher quality innovation, especially when the CEO is a high-impact inventor. During an inventor CEO's tenure, firms file a greater number of patents and more valuable patents in technology classes where the CEO's hands-on experience lies. It is possible that such inventor CEOs are more capable of evaluating, selecting and executing innovative investment projects.","title":"3. Creativity and innovation"},{"location":"posts/what-it-takes-to-be-a-ceo/#family-marriage-and-fidelity","text":"","title":"Family, marriage and fidelity"},{"location":"posts/what-it-takes-to-be-a-ceo/#1-newborns-and-loss-of-family-members","text":"\"Corporate executives managing some of the largest public companies in the U.S. are shaped by their daughters\". Cronqvist and Yu (2017 JFE) find that when a firm\u2019s CEO has a daughter, the corporate social responsibility rating (CSR) is about 9.1% higher, compared to a median firm. This finding perhaps reveals another plausibly exogenous determinant of CEO's styles. On the other hand, a loss of important family member poses a significant negative shock. In the 2020 AFA Annual Meeting, I encountered a paper by Liu, Shu, Sulaeman and Yeung (2019) who find that after deaths in the family, bereaved managers take significantly less risk. Firms managed by bereaved CEOs exhibit lower capital expenditures, fewer acquisitions, lower debt issuance and lower CEO ownership after the bereavement events.","title":"1. Newborns and loss of family members"},{"location":"posts/what-it-takes-to-be-a-ceo/#2-marriage-divorce-and-infidelity","text":"While previous studies focused on the cultural background of the CEOs themselves, another paper I encountered in AFA Annual Meeting by Antoniou, Cuculiza, Kumar and Yang (2019) incorporates CEO spouses into the research. They show that the high uncertainty avoidance of CEO spouses will influence CEOs\u2019 personal uncertainty avoidance, and then lead to less corporate risk-taking. Larcker, McCall and Tayan (2013) show that CEO's divorce is impactful because it causes loss of control due to sale of stocks for divorce settlement, affects productivity, and attitude towards defaults. One final interesting paper I want to mention to conclude this post is \"the geography of financial miscoundct\" by Parsons, Sulaeman and Titman (2018 JF) . In 2015, the website Ashley Madison , whose target clients are married people seeking an extramarital affair, was hacked and there was a leak of 40 million user account data of name, address and billing information. The researchers use the data to measure the intensity of spousal infidelity of a local area and find that financial misconducts are strongly related to unfaithfulness in the city.","title":"2. Marriage, divorce and (in)fidelity"},{"location":"posts/what-it-takes-to-be-a-ceo/#final-note","text":"This short survey of CEO literature is not meant to be comprehensive, but to list a few very interesting papers that I find fun to read. I guess the message is that being a CEO means a lot more than managing the firm and stakeholders, and shareholders also need to open their minds and eyes. A funny example. Next time hiring a CEO, other things equal, maybe you'll want a female immigrant who is the first-born kid and born in August, attended certain schools in certain areas, experienced natural diasters, served in military before, has a daughter and no sports cars, knows how to fly airplanes, loyal to her spouse from certain countries, and whose all family members are live and well...","title":"Final note"},{"location":"posts/winsorization-in-sas/","text":"Winsorization in SAS \u00b6 These are two versions of winsorization in SAS, of which I recommend the first one. Version 1 (Unknown Author) \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 /***************************************** Author unknown - that is a pity because this macro is the best since sliced bread! Trim or winsorize macro * byvar = none for no byvar; * type = delete/winsor (delete will trim, winsor will winsorize; *dsetin = dataset to winsorize/trim; *dsetout = dataset to output with winsorized/trimmed values; *byvar = subsetting variables to winsorize/trim on; Sample usage: %winsor(dsetin=work.myDsetIn, byvar=fyear, dsetout=work.myDsOut, vars=btm roa roe, type=winsor, pctl=1 99); ****************************************/ %macro winsor(dsetin=, dsetout=, byvar=none, vars=, type=winsor, pctl= 1 99 ); %if &dsetout = %then %let dsetout = &dsetin ; %let varL=; %let varH=; %let xn= 1 ; %do %until ( %scan ( &vars , &xn )= ); %let token = %scan ( &vars , &xn ); %let varL = &varL &token. L; %let varH = &varH &token. H; %let xn= %EVAL ( &xn + 1 ); %end ; %let xn= %eval ( &xn -1 ) ; data xtemp; set &dsetin ; run; %if &byvar = none %then %do ; data xtemp; set xtemp; xbyvar = 1 ; run; %let byvar = xbyvar; %end ; proc sort data = xtemp; by &byvar ; run; proc univariate data = xtemp noprint; by &byvar ; var &vars ; output out = xtemp_pctl PCTLPTS = &pctl PCTLPRE = &vars PCTLNAME = L H ; run; data &dsetout ; merge xtemp xtemp_pctl; by &byvar ; array trimvars{ &xn } &vars ; array trimvarl{ &xn } &varL ; array trimvarh{ &xn } &varH ; do xi = 1 to dim( trimvars); %if &type = winsor %then %do ; if not missing (trimvars{xi}) then do ; if (trimvars{xi} < trimvarl{xi}) then trimvars{xi} = trimvarl{xi}; if (trimvars{xi} > trimvarh{xi}) then trimvars{xi} = trimvarh{xi}; end ; %end ; %else %do ; if not missing (trimvars{xi}) then do ; if (trimvars{xi} < trimvarl{xi}) then delete ; if (trimvars{xi} > trimvarh{xi}) then delete ; end ; %end ; end ; drop &varL &varH xbyvar xi ; run; %mend winsor; Version 2 (WRDS) \u00b6 A potential problem with this WRDS macro is that a variable named a is used in line 57 and 59 (highlighted below). So if the INSET has a variable named a as well, there\u2019ll be possible data integrity issue. WINSORIZE macro 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 /* ********************************************************************************* */ /* ******************** W R D S R E S E A R C H M A C R O S ******************** */ /* ********************************************************************************* */ /* WRDS Macro: WINSORIZE */ /* Summary : Winsorizes or Trims Outliers */ /* Date : April 14, 2009 */ /* Author : Rabih Moussawi, WRDS */ /* Variables : - INSET and OUTSET are input and output datasets */ /* - SORTVAR: sort variable used in ranking */ /* - VARS: variables to trim and winsorize */ /* - PERC1: trimming and winsorization percent, each tail (default=1%) */ /* - TRIM: trimming=1/winsorization=0, default=0 */ /* ********************************************************************************* */ %MACRO WINSORIZE (INSET=,OUTSET=,SORTVAR=,VARS=,PERC1= 1 ,TRIM= 0 ); /* List of all variables */ %let vars = %sysfunc ( compbl( &vars )); %let nvars = %nwords ( &vars ); /* Display Output */ %put ### START.; /* Trimming / Winsorization Options */ %if &trim = 0 %then %put ### Winsorization; %else %put ### Trimming; %put ### Number of Variables: &nvars ; %put ### List of Variables: &vars ; options nonotes; /* Ranking within &sortvar levels */ %put ### Sorting... ; proc sort data= &inset ; by &sortvar ; run; /* 2-tail winsorization/trimming */ %let perc2 = %eval ( 100 - &perc1 ); %let var2 = %sysfunc ( tranwrd( &vars , %str ( ), %str (__ )))__; %let var_p1 = %sysfunc ( tranwrd( &vars , %str ( ), %str (__ &perc1 )))__ &perc1 ; %let var_p2 = %sysfunc ( tranwrd( &vars , %str ( ), %str (__ &perc2 )))__ &perc2 ; /* Calculate upper and lower percentiles */ proc univariate data= &inset noprint; by &sortvar ; var &vars ; output out =_perc pctlpts= &perc1 &perc2 pctlpre= &var2 ; run; %if &trim = 1 %then %let condition = %str ( if myvars(i)>=perct2(i) or myvars(i)<=perct1(i) then myvars(i)=. ); %else %let condition = %str (myvars(i)= min( perct2(i), max( perct1(i),myvars(i))) ); %if &trim = 0 %then %put ### Winsorizing at &perc1. %... ; %else %put ### Trimming at &perc1. %... ; /* Save output with trimmed/winsorized variables */ data &outset ; merge &inset ( in =a) _perc; by &sortvar ; if a; array myvars { &nvars } &vars ; array perct1 { &nvars } &var_p1 ; array perct2 { &nvars } &var_p2 ; do i = 1 to &nvars ; if not missing (myvars(i)) then do ; &condition ; end ; end ; drop i &var_p1 &var_p2 ; run; /* House Cleaning */ proc sql; drop table _perc ; quit; options notes; %put ### DONE . ; %put ; %MEND WINSORIZE; /* ********************************************************************************* */ /* ************* Material Copyright Wharton Research Data Services *************** */ /* ****************************** All Rights Reserved ****************************** */ /* ********************************************************************************* */","title":"Winsorization in SAS"},{"location":"posts/winsorization-in-sas/#winsorization-in-sas","text":"These are two versions of winsorization in SAS, of which I recommend the first one.","title":"Winsorization in SAS"},{"location":"posts/winsorization-in-sas/#version-1-unknown-author","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 /***************************************** Author unknown - that is a pity because this macro is the best since sliced bread! Trim or winsorize macro * byvar = none for no byvar; * type = delete/winsor (delete will trim, winsor will winsorize; *dsetin = dataset to winsorize/trim; *dsetout = dataset to output with winsorized/trimmed values; *byvar = subsetting variables to winsorize/trim on; Sample usage: %winsor(dsetin=work.myDsetIn, byvar=fyear, dsetout=work.myDsOut, vars=btm roa roe, type=winsor, pctl=1 99); ****************************************/ %macro winsor(dsetin=, dsetout=, byvar=none, vars=, type=winsor, pctl= 1 99 ); %if &dsetout = %then %let dsetout = &dsetin ; %let varL=; %let varH=; %let xn= 1 ; %do %until ( %scan ( &vars , &xn )= ); %let token = %scan ( &vars , &xn ); %let varL = &varL &token. L; %let varH = &varH &token. H; %let xn= %EVAL ( &xn + 1 ); %end ; %let xn= %eval ( &xn -1 ) ; data xtemp; set &dsetin ; run; %if &byvar = none %then %do ; data xtemp; set xtemp; xbyvar = 1 ; run; %let byvar = xbyvar; %end ; proc sort data = xtemp; by &byvar ; run; proc univariate data = xtemp noprint; by &byvar ; var &vars ; output out = xtemp_pctl PCTLPTS = &pctl PCTLPRE = &vars PCTLNAME = L H ; run; data &dsetout ; merge xtemp xtemp_pctl; by &byvar ; array trimvars{ &xn } &vars ; array trimvarl{ &xn } &varL ; array trimvarh{ &xn } &varH ; do xi = 1 to dim( trimvars); %if &type = winsor %then %do ; if not missing (trimvars{xi}) then do ; if (trimvars{xi} < trimvarl{xi}) then trimvars{xi} = trimvarl{xi}; if (trimvars{xi} > trimvarh{xi}) then trimvars{xi} = trimvarh{xi}; end ; %end ; %else %do ; if not missing (trimvars{xi}) then do ; if (trimvars{xi} < trimvarl{xi}) then delete ; if (trimvars{xi} > trimvarh{xi}) then delete ; end ; %end ; end ; drop &varL &varH xbyvar xi ; run; %mend winsor;","title":"Version 1 (Unknown Author)"},{"location":"posts/winsorization-in-sas/#version-2-wrds","text":"A potential problem with this WRDS macro is that a variable named a is used in line 57 and 59 (highlighted below). So if the INSET has a variable named a as well, there\u2019ll be possible data integrity issue. WINSORIZE macro 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 /* ********************************************************************************* */ /* ******************** W R D S R E S E A R C H M A C R O S ******************** */ /* ********************************************************************************* */ /* WRDS Macro: WINSORIZE */ /* Summary : Winsorizes or Trims Outliers */ /* Date : April 14, 2009 */ /* Author : Rabih Moussawi, WRDS */ /* Variables : - INSET and OUTSET are input and output datasets */ /* - SORTVAR: sort variable used in ranking */ /* - VARS: variables to trim and winsorize */ /* - PERC1: trimming and winsorization percent, each tail (default=1%) */ /* - TRIM: trimming=1/winsorization=0, default=0 */ /* ********************************************************************************* */ %MACRO WINSORIZE (INSET=,OUTSET=,SORTVAR=,VARS=,PERC1= 1 ,TRIM= 0 ); /* List of all variables */ %let vars = %sysfunc ( compbl( &vars )); %let nvars = %nwords ( &vars ); /* Display Output */ %put ### START.; /* Trimming / Winsorization Options */ %if &trim = 0 %then %put ### Winsorization; %else %put ### Trimming; %put ### Number of Variables: &nvars ; %put ### List of Variables: &vars ; options nonotes; /* Ranking within &sortvar levels */ %put ### Sorting... ; proc sort data= &inset ; by &sortvar ; run; /* 2-tail winsorization/trimming */ %let perc2 = %eval ( 100 - &perc1 ); %let var2 = %sysfunc ( tranwrd( &vars , %str ( ), %str (__ )))__; %let var_p1 = %sysfunc ( tranwrd( &vars , %str ( ), %str (__ &perc1 )))__ &perc1 ; %let var_p2 = %sysfunc ( tranwrd( &vars , %str ( ), %str (__ &perc2 )))__ &perc2 ; /* Calculate upper and lower percentiles */ proc univariate data= &inset noprint; by &sortvar ; var &vars ; output out =_perc pctlpts= &perc1 &perc2 pctlpre= &var2 ; run; %if &trim = 1 %then %let condition = %str ( if myvars(i)>=perct2(i) or myvars(i)<=perct1(i) then myvars(i)=. ); %else %let condition = %str (myvars(i)= min( perct2(i), max( perct1(i),myvars(i))) ); %if &trim = 0 %then %put ### Winsorizing at &perc1. %... ; %else %put ### Trimming at &perc1. %... ; /* Save output with trimmed/winsorized variables */ data &outset ; merge &inset ( in =a) _perc; by &sortvar ; if a; array myvars { &nvars } &vars ; array perct1 { &nvars } &var_p1 ; array perct2 { &nvars } &var_p2 ; do i = 1 to &nvars ; if not missing (myvars(i)) then do ; &condition ; end ; end ; drop i &var_p1 &var_p2 ; run; /* House Cleaning */ proc sql; drop table _perc ; quit; options notes; %put ### DONE . ; %put ; %MEND WINSORIZE; /* ********************************************************************************* */ /* ************* Material Copyright Wharton Research Data Services *************** */ /* ****************************** All Rights Reserved ****************************** */ /* ********************************************************************************* */","title":"Version 2 (WRDS)"},{"location":"posts/working-remotely-on-a-windows-machine-wsl-from-vscode-on-a-mac/","text":"Working Remotely on a Windows Machine from VSCode on a Mac \u00b6 Now I only need a MacBook (1.3 GHz dual-core i5) to do all my work anywhere, thanks to a powerful workstation provided by the university. Yet the workstation is based on Windows 10 and sitting behind the university VPN. I don't want to use Remote Desktop everytime I need to do some coding, so I decided to make it so I can code remotely on the workstation but from the lovely VSCode on my little Mac. 1. Set up the Windows 10 host machine \u00b6 The first step is to enable remote SSH login on the Windows machine. It is now super easy to do with the Windows Subsystem for Linux (WSL) . I use the Ubuntu 18.04 LTS distro but other Linux distros should work just fine. This will be the remote environment that I work in. Then I follow the instruction in SSH on Windows Subsystem for Linux (WSL) . The post is in great detail with step-by-step guidance. So I won't repeat it again. 2. Set up the VSCode on Mac \u00b6 The second step is to install the Remote-SSH extension on VSCode. Then simply ssh into the Ubuntu environment on Windows 10 host machine using the username and password created for the Ubuntu distro. In my case is ssh myusername @asgard.econ.usyd.edu.au . A password prompt will of course kindly show up. 3. Use SSH key to avoid using password login \u00b6 The annoying thing is that each time the window reloads and when I start VSCode, I need to manually type in my lengthy password. The better way must be using a SSH key instead. To do so, open up the Terminal on the Mac and run: 1 ssh-keygen A public-private key pair will be generated as ~/.ssh/id_rsa.pub and ~/.ssh/id_rsa . Then we need to tell the host machine that this key can be used to identify myself so i can skip entering password next time: 1 ssh-copy-id myusername@asgard.econ.usyd.edu.au It will ask for the password on the host machine to confirm I am who I am. But after this, starting VSCode will never ask my password again. What a relief! Lastly... \u00b6 Because the host machine is inside the university network, I need to first connect to the university VPN, otherwise the host address asgard.econ.usyd.edu.au will not resolve. Still, it's really great that I can code and run my programs remotely on the powerful 8-core 16-thread machine without feeling the hotness and noise, which turns out to be really important in the summer of Australia......","title":"Working remotely on a Windows Machine from VSCode on a Mac"},{"location":"posts/working-remotely-on-a-windows-machine-wsl-from-vscode-on-a-mac/#working-remotely-on-a-windows-machine-from-vscode-on-a-mac","text":"Now I only need a MacBook (1.3 GHz dual-core i5) to do all my work anywhere, thanks to a powerful workstation provided by the university. Yet the workstation is based on Windows 10 and sitting behind the university VPN. I don't want to use Remote Desktop everytime I need to do some coding, so I decided to make it so I can code remotely on the workstation but from the lovely VSCode on my little Mac.","title":"Working Remotely on a Windows Machine from VSCode on a Mac"},{"location":"posts/working-remotely-on-a-windows-machine-wsl-from-vscode-on-a-mac/#1-set-up-the-windows-10-host-machine","text":"The first step is to enable remote SSH login on the Windows machine. It is now super easy to do with the Windows Subsystem for Linux (WSL) . I use the Ubuntu 18.04 LTS distro but other Linux distros should work just fine. This will be the remote environment that I work in. Then I follow the instruction in SSH on Windows Subsystem for Linux (WSL) . The post is in great detail with step-by-step guidance. So I won't repeat it again.","title":"1. Set up the Windows 10 host machine"},{"location":"posts/working-remotely-on-a-windows-machine-wsl-from-vscode-on-a-mac/#2-set-up-the-vscode-on-mac","text":"The second step is to install the Remote-SSH extension on VSCode. Then simply ssh into the Ubuntu environment on Windows 10 host machine using the username and password created for the Ubuntu distro. In my case is ssh myusername @asgard.econ.usyd.edu.au . A password prompt will of course kindly show up.","title":"2. Set up the VSCode on Mac"},{"location":"posts/working-remotely-on-a-windows-machine-wsl-from-vscode-on-a-mac/#3-use-ssh-key-to-avoid-using-password-login","text":"The annoying thing is that each time the window reloads and when I start VSCode, I need to manually type in my lengthy password. The better way must be using a SSH key instead. To do so, open up the Terminal on the Mac and run: 1 ssh-keygen A public-private key pair will be generated as ~/.ssh/id_rsa.pub and ~/.ssh/id_rsa . Then we need to tell the host machine that this key can be used to identify myself so i can skip entering password next time: 1 ssh-copy-id myusername@asgard.econ.usyd.edu.au It will ask for the password on the host machine to confirm I am who I am. But after this, starting VSCode will never ask my password again. What a relief!","title":"3. Use SSH key to avoid using password login"},{"location":"posts/working-remotely-on-a-windows-machine-wsl-from-vscode-on-a-mac/#lastly","text":"Because the host machine is inside the university network, I need to first connect to the university VPN, otherwise the host address asgard.econ.usyd.edu.au will not resolve. Still, it's really great that I can code and run my programs remotely on the powerful 8-core 16-thread machine without feeling the hotness and noise, which turns out to be really important in the summer of Australia......","title":"Lastly..."},{"location":"specurve/","text":"Specification Curve Analysis \u00b6 Motivation \u00b6 More offen than not, empirical researchers need to argue that their chosen model specification reigns. If not, they need to run a battery of tests on alternative specifications and report them. The problem is, researchers can fit a few tables each with a few models in the paper at best, and it's extremely hard for readers to know whether the reported results are being cherry-picked. So, why not run all possible model specifications and find a concise way to report them all? The Specification Curve \u00b6 The idea of specificaiton curve is a direct answer to the question provided by Simonsohn, Simmons and Nelson (2020). 1 2 To intuitively explain this concept, below is the Figure 2 from my recent paper Organization Capital and Executive Performance Incentives on the Journal of Banking & Finance , 3 which is used to show the robustness of an substitution effect of organization capital on executive pay-for-performance sensitivity. Therefore, the estimated coefficients for the variable of interest OC are expected to be negative across different model specifications. The plot is made up of two parts. The upper panel plots the coefficient estimates of OC in various model specifications, in descending order, and the associated 95% confidence intervals. Sample sizes of each model are plotted as bars at the bottom of the upper panel. For simplicity, we annotate only the maximum and minimum coefficient estimates, as well as the threshold of zero. The lower panel reports the exact specification for each model, where colored dots indicate the choices from various specification alternatives. Both panels share the same x-axis of model number. To interpret this specification curve, for example, OC has an estimated coefficient of \u22120.11 in the first model, which uses the natural logarithm of DELTA_MGMT (a measure of executive pay-for-performance sensitivity) as the dependent variable, and control variables as in the baseline model, including industry fixed effects and year fixed effects, clustering standard errors at the firm level, and is estimated on the full sample. Further, the ordered nature of the curve implies that this is the minimum estimated impact of OC on ln( DELTA_MGMT ), whereas the maximum estimated coefficient is doubled at \u22120.22 when the industry fixed effects are replaced with the more conservative firm fixed effects and estimated on the sample excluding global financial crisis period. More importantly, in all specifications, we find the coefficient estimates of OC to be statistically significant. Using an alternative measure of executive pay-for-performance sensitivity as the dependent variable, again, has minimal impact on the documented substitution effect of OC . This specification curve reports a total of 2\\times2\\times4\\times1\\times2=32 2\\times2\\times4\\times1\\times2=32 specifications: 2 choices of dependent variables (as alternative measures of executive pay-for-performance sensitivity) 2 choices of controls variables (controlling for managerial ability at the cost of reduced sample size) 4 choices of fixed effects 1 choice of standard error clustering 2 choices of sample periods Beyond reporting all estimates from hundreds and thousands of models, the more appealing point of specification curve is that we can identify the most impactful factors in specifying the model. As the models are sorted by the coefficient estimates, the distribution of dots in the lower panel can reveal whether certain specification choices drive the results. Alternative measures of executive pay-for-performance sensitivity do not affect the main findings. The inclusion of additional control variable of managerial ability does not affect the main findings. The industry and year fixed effects seem to lead to weaker coefficient estimates for the variable of interest, albeit the more conservative firm and year fixed effects lead to stronger ones. This is very important. The main findings hold with and without the global financial crisis (GFC) period. Of course, even 32 models cannot exhaust all possible specifications. Nevertheless, by addressing the most critical ones, we are able to use one specification curve plot to convince readers that our findings are robust. specurve - Stata command for specification curve analysis \u00b6 Since there was no available software or package to conduct specification curve analysis. I wrote myself a Stata command specurve , open-sourced at github.com/mgao6767/specurve . Dependencies \u00b6 specurve depends on Stata 16's Python integration and requires a Python version of 3.6 or above. Python modules required: pandas : for basic dataset manipulation. pyyaml : for reading and parsing the YAML-formatted configuration file. plotly : for generating the specification curve plot. kaleido : for static image export with plotly . To install the required modules, try: 1 pip install pandas pyyaml plotly kaleido Installation \u00b6 Download specurve.ado and specurve.hlp and put them in your personal ado folder. To find the path to your personal ado folder, type adopath in Stata. Example usage \u00b6 The associated help file contains a step-by-step guide on using specurve . To open the help file, type help specurve in Stata after installation. Example output \u00b6 Simonsohn, Uri and Simmons, Joseph P. and Nelson, Leif D., 2020, Specification Curve Analysis, Nature Human Behaviour . \u21a9 Special thanks to Rawley Heimer from Boston College who visited our discipline in 2019 and introduced the Specification Curve Analysis to us in the seminar on research methods. \u21a9 Gao, M. Leung, H. and Qiu, B. (2021). Organization Capital and Executive Performance Incentives, Journal of Banking & Finance , 123, 106017. \u21a9","title":"Specurve"},{"location":"specurve/#specification-curve-analysis","text":"","title":"Specification Curve Analysis"},{"location":"specurve/#motivation","text":"More offen than not, empirical researchers need to argue that their chosen model specification reigns. If not, they need to run a battery of tests on alternative specifications and report them. The problem is, researchers can fit a few tables each with a few models in the paper at best, and it's extremely hard for readers to know whether the reported results are being cherry-picked. So, why not run all possible model specifications and find a concise way to report them all?","title":"Motivation"},{"location":"specurve/#the-specification-curve","text":"The idea of specificaiton curve is a direct answer to the question provided by Simonsohn, Simmons and Nelson (2020). 1 2 To intuitively explain this concept, below is the Figure 2 from my recent paper Organization Capital and Executive Performance Incentives on the Journal of Banking & Finance , 3 which is used to show the robustness of an substitution effect of organization capital on executive pay-for-performance sensitivity. Therefore, the estimated coefficients for the variable of interest OC are expected to be negative across different model specifications. The plot is made up of two parts. The upper panel plots the coefficient estimates of OC in various model specifications, in descending order, and the associated 95% confidence intervals. Sample sizes of each model are plotted as bars at the bottom of the upper panel. For simplicity, we annotate only the maximum and minimum coefficient estimates, as well as the threshold of zero. The lower panel reports the exact specification for each model, where colored dots indicate the choices from various specification alternatives. Both panels share the same x-axis of model number. To interpret this specification curve, for example, OC has an estimated coefficient of \u22120.11 in the first model, which uses the natural logarithm of DELTA_MGMT (a measure of executive pay-for-performance sensitivity) as the dependent variable, and control variables as in the baseline model, including industry fixed effects and year fixed effects, clustering standard errors at the firm level, and is estimated on the full sample. Further, the ordered nature of the curve implies that this is the minimum estimated impact of OC on ln( DELTA_MGMT ), whereas the maximum estimated coefficient is doubled at \u22120.22 when the industry fixed effects are replaced with the more conservative firm fixed effects and estimated on the sample excluding global financial crisis period. More importantly, in all specifications, we find the coefficient estimates of OC to be statistically significant. Using an alternative measure of executive pay-for-performance sensitivity as the dependent variable, again, has minimal impact on the documented substitution effect of OC . This specification curve reports a total of 2\\times2\\times4\\times1\\times2=32 2\\times2\\times4\\times1\\times2=32 specifications: 2 choices of dependent variables (as alternative measures of executive pay-for-performance sensitivity) 2 choices of controls variables (controlling for managerial ability at the cost of reduced sample size) 4 choices of fixed effects 1 choice of standard error clustering 2 choices of sample periods Beyond reporting all estimates from hundreds and thousands of models, the more appealing point of specification curve is that we can identify the most impactful factors in specifying the model. As the models are sorted by the coefficient estimates, the distribution of dots in the lower panel can reveal whether certain specification choices drive the results. Alternative measures of executive pay-for-performance sensitivity do not affect the main findings. The inclusion of additional control variable of managerial ability does not affect the main findings. The industry and year fixed effects seem to lead to weaker coefficient estimates for the variable of interest, albeit the more conservative firm and year fixed effects lead to stronger ones. This is very important. The main findings hold with and without the global financial crisis (GFC) period. Of course, even 32 models cannot exhaust all possible specifications. Nevertheless, by addressing the most critical ones, we are able to use one specification curve plot to convince readers that our findings are robust.","title":"The Specification Curve"},{"location":"specurve/#specurve-stata-command-for-specification-curve-analysis","text":"Since there was no available software or package to conduct specification curve analysis. I wrote myself a Stata command specurve , open-sourced at github.com/mgao6767/specurve .","title":"specurve - Stata command for specification curve analysis"},{"location":"specurve/#dependencies","text":"specurve depends on Stata 16's Python integration and requires a Python version of 3.6 or above. Python modules required: pandas : for basic dataset manipulation. pyyaml : for reading and parsing the YAML-formatted configuration file. plotly : for generating the specification curve plot. kaleido : for static image export with plotly . To install the required modules, try: 1 pip install pandas pyyaml plotly kaleido","title":"Dependencies"},{"location":"specurve/#installation","text":"Download specurve.ado and specurve.hlp and put them in your personal ado folder. To find the path to your personal ado folder, type adopath in Stata.","title":"Installation"},{"location":"specurve/#example-usage","text":"The associated help file contains a step-by-step guide on using specurve . To open the help file, type help specurve in Stata after installation.","title":"Example usage"},{"location":"specurve/#example-output","text":"Simonsohn, Uri and Simmons, Joseph P. and Nelson, Leif D., 2020, Specification Curve Analysis, Nature Human Behaviour . \u21a9 Special thanks to Rawley Heimer from Boston College who visited our discipline in 2019 and introduced the Specification Curve Analysis to us in the seminar on research methods. \u21a9 Gao, M. Leung, H. and Qiu, B. (2021). Organization Capital and Executive Performance Incentives, Journal of Banking & Finance , 123, 106017. \u21a9","title":"Example output"}]}